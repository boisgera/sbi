
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://sbi-dev.github.io/sbi/dev/tutorials/17_importance_sampled_posteriors/">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.31">
    
    
      
        <title>17 importance sampled posteriors - sbi</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      
  
  
    
    
  
  
  <style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16 16"><path d="M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z"/></svg>');}</style>



    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../static/global.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#theory" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="sbi" class="md-header__button md-logo" aria-label="sbi" data-md-component="logo">
      
  <img src="../../static/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            sbi
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              17 importance sampled posteriors
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="http://github.com/sbi-dev/sbi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    sbi-dev/sbi
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="sbi" class="md-nav__button md-logo" aria-label="sbi" data-md-component="logo">
      
  <img src="../../static/logo.svg" alt="logo">

    </a>
    sbi
  </label>
  
    <div class="md-nav__source">
      <a href="http://github.com/sbi-dev/sbi" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    sbi-dev/sbi
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tutorials and Examples
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../reference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    API Reference
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../faq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FAQ
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Contributing
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Contributing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../contribute/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    How to contribute
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../code_of_conduct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code of Conduct
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../citation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Citation
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../credits/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Credits
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#importance-weights" class="md-nav__link">
    <span class="md-ellipsis">
      Importance weights
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#effective-sample-size-n_texteff-and-sample-efficiency-epsilon" class="md-nav__link">
    <span class="md-ellipsis">
      Effective sample size \(n_\text{eff}\) and sample efficiency \(\epsilon\)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mass-coverage" class="md-nav__link">
    <span class="md-ellipsis">
      Mass coverage
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#self-normalized-importance-sampling-and-the-bayesian-evidence" class="md-nav__link">
    <span class="md-ellipsis">
      Self-normalized importance sampling and the Bayesian evidence
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<div class="highlight"><pre><span></span><code><span class="c1">### TLDR:</span>
</code></pre></div>
<h1 id="theory">Theory<a class="headerlink" href="#theory" title="Permanent link">&para;</a></h1>
<p>SBI estimates the posterior <span class="arithmatex">\(p(\theta|x) = {p(\theta)p(x|\theta)}/{p(x)}\)</span> based on samples from the prior <span class="arithmatex">\(\theta\sim p(\theta)\)</span> and the likelihood <span class="arithmatex">\(x\sim p(x|\theta)\)</span>. Sometimes, we can do both, <em>sample</em> and <em>evaluate</em> the prior and likelihood. In this case, we can combine the <em>simulation-based</em> estimate <span class="arithmatex">\(q(\theta|x)\)</span> with <em>likelihood-based</em> importance sampling, and thereby generate an asymptotically exact estimate for <span class="arithmatex">\(p(\theta|x)\)</span>.</p>
<h3 id="importance-weights">Importance weights<a class="headerlink" href="#importance-weights" title="Permanent link">&para;</a></h3>
<p>The main idea is to interpret <span class="arithmatex">\(q(\theta|x)\)</span> as a proposal distribution and generate proposal samples <span class="arithmatex">\(\theta_i\sim q(\theta|x)\)</span>, and then augment each sample with an importance weight <span class="arithmatex">\(w_i = p(\theta_i|x) / q(\theta_i|x)\)</span>. The definition of the importance weights is motivated from Monte Carlo estimates for the random variable <span class="arithmatex">\(f(\theta)\)</span>, </p>
<div class="arithmatex">\[ 
\mathbb{E}_{\theta\sim p(\theta|x)}\left[f(\theta)\right] 
=\int p(\theta|x) f(\theta)\,\text{d}\theta
\approx \sum_{\theta_i\sim p(\theta_i|x)} f(\theta_i).
\]</div>
<p>We can rewrite this expression as </p>
<div class="arithmatex">\[ 
\mathbb{E}_{\theta\sim p(\theta|x)}\left[f(\theta)\right] 
=\int p(\theta|x) f(\theta)\,\text{d}\theta
=\int q(\theta|x) \frac{p(\theta|x)}{q(\theta|x)}f(\theta)\,\text{d}\theta
\approx \sum_{\theta_i\sim q(\theta_i|x)} \frac{p(\theta_i|x)}{q(\theta_i|x)}f(\theta_i)
\approx \sum_{\theta_i\sim q(\theta_i|x)} w_i\cdot f(\theta_i).
\]</div>
<p>Instead of sampling <span class="arithmatex">\(\theta_i\sim p(\theta_i|x)\)</span>, we can thus sample <span class="arithmatex">\(\theta_i\sim q(\theta_i|x)\)</span> and attach a corresponding importance weight <span class="arithmatex">\(w_i\)</span> to each sample. Intuitively, the importance weights downweight samples where <span class="arithmatex">\(q(\theta|x)\)</span> overestimates <span class="arithmatex">\(p(\theta|x)\)</span> and upweight samples where <span class="arithmatex">\(p(\theta|x)\)</span> underestimates <span class="arithmatex">\(q(\theta|x)\)</span>.</p>
<h3 id="effective-sample-size-n_texteff-and-sample-efficiency-epsilon">Effective sample size <span class="arithmatex">\(n_\text{eff}\)</span> and sample efficiency <span class="arithmatex">\(\epsilon\)</span><a class="headerlink" href="#effective-sample-size-n_texteff-and-sample-efficiency-epsilon" title="Permanent link">&para;</a></h3>
<p>If inference were perfect, we would have <span class="arithmatex">\(w_i = p(\theta_i|x) / q(\theta_i|x) = 1~\forall i\)</span>. In practice however, SBI does not provide exact inference results <span class="arithmatex">\(q(\theta_i|x)\)</span>, and the weights will have a finite variance <span class="arithmatex">\(\text{Var}(w) &gt; 0\)</span>. Performing the Monte Carlo estimate above with <span class="arithmatex">\(n\)</span> samples from <span class="arithmatex">\(q(\theta|x)\)</span> thus results in reduced precision compared to doing the same with <span class="arithmatex">\(n\)</span> samples from <span class="arithmatex">\(p(\theta|x)\)</span>. This is formalized by the notion of the <em>effective sample size</em> (see e.g. <a href="http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/ConvergeRates/LiuMetropolized1996.pdf">here</a>)</p>
<div class="arithmatex">\[
n_\text{eff} = \frac{n}{1 + \text{Var}(w)} = \frac{\left(\sum_i w_i\right)^2}{\sum_i \left(w_i^2\right)}.
\]</div>
<p>Loosely speaking, using <span class="arithmatex">\(n\)</span> samples <span class="arithmatex">\(\theta_i\sim q(\theta_i|x)\)</span> is equivalent to using <span class="arithmatex">\(n_\text{eff}\)</span> samples from the true posterior <span class="arithmatex">\(p(\theta|x)\)</span>. The <em>sample efficiency</em></p>
<div class="arithmatex">\[
\epsilon = \frac{n_\text{eff}}{n} \in (0, 1]
\]</div>
<p>is an indirect measure of the quality of the proposal <span class="arithmatex">\(q(\theta|x)\)</span>.</p>
<h3 id="mass-coverage">Mass coverage<a class="headerlink" href="#mass-coverage" title="Permanent link">&para;</a></h3>
<p>Importance sampling requires <span class="arithmatex">\(p(\theta|x) \subseteq q(\theta|x)\)</span>. When using NPE, this should naturally be ensured, as NPE is trained with the mass-covering forward KL divergence, such that <span class="arithmatex">\(p(\theta|x) \not\subseteq q(\theta|x)\)</span> for in-distribution data would imply a diverging validation loss. </p>
<p>When <span class="arithmatex">\(q(\theta|x)\)</span> is a light-tailed estimate of <span class="arithmatex">\(p(\theta|x)\)</span>, the variance of the importance weights is unbounded and we may encounter a small sample efficiency <span class="arithmatex">\(\epsilon\)</span>.</p>
<h3 id="self-normalized-importance-sampling-and-the-bayesian-evidence">Self-normalized importance sampling and the Bayesian evidence<a class="headerlink" href="#self-normalized-importance-sampling-and-the-bayesian-evidence" title="Permanent link">&para;</a></h3>
<p>In practice, we don&rsquo;t have access to the normalized posterior, but only to <span class="arithmatex">\(p(\theta|x) \cdot p(x) = p(\theta)p(x|\theta)\)</span>. We thus have to use self-normalized importance sampling. In this case, an unbiased estimate of the Bayesian evidence <span class="arithmatex">\(p(x)\)</span> can be computed from the normalization of the importance weights (see e.g. <a href="https://arxiv.org/abs/2210.05686">here</a>)</p>
<div class="arithmatex">\[
p(x) = \frac{\sum_i w_i}{n}
\]</div>
<p>with a statistical uncertainty scaling with <span class="arithmatex">\(1/\sqrt{n}\)</span>,</p>
<div class="arithmatex">\[
\sigma_{p(x)} = p(x)\cdot \sqrt{\frac{1-\epsilon}{n\cdot \epsilon}}.
\]</div>
<h1 id="implementation">Implementation<a class="headerlink" href="#implementation" title="Permanent link">&para;</a></h1>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">ones</span><span class="p">,</span> <span class="n">eye</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">MultivariateNormal</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sbi.inference</span> <span class="kn">import</span> <span class="n">SNPE</span><span class="p">,</span> <span class="n">ImportanceSamplingPosterior</span>
<span class="kn">from</span> <span class="nn">sbi.utils</span> <span class="kn">import</span> <span class="n">BoxUniform</span>
<span class="kn">from</span> <span class="nn">sbi.inference.potentials.base_potential</span> <span class="kn">import</span> <span class="n">BasePotential</span>
<span class="kn">from</span> <span class="nn">sbi.analysis</span> <span class="kn">import</span> <span class="n">pairplot</span><span class="p">,</span> <span class="n">marginal_plot</span>
</code></pre></div>
<p>We first define a simulator and a prior which both have functions for sampling (as required for SBI) and log_prob evaluations (as required for importance sampling).</p>
<p>Next we train an NPE model for inference.</p>
<p>Now we perfrom inference with the model.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># define prior and simulator</span>
<span class="k">class</span> <span class="nc">Simulator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="n">prior</span> <span class="o">=</span> <span class="n">BoxUniform</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span> <span class="o">*</span> <span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,)))</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">Simulator</span><span class="p">()</span>
<span class="n">log_prob_fn</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x_o</span><span class="p">:</span> <span class="n">sim</span><span class="o">.</span><span class="n">log_likelihood</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x_o</span><span class="p">)</span> <span class="o">+</span> <span class="n">prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="c1"># generate train data</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="c1"># train NPE model</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">inference</span> <span class="o">=</span> <span class="n">SNPE</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">append_simulations</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">build_posterior</span><span class="p">()</span>

<span class="c1"># generate a synthetic observation</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">theta_gt</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">1</span><span class="p">,))</span>
<span class="n">observation</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">theta_gt</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">observation</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;observations.shape&quot;</span><span class="p">,</span> <span class="n">observation</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># sample from posterior</span>
<span class="n">theta_inferred</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">10_000</span><span class="p">,))</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code> Neural network successfully converged after 70 epochs.observations.shape torch.Size([2])



Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00&lt;?, ?it/s]
</code></pre></div>

<h3 id="manual-importance-sampling">Manual importance sampling<a class="headerlink" href="#manual-importance-sampling" title="Permanent link">&para;</a></h3>
<p>For the inferred samples, we can evaluate the proposal density (i.e., the density under our inference model) and the ground truth density defined by the prior and the simulator likelihood (unnormalized).</p>
<div class="highlight"><pre><span></span><code><span class="n">log_probs_inferred</span> <span class="o">=</span> <span class="n">posterior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">)</span>  <span class="c1"># log probs of proposal</span>
<span class="n">log_probs_gt</span> <span class="o">=</span> <span class="n">log_prob_fn</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">,</span> <span class="n">observation</span><span class="p">)</span>  <span class="c1"># gt log probs (unnormalized)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">log_probs_inferred</span><span class="p">,</span> <span class="n">log_probs_gt</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;proposal log prob&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;ground truth log prob (unnormalized)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_10_0.png" /></p>
<p>Based on these densities, we can now compute the importance weights.</p>
<div class="highlight"><pre><span></span><code><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_probs_gt</span> <span class="o">-</span> <span class="n">log_probs_inferred</span><span class="p">)</span>  <span class="c1"># importance weights</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># self-normalized importance sampling: normalize weights to mean 1</span>
<span class="n">ESS</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">w</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">sample_efficiency</span> <span class="o">=</span> <span class="n">ESS</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Effective sample size: </span><span class="si">{</span><span class="n">ESS</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sample efficiency: </span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">sample_efficiency</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Effective sample size: 1466
Sample efficiency: 14.7%
</code></pre></div>

<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_12_1.png" /></p>
<p>With these importance weights, we can correct the inferred samples.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># get weighted samples</span>
<span class="n">theta_inferred_is</span> <span class="o">=</span> <span class="n">theta_inferred</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">w</span> <span class="o">&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">))</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">w</span><span class="p">))]</span>
<span class="c1"># *Note*: we here perform rejection sampling, as the plotting function</span>
<span class="c1"># used below does not support weighted samples. In general, with rejection</span>
<span class="c1"># sampling the number of samples will be smaller than the effective sample</span>
<span class="c1"># size unless we allow for duplicate samples.</span>

<span class="c1"># gt samples</span>
<span class="n">gt_samples</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">)</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,))</span>
<span class="n">gt_samples</span> <span class="o">=</span> <span class="n">gt_samples</span><span class="p">[</span><span class="n">prior</span><span class="o">.</span><span class="n">support</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)][:</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">)]</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">marginal_plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">theta_inferred</span><span class="p">,</span> <span class="n">theta_inferred_is</span><span class="p">,</span> <span class="n">gt_samples</span><span class="p">],</span>
    <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span>
    <span class="n">diag</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>  <span class="c1"># smooth histogram</span>
<span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;NPE&quot;</span><span class="p">,</span> <span class="s2">&quot;NPE-IS&quot;</span><span class="p">,</span> <span class="s2">&quot;Groud Truth&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">[</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_14_0.png" /></p>
<p>Indeed, the importance-sampled posterior matches the ground truth well, despite significant deviations of the initial NPE estimate.</p>
<h3 id="importance-sampling-with-the-sbi-toolbox">Importance sampling with the SBI toolbox<a class="headerlink" href="#importance-sampling-with-the-sbi-toolbox" title="Permanent link">&para;</a></h3>
<p>With the SBI toolbox, importance sampling is a one-liner. SBI supports two methods for importance sampling:
- <code>"importance"</code>: returns <code>n_samples</code> weighted samples (as above) corresponding to <code>n_samples * sample_efficiency</code> samples from the posterior. This results in unbiased samples, but the number of effective samples may be small when the SBI estimate is inaccurate.
- <code>"sir"</code> (sampling-importance-resampling): performs rejection sampling on a batched basis with batch size <code>oversampling_factor</code>.  This is a guaranteed way to obtain <code>N / oversampling_factor</code> samples, but these may be biased as the weight normalization is not performed across the entire set of samples.</p>
<div class="highlight"><pre><span></span><code><span class="n">posterior_sir</span> <span class="o">=</span> <span class="n">ImportanceSamplingPosterior</span><span class="p">(</span>
    <span class="n">potential_fn</span><span class="o">=</span><span class="n">log_prob_fn</span><span class="p">,</span>
    <span class="n">proposal</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">observation</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sir&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">theta_inferred_sir_2</span> <span class="o">=</span> <span class="n">posterior_sir</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">),),</span> <span class="n">x</span><span class="o">=</span><span class="n">observation</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">theta_inferred_sir_32</span> <span class="o">=</span> <span class="n">posterior_sir</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">),),</span> <span class="n">x</span><span class="o">=</span><span class="n">observation</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:],</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Posterior: oversampling factor 1
Num candidate samples: 1



Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00&lt;?, ?it/s]



Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00&lt;?, ?it/s]


batch_size 10000
weights tensor([[1.],
        [1.],
        [1.],
        ...,
        [1.],
        [1.],
        [1.]]) torch.Size([10000, 1])
uniform_decision tensor([[0.2584],
        [0.8255],
        [0.5367],
        ...,
        [0.1285],
        [0.6491],
        [0.4784]]) torch.Size([10000, 1])
mask tensor([[True],
        [True],
        [True],
        ...,
        [True],
        [True],
        [True]]) torch.Size([10000, 1])
thetas tensor([[-0.6660, -0.0286],
        [ 2.9079,  2.3848],
        [ 4.9626,  3.5430],
        ...,
        [-0.5071,  1.7816],
        [ 2.1563,  1.5912],
        [ 0.3401,  0.3996]]) torch.Size([10000, 2])
samples tensor([[-0.6660, -0.0286],
        [ 2.9079,  2.3848],
        [ 4.9626,  3.5430],
        ...,
        [-0.5071,  1.7816],
        [ 2.1563,  1.5912],
        [ 0.3401,  0.3996]]) torch.Size([10000, 2])
Posterior: oversampling factor 32
Num candidate samples: 32



Drawing 10000 posterior samples:   0%|          | 0/10000 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[3.3657e-03, 9.2805e-02, 9.6103e-02,  ..., 9.7422e-01, 9.9998e-01,
         1.0000e+00],
        [1.8362e-02, 4.8308e-02, 6.8778e-02,  ..., 9.9464e-01, 9.9464e-01,
         1.0000e+00],
        [2.9750e-02, 2.8256e-01, 2.8398e-01,  ..., 9.8681e-01, 9.8682e-01,
         1.0000e+00],
        ...,
        [1.3679e-04, 1.3680e-04, 8.5970e-03,  ..., 9.9854e-01, 9.9863e-01,
         1.0000e+00],
        [5.8125e-05, 4.3372e-02, 9.2864e-02,  ..., 9.1176e-01, 9.9218e-01,
         1.0000e+00],
        [9.8639e-02, 1.1216e-01, 1.1227e-01,  ..., 9.9939e-01, 9.9955e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.5609],
        [0.1802],
        [0.7231],
        [0.2811],
        [0.9153],
        [0.8000],
        [0.3323],
        [0.8574],
        [0.7233],
        [0.7077],
        [0.3043],
        [0.7238],
        [0.0384],
        [0.5480],
        [0.8734],
        [0.0630],
        [0.8672],
        [0.8422],
        [0.5536],
        [0.0682],
        [0.2335],
        [0.6293],
        [0.9219],
        [0.2054],
        [0.8724],
        [0.4763],
        [0.2748],
        [0.8620],
        [0.1215],
        [0.6521],
        [0.4422],
        [0.1607],
        [0.6894],
        [0.3839],
        [0.2287],
        [0.4263],
        [0.4987],
        [0.5518],
        [0.5254],
        [0.2184],
        [0.0103],
        [0.6425],
        [0.7706],
        [0.4420],
        [0.5052],
        [0.9328],
        [0.0958],
        [0.6404],
        [0.9120],
        [0.6256],
        [0.1449],
        [0.1109],
        [0.9517],
        [0.7369],
        [0.7208],
        [0.0287],
        [0.5828],
        [0.4510],
        [0.1043],
        [0.1766],
        [0.3053],
        [0.8417],
        [0.9702],
        [0.0579],
        [0.0975],
        [0.6361],
        [0.0086],
        [0.8690],
        [0.7788],
        [0.5924],
        [0.4042],
        [0.5683],
        [0.9278],
        [0.9242],
        [0.0113],
        [0.9374],
        [0.5024],
        [0.4333],
        [0.6370],
        [0.5163],
        [0.4462],
        [0.6453],
        [0.5009],
        [0.4439],
        [0.9271],
        [0.2878],
        [0.9775],
        [0.2036],
        [0.0303],
        [0.4066],
        [0.8465],
        [0.5130],
        [0.8401],
        [0.7749],
        [0.4766],
        [0.3304],
        [0.4431],
        [0.7184],
        [0.1640],
        [0.4833],
        [0.6065],
        [0.1900],
        [0.1621],
        [0.7186],
        [0.5576],
        [0.7064],
        [0.9667],
        [0.8879],
        [0.5902],
        [0.1974],
        [0.0630],
        [0.9251],
        [0.1121],
        [0.4407],
        [0.4111],
        [0.2963],
        [0.7778],
        [0.0479],
        [0.2150],
        [0.1796],
        [0.1219],
        [0.0688],
        [0.0302],
        [0.5158],
        [0.3120],
        [0.9318],
        [0.9023],
        [0.8749],
        [0.4669],
        [0.7286],
        [0.9173],
        [0.6609],
        [0.2603],
        [0.0082],
        [0.3112],
        [0.1892],
        [0.0540],
        [0.4101],
        [0.3867],
        [0.4954],
        [0.4728],
        [0.8358],
        [0.2954],
        [0.0694],
        [0.6179],
        [0.0370],
        [0.1232],
        [0.7175],
        [0.8207],
        [0.6838],
        [0.2718],
        [0.0692],
        [0.5984],
        [0.1902],
        [0.9762],
        [0.5874],
        [0.4535],
        [0.1849],
        [0.4605],
        [0.4567],
        [0.8305],
        [0.0683],
        [0.1479],
        [0.0413],
        [0.4149],
        [0.3259],
        [0.7442],
        [0.6243],
        [0.6045],
        [0.9940],
        [0.1933],
        [0.3464],
        [0.2005],
        [0.4178],
        [0.6302],
        [0.9007],
        [0.5954],
        [0.6486],
        [0.9823],
        [0.8163],
        [0.6731],
        [0.3539],
        [0.4640],
        [0.6019],
        [0.8181],
        [0.6761],
        [0.7376],
        [0.3226],
        [0.5677],
        [0.1445],
        [0.0055],
        [0.4362],
        [0.2881],
        [0.3128],
        [0.2238],
        [0.2772],
        [0.8488],
        [0.1720],
        [0.0930],
        [0.0302],
        [0.6756],
        [0.3056],
        [0.0593],
        [0.8843],
        [0.2660],
        [0.1958],
        [0.8084],
        [0.3739],
        [0.7914],
        [0.6191],
        [0.5149],
        [0.3978],
        [0.7901],
        [0.5726],
        [0.0672],
        [0.2448],
        [0.8224],
        [0.3410],
        [0.0982],
        [0.9255],
        [0.9197],
        [0.8272],
        [0.2612],
        [0.3210],
        [0.2199],
        [0.3715],
        [0.8633],
        [0.4053],
        [0.1952],
        [0.9599],
        [0.0494],
        [0.6150],
        [0.3925],
        [0.1228],
        [0.2823],
        [0.1211],
        [0.8708],
        [0.2565],
        [0.6887],
        [0.4460],
        [0.0465],
        [0.4974],
        [0.3677],
        [0.3318],
        [0.4483],
        [0.9363],
        [0.4510],
        [0.8819],
        [0.1970],
        [0.1233],
        [0.8601],
        [0.6889],
        [0.4228],
        [0.1048],
        [0.7264],
        [0.1140],
        [0.7646],
        [0.8379],
        [0.0531],
        [0.7497],
        [0.5102],
        [0.2252],
        [0.5736],
        [0.5161],
        [0.4190],
        [0.2871],
        [0.6234],
        [0.0184],
        [0.8827],
        [0.8717],
        [0.9982],
        [0.8366],
        [0.6113],
        [0.0491],
        [0.9632],
        [0.3444],
        [0.0099],
        [0.2690],
        [0.1148],
        [0.7341],
        [0.8503],
        [0.5112],
        [0.2581],
        [0.4834],
        [0.2352],
        [0.1443],
        [0.6261],
        [0.8550],
        [0.8140],
        [0.2807],
        [0.7274],
        [0.4870],
        [0.4802],
        [0.0626],
        [0.2117],
        [0.1284],
        [0.4525],
        [0.4933],
        [0.2016],
        [0.7381],
        [0.1386],
        [0.2107],
        [0.2620],
        [0.3730],
        [0.3606],
        [0.1613],
        [0.4335],
        [0.3323],
        [0.9146],
        [0.3787],
        [0.9761],
        [0.4871]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False,  True, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 0.8433,  1.9718],
        [ 1.3871, -0.1943],
        [ 0.9396,  2.2405],
        ...,
        [-0.2881,  1.4732],
        [-0.9959,  0.2876],
        [-0.2192,  1.6795]]) torch.Size([9984, 2])
samples tensor([[ 3.7983e+00, -9.5277e-01],
        [ 2.4002e+00,  6.5210e-01],
        [ 3.1402e+00, -4.9353e-01],
        [ 2.2563e+00,  3.4680e-01],
        [ 3.1766e+00,  1.3099e-01],
        [ 2.1083e+00, -7.2484e-01],
        [ 1.6346e+00, -1.7790e+00],
        [ 2.3102e+00, -2.3281e-01],
        [ 3.3878e+00, -6.4433e-01],
        [ 2.7905e+00,  2.1508e-01],
        [ 1.4078e+00, -1.0705e+00],
        [ 3.2774e+00,  5.2925e-01],
        [ 2.2223e+00, -1.3279e+00],
        [ 3.3039e+00, -1.4722e+00],
        [ 1.9496e+00, -4.4928e-01],
        [ 4.4393e-01, -8.4045e-02],
        [ 1.5696e+00,  1.0164e+00],
        [ 2.1504e+00, -4.8981e-01],
        [ 2.4236e+00, -1.5703e+00],
        [ 1.4733e+00, -1.4278e+00],
        [ 1.2428e+00,  6.7372e-01],
        [ 8.9325e-01, -1.2726e+00],
        [ 2.1457e+00,  4.0246e-01],
        [ 3.9577e+00, -3.6130e-01],
        [ 1.7966e+00, -3.6581e-01],
        [ 1.9434e+00, -2.8449e+00],
        [ 2.0145e+00, -3.3267e-01],
        [ 1.9601e+00, -1.2445e+00],
        [ 2.0064e+00,  2.4686e+00],
        [ 2.1769e+00, -6.5537e-01],
        [ 3.0098e+00, -6.0037e-01],
        [-5.4974e-01, -2.6071e-01],
        [ 2.8795e+00,  2.2497e-01],
        [ 1.6841e+00, -1.2873e+00],
        [ 2.0572e+00,  1.0230e+00],
        [ 1.5382e+00, -1.5489e+00],
        [ 2.0763e+00, -1.2098e+00],
        [ 3.1763e+00, -1.8304e+00],
        [ 1.2967e+00, -6.6523e-01],
        [ 2.5349e+00,  5.2330e-01],
        [ 3.9458e+00,  1.9862e+00],
        [ 2.8098e+00, -1.3060e+00],
        [ 4.3993e-01, -3.0887e-01],
        [ 1.5327e+00, -4.5640e-01],
        [ 1.0073e+00, -6.6029e-01],
        [ 2.3466e+00, -9.3973e-02],
        [ 3.1582e+00,  8.9177e-02],
        [ 3.4102e+00, -6.4670e-01],
        [ 3.8619e+00,  7.0547e-01],
        [ 1.3932e+00,  6.5893e-01],
        [ 1.7876e+00, -1.6402e+00],
        [ 2.8164e+00, -1.4278e+00],
        [ 1.9493e+00,  1.3156e+00],
        [ 3.2439e+00, -8.0610e-01],
        [ 4.0511e+00,  6.6065e-01],
        [ 1.9407e+00,  7.0360e-01],
        [ 3.2989e+00, -1.3813e+00],
        [ 2.0591e+00, -1.2774e+00],
        [ 7.8391e-01, -9.4996e-01],
        [ 3.1565e+00,  4.8285e-01],
        [ 3.5133e+00, -3.4145e-01],
        [ 2.0846e+00,  3.8069e-02],
        [ 2.1852e+00,  1.3435e+00],
        [ 3.3503e-02, -1.6286e+00],
        [ 1.6089e+00, -1.2668e+00],
        [ 2.4408e+00, -1.0148e+00],
        [ 3.1669e-01, -4.1545e-01],
        [ 4.0254e+00, -8.7693e-01],
        [ 3.8696e+00,  1.2203e+00],
        [ 4.3109e+00, -8.6762e-01],
        [ 3.6158e+00,  9.4057e-01],
        [ 2.8432e+00, -9.4343e-02],
        [ 2.2427e+00, -5.7202e-01],
        [ 2.0642e+00,  1.3923e+00],
        [ 1.8554e+00,  1.8467e+00],
        [ 2.9234e+00,  2.4788e+00],
        [ 4.3535e+00, -1.9480e-01],
        [ 4.4564e+00,  3.7741e-02],
        [ 3.2895e+00,  5.8227e-01],
        [ 3.2214e+00,  3.1523e-01],
        [ 4.2248e+00, -8.4053e-01],
        [ 1.4050e+00, -7.2848e-01],
        [ 1.5643e+00, -1.0109e+00],
        [ 4.8989e-01,  6.1437e-01],
        [ 1.5063e+00,  4.9172e-01],
        [ 3.0549e-01, -5.3478e-03],
        [ 1.1059e+00,  7.6544e-01],
        [ 1.0731e+00, -2.8631e-01],
        [ 1.8460e+00,  7.2345e-01],
        [ 2.2318e+00, -3.3119e-02],
        [ 2.3323e+00, -3.2224e-01],
        [ 3.2991e+00, -1.2857e+00],
        [ 2.4766e+00,  6.3352e-01],
        [ 2.9113e+00,  2.5213e-01],
        [ 1.4102e+00,  6.3385e-01],
        [ 1.1767e+00, -8.0411e-01],
        [ 4.3097e+00, -2.2955e-01],
        [ 1.6657e+00,  6.8432e-01],
        [ 2.4005e+00,  1.8280e-01],
        [ 3.7550e+00, -2.2970e-01],
        [ 9.3162e-01,  5.0684e-01],
        [ 4.8047e-01, -1.4644e-01],
        [ 6.7121e-03, -3.7322e-01],
        [ 2.2019e+00, -6.4783e-01],
        [ 4.4300e+00, -1.9488e+00],
        [ 1.9269e+00,  5.9016e-01],
        [-2.9857e-01, -1.2069e+00],
        [ 1.7388e+00,  8.1079e-01],
        [ 2.7056e+00,  1.3022e+00],
        [-5.2956e-01, -4.9895e-01],
        [ 1.6626e+00,  3.2019e-01],
        [ 2.5406e+00,  1.3105e-01],
        [ 2.2977e+00,  7.3025e-02],
        [ 4.6541e+00, -1.6362e-01],
        [ 4.7530e+00, -7.5240e-01],
        [ 2.0598e+00,  7.7153e-02],
        [ 2.2679e+00,  2.3658e+00],
        [ 5.6738e-01, -9.9163e-01],
        [ 3.7123e+00, -5.6098e-01],
        [ 2.8703e+00,  1.3631e+00],
        [ 2.3020e+00,  1.6844e+00],
        [ 2.4091e+00, -2.9735e-01],
        [ 1.0008e+00,  1.2947e-03],
        [ 2.0032e+00, -2.1697e+00],
        [ 1.5862e+00,  9.3714e-01],
        [ 3.2001e+00,  8.6221e-01],
        [ 1.2566e+00, -6.4470e-01],
        [ 2.6587e+00, -1.4783e-01],
        [-2.7778e-01,  7.3893e-01],
        [ 2.1558e+00, -1.4962e+00],
        [ 2.4752e+00, -9.8409e-02],
        [ 2.1549e+00, -3.4141e-01],
        [ 2.4425e+00, -2.8502e-01],
        [ 1.1164e+00,  1.5390e+00],
        [ 2.0054e+00,  8.1152e-02],
        [ 3.7117e+00, -8.3607e-01],
        [ 2.2339e+00,  2.7737e-01],
        [ 1.0191e+00,  8.5823e-02],
        [ 1.4512e+00, -7.1243e-02],
        [ 1.3787e+00,  1.6523e-01],
        [ 1.6046e+00, -1.4023e+00],
        [-1.6447e-01,  1.0489e+00],
        [ 4.1686e+00, -5.9055e-01],
        [ 2.5249e+00,  8.4978e-01],
        [ 2.4523e+00,  2.5104e-01],
        [ 2.6398e+00,  1.2358e+00],
        [ 6.1637e-01, -8.4783e-01],
        [ 3.9443e+00, -1.1663e+00],
        [ 3.0445e+00,  6.1312e-01],
        [ 2.0608e+00, -9.5405e-02],
        [ 1.4325e+00, -5.9439e-01],
        [ 2.0060e+00,  6.0488e-01],
        [ 4.1712e+00,  1.0511e+00],
        [ 2.5063e+00, -5.9858e-01],
        [ 2.1273e+00,  5.5034e-02],
        [ 2.2900e+00, -2.2832e+00],
        [ 2.5081e+00,  1.6178e+00],
        [ 3.4493e+00,  9.8032e-01],
        [ 2.0718e+00, -7.8538e-02],
        [ 1.0518e+00,  6.9901e-01],
        [ 1.7676e-01, -1.1576e+00],
        [ 2.2866e+00,  2.1740e-01],
        [ 1.6043e+00, -1.2261e+00],
        [ 2.3357e+00, -1.7587e-01],
        [ 2.0536e+00, -5.7002e-01],
        [ 2.4997e+00,  1.6891e-01],
        [ 3.3021e+00,  3.7247e-01],
        [ 3.6295e+00,  1.1077e-01],
        [ 6.0719e-01, -9.0288e-01],
        [ 2.4757e+00,  9.7253e-01],
        [ 8.3692e-01, -6.9187e-01],
        [ 3.7373e+00,  2.9465e-01],
        [ 1.2235e+00, -1.4487e+00],
        [ 3.0314e+00, -1.1525e+00],
        [ 2.4343e+00, -1.9783e-01],
        [ 3.3991e+00,  2.5957e-02],
        [ 7.5365e-01, -5.6195e-01],
        [ 1.6370e+00,  1.1503e+00],
        [ 3.0400e+00, -1.7989e+00],
        [ 1.8449e+00, -1.1344e+00],
        [ 4.4212e+00,  4.9499e-01],
        [ 1.4890e+00, -9.5507e-01],
        [ 3.3824e-01, -9.3983e-01],
        [ 4.0452e+00,  7.4246e-01],
        [ 2.6677e+00, -4.0791e-01],
        [ 7.1996e-01, -1.1502e+00],
        [ 1.8901e+00, -9.9159e-01],
        [ 2.4602e+00, -2.1743e-01],
        [ 2.1541e+00,  1.1640e-01],
        [ 1.2773e+00,  8.3463e-02],
        [ 2.0549e+00,  4.7520e-01],
        [ 2.5565e+00, -1.2946e+00],
        [ 3.6072e+00, -1.0358e-01],
        [ 1.6421e+00, -1.6996e-02],
        [ 1.8249e+00, -5.8015e-01],
        [ 3.0471e+00,  3.5202e-01],
        [ 3.4445e+00,  8.1781e-01],
        [ 4.2016e+00, -2.7191e-01],
        [ 2.4785e+00, -1.4414e+00],
        [ 1.0011e+00, -7.7364e-01],
        [ 4.0414e+00, -7.2181e-01],
        [ 3.6486e+00,  6.8027e-01],
        [ 2.6788e+00,  1.0019e+00],
        [ 1.5905e-01,  7.6390e-01],
        [ 3.0073e+00, -8.1662e-01],
        [ 1.6606e+00, -1.4729e+00],
        [ 3.8198e+00,  1.7631e-01],
        [ 3.2103e+00, -6.1321e-01],
        [ 3.7624e+00,  6.3539e-02],
        [ 1.6196e+00,  3.3790e-01],
        [ 2.3316e+00, -2.6333e-01],
        [ 1.8108e+00, -5.4011e-01],
        [ 3.9371e+00, -1.4623e-01],
        [ 1.3494e+00,  1.9220e-01],
        [ 1.7386e+00,  5.7527e-01],
        [ 1.5992e+00, -7.6538e-01],
        [ 3.1849e+00, -1.9510e+00],
        [ 2.1099e+00, -3.1680e-01],
        [ 1.0614e+00,  5.7811e-01],
        [ 3.1728e+00, -1.3652e+00],
        [ 2.5590e+00, -2.8911e-01],
        [ 3.5773e+00, -1.5837e+00],
        [ 1.2180e+00, -9.6802e-01],
        [ 4.6189e+00,  1.5654e-01],
        [ 2.3208e+00,  9.6199e-01],
        [ 1.3187e+00,  1.2538e+00],
        [ 2.4013e+00, -1.0061e+00],
        [ 4.2516e+00, -4.8570e-01],
        [ 9.3050e-01,  1.8211e-01],
        [ 1.5551e+00,  1.7529e+00],
        [ 3.9270e+00, -1.2346e+00],
        [ 2.4576e+00,  1.9438e-01],
        [ 1.8812e+00, -7.9041e-03],
        [ 4.2549e+00, -1.1162e+00],
        [ 1.0708e+00, -7.9334e-01],
        [ 2.4405e+00,  1.2201e-01],
        [ 3.0748e+00,  9.1456e-01],
        [ 1.5960e+00, -5.9089e-01],
        [ 4.4295e+00, -1.5030e+00],
        [ 2.4463e+00,  6.1737e-01],
        [ 3.8516e+00,  6.8419e-01],
        [ 4.2196e+00, -2.0696e+00],
        [ 1.4543e+00, -3.5198e+00],
        [ 3.0740e+00,  1.0472e+00],
        [ 2.8106e+00,  1.2350e+00],
        [ 2.7629e+00,  1.5657e+00],
        [ 2.3611e+00, -2.0997e-01],
        [ 1.4600e+00, -1.7766e+00],
        [ 2.6444e+00,  1.4622e+00],
        [ 1.5539e+00,  9.1215e-03],
        [ 2.2077e+00, -1.2364e+00],
        [ 3.3571e+00, -1.9238e+00],
        [ 2.5387e+00, -1.8228e+00],
        [ 3.2229e+00, -6.5571e-01],
        [ 1.5865e+00, -6.9649e-01],
        [ 3.0733e+00,  1.4725e-01],
        [ 2.6344e+00,  5.9856e-01],
        [ 2.0615e+00,  1.5584e+00],
        [ 1.4886e+00, -2.4713e-01],
        [ 3.5266e+00, -1.0504e+00],
        [ 2.6565e+00, -1.4062e-01],
        [ 2.7700e+00, -1.0328e-02],
        [ 2.7264e+00, -1.2401e+00],
        [ 3.1060e+00, -6.6170e-01],
        [ 2.8169e+00, -9.6543e-01],
        [ 2.0481e+00, -1.7716e+00],
        [ 2.0045e+00, -6.0776e-01],
        [ 1.1749e+00,  8.0867e-01],
        [ 1.4048e+00,  3.8333e-01],
        [ 1.7773e+00,  8.0196e-01],
        [ 3.0387e+00,  2.2004e+00],
        [ 2.3810e+00, -2.2900e-01],
        [ 3.3341e+00, -1.4585e+00],
        [ 1.9658e+00, -2.2663e-01],
        [ 1.6753e+00,  3.2544e-01],
        [ 1.6836e+00,  5.6933e-01],
        [ 2.0034e+00,  1.5343e+00],
        [ 2.8837e+00, -5.7627e-01],
        [ 2.6466e+00,  1.0002e-01],
        [ 3.3988e+00, -2.8329e-01],
        [ 2.1983e+00,  5.5921e-01],
        [ 1.7686e+00, -6.4981e-01],
        [ 3.0100e+00, -7.1992e-01],
        [ 1.3642e+00, -4.1955e-01],
        [ 1.9538e+00,  9.4807e-01],
        [ 3.2115e+00, -8.4148e-01],
        [ 1.5068e+00,  3.4619e-01],
        [ 3.1295e+00,  3.3034e-02],
        [ 1.9385e+00, -3.6905e-01],
        [ 3.2890e+00, -1.5475e+00],
        [ 2.9379e+00, -1.7714e-01],
        [ 2.8923e+00, -1.9061e-02],
        [ 1.1472e+00,  9.7185e-01],
        [ 3.0245e+00, -1.0569e-01],
        [ 9.2289e-01,  9.6421e-02],
        [ 3.2172e+00, -5.3941e-01],
        [ 1.5665e+00, -9.9056e-01],
        [ 2.1412e+00, -1.1210e+00],
        [ 1.8904e+00, -1.6612e+00],
        [ 2.0903e+00, -4.0059e-01],
        [ 3.3491e+00, -1.0291e+00],
        [ 1.5224e+00,  2.5912e-01],
        [ 1.5243e+00, -6.2866e-01],
        [ 9.2886e-01,  3.4410e-01],
        [ 2.3223e+00,  2.0268e+00],
        [ 1.0284e+00, -1.8811e-01],
        [ 3.3947e+00, -3.4225e-01],
        [ 2.0881e+00,  7.3325e-01],
        [ 1.9337e+00,  6.8761e-01],
        [ 2.4650e+00,  1.3310e+00],
        [ 4.7288e+00,  8.3481e-01],
        [ 3.6763e+00,  2.2086e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[6.2398e-03, 9.2738e-03, 2.1753e-01,  ..., 9.9973e-01, 9.9973e-01,
         1.0000e+00],
        [8.0091e-03, 1.0854e-01, 1.0870e-01,  ..., 9.8941e-01, 9.8941e-01,
         1.0000e+00],
        [4.0719e-04, 5.0207e-03, 5.0209e-03,  ..., 9.8403e-01, 9.8423e-01,
         1.0000e+00],
        ...,
        [2.4598e-08, 6.5316e-05, 3.3890e-03,  ..., 9.8542e-01, 9.8542e-01,
         1.0000e+00],
        [6.3988e-09, 1.3645e-03, 2.4852e-02,  ..., 7.6731e-01, 9.9847e-01,
         1.0000e+00],
        [3.0970e-02, 4.6140e-02, 4.6140e-02,  ..., 9.9728e-01, 9.9728e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.2560],
        [0.7925],
        [0.2993],
        [0.4847],
        [0.7226],
        [0.9429],
        [0.8611],
        [0.2856],
        [0.3295],
        [0.1790],
        [0.2382],
        [0.7403],
        [0.5663],
        [0.5192],
        [0.0788],
        [0.7923],
        [0.3727],
        [0.0698],
        [0.8765],
        [0.8109],
        [0.5033],
        [0.3537],
        [0.0077],
        [0.3766],
        [0.2331],
        [0.8579],
        [0.6924],
        [0.7780],
        [0.7414],
        [0.6080],
        [0.0854],
        [0.4152],
        [0.7289],
        [0.1530],
        [0.2957],
        [0.6249],
        [0.2416],
        [0.4875],
        [0.8688],
        [0.0085],
        [0.0213],
        [0.0275],
        [0.9762],
        [0.3832],
        [0.2991],
        [0.6320],
        [0.8687],
        [0.5092],
        [0.9463],
        [0.2066],
        [0.0484],
        [0.4383],
        [0.9531],
        [0.2773],
        [0.8798],
        [0.8848],
        [0.7497],
        [0.2819],
        [0.9913],
        [0.5278],
        [0.8286],
        [0.0922],
        [0.8336],
        [0.7050],
        [0.7471],
        [0.6862],
        [0.2535],
        [0.9456],
        [0.7878],
        [0.1912],
        [0.1993],
        [0.1554],
        [0.9289],
        [0.0765],
        [0.0997],
        [0.8280],
        [0.5044],
        [0.7917],
        [0.8309],
        [0.7914],
        [0.7287],
        [0.9350],
        [0.4203],
        [0.3648],
        [0.4457],
        [0.9357],
        [0.3221],
        [0.5701],
        [0.2321],
        [0.3586],
        [0.2059],
        [0.9101],
        [0.3132],
        [0.9742],
        [0.2794],
        [0.7454],
        [0.1621],
        [0.8004],
        [0.3226],
        [0.9474],
        [0.5478],
        [0.6200],
        [0.9250],
        [0.9034],
        [0.8492],
        [0.4774],
        [0.5914],
        [0.1281],
        [0.3642],
        [0.3897],
        [0.3208],
        [0.2808],
        [0.5784],
        [0.9130],
        [0.1946],
        [0.4574],
        [0.0092],
        [0.1275],
        [0.9770],
        [0.1740],
        [0.9113],
        [0.6728],
        [0.8551],
        [0.8739],
        [0.0240],
        [0.1684],
        [0.5899],
        [0.9765],
        [0.3800],
        [0.2374],
        [0.0248],
        [0.7682],
        [0.0738],
        [0.5186],
        [0.7463],
        [0.9094],
        [0.2842],
        [0.2935],
        [0.9949],
        [0.6000],
        [0.6879],
        [0.0565],
        [0.9761],
        [0.7692],
        [0.3668],
        [0.8701],
        [0.3804],
        [0.0884],
        [0.4573],
        [0.6420],
        [0.7238],
        [0.3659],
        [0.5424],
        [0.3261],
        [0.6093],
        [0.6833],
        [0.6782],
        [0.4591],
        [0.8069],
        [0.6771],
        [0.6356],
        [0.1197],
        [0.3697],
        [0.2450],
        [0.9702],
        [0.6633],
        [0.1493],
        [0.9264],
        [0.8780],
        [0.8943],
        [0.6970],
        [0.7766],
        [0.6645],
        [0.1188],
        [0.1572],
        [0.1046],
        [0.3123],
        [0.3480],
        [0.5230],
        [0.6607],
        [0.7290],
        [0.0232],
        [0.2994],
        [0.9106],
        [0.3128],
        [0.4601],
        [0.4950],
        [0.2400],
        [0.4331],
        [0.7203],
        [0.9882],
        [0.8751],
        [0.8372],
        [0.8006],
        [0.8519],
        [0.5122],
        [0.2215],
        [0.5260],
        [0.8086],
        [0.4610],
        [0.7727],
        [0.2656],
        [0.9680],
        [0.1008],
        [0.0049],
        [0.4811],
        [0.2013],
        [0.6808],
        [0.1726],
        [0.7172],
        [0.8282],
        [0.6390],
        [0.3210],
        [0.0898],
        [0.4058],
        [0.0670],
        [0.3134],
        [0.5519],
        [0.0033],
        [0.2042],
        [0.1602],
        [0.6171],
        [0.4396],
        [0.4507],
        [0.9845],
        [0.4236],
        [0.8076],
        [0.0671],
        [0.0766],
        [0.3597],
        [0.2583],
        [0.3981],
        [0.1960],
        [0.2846],
        [0.6579],
        [0.5590],
        [0.1592],
        [0.6033],
        [0.3030],
        [0.4321],
        [0.1504],
        [0.0863],
        [0.2352],
        [0.4203],
        [0.3468],
        [0.7733],
        [0.9803],
        [0.5568],
        [0.9751],
        [0.4518],
        [0.1096],
        [0.2438],
        [0.9409],
        [0.8682],
        [0.8449],
        [0.3121],
        [0.1573],
        [0.4192],
        [0.4152],
        [0.2340],
        [0.6331],
        [0.7351],
        [0.9250],
        [0.3486],
        [0.7726],
        [0.7533],
        [0.3045],
        [0.0333],
        [0.4418],
        [0.5557],
        [0.8306],
        [0.7703],
        [0.8633],
        [0.3770],
        [0.8774],
        [0.1393],
        [0.0043],
        [0.1794],
        [0.1018],
        [0.1126],
        [0.2447],
        [0.9087],
        [0.3991],
        [0.8870],
        [0.7749],
        [0.4215],
        [0.4131],
        [0.2127],
        [0.5598],
        [0.5789],
        [0.9568],
        [0.0039],
        [0.8914],
        [0.8192],
        [0.1380],
        [0.2042],
        [0.1583],
        [0.1879],
        [0.8169],
        [0.8909],
        [0.3464],
        [0.5024],
        [0.9358],
        [0.2248],
        [0.7168],
        [0.3037],
        [0.0482],
        [0.7970],
        [0.5611],
        [0.1072],
        [0.9239],
        [0.6759]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False,  True, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 0.2920,  0.0682],
        [ 0.7337,  1.4474],
        [ 3.5707, -0.0824],
        ...,
        [-1.9299,  1.1226],
        [-3.8134, -1.2183],
        [ 0.1067,  0.9197]]) torch.Size([9984, 2])
samples tensor([[ 2.7071e+00,  6.9457e-01],
        [ 1.0092e+00, -1.3004e+00],
        [ 1.5173e+00, -1.1472e+00],
        [ 1.8908e+00, -5.4203e-01],
        [ 4.1989e+00,  7.0473e-01],
        [-3.5896e-01,  2.9994e-01],
        [ 2.2502e+00, -1.8622e+00],
        [ 2.7638e+00, -2.4133e+00],
        [ 4.5395e+00,  8.1171e-01],
        [ 2.1407e+00,  3.6853e-01],
        [ 2.7260e+00, -1.9128e+00],
        [ 2.9426e+00, -5.0815e-01],
        [ 2.5577e+00, -1.9825e+00],
        [ 4.4048e+00,  2.8199e-01],
        [ 3.6191e+00,  6.8608e-01],
        [-6.2237e-02, -1.0250e+00],
        [ 4.3257e+00, -2.9630e+00],
        [ 3.2196e+00,  3.3040e-01],
        [ 1.7248e+00,  7.5856e-01],
        [ 2.9527e+00,  1.5323e+00],
        [ 2.9377e+00, -1.6184e+00],
        [ 2.5379e+00, -5.5600e-01],
        [ 2.1903e+00,  1.9454e+00],
        [ 3.6080e+00, -7.6772e-02],
        [ 1.2345e+00,  7.5257e-01],
        [ 4.6578e+00, -9.8970e-01],
        [ 1.6401e+00,  8.9483e-01],
        [ 1.8908e+00, -2.2203e+00],
        [ 1.9619e+00, -1.8329e+00],
        [ 1.8283e+00,  1.7634e+00],
        [ 2.9472e+00,  4.2269e-01],
        [ 1.6309e+00,  8.5541e-01],
        [ 2.4667e+00,  6.3859e-01],
        [ 2.8617e+00, -5.5973e-01],
        [ 1.8152e+00, -7.8208e-01],
        [ 1.3490e+00,  1.1928e+00],
        [ 2.8111e+00,  8.7813e-01],
        [ 3.5550e+00,  6.3002e-01],
        [ 1.7689e+00, -7.5105e-02],
        [ 1.6709e+00,  2.6404e-01],
        [ 1.5974e-01,  1.8706e-01],
        [ 1.1608e+00,  8.0139e-01],
        [ 2.5080e+00,  1.5566e+00],
        [ 2.3530e+00, -8.2125e-01],
        [ 1.8930e+00, -1.4909e+00],
        [ 1.1379e+00, -1.0628e+00],
        [ 8.7954e-01,  5.9697e-01],
        [ 3.4618e+00,  7.7575e-01],
        [ 1.0434e+00,  2.5684e-01],
        [ 6.2713e-01, -1.4934e+00],
        [ 3.8264e+00, -8.6602e-02],
        [ 3.1188e+00, -8.3132e-01],
        [ 1.4871e+00, -6.4350e-01],
        [ 3.7657e+00,  1.1247e+00],
        [ 1.8944e+00,  6.8105e-01],
        [ 2.1937e+00,  6.5030e-01],
        [ 2.9569e+00,  9.5132e-01],
        [ 3.0537e+00, -1.2179e+00],
        [ 3.6177e+00,  1.4716e+00],
        [ 2.5196e+00,  2.3030e-01],
        [ 1.3977e+00, -9.4914e-01],
        [ 2.3105e+00,  8.7829e-01],
        [ 2.0459e+00,  3.8111e-01],
        [ 1.8935e+00, -2.2412e-01],
        [ 1.8396e+00,  7.9413e-01],
        [ 1.6191e+00, -2.4596e-01],
        [ 2.2300e+00,  7.6460e-01],
        [ 1.4558e+00,  1.3999e-01],
        [ 2.3122e+00, -1.2291e+00],
        [ 2.1900e+00,  1.0298e+00],
        [ 1.7363e+00, -2.1785e-01],
        [ 2.3241e+00, -3.2953e-01],
        [ 2.3491e+00,  6.8270e-01],
        [ 2.1451e+00, -3.1757e-01],
        [ 3.5975e+00,  9.0552e-01],
        [ 2.3777e+00, -3.7477e-01],
        [ 2.5427e+00, -8.4497e-01],
        [ 1.9164e+00,  2.4206e-01],
        [ 2.3329e+00,  6.9644e-01],
        [ 3.4578e+00, -5.7645e-01],
        [ 2.9863e+00,  2.4101e-02],
        [ 2.0199e+00,  2.3594e+00],
        [ 2.3902e+00,  1.6138e+00],
        [ 5.6204e-01, -5.1995e-01],
        [ 7.4729e-01, -7.9245e-01],
        [ 1.8202e+00, -1.1973e+00],
        [ 1.8182e+00, -1.5041e+00],
        [ 4.4979e+00,  7.1886e-01],
        [ 1.1714e+00,  2.2460e-01],
        [ 1.5699e+00,  1.2156e+00],
        [ 3.2066e+00, -1.4063e+00],
        [ 2.1199e+00, -1.0456e+00],
        [ 4.0588e+00, -8.7980e-01],
        [ 2.0461e+00,  9.7621e-01],
        [ 3.4609e+00, -1.1032e+00],
        [ 1.8440e+00,  9.8863e-01],
        [ 3.3262e+00, -2.4148e-01],
        [-1.4272e-01, -2.1192e+00],
        [ 3.8822e+00, -1.0421e+00],
        [ 2.3056e+00, -7.8776e-02],
        [ 3.0862e+00, -5.5915e-01],
        [ 1.0496e+00, -4.4142e-02],
        [ 1.9092e+00,  2.3114e-01],
        [ 1.6809e+00, -1.8540e+00],
        [ 3.7326e+00,  4.2484e-04],
        [ 2.6762e+00, -7.0295e-01],
        [ 3.1001e+00, -1.8774e+00],
        [ 6.9074e-01, -1.0811e+00],
        [ 1.4787e+00,  7.0380e-01],
        [ 3.4210e+00,  2.9791e-01],
        [ 1.4831e+00,  1.1902e+00],
        [ 3.6643e+00, -6.7498e-01],
        [ 2.7041e+00, -3.3148e-01],
        [ 1.7836e+00,  9.4583e-01],
        [ 2.9468e+00, -7.0626e-01],
        [ 2.6041e+00,  2.3771e-01],
        [ 2.3540e+00, -9.3334e-01],
        [ 3.0877e+00, -1.0170e+00],
        [ 2.3907e+00, -7.1131e-01],
        [ 3.8192e+00,  3.6719e-01],
        [ 3.2634e+00, -1.1991e+00],
        [ 1.7749e+00,  1.0107e-02],
        [ 1.8454e+00, -9.6291e-01],
        [ 1.4572e+00, -8.1822e-01],
        [ 2.0157e+00,  2.2562e+00],
        [ 1.8113e+00,  7.5037e-01],
        [ 3.2362e+00,  1.1377e+00],
        [ 3.3865e+00, -1.2948e+00],
        [ 9.9888e-01, -1.1378e+00],
        [ 1.7586e+00, -1.5091e+00],
        [ 2.8511e+00,  6.9916e-01],
        [ 3.2805e+00, -2.3702e-01],
        [ 1.2892e+00,  3.2415e-01],
        [ 2.0112e+00,  5.1955e-01],
        [ 2.1215e+00,  2.6353e-01],
        [ 2.0479e+00, -1.3728e+00],
        [ 1.0737e+00, -2.2315e+00],
        [ 1.7165e+00, -1.9811e+00],
        [ 5.2757e-01, -1.0101e+00],
        [ 2.5951e+00,  4.4232e-01],
        [ 2.2638e+00, -1.1847e+00],
        [ 2.9473e+00,  9.4301e-01],
        [ 1.9964e+00, -3.5490e-01],
        [ 1.7646e+00, -1.0003e+00],
        [ 2.5326e+00, -2.3648e+00],
        [ 2.4303e+00,  5.4415e-01],
        [ 2.8585e+00,  4.5626e-01],
        [ 3.9163e+00,  6.6740e-01],
        [ 2.9568e+00, -3.5690e-01],
        [ 2.1638e+00, -1.0075e+00],
        [ 3.4691e+00, -6.8483e-01],
        [ 1.0103e+00,  5.0561e-01],
        [ 8.0475e-01, -2.0307e-02],
        [ 3.2437e+00, -1.9878e+00],
        [ 2.4461e+00, -8.4143e-01],
        [ 4.3017e+00, -1.3531e+00],
        [ 1.6917e+00, -1.6968e-01],
        [ 3.7974e+00, -4.0212e-01],
        [ 2.9584e+00, -9.3366e-03],
        [ 2.8775e+00,  1.3183e-01],
        [ 4.0837e+00, -1.2031e+00],
        [ 2.9350e+00,  4.3231e-01],
        [ 2.3956e+00, -1.8635e-01],
        [ 2.1778e+00, -8.2174e-01],
        [ 3.7092e+00, -6.0826e-02],
        [ 1.2363e+00,  4.2003e-01],
        [ 2.4492e+00,  1.7312e+00],
        [ 1.2864e+00, -7.0073e-02],
        [ 4.0220e+00, -1.6718e+00],
        [ 1.6555e+00, -2.1304e-01],
        [-3.8797e-01, -1.1021e+00],
        [ 2.6501e+00, -1.6100e+00],
        [ 2.7467e+00,  3.2343e-01],
        [ 4.9969e-01, -2.4207e-01],
        [ 1.3535e+00, -1.7134e-01],
        [ 1.7409e+00,  1.5805e-01],
        [ 2.1468e+00, -2.5997e+00],
        [ 7.5982e-01,  1.2230e-01],
        [ 1.4599e+00,  9.5430e-01],
        [ 2.3947e+00,  9.9643e-01],
        [ 3.8404e+00,  1.7022e+00],
        [ 1.5994e+00, -2.9554e-01],
        [ 2.4003e+00, -1.3487e+00],
        [ 1.4568e-01, -1.3714e-01],
        [ 2.8087e+00, -6.4062e-01],
        [ 3.3635e+00, -1.0392e+00],
        [ 2.0032e+00, -8.5905e-01],
        [ 1.8777e+00, -1.7190e+00],
        [ 1.4998e+00, -7.2023e-01],
        [ 1.5301e+00,  1.8143e+00],
        [ 2.8681e+00,  1.1507e+00],
        [ 9.3683e-01,  2.0155e+00],
        [ 1.3762e+00,  1.1047e-01],
        [ 3.5379e+00,  4.2880e-01],
        [ 2.9569e+00, -1.8776e+00],
        [ 2.9175e+00,  5.8475e-01],
        [ 3.1205e+00, -8.3904e-01],
        [ 7.3747e-01,  7.3285e-01],
        [ 1.8715e+00,  4.0018e-01],
        [ 4.1206e+00, -3.7558e-01],
        [ 3.6312e+00, -2.3141e+00],
        [ 2.7489e+00,  4.3075e-01],
        [ 3.1712e+00,  1.0820e+00],
        [ 1.4530e+00, -3.4160e-01],
        [ 3.8884e+00, -2.1161e+00],
        [ 2.2119e+00, -4.6963e-01],
        [ 1.3435e+00, -8.3001e-01],
        [ 1.6902e+00, -1.5431e-01],
        [ 1.8088e+00, -2.4353e-01],
        [ 8.3334e-01, -1.4906e+00],
        [ 2.4322e+00, -1.7689e+00],
        [ 2.9927e+00, -8.3781e-01],
        [ 1.9025e+00,  2.4226e-01],
        [ 1.2903e+00,  6.9466e-01],
        [ 1.9940e+00,  1.8096e-01],
        [ 2.8688e+00,  7.0916e-01],
        [ 2.4400e+00, -2.1985e+00],
        [ 6.9615e-01,  5.9637e-02],
        [ 2.5632e+00,  3.6060e-01],
        [ 2.6632e+00, -8.9592e-02],
        [ 1.7350e+00,  7.0229e-01],
        [ 2.8006e+00, -1.2100e+00],
        [ 3.7213e+00,  2.3871e-01],
        [ 2.8952e+00, -1.6402e+00],
        [ 2.6600e+00,  5.0881e-01],
        [ 4.6817e+00,  9.1427e-01],
        [ 3.2891e+00,  2.3933e-01],
        [ 1.7885e+00,  4.4187e-02],
        [ 4.6976e+00,  1.8305e-01],
        [ 2.5037e+00,  1.9691e+00],
        [ 1.4856e+00, -4.2494e-01],
        [ 2.4278e+00, -9.2035e-01],
        [ 1.9592e+00, -6.7515e-02],
        [ 3.3632e+00, -2.2450e+00],
        [ 2.4521e-01,  1.5956e+00],
        [ 1.6938e+00, -1.7257e+00],
        [ 1.7368e+00, -2.1904e-01],
        [ 2.5856e+00, -2.1636e-01],
        [ 3.2149e+00, -1.4153e+00],
        [ 3.1281e+00,  1.4368e+00],
        [ 1.6353e+00, -1.4636e-01],
        [ 3.1546e-01, -6.6804e-01],
        [ 3.0988e+00, -5.8149e-01],
        [ 1.9457e+00,  1.0536e+00],
        [ 1.5653e+00,  1.0035e-01],
        [ 3.0710e+00,  1.5257e-01],
        [ 1.3443e+00,  9.2217e-01],
        [ 1.1468e+00, -1.6257e+00],
        [ 2.4843e+00,  7.3122e-01],
        [ 1.8878e+00,  3.5638e-01],
        [ 3.4906e+00, -5.5896e-01],
        [ 1.6854e+00,  1.0148e+00],
        [ 2.9475e+00, -7.8805e-01],
        [ 1.7473e+00, -9.7766e-01],
        [ 3.1159e+00, -1.1123e+00],
        [ 2.8695e+00, -7.0422e-01],
        [ 1.5784e+00, -9.6912e-01],
        [ 2.4525e+00, -1.9845e-01],
        [ 2.1427e+00,  3.6348e-01],
        [-1.8671e-01,  2.8422e-01],
        [ 1.2668e+00, -2.8126e-01],
        [ 2.9750e+00,  9.8529e-01],
        [ 2.9838e+00,  1.0754e+00],
        [ 3.4163e+00,  2.4502e+00],
        [ 2.3697e+00, -1.0390e+00],
        [ 2.6261e+00, -1.1176e+00],
        [ 1.2615e+00, -1.1320e-01],
        [ 3.0492e+00,  8.9739e-01],
        [ 1.6898e+00,  7.5717e-01],
        [ 1.3703e+00,  3.7512e-01],
        [ 1.6169e-03, -4.4538e-01],
        [ 2.4913e+00,  1.0059e+00],
        [ 1.8225e+00, -1.5882e+00],
        [ 1.9670e+00, -5.0956e-01],
        [ 1.6048e+00, -2.1720e-01],
        [ 1.3671e+00,  8.7040e-01],
        [ 1.7855e+00,  2.1773e+00],
        [ 2.9156e+00,  6.7569e-01],
        [ 1.4042e+00,  1.1169e+00],
        [ 2.9632e+00,  5.7582e-01],
        [ 2.9645e+00,  8.5207e-01],
        [ 2.7831e+00,  5.6442e-02],
        [ 3.1349e+00, -8.7431e-01],
        [ 1.8396e+00,  3.0701e-01],
        [ 3.3299e+00, -3.3251e-01],
        [ 3.5359e+00, -1.0241e+00],
        [ 4.1639e+00, -1.2957e+00],
        [ 3.8491e+00, -6.1818e-01],
        [ 3.1847e+00, -1.4861e+00],
        [ 1.5483e+00,  1.2715e+00],
        [ 3.7812e+00,  8.0985e-01],
        [ 1.2416e+00,  1.2407e-01],
        [ 6.7867e-01, -9.3393e-01],
        [ 2.2598e+00, -5.6145e-02],
        [ 1.6331e+00,  4.4621e-02],
        [ 3.6659e+00, -4.3895e-01],
        [ 4.0194e+00, -6.3254e-01],
        [ 3.4200e-01,  1.5390e+00],
        [ 2.0801e+00, -2.4542e+00],
        [ 2.1878e+00, -3.0880e+00],
        [ 3.5210e+00, -1.2321e+00],
        [ 2.3945e+00, -4.5160e-01],
        [ 1.1140e+00, -5.4413e-01],
        [ 1.3425e+00,  1.4111e+00],
        [ 7.9628e-01, -1.2602e+00],
        [ 2.9178e+00, -2.3472e-01],
        [ 1.5648e+00,  7.1612e-01],
        [ 2.4639e+00,  5.0586e-01],
        [ 4.0690e+00,  5.6994e-01],
        [ 2.1965e+00,  8.8718e-01],
        [ 1.8677e+00, -1.0360e+00],
        [ 2.4120e+00, -2.5143e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.4709e-02, 1.5426e-02, 3.9493e-02,  ..., 9.9185e-01, 9.9195e-01,
         1.0000e+00],
        [1.1468e-01, 1.3385e-01, 1.3474e-01,  ..., 9.9982e-01, 9.9982e-01,
         1.0000e+00],
        [8.9613e-07, 2.5286e-03, 1.0665e-02,  ..., 8.9513e-01, 8.9518e-01,
         1.0000e+00],
        ...,
        [2.3893e-02, 2.3893e-02, 9.5164e-02,  ..., 9.9995e-01, 9.9995e-01,
         1.0000e+00],
        [1.7123e-03, 2.4250e-03, 1.4646e-02,  ..., 6.0634e-01, 6.0635e-01,
         1.0000e+00],
        [1.0549e-02, 1.0552e-02, 6.9013e-02,  ..., 6.5248e-01, 9.2858e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[5.2506e-01],
        [9.7691e-01],
        [9.5048e-01],
        [9.6085e-01],
        [5.4514e-03],
        [4.6091e-01],
        [9.7526e-01],
        [4.2565e-01],
        [7.7305e-01],
        [9.7982e-01],
        [2.2154e-01],
        [7.8294e-01],
        [6.7628e-01],
        [4.0828e-02],
        [8.2773e-01],
        [7.4014e-01],
        [4.7713e-01],
        [8.1016e-01],
        [9.3583e-01],
        [4.0816e-01],
        [1.5991e-01],
        [8.6017e-01],
        [5.7492e-01],
        [8.6257e-01],
        [5.1009e-02],
        [2.6023e-01],
        [4.8749e-01],
        [4.5875e-01],
        [6.2711e-01],
        [9.1686e-01],
        [7.6142e-01],
        [8.3126e-01],
        [5.8841e-01],
        [5.4371e-02],
        [7.7157e-01],
        [5.7222e-01],
        [7.0108e-01],
        [3.2055e-01],
        [8.7727e-01],
        [9.8308e-01],
        [3.6764e-01],
        [3.4296e-01],
        [8.4379e-01],
        [3.3148e-01],
        [4.1582e-01],
        [1.9998e-01],
        [9.5964e-01],
        [9.1412e-01],
        [3.1939e-01],
        [6.7028e-01],
        [5.5981e-01],
        [7.2075e-01],
        [5.7485e-01],
        [6.1995e-02],
        [3.1495e-01],
        [1.2097e-01],
        [5.4263e-02],
        [2.8722e-01],
        [6.0499e-01],
        [4.0053e-01],
        [1.0163e-01],
        [5.5139e-01],
        [9.0612e-01],
        [9.3569e-01],
        [5.3694e-01],
        [4.4507e-01],
        [3.9033e-02],
        [2.1281e-01],
        [4.1735e-01],
        [3.0515e-01],
        [4.5058e-01],
        [7.6226e-02],
        [3.9951e-02],
        [2.6025e-02],
        [3.7806e-01],
        [3.1973e-01],
        [5.7551e-01],
        [8.7680e-01],
        [8.1483e-01],
        [3.2412e-01],
        [2.9835e-02],
        [7.6681e-01],
        [3.5176e-01],
        [9.2374e-01],
        [3.6468e-01],
        [2.2612e-02],
        [7.2683e-01],
        [8.6797e-01],
        [6.4888e-01],
        [3.2222e-01],
        [5.3347e-01],
        [1.0790e-01],
        [8.6951e-01],
        [8.8162e-01],
        [7.3105e-03],
        [1.1966e-01],
        [4.4549e-01],
        [7.8345e-01],
        [1.3205e-01],
        [7.8814e-01],
        [5.5539e-02],
        [4.6227e-01],
        [3.2035e-01],
        [2.0572e-01],
        [1.9883e-01],
        [4.0867e-01],
        [6.8357e-01],
        [2.8452e-01],
        [3.4987e-01],
        [5.6335e-01],
        [8.6535e-02],
        [9.8789e-01],
        [7.1327e-01],
        [1.8570e-01],
        [8.2205e-01],
        [5.4303e-01],
        [6.0472e-02],
        [2.6594e-01],
        [5.6519e-01],
        [7.1653e-01],
        [7.5448e-01],
        [7.1069e-01],
        [1.0826e-01],
        [7.1797e-01],
        [7.4533e-02],
        [3.9320e-01],
        [2.9348e-01],
        [8.8088e-01],
        [8.1461e-01],
        [4.4161e-01],
        [9.1066e-01],
        [8.4285e-01],
        [3.4269e-01],
        [6.6002e-01],
        [1.9180e-01],
        [8.1155e-01],
        [5.0205e-01],
        [3.5244e-01],
        [9.4100e-01],
        [9.1684e-01],
        [8.4867e-01],
        [6.1658e-01],
        [8.5004e-01],
        [9.9966e-01],
        [7.3799e-01],
        [7.8466e-01],
        [6.1812e-01],
        [9.7768e-01],
        [6.8510e-01],
        [1.2127e-01],
        [9.0878e-01],
        [1.9635e-01],
        [1.6868e-01],
        [4.4179e-01],
        [2.0453e-01],
        [6.7242e-01],
        [1.5856e-01],
        [3.1493e-01],
        [1.4669e-01],
        [8.1997e-01],
        [1.5708e-01],
        [3.8113e-01],
        [1.6404e-01],
        [4.1317e-01],
        [6.7534e-01],
        [7.4636e-01],
        [1.9015e-01],
        [6.6988e-02],
        [6.2986e-02],
        [9.2460e-01],
        [4.6638e-01],
        [7.9950e-01],
        [3.0663e-01],
        [5.5350e-01],
        [4.3338e-02],
        [6.2915e-01],
        [5.0118e-01],
        [6.4646e-01],
        [6.1925e-01],
        [9.4420e-01],
        [7.4936e-01],
        [5.3338e-01],
        [4.2851e-02],
        [7.6773e-02],
        [6.2094e-01],
        [5.3123e-01],
        [9.7888e-01],
        [6.6067e-01],
        [6.2631e-01],
        [8.9787e-01],
        [5.3753e-01],
        [4.2584e-01],
        [1.8270e-01],
        [4.2607e-01],
        [8.6629e-01],
        [4.2215e-01],
        [9.1079e-01],
        [7.4714e-01],
        [7.2904e-01],
        [3.5357e-04],
        [9.3258e-01],
        [9.0728e-01],
        [5.6357e-01],
        [2.0556e-01],
        [7.7383e-01],
        [4.6628e-01],
        [2.7015e-01],
        [2.4009e-01],
        [3.9793e-02],
        [8.1542e-01],
        [1.9310e-02],
        [3.2079e-01],
        [4.2148e-01],
        [8.0445e-02],
        [8.5937e-02],
        [9.3669e-02],
        [1.8645e-01],
        [9.8083e-01],
        [4.3263e-01],
        [1.7070e-01],
        [1.0533e-01],
        [3.5415e-01],
        [6.0060e-01],
        [7.7559e-01],
        [5.1420e-01],
        [9.0432e-01],
        [3.9692e-01],
        [6.6026e-01],
        [6.1780e-02],
        [1.1240e-01],
        [2.4442e-01],
        [1.4858e-01],
        [9.3005e-01],
        [6.5793e-01],
        [8.2776e-01],
        [7.3702e-01],
        [4.5390e-01],
        [4.2654e-01],
        [7.6769e-01],
        [7.6479e-01],
        [1.5651e-01],
        [4.0410e-01],
        [7.2284e-02],
        [6.3024e-02],
        [2.5806e-01],
        [1.5592e-01],
        [5.5513e-01],
        [5.3050e-01],
        [9.3949e-01],
        [7.2322e-01],
        [9.2010e-01],
        [5.3690e-01],
        [4.6464e-01],
        [5.6838e-01],
        [2.5354e-01],
        [5.5642e-01],
        [6.5851e-02],
        [1.9760e-01],
        [5.8078e-01],
        [3.8148e-01],
        [1.6590e-01],
        [2.5032e-01],
        [1.1477e-01],
        [5.9273e-01],
        [4.2225e-01],
        [6.0284e-01],
        [7.3756e-02],
        [6.7438e-01],
        [1.1236e-01],
        [7.0039e-01],
        [3.3120e-01],
        [6.4324e-01],
        [1.2605e-01],
        [8.1833e-01],
        [8.1225e-01],
        [8.5613e-01],
        [5.7160e-01],
        [8.3530e-02],
        [9.1431e-01],
        [3.6423e-01],
        [1.2398e-01],
        [4.2834e-01],
        [4.3880e-01],
        [3.0699e-01],
        [5.1058e-01],
        [7.7657e-01],
        [2.4941e-01],
        [2.2120e-01],
        [4.5667e-01],
        [3.9957e-01],
        [8.0880e-01],
        [7.1123e-01],
        [5.8210e-01],
        [6.6115e-01],
        [8.0549e-02],
        [6.2569e-01],
        [6.0800e-01],
        [4.5505e-01],
        [9.1097e-01],
        [7.1683e-01],
        [8.6330e-01],
        [2.8315e-01],
        [5.9156e-01],
        [9.8282e-02],
        [1.4577e-01],
        [5.6502e-01],
        [5.6335e-01],
        [4.9166e-01],
        [7.9069e-01],
        [9.5383e-01],
        [1.3854e-01],
        [1.7082e-01]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False,  True],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 0.9303,  0.7979],
        [-0.0770,  2.1590],
        [ 1.3662,  0.9718],
        ...,
        [-2.2755,  0.9524],
        [ 3.1071, -1.8171],
        [ 2.4258,  0.7896]]) torch.Size([9984, 2])
samples tensor([[ 2.3457, -0.8343],
        [ 1.0262,  0.6289],
        [ 1.3049, -0.3708],
        [ 4.9774, -0.0567],
        [ 1.4525,  0.9430],
        [ 1.6871, -1.3678],
        [ 2.2811, -0.1807],
        [ 3.4394, -0.7998],
        [ 2.3080, -0.2831],
        [ 1.4879,  1.7569],
        [ 2.2915,  2.2162],
        [ 3.6119,  0.1065],
        [ 2.0363, -1.4478],
        [ 1.1556,  1.1752],
        [ 2.4251, -2.3452],
        [-0.0636,  0.8658],
        [ 0.2300, -0.8970],
        [ 1.6111, -0.4922],
        [ 3.6374,  1.2071],
        [ 2.2254, -0.9649],
        [ 1.0003, -0.6511],
        [ 2.6872, -0.1290],
        [ 3.3785,  1.1370],
        [ 4.2680,  0.5710],
        [ 0.7815,  0.3296],
        [ 1.2567, -0.7687],
        [ 2.5790, -1.6790],
        [ 1.4138, -0.3044],
        [ 1.4004,  1.7109],
        [ 0.8326,  1.3832],
        [ 4.3238, -0.3455],
        [ 2.2222, -0.8979],
        [ 1.5849,  0.1711],
        [ 1.6235,  0.4108],
        [ 3.3719, -1.0107],
        [ 0.9424,  0.5413],
        [ 1.1135, -0.3616],
        [ 2.3732, -0.2094],
        [ 0.6087, -0.5875],
        [ 1.9397,  1.7225],
        [ 1.6128,  0.1554],
        [ 2.7268, -0.3394],
        [ 3.3822, -0.3687],
        [ 1.6698,  1.5893],
        [ 2.9417,  0.5396],
        [ 3.5912, -0.1703],
        [ 1.0382, -0.8067],
        [-1.1611, -0.4964],
        [ 3.2822, -0.5234],
        [ 4.3676, -2.0459],
        [-0.7063, -0.0058],
        [ 4.4659, -1.8122],
        [ 0.9190,  0.1471],
        [-0.3106, -1.5198],
        [ 1.9215, -2.0563],
        [ 3.9567, -0.4427],
        [ 4.0112,  1.5687],
        [ 4.2383, -1.5866],
        [ 4.2867, -0.3755],
        [ 2.5268, -0.3809],
        [ 0.4991,  0.7938],
        [ 4.7167,  1.7311],
        [ 1.6038, -0.1364],
        [ 3.7047, -1.9313],
        [ 3.5033,  1.1635],
        [ 2.2690, -0.2005],
        [ 1.1836,  1.5756],
        [ 1.2049, -0.3614],
        [ 1.9835, -0.7566],
        [ 1.8936, -1.2783],
        [ 2.9745,  0.3463],
        [ 2.9892,  1.7311],
        [ 1.7378,  1.3411],
        [-0.0822,  0.0763],
        [ 2.9958,  0.2452],
        [ 1.9906,  0.0944],
        [ 1.2312,  0.4802],
        [ 2.0539,  0.0050],
        [ 2.6997, -0.1954],
        [ 2.6936, -0.0734],
        [ 1.5671,  0.4338],
        [ 3.6470,  0.7231],
        [ 3.5103,  0.1922],
        [ 2.7410, -1.7333],
        [ 2.0415, -0.7258],
        [ 2.0168,  1.4122],
        [ 2.2608,  0.9721],
        [ 1.3366, -1.4304],
        [ 1.7465, -0.4648],
        [ 1.2032, -0.1526],
        [ 3.4193, -0.7933],
        [ 1.8681,  2.0617],
        [ 2.3486,  0.1427],
        [ 3.5778, -0.3105],
        [ 1.9966,  0.9065],
        [ 3.7107,  0.5576],
        [ 2.3938,  1.3781],
        [ 2.3335, -1.1695],
        [ 2.8722, -0.7832],
        [ 1.6022, -1.2782],
        [ 2.1074,  1.5017],
        [ 4.6388,  0.1096],
        [ 1.1790,  0.1798],
        [ 2.4030, -0.4633],
        [ 2.6338,  0.1707],
        [ 1.4026, -1.6054],
        [ 3.8105, -0.1716],
        [ 1.4600, -0.5683],
        [ 2.7006,  1.1532],
        [ 1.9279,  1.5400],
        [ 1.1697, -0.3885],
        [ 1.8320,  1.0095],
        [ 2.1817,  1.0249],
        [ 3.7171,  0.1429],
        [ 1.3266,  1.0044],
        [ 4.4805,  0.3908],
        [ 1.7160, -1.4352],
        [ 3.3371, -1.4333],
        [ 2.5133, -1.3366],
        [ 2.2456, -0.5313],
        [ 3.7250, -0.6644],
        [ 3.1178, -0.2853],
        [ 3.4224, -0.6717],
        [ 3.2173, -0.4696],
        [ 1.4027,  0.4755],
        [ 3.3354, -0.0253],
        [ 1.4566,  0.7736],
        [ 2.9095,  0.4208],
        [ 2.2789,  1.4262],
        [ 2.4672, -0.6897],
        [ 1.6105,  0.4794],
        [ 2.7485, -0.7318],
        [ 3.2133, -0.6305],
        [ 3.2707, -0.4538],
        [ 4.3452,  0.7518],
        [ 2.5872, -0.7759],
        [ 3.3184, -0.5040],
        [ 0.5434,  1.0246],
        [ 1.1616, -0.4061],
        [ 1.4767, -0.7822],
        [ 3.8924, -1.1413],
        [ 2.3995, -1.3147],
        [ 0.1032, -0.7095],
        [ 4.0366, -3.9489],
        [ 3.5104,  1.5794],
        [ 1.9652,  0.7101],
        [ 2.2159, -0.4974],
        [ 1.3154,  1.6906],
        [ 2.4193,  0.7448],
        [ 3.1700,  0.6798],
        [ 4.2739,  0.0708],
        [ 3.9036, -1.1386],
        [ 2.2852, -0.2976],
        [ 2.8306, -1.2885],
        [ 2.7309,  0.4983],
        [ 3.4583, -0.6322],
        [ 3.1807,  0.1521],
        [ 2.2547, -3.1438],
        [ 2.1547,  1.0484],
        [ 2.4811,  1.4540],
        [ 1.1618, -1.9679],
        [ 2.8473, -1.5171],
        [ 3.6083, -0.6252],
        [ 1.0108,  0.7887],
        [ 3.5275,  1.1408],
        [ 2.6574, -1.8183],
        [ 3.4650,  2.2539],
        [ 1.8399,  1.0889],
        [ 2.4046,  1.0473],
        [ 1.0857,  0.1136],
        [ 2.7575,  1.1005],
        [ 2.0920,  0.5088],
        [ 3.7886, -0.7629],
        [ 1.4322, -1.8309],
        [ 0.9895, -0.4767],
        [ 2.1359, -0.7295],
        [ 2.2518, -1.2528],
        [ 3.1722, -0.0629],
        [ 2.0695, -0.6366],
        [ 4.5688,  1.1063],
        [ 2.5370, -1.7618],
        [ 3.1228, -0.9317],
        [ 1.8676,  0.5724],
        [ 3.5526,  1.1557],
        [ 3.4022, -3.6508],
        [ 1.0071, -0.9635],
        [ 1.1653, -0.4330],
        [ 0.7136, -1.2722],
        [ 3.9266, -1.1182],
        [ 2.6705, -2.6509],
        [ 0.8136, -2.2884],
        [ 2.0903, -1.9606],
        [ 3.2331, -3.0426],
        [ 2.1272, -0.5005],
        [ 1.7247, -0.6217],
        [ 0.8664,  0.2268],
        [ 2.2236,  0.8457],
        [ 2.4633,  1.0288],
        [ 1.5562,  0.6984],
        [ 2.2342, -0.9467],
        [ 2.8065, -0.1132],
        [ 2.0671,  0.2796],
        [ 1.3695,  0.2581],
        [ 2.3462, -0.6366],
        [ 1.6090, -1.4771],
        [ 1.9151, -0.6460],
        [ 1.4078, -1.4257],
        [ 0.4631, -0.3953],
        [ 1.4836, -0.3444],
        [ 2.1620, -0.3480],
        [ 0.5723,  1.5419],
        [ 4.0884, -0.7600],
        [ 0.5757,  0.1967],
        [ 1.5177,  0.4948],
        [ 1.1754, -0.1856],
        [ 2.0358, -0.0666],
        [ 3.0967,  0.2160],
        [ 4.9889,  0.7010],
        [ 2.9835,  0.1238],
        [ 2.7618, -0.8615],
        [ 3.1440,  0.7897],
        [ 1.9549, -0.8055],
        [ 1.8997, -0.4715],
        [ 2.5426, -0.6874],
        [ 2.4106,  1.5313],
        [ 1.1374,  0.3602],
        [ 1.6856, -0.2316],
        [ 2.4479, -0.5656],
        [ 1.6236,  1.0762],
        [ 4.1139, -0.3494],
        [ 3.8973, -0.3777],
        [ 3.9068, -0.7614],
        [ 3.6247,  0.0335],
        [ 4.9091,  0.4348],
        [ 4.5004,  0.0286],
        [ 2.4822,  0.6448],
        [ 2.5098, -0.3802],
        [ 1.4052, -0.8661],
        [ 2.3125,  0.0139],
        [ 4.0272,  0.3865],
        [ 1.2567,  2.7807],
        [ 1.2609,  0.1185],
        [ 3.1524,  0.2359],
        [ 3.1990, -0.8110],
        [ 3.0000, -0.1676],
        [ 1.3552, -0.1595],
        [ 3.2301, -0.3856],
        [ 1.2554,  0.5860],
        [ 2.5150,  1.7473],
        [ 2.6539, -2.5281],
        [ 2.0110, -0.9258],
        [ 3.4101, -3.0627],
        [ 2.0512,  1.9925],
        [ 0.9381, -1.2794],
        [ 1.8110,  0.6225],
        [ 3.9626, -0.0609],
        [ 1.7930,  1.5181],
        [ 2.6744, -0.1783],
        [ 3.4566, -0.6334],
        [ 3.3113, -2.6501],
        [ 2.1487,  0.2918],
        [ 1.8940, -0.2569],
        [ 1.0519, -0.9995],
        [ 1.1471, -0.5777],
        [ 3.9452,  0.7069],
        [ 2.4202, -0.3590],
        [ 2.8190,  0.2988],
        [ 1.7910,  0.0521],
        [ 3.7899, -0.8641],
        [ 1.6574, -0.3977],
        [ 2.6365, -1.0022],
        [ 3.6528, -0.8160],
        [ 3.8605, -0.1074],
        [ 1.5757, -2.1420],
        [ 0.9897, -0.1928],
        [ 4.8392,  0.1518],
        [ 2.2276, -0.7557],
        [ 3.6888,  0.2933],
        [ 3.2383,  0.1311],
        [ 2.8987, -1.6291],
        [ 1.7249, -0.9256],
        [ 2.4321,  0.3025],
        [ 3.0736,  1.4414],
        [ 3.2322, -0.7036],
        [ 1.5121,  0.5651],
        [ 2.2122,  0.6929],
        [ 2.2206,  0.4395],
        [ 1.3385,  0.8792],
        [ 1.5592,  0.3054],
        [ 3.6447, -0.6356],
        [ 2.0611,  1.4160],
        [ 3.6631,  1.3462],
        [ 3.2628,  1.4179],
        [ 2.5578,  0.0170],
        [ 2.6071,  1.9462],
        [ 4.2352, -1.9760],
        [ 3.2748, -1.5610],
        [ 2.6056,  1.0544],
        [ 2.4220, -0.4502],
        [ 3.5368,  0.6422],
        [ 2.8400, -2.1863],
        [ 1.6469, -2.0553],
        [ 2.7737, -1.1386],
        [ 4.9488,  0.1838],
        [ 3.2816,  0.8292],
        [ 3.5953, -1.1235],
        [ 2.0789, -2.3060],
        [ 3.2081,  1.1989],
        [ 0.6151, -1.6353],
        [ 1.6518, -0.9949],
        [ 1.8086, -0.2008],
        [ 1.7282,  0.0073]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[2.7364e-06, 3.2918e-06, 1.3887e-04,  ..., 9.2989e-01, 9.6429e-01,
         1.0000e+00],
        [4.7252e-02, 4.7252e-02, 1.1774e-01,  ..., 9.8684e-01, 9.8684e-01,
         1.0000e+00],
        [7.1423e-02, 7.1452e-02, 7.1524e-02,  ..., 9.7792e-01, 9.9079e-01,
         1.0000e+00],
        ...,
        [1.0652e-02, 1.0421e-01, 1.0477e-01,  ..., 9.9358e-01, 9.9421e-01,
         1.0000e+00],
        [8.6970e-07, 3.4477e-01, 3.4750e-01,  ..., 9.8260e-01, 9.9960e-01,
         1.0000e+00],
        [7.3169e-07, 1.0781e-02, 8.3317e-02,  ..., 9.9009e-01, 1.0000e+00,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[7.2410e-01],
        [7.3140e-01],
        [3.0839e-01],
        [6.3693e-01],
        [2.4748e-01],
        [4.7156e-01],
        [2.8385e-01],
        [9.0308e-01],
        [1.9355e-03],
        [9.8726e-01],
        [6.4838e-01],
        [3.8005e-01],
        [4.1623e-01],
        [3.4537e-01],
        [3.7655e-01],
        [4.1583e-01],
        [3.0857e-01],
        [7.3752e-01],
        [5.7410e-02],
        [8.8475e-01],
        [6.4767e-01],
        [7.0290e-01],
        [6.0624e-01],
        [3.9668e-02],
        [7.9491e-01],
        [3.6950e-01],
        [3.9633e-01],
        [7.9018e-01],
        [4.1755e-01],
        [6.3118e-01],
        [6.3712e-01],
        [9.6587e-01],
        [5.4270e-01],
        [5.7773e-01],
        [2.6888e-02],
        [2.3635e-01],
        [7.5510e-01],
        [3.4481e-01],
        [5.0092e-03],
        [4.9879e-01],
        [7.6212e-02],
        [1.1098e-01],
        [6.3234e-01],
        [6.7083e-01],
        [1.4824e-01],
        [7.3943e-01],
        [3.4263e-01],
        [5.7433e-01],
        [2.8761e-01],
        [5.6730e-01],
        [9.4041e-02],
        [6.4244e-01],
        [5.2330e-01],
        [9.5706e-02],
        [7.2351e-01],
        [4.3631e-01],
        [1.6683e-01],
        [3.8986e-01],
        [3.5924e-01],
        [2.8140e-02],
        [5.3944e-01],
        [9.8688e-01],
        [1.4887e-01],
        [5.5890e-01],
        [8.1442e-01],
        [2.8027e-01],
        [7.8937e-03],
        [4.3768e-01],
        [4.6871e-01],
        [5.5616e-01],
        [1.5822e-01],
        [9.8843e-01],
        [7.1579e-01],
        [2.0453e-01],
        [3.5735e-01],
        [3.0425e-01],
        [9.1826e-01],
        [7.2403e-01],
        [8.8980e-01],
        [6.5273e-01],
        [6.2962e-01],
        [8.4859e-01],
        [4.6554e-01],
        [3.5309e-01],
        [8.5385e-01],
        [4.5564e-02],
        [9.6205e-01],
        [5.3957e-01],
        [5.8793e-01],
        [6.1591e-01],
        [2.8928e-02],
        [6.2062e-01],
        [1.5421e-01],
        [6.0873e-01],
        [5.6428e-01],
        [3.4976e-01],
        [5.9171e-01],
        [8.0753e-01],
        [7.3113e-01],
        [2.6317e-01],
        [4.9392e-01],
        [7.9036e-01],
        [3.5089e-01],
        [6.5996e-01],
        [5.1934e-01],
        [9.6382e-03],
        [8.4940e-01],
        [7.6270e-01],
        [1.9398e-01],
        [2.0297e-01],
        [5.3737e-01],
        [8.5077e-01],
        [9.2426e-01],
        [5.7255e-01],
        [7.0507e-01],
        [8.1141e-01],
        [4.9238e-01],
        [4.7668e-01],
        [1.5045e-01],
        [6.5500e-01],
        [5.8245e-01],
        [1.6561e-01],
        [7.4098e-01],
        [1.2756e-01],
        [1.3657e-01],
        [7.3694e-01],
        [8.2506e-01],
        [1.2410e-01],
        [5.7952e-01],
        [5.9498e-01],
        [9.3138e-01],
        [1.1895e-01],
        [3.6058e-01],
        [5.0956e-01],
        [1.1398e-01],
        [8.7724e-01],
        [6.6923e-02],
        [5.6221e-01],
        [4.3433e-01],
        [6.5741e-01],
        [5.6521e-01],
        [5.1663e-01],
        [5.8323e-01],
        [6.7124e-01],
        [5.5396e-02],
        [8.6117e-01],
        [8.5096e-01],
        [1.5706e-01],
        [3.9863e-01],
        [4.0497e-01],
        [1.3265e-01],
        [7.8560e-01],
        [8.7103e-02],
        [6.3039e-01],
        [1.2734e-01],
        [4.9616e-01],
        [3.4135e-01],
        [4.2412e-01],
        [2.6773e-01],
        [5.4293e-01],
        [6.4039e-02],
        [8.0594e-01],
        [2.2945e-01],
        [9.0374e-01],
        [3.9321e-01],
        [5.0867e-01],
        [6.4143e-01],
        [4.1177e-01],
        [2.9432e-02],
        [9.2663e-02],
        [1.7127e-01],
        [8.9677e-02],
        [6.0988e-01],
        [7.7746e-01],
        [7.5642e-01],
        [5.9786e-01],
        [8.5551e-01],
        [8.8502e-01],
        [4.8192e-01],
        [8.6457e-01],
        [2.1176e-01],
        [2.0058e-01],
        [5.0197e-01],
        [8.7698e-01],
        [4.1152e-01],
        [4.3931e-01],
        [1.4247e-01],
        [9.0939e-01],
        [9.1107e-01],
        [3.6306e-01],
        [5.7478e-01],
        [6.6120e-01],
        [5.2104e-01],
        [2.9795e-01],
        [5.7628e-01],
        [1.5151e-01],
        [5.4756e-01],
        [4.2449e-01],
        [7.9860e-01],
        [8.8196e-01],
        [8.8557e-01],
        [5.4377e-01],
        [5.6654e-01],
        [4.1858e-02],
        [4.6154e-01],
        [5.6387e-01],
        [8.1393e-01],
        [5.5202e-01],
        [1.9778e-01],
        [4.7218e-02],
        [9.1986e-01],
        [1.8983e-01],
        [1.8929e-01],
        [6.7415e-01],
        [9.3171e-01],
        [3.1257e-01],
        [1.6888e-01],
        [6.3862e-01],
        [4.6881e-01],
        [8.1923e-01],
        [1.3225e-02],
        [7.8015e-01],
        [1.1721e-01],
        [6.0018e-01],
        [2.7089e-01],
        [3.9319e-01],
        [8.3839e-01],
        [5.5523e-01],
        [4.8753e-01],
        [4.3553e-01],
        [3.5350e-01],
        [3.0368e-01],
        [2.5468e-01],
        [7.6817e-01],
        [6.6179e-02],
        [6.9423e-01],
        [9.0479e-01],
        [8.5239e-01],
        [2.4682e-01],
        [8.2064e-01],
        [1.9972e-03],
        [4.6821e-01],
        [4.8636e-01],
        [8.4696e-01],
        [4.4743e-01],
        [6.4257e-01],
        [6.0901e-01],
        [2.2033e-01],
        [6.4793e-01],
        [7.6111e-01],
        [8.3951e-01],
        [6.4989e-02],
        [4.6715e-02],
        [5.3125e-01],
        [8.1563e-01],
        [7.9609e-01],
        [2.3318e-01],
        [6.0671e-01],
        [4.0770e-05],
        [1.3643e-01],
        [9.8774e-01],
        [2.7342e-01],
        [6.5860e-01],
        [4.6580e-01],
        [6.2642e-01],
        [4.9026e-01],
        [1.2639e-01],
        [5.1742e-01],
        [1.3747e-01],
        [4.3061e-01],
        [2.5987e-01],
        [3.4893e-01],
        [8.8125e-01],
        [8.5189e-02],
        [3.2402e-01],
        [1.0781e-01],
        [3.3275e-01],
        [8.3320e-01],
        [9.3263e-01],
        [6.4145e-01],
        [1.9598e-02],
        [6.3697e-01],
        [2.3139e-01],
        [9.9086e-01],
        [8.1893e-02],
        [9.5421e-01],
        [9.5129e-02],
        [2.4622e-01],
        [7.9369e-01],
        [3.6806e-01],
        [2.7474e-01],
        [2.4580e-01],
        [5.1981e-01],
        [8.3429e-01],
        [7.5507e-01],
        [7.5237e-01],
        [4.9439e-01],
        [6.5312e-01],
        [6.4704e-01],
        [5.9037e-01],
        [8.0689e-01],
        [7.5269e-01],
        [5.2062e-02],
        [6.3599e-01],
        [1.9239e-01],
        [3.9173e-01],
        [9.2849e-01],
        [8.8729e-01],
        [3.0711e-01],
        [6.6435e-01],
        [5.0910e-01],
        [6.3608e-01]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-1.7626,  2.5913],
        [-2.4331,  0.7854],
        [-0.8169,  1.0625],
        ...,
        [ 1.8874,  1.1056],
        [ 1.0799,  0.9373],
        [-2.4379,  0.6437]]) torch.Size([9984, 2])
samples tensor([[ 4.2837e+00, -8.8502e-01],
        [ 3.7088e+00, -8.6289e-01],
        [ 2.4411e+00,  3.4825e-01],
        [ 2.4020e+00, -4.6282e-01],
        [ 3.5088e+00,  1.7409e+00],
        [ 2.7144e+00, -7.3335e-01],
        [ 3.1912e+00, -1.4227e+00],
        [ 3.2789e+00, -7.6721e-01],
        [ 3.0690e+00,  1.1631e+00],
        [ 1.3750e+00,  7.0951e-01],
        [ 3.2314e+00, -1.0913e+00],
        [ 1.6146e+00,  2.8618e-01],
        [ 4.5419e+00, -1.4912e+00],
        [ 1.2676e+00,  1.4454e+00],
        [ 8.8501e-01, -8.4649e-01],
        [ 1.5234e+00,  1.5235e+00],
        [ 3.7592e+00, -1.1930e+00],
        [ 7.6763e-01, -6.7597e-01],
        [ 1.9242e+00,  6.1347e-01],
        [ 3.8475e+00, -4.0391e-01],
        [ 2.1327e+00, -7.8380e-01],
        [ 3.5244e+00,  8.0775e-01],
        [ 2.8758e+00,  6.6896e-01],
        [ 1.6114e+00,  4.5490e-01],
        [ 8.3655e-01, -2.9318e-01],
        [ 2.1287e+00,  4.4238e-01],
        [ 9.6490e-01, -1.8424e+00],
        [ 2.1408e+00,  5.1620e-01],
        [ 2.7425e+00,  6.9456e-01],
        [ 3.3574e+00,  8.6056e-02],
        [ 4.1667e+00, -4.8885e-01],
        [ 1.5175e+00,  6.1336e-01],
        [ 2.0298e+00,  6.7576e-01],
        [ 1.5945e+00,  7.0133e-01],
        [ 2.2574e+00,  1.7794e+00],
        [ 2.8596e+00, -6.3812e-01],
        [ 2.8689e+00, -5.3144e-01],
        [ 4.6656e+00,  3.4421e-01],
        [ 4.4290e+00, -2.2159e+00],
        [ 3.1167e+00, -2.6769e-01],
        [ 2.0716e+00,  7.6597e-01],
        [ 2.7007e+00,  8.2478e-02],
        [ 9.5696e-01,  1.0060e+00],
        [ 1.4845e+00, -1.7371e-01],
        [ 3.1526e+00,  6.7023e-02],
        [ 1.7216e+00,  1.4060e+00],
        [ 2.1001e+00,  1.3621e+00],
        [ 3.2781e+00,  2.5549e-01],
        [ 3.1105e+00, -3.7236e-01],
        [ 3.0872e+00, -2.0572e+00],
        [ 2.4851e+00, -2.3790e-01],
        [ 2.2349e+00, -6.1396e-01],
        [ 3.2090e+00, -4.8643e-01],
        [ 1.5603e+00,  6.4005e-01],
        [ 1.4733e+00,  1.0092e-01],
        [ 3.5731e+00, -2.4068e+00],
        [ 2.2541e+00, -2.0405e-01],
        [ 2.9580e+00, -1.2405e+00],
        [ 4.7938e+00, -1.1439e+00],
        [ 2.6669e+00,  3.5621e-01],
        [ 1.5787e+00,  8.7527e-01],
        [ 2.0938e+00,  7.1867e-01],
        [ 2.6316e+00,  4.7429e-01],
        [ 2.8005e+00, -1.7547e+00],
        [ 1.1884e+00, -1.9101e-01],
        [ 1.8379e+00, -1.1497e+00],
        [ 3.0411e+00,  1.8639e+00],
        [ 3.8670e-01, -1.4580e+00],
        [ 3.1984e+00, -4.1440e-01],
        [ 2.2266e+00,  1.2930e-01],
        [ 1.7687e+00,  3.2187e-01],
        [ 1.2318e-01, -4.8196e-01],
        [ 1.6309e+00,  3.5821e-01],
        [ 1.9196e+00, -9.4750e-01],
        [ 1.0343e+00, -2.4621e+00],
        [ 4.3197e+00, -9.3106e-02],
        [ 4.1939e+00,  1.0713e+00],
        [ 2.0828e+00, -5.0339e-01],
        [ 3.0094e+00,  7.5717e-01],
        [ 1.7112e+00, -2.8433e+00],
        [ 2.7360e+00,  8.7167e-01],
        [ 4.3462e+00, -2.0282e-01],
        [ 2.0931e+00, -8.8640e-01],
        [ 3.5893e+00,  8.9228e-01],
        [ 1.7009e-01,  3.1368e-01],
        [ 1.8177e+00, -5.1895e-01],
        [ 1.8927e+00,  1.2925e+00],
        [ 3.4733e+00, -2.2168e+00],
        [ 3.5399e+00,  8.6467e-01],
        [ 3.2381e+00,  1.2728e+00],
        [ 1.6885e+00,  6.3899e-01],
        [ 2.2693e+00, -4.7994e-01],
        [ 2.7684e+00, -3.4902e-01],
        [ 4.2448e+00,  1.9161e-01],
        [ 2.3816e+00,  6.4727e-02],
        [ 7.7277e-01, -1.4287e+00],
        [ 1.9095e+00,  2.4817e-01],
        [ 2.4539e+00,  1.0643e+00],
        [ 1.9040e+00, -7.2195e-01],
        [ 2.9784e+00, -5.1013e-01],
        [ 2.8879e+00,  8.0244e-01],
        [ 3.0335e+00, -2.3109e-01],
        [ 4.1723e+00, -1.2860e+00],
        [ 2.1918e+00,  2.6160e-01],
        [ 1.7095e+00, -8.6072e-01],
        [ 2.5130e+00,  1.0296e+00],
        [ 2.4211e+00,  1.6811e+00],
        [ 1.1142e+00,  9.9503e-01],
        [ 4.4661e-01,  4.5632e-01],
        [ 4.1465e+00,  7.2573e-01],
        [ 3.3500e+00, -1.4737e+00],
        [ 3.0711e+00, -8.0185e-01],
        [ 2.5703e+00,  1.3293e-01],
        [ 2.6645e+00, -7.5605e-01],
        [ 3.1756e+00, -6.8346e-01],
        [ 3.1965e+00, -3.2811e-02],
        [ 2.4093e+00,  1.1926e+00],
        [ 2.9130e+00, -1.0338e+00],
        [ 4.1858e+00,  7.1652e-02],
        [ 2.2339e+00, -4.8469e-01],
        [ 2.5875e+00,  1.7717e+00],
        [ 2.7105e+00, -3.1119e-01],
        [ 2.3057e+00,  1.1052e+00],
        [ 2.2752e+00, -1.5585e+00],
        [ 2.9285e+00, -1.5220e+00],
        [ 1.8782e+00,  7.1074e-01],
        [ 4.7479e+00, -1.5346e+00],
        [ 1.9519e+00, -3.3263e-01],
        [ 3.7588e+00,  3.1470e-01],
        [ 2.6543e+00,  4.4119e-01],
        [ 1.8751e+00,  5.0484e-01],
        [ 2.4796e+00,  1.0541e+00],
        [ 2.5095e+00,  7.2458e-01],
        [ 3.0558e+00, -8.2290e-01],
        [ 2.4479e+00,  3.7471e-01],
        [ 1.9585e+00,  2.6109e-01],
        [ 2.0489e+00, -3.1786e-03],
        [ 1.1457e+00, -2.3354e+00],
        [ 1.1121e+00, -1.0315e+00],
        [ 2.5100e+00, -1.3110e+00],
        [ 4.0882e+00, -8.0192e-01],
        [ 3.3090e+00,  3.0827e-01],
        [ 3.0967e+00, -1.0194e+00],
        [ 4.0827e+00,  1.6958e-01],
        [ 1.8633e+00,  2.9419e-01],
        [ 2.1451e+00, -1.2528e+00],
        [ 2.5496e+00,  1.7810e-02],
        [ 2.6286e+00, -6.2313e-02],
        [ 2.5214e+00, -7.0783e-01],
        [ 4.2636e+00, -3.7459e+00],
        [ 3.6124e+00, -6.7981e-01],
        [ 3.8471e+00, -2.3199e+00],
        [ 1.9158e+00,  8.9943e-01],
        [ 3.3920e+00, -2.2415e+00],
        [ 2.7890e+00, -4.2217e-02],
        [ 1.5315e+00, -5.6023e-01],
        [ 1.6304e+00,  1.1108e+00],
        [ 2.4760e+00, -1.0713e+00],
        [ 3.7715e-01,  6.5614e-01],
        [ 1.0620e+00,  7.3818e-02],
        [ 1.9144e+00,  2.3884e-01],
        [ 1.6763e+00, -5.3032e-01],
        [ 2.5037e+00, -1.6187e-01],
        [ 1.1676e+00, -8.9948e-01],
        [ 4.0058e+00, -1.5817e+00],
        [ 1.3580e+00, -1.2308e+00],
        [ 1.3672e+00,  1.0705e-04],
        [ 2.5982e+00, -1.6250e+00],
        [ 1.8626e+00,  5.1887e-01],
        [ 2.5271e+00, -3.0413e-01],
        [ 3.3622e+00,  1.9105e-01],
        [ 2.7455e+00,  8.0055e-01],
        [ 2.8038e+00,  2.3278e-01],
        [ 1.9289e+00, -1.0400e+00],
        [ 2.1095e+00, -5.3196e-01],
        [ 3.9527e+00,  1.9739e-01],
        [ 1.9774e+00,  1.7029e+00],
        [ 2.1653e+00, -3.5604e-01],
        [ 2.0543e+00,  6.1577e-01],
        [ 3.3565e+00, -4.7824e-01],
        [ 2.0107e+00,  8.8817e-02],
        [ 2.3473e+00,  1.3219e+00],
        [ 2.6123e+00, -2.0907e+00],
        [ 2.7751e+00, -2.1964e-01],
        [ 2.1053e+00,  1.9737e+00],
        [ 3.5921e+00,  2.5457e+00],
        [ 2.7095e+00,  8.8301e-02],
        [ 7.5951e-01, -8.7484e-01],
        [ 2.4944e+00,  2.3068e-01],
        [ 8.6160e-01, -6.7937e-01],
        [ 2.3678e+00, -1.7733e+00],
        [ 4.1572e+00, -2.5294e+00],
        [ 4.1899e+00, -8.9525e-01],
        [ 2.7033e+00, -5.8220e-01],
        [ 4.0357e+00, -2.1616e+00],
        [ 2.1100e+00,  5.1614e-01],
        [ 4.3236e+00,  1.4941e+00],
        [ 2.8040e+00, -5.7775e-01],
        [ 3.5768e+00, -1.8889e+00],
        [ 1.4704e+00,  3.8972e-01],
        [ 2.6057e+00, -5.2659e-01],
        [ 2.3468e+00, -1.1980e+00],
        [-1.1353e+00, -1.1574e+00],
        [ 1.3367e+00,  9.1802e-01],
        [ 3.0952e+00,  1.4732e+00],
        [ 2.4468e+00, -1.5934e-01],
        [ 2.9537e+00, -9.3210e-01],
        [ 2.1922e+00,  3.3052e-01],
        [ 2.4856e+00, -1.5788e+00],
        [ 1.7853e+00,  4.7995e-01],
        [ 2.9445e+00, -2.4234e-01],
        [ 2.5997e+00, -1.0246e+00],
        [ 2.8505e+00, -3.1168e-01],
        [ 4.2228e+00,  1.6677e+00],
        [ 2.3577e+00,  3.8835e-01],
        [ 1.1403e+00, -1.4540e+00],
        [ 2.2134e+00, -1.0792e+00],
        [ 3.0626e+00, -8.9367e-01],
        [ 2.2456e+00, -8.2852e-01],
        [ 3.1942e+00,  7.4540e-01],
        [ 9.2470e-01,  1.4513e-01],
        [ 3.4068e+00, -9.4572e-01],
        [ 3.2136e+00, -2.5677e+00],
        [ 3.2041e+00,  7.8558e-01],
        [ 3.3867e+00,  4.0044e-01],
        [ 5.2993e-01, -1.1072e-01],
        [ 1.4150e+00,  1.4917e-01],
        [ 1.8814e+00, -6.2556e-02],
        [ 2.1710e+00,  1.0758e+00],
        [ 2.0361e+00, -1.4289e+00],
        [ 2.3804e+00, -1.5252e+00],
        [ 1.0970e+00,  6.0492e-01],
        [ 3.5952e+00,  1.6568e+00],
        [ 3.1585e+00, -1.5528e+00],
        [ 1.6696e+00,  4.9989e-01],
        [ 2.4857e+00,  5.4938e-01],
        [ 2.0556e+00, -1.8397e-02],
        [ 3.2569e+00, -1.2997e+00],
        [ 2.7988e+00, -8.1886e-01],
        [ 2.9186e+00, -1.8050e+00],
        [ 3.5625e-01,  3.8358e-02],
        [ 2.1766e+00, -7.8004e-01],
        [ 3.4470e+00, -4.3517e-01],
        [ 3.6683e+00, -2.7028e-01],
        [ 2.2347e+00, -2.1667e-01],
        [ 1.9039e+00,  1.6152e+00],
        [ 2.2902e+00,  5.7558e-01],
        [ 2.0358e+00,  1.0975e+00],
        [ 1.5349e+00, -1.5416e+00],
        [ 3.3978e+00, -5.1615e-01],
        [ 2.6682e-01, -6.5158e-01],
        [ 1.7460e+00,  6.4705e-01],
        [ 1.5187e+00,  4.8934e-01],
        [ 1.6644e+00, -2.3149e+00],
        [ 3.8759e+00,  6.2774e-01],
        [ 1.7444e+00,  6.9348e-02],
        [ 1.1096e+00,  4.0783e-01],
        [ 1.2084e+00, -5.4748e-01],
        [ 4.4783e+00, -9.8398e-01],
        [ 3.8662e+00,  9.9942e-01],
        [ 3.3556e+00, -2.5671e+00],
        [ 2.6341e+00,  2.2223e-01],
        [ 1.2991e+00, -1.1036e+00],
        [ 2.7941e+00, -1.0916e+00],
        [ 3.8872e+00, -1.7363e-01],
        [ 6.4468e-01, -1.7852e+00],
        [ 2.9923e+00,  3.9525e-01],
        [ 2.2383e+00, -2.0806e-01],
        [ 2.1136e+00,  3.6637e-01],
        [ 1.1202e+00, -1.7134e+00],
        [ 4.2076e+00, -1.6829e+00],
        [ 1.8854e+00,  1.0684e-01],
        [ 3.2409e+00,  5.8522e-01],
        [ 1.9270e+00, -1.7537e+00],
        [ 3.1608e+00, -1.3821e+00],
        [ 1.4867e+00, -9.7866e-01],
        [ 3.0482e+00,  3.4801e-01],
        [ 3.6542e+00, -6.6914e-01],
        [ 2.8808e+00,  8.2327e-01],
        [ 1.3074e+00,  8.3312e-01],
        [ 1.8057e+00,  5.8454e-01],
        [ 2.7097e+00,  2.5801e-01],
        [ 1.5205e+00,  6.4901e-01],
        [ 6.7009e-01, -1.1546e+00],
        [ 1.4302e+00, -1.1266e-01],
        [ 2.9934e+00,  2.1386e+00],
        [ 1.5739e+00, -8.4010e-01],
        [ 2.9594e+00, -7.3117e-03],
        [ 2.6211e+00,  2.0658e-02],
        [ 1.5543e+00, -1.7219e+00],
        [ 1.5260e+00,  9.1423e-01],
        [ 3.1493e+00, -1.7991e+00],
        [ 2.7053e+00, -1.0017e+00],
        [ 1.9916e+00,  2.0684e-01],
        [ 2.8538e+00, -5.1779e-01],
        [ 1.3785e+00, -3.9736e-01],
        [ 3.5648e+00,  1.2273e+00],
        [ 2.4587e+00, -4.0786e-01],
        [ 1.0408e+00,  9.1333e-01],
        [ 1.6787e+00, -3.4521e-01],
        [ 2.2373e+00, -1.7860e+00],
        [ 1.2590e+00, -2.5248e+00],
        [ 2.3394e+00,  8.6646e-01],
        [ 2.7888e+00,  2.4309e+00],
        [ 2.3874e+00, -6.3496e-01],
        [ 1.9386e+00, -1.3461e+00],
        [ 3.7233e+00, -1.6176e+00],
        [ 2.9241e+00,  8.8637e-01],
        [ 3.7087e+00,  6.8921e-01],
        [ 1.6466e+00,  3.4867e-02],
        [ 2.3546e+00, -1.7662e-01],
        [ 6.2629e-01, -1.3923e+00]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[6.0472e-03, 6.0472e-03, 1.8282e-02,  ..., 9.7753e-01, 1.0000e+00,
         1.0000e+00],
        [2.5264e-02, 2.5264e-02, 3.0328e-02,  ..., 9.9719e-01, 9.9726e-01,
         1.0000e+00],
        [3.1696e-02, 3.1697e-02, 3.6318e-02,  ..., 8.4158e-01, 8.4255e-01,
         1.0000e+00],
        ...,
        [2.6932e-05, 1.5258e-03, 1.5271e-03,  ..., 9.4119e-01, 9.4399e-01,
         1.0000e+00],
        [8.4984e-05, 8.4986e-03, 8.5645e-03,  ..., 9.6005e-01, 9.6698e-01,
         1.0000e+00],
        [2.4355e-03, 2.4365e-03, 4.8751e-02,  ..., 9.8897e-01, 1.0000e+00,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.1788],
        [0.0315],
        [0.5880],
        [0.5029],
        [0.6750],
        [0.7497],
        [0.5103],
        [0.3571],
        [0.5345],
        [0.5693],
        [0.8721],
        [0.3841],
        [0.3620],
        [0.7376],
        [0.7406],
        [0.3944],
        [0.6119],
        [0.9727],
        [0.8705],
        [0.1956],
        [0.9594],
        [0.5227],
        [0.3722],
        [0.1022],
        [0.8363],
        [0.6765],
        [0.9596],
        [0.4272],
        [0.8407],
        [0.4164],
        [0.4758],
        [0.2756],
        [0.4041],
        [0.4850],
        [0.8235],
        [0.0908],
        [0.9137],
        [0.4827],
        [0.8238],
        [0.2219],
        [0.7573],
        [0.0437],
        [0.9286],
        [0.2685],
        [0.5080],
        [0.8729],
        [0.7007],
        [0.8828],
        [0.8770],
        [0.5064],
        [0.0536],
        [0.0479],
        [0.7126],
        [0.9087],
        [0.8490],
        [0.8567],
        [0.9528],
        [0.5650],
        [0.9146],
        [0.5973],
        [0.6539],
        [0.6711],
        [0.8310],
        [0.1965],
        [0.6942],
        [0.1559],
        [0.2091],
        [0.3347],
        [0.5906],
        [0.2044],
        [0.5440],
        [0.6776],
        [0.5546],
        [0.7445],
        [0.6625],
        [0.7974],
        [0.2382],
        [0.9677],
        [0.5016],
        [0.8997],
        [0.7730],
        [0.0026],
        [0.6197],
        [0.4840],
        [0.3939],
        [0.5931],
        [0.6334],
        [0.0941],
        [0.5145],
        [0.0306],
        [0.7151],
        [0.1629],
        [0.3080],
        [0.7008],
        [0.3336],
        [0.5269],
        [0.1787],
        [0.9140],
        [0.0189],
        [0.6462],
        [0.7889],
        [0.9286],
        [0.2977],
        [0.7437],
        [0.1227],
        [0.9533],
        [0.0939],
        [0.9482],
        [0.3862],
        [0.7337],
        [0.3446],
        [0.7313],
        [0.7032],
        [0.4136],
        [0.4556],
        [0.7928],
        [0.6209],
        [0.6573],
        [0.5652],
        [0.0437],
        [0.0868],
        [0.2978],
        [0.1979],
        [0.2048],
        [0.7278],
        [0.8711],
        [0.2948],
        [0.4573],
        [0.5702],
        [0.3052],
        [0.2268],
        [0.5144],
        [0.7723],
        [0.8219],
        [0.9420],
        [0.1257],
        [0.4758],
        [0.0643],
        [0.6357],
        [0.0337],
        [0.5106],
        [0.6359],
        [0.3556],
        [0.4065],
        [0.8610],
        [0.3671],
        [0.6117],
        [0.2895],
        [0.8074],
        [0.7910],
        [0.1084],
        [0.8244],
        [0.7620],
        [0.6178],
        [0.5819],
        [0.9979],
        [0.8774],
        [0.8153],
        [0.0426],
        [0.5110],
        [0.7137],
        [0.8256],
        [0.5113],
        [0.5126],
        [0.7109],
        [0.9386],
        [0.4800],
        [0.7514],
        [0.0537],
        [0.2397],
        [0.3374],
        [0.0326],
        [0.0287],
        [0.0132],
        [0.4765],
        [0.9095],
        [0.3943],
        [0.1644],
        [0.4595],
        [0.8864],
        [0.4582],
        [0.9269],
        [0.6153],
        [0.0822],
        [0.8623],
        [0.3076],
        [0.9393],
        [0.1863],
        [0.1785],
        [0.7381],
        [0.5603],
        [0.4952],
        [0.3130],
        [0.1637],
        [0.7120],
        [0.0825],
        [0.4540],
        [0.7800],
        [0.2613],
        [0.8586],
        [0.0820],
        [0.3502],
        [0.1896],
        [0.6427],
        [0.4649],
        [0.3638],
        [0.0298],
        [0.6969],
        [0.6966],
        [0.6685],
        [0.0657],
        [0.6748],
        [0.1131],
        [0.4724],
        [0.4490],
        [0.3666],
        [0.3894],
        [0.6276],
        [0.2083],
        [0.4938],
        [0.2654],
        [0.0448],
        [0.2057],
        [0.4299],
        [0.3505],
        [0.7821],
        [0.5172],
        [0.7954],
        [0.0278],
        [0.2304],
        [0.2633],
        [0.0389],
        [0.3786],
        [0.6766],
        [0.3567],
        [0.2972],
        [0.3587],
        [0.2001],
        [0.0532],
        [0.1688],
        [0.3419],
        [0.0303],
        [0.1128],
        [0.1886],
        [0.8435],
        [0.1118],
        [0.5980],
        [0.0497],
        [0.2646],
        [0.9386],
        [0.4188],
        [0.1610],
        [0.4818],
        [0.9443],
        [0.2982],
        [0.1699],
        [0.3009],
        [0.2174],
        [0.1679],
        [0.6350],
        [0.5269],
        [0.8346],
        [0.3356],
        [0.4555],
        [0.5120],
        [0.2818],
        [0.7863],
        [0.4923],
        [0.2148],
        [0.4060],
        [0.6244],
        [0.6231],
        [0.6727],
        [0.5720],
        [0.4778],
        [0.0472],
        [0.3759],
        [0.5495],
        [0.0670],
        [0.7439],
        [0.4656],
        [0.7313],
        [0.0758],
        [0.2775],
        [0.4855],
        [0.7933],
        [0.1067],
        [0.8393],
        [0.7457],
        [0.5475],
        [0.2653],
        [0.9322],
        [0.2550],
        [0.7143],
        [0.6503],
        [0.5842],
        [0.4031],
        [0.3067],
        [0.3200],
        [0.9231],
        [0.0517],
        [0.4561],
        [0.8432],
        [0.4019],
        [0.8237],
        [0.4550],
        [0.7170],
        [0.8336],
        [0.7921],
        [0.5518],
        [0.1360],
        [0.3981]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 1.7216,  2.4647],
        [-3.9924,  0.6029],
        [ 0.6497,  0.3499],
        ...,
        [-1.9344,  1.8395],
        [ 2.1071,  1.8656],
        [-3.1773,  2.1948]]) torch.Size([9984, 2])
samples tensor([[ 1.6437e+00, -7.4844e-01],
        [ 7.7750e-01,  1.9505e-01],
        [ 2.4083e+00,  4.2907e-01],
        [ 1.8980e+00,  8.1617e-01],
        [ 2.2277e+00,  1.2194e+00],
        [ 2.2840e+00, -3.8158e-01],
        [ 1.8336e+00, -4.4810e-01],
        [ 2.8606e+00,  1.2067e+00],
        [ 3.8168e+00, -1.7247e+00],
        [ 2.7537e+00, -8.2532e-01],
        [ 1.5042e+00,  2.2845e+00],
        [ 2.5564e+00, -4.8896e-01],
        [ 3.8644e+00,  1.5093e+00],
        [ 1.2489e+00,  7.5349e-01],
        [ 6.0983e-01,  4.8856e-01],
        [ 3.0382e+00, -2.8588e-01],
        [ 2.9154e+00, -1.8896e+00],
        [ 3.3728e+00, -1.6329e+00],
        [ 3.8120e+00,  4.2314e-01],
        [ 3.3034e+00, -8.9001e-01],
        [ 3.8010e-01,  4.3964e-01],
        [ 1.2680e+00,  2.6291e-01],
        [ 3.5559e+00,  4.1745e-01],
        [ 3.0805e+00, -6.2923e-02],
        [ 2.0241e+00, -6.8315e-01],
        [ 1.9131e+00, -1.5707e+00],
        [ 5.7578e-01,  4.6773e-01],
        [ 2.3190e+00, -1.1517e+00],
        [ 1.3415e+00,  7.2033e-01],
        [ 2.5161e+00, -8.7687e-01],
        [ 2.1139e-01,  8.1594e-01],
        [ 3.3201e+00, -1.1507e-01],
        [ 3.7660e+00, -2.7799e-01],
        [ 2.5221e+00,  1.1301e+00],
        [ 9.2511e-01,  1.3128e+00],
        [ 2.5288e+00, -5.6627e-01],
        [ 4.0670e+00, -1.2270e-01],
        [ 3.4439e+00, -1.9035e+00],
        [ 2.8549e+00,  1.1961e+00],
        [ 1.4883e+00,  5.1012e-01],
        [ 3.4393e+00, -7.9757e-02],
        [ 5.0440e-01, -3.4878e-01],
        [ 2.3954e+00,  9.0329e-01],
        [ 2.8726e+00, -1.5621e+00],
        [ 1.8247e+00, -1.3021e+00],
        [ 3.0519e+00,  1.9824e+00],
        [ 2.2273e+00,  1.0109e-01],
        [ 2.9438e+00,  4.9102e-01],
        [ 3.4565e+00, -3.2245e-01],
        [ 2.1923e+00, -4.3758e-01],
        [ 1.0316e+00,  6.8893e-01],
        [ 1.2575e+00, -1.7783e-01],
        [ 1.8382e+00,  3.2897e-01],
        [ 2.0152e+00, -1.0906e-01],
        [ 2.8011e+00, -1.2350e+00],
        [ 9.1763e-01,  2.3025e-02],
        [ 2.3840e+00,  1.5419e+00],
        [ 3.0841e+00,  8.0527e-01],
        [ 2.1941e+00,  6.1635e-01],
        [ 3.7742e+00, -5.8988e-02],
        [ 3.1509e+00,  2.2053e-01],
        [ 1.7170e+00, -4.2134e-01],
        [ 4.8933e+00, -9.4426e-01],
        [ 1.8445e+00, -1.0404e+00],
        [ 1.5697e+00, -3.5241e-01],
        [ 1.2414e+00,  2.8389e-01],
        [ 2.4232e+00,  8.3230e-01],
        [ 2.3596e+00,  1.3646e-01],
        [ 2.0809e+00, -8.1779e-01],
        [ 1.2002e+00,  1.6548e-01],
        [ 2.1831e+00, -1.4239e+00],
        [ 3.9798e+00, -6.7868e-01],
        [ 8.5204e-01, -1.8139e+00],
        [ 8.7579e-01,  7.3337e-01],
        [ 4.3356e+00, -6.5386e-01],
        [ 3.0279e+00,  1.3220e-01],
        [ 3.2236e+00,  8.6904e-01],
        [ 4.2454e+00,  1.5770e-01],
        [ 7.5806e-01, -1.3676e+00],
        [ 2.8381e+00,  7.8230e-01],
        [ 2.6310e+00, -7.6313e-01],
        [ 1.1282e+00,  1.0501e+00],
        [ 4.6889e+00,  2.8726e-01],
        [ 1.6515e-01,  4.9863e-01],
        [ 2.1642e+00, -2.9246e-01],
        [ 2.0228e+00,  4.2385e-01],
        [ 2.9804e+00, -1.2911e-01],
        [ 1.1813e+00,  1.5653e-01],
        [ 2.2883e+00, -6.9952e-01],
        [-3.5305e-01,  5.0417e-01],
        [ 2.0247e+00, -2.9619e-01],
        [ 1.8288e+00, -2.6634e-02],
        [ 1.1263e+00, -1.3439e+00],
        [ 3.0255e+00, -1.2209e+00],
        [ 2.7358e+00,  3.7883e-01],
        [ 2.7303e+00,  3.0181e-01],
        [ 2.2188e+00, -3.8960e-01],
        [ 1.5069e+00, -1.1648e+00],
        [ 1.8951e+00,  1.6951e+00],
        [ 3.6373e+00,  5.8200e-01],
        [ 2.0365e+00, -3.6653e-01],
        [ 3.3840e+00,  3.3859e-01],
        [ 2.2767e+00, -2.7094e+00],
        [ 3.8348e+00, -1.1632e+00],
        [ 2.6706e+00, -8.5457e-02],
        [ 9.7629e-01, -6.1804e-01],
        [ 3.8246e+00, -2.6070e-01],
        [ 3.1157e+00,  1.1327e+00],
        [ 2.7359e+00,  1.2829e+00],
        [ 1.4105e+00,  8.0641e-01],
        [ 1.9642e+00, -1.6932e+00],
        [ 4.5627e+00, -5.1475e-01],
        [ 3.2860e+00,  3.4386e-01],
        [ 4.4158e+00,  1.1984e+00],
        [ 1.5600e+00,  1.0283e+00],
        [ 2.2352e+00, -2.0752e+00],
        [ 1.6618e+00, -1.0231e+00],
        [ 1.3492e+00,  6.3629e-01],
        [ 2.0871e+00, -8.7292e-01],
        [ 3.8643e+00,  1.7497e+00],
        [ 1.5292e+00, -3.1165e-01],
        [ 2.0478e+00, -1.1692e+00],
        [ 3.1307e+00, -4.8718e-02],
        [ 2.5946e+00, -1.2774e+00],
        [ 1.7985e+00, -2.3544e-01],
        [ 1.3625e+00,  3.1613e-01],
        [ 2.4219e+00, -6.3253e-01],
        [ 1.3118e+00, -7.3776e-01],
        [ 3.5898e+00, -1.9010e+00],
        [ 4.0840e+00, -1.9450e-01],
        [ 2.8415e+00,  1.2238e+00],
        [ 2.4627e+00, -5.5118e-01],
        [ 1.9770e+00,  4.3574e-01],
        [ 1.6805e+00, -9.9546e-01],
        [ 1.2663e+00, -7.4480e-01],
        [ 1.9412e+00,  4.3630e-01],
        [ 1.4192e+00, -1.7485e+00],
        [ 3.0892e+00,  1.2906e+00],
        [ 1.5571e+00, -5.7388e-01],
        [ 9.1817e-01,  2.8559e-01],
        [ 1.6927e+00, -1.8258e+00],
        [ 3.0860e+00, -1.4765e+00],
        [ 1.5803e+00, -1.4105e-02],
        [ 2.8034e+00, -7.0490e-01],
        [ 8.2564e-01, -3.0131e-01],
        [ 3.3134e+00,  7.8028e-01],
        [ 3.4927e+00, -1.3787e+00],
        [ 2.6722e+00, -2.0291e+00],
        [ 1.3258e+00, -4.1716e-01],
        [ 3.2507e+00, -5.9782e-02],
        [ 1.7739e+00, -1.9490e-01],
        [ 2.5942e+00,  2.2725e-01],
        [ 2.3826e+00, -2.0215e-02],
        [ 1.8143e+00,  1.0633e+00],
        [ 4.4219e+00, -9.9515e-01],
        [ 1.6195e+00,  9.8776e-02],
        [ 2.7949e+00,  8.6179e-01],
        [ 3.0790e+00, -1.2457e+00],
        [ 1.8067e+00,  6.4060e-01],
        [ 3.0672e+00, -3.6129e-01],
        [ 1.6318e+00,  6.1121e-01],
        [ 1.3657e+00, -2.8513e-02],
        [ 3.1174e+00, -1.5957e+00],
        [ 2.5562e+00,  6.5907e-01],
        [ 4.0404e+00, -1.5461e+00],
        [ 4.3936e+00, -8.8490e-01],
        [ 2.3866e+00, -9.8948e-02],
        [ 3.8538e+00,  3.6338e-01],
        [ 3.1625e+00,  1.5186e+00],
        [ 1.6886e+00, -7.0487e-01],
        [ 2.0441e+00, -1.6745e-01],
        [ 4.0776e+00, -3.1471e-01],
        [ 3.2059e+00, -8.8394e-01],
        [ 1.8375e+00,  3.2230e-01],
        [ 2.4960e+00,  4.6508e-01],
        [ 2.6857e+00, -1.4376e+00],
        [ 2.9917e+00,  2.1193e+00],
        [ 2.1420e+00,  2.9615e-01],
        [ 9.6490e-01, -9.8345e-01],
        [ 2.6779e+00, -2.3251e-01],
        [ 2.0082e+00, -5.9715e-01],
        [ 3.3140e+00,  2.9383e-01],
        [ 2.4565e+00, -2.0462e+00],
        [ 2.1203e+00,  2.7738e-01],
        [ 3.4424e+00, -4.4378e-01],
        [ 1.4600e+00, -1.4632e+00],
        [ 2.3316e+00,  5.5212e-01],
        [ 2.0336e+00, -1.5060e-01],
        [ 1.9142e+00, -4.9896e-01],
        [ 4.9282e+00, -8.4021e-01],
        [ 1.7295e+00,  2.3404e-01],
        [ 3.4586e+00,  3.3770e-01],
        [ 2.2184e+00,  4.8176e-01],
        [ 3.5994e+00, -4.5049e-01],
        [ 3.8096e+00, -5.6496e-01],
        [ 1.6036e+00,  8.5717e-02],
        [ 1.3633e+00, -1.9531e+00],
        [ 2.2022e+00, -1.1086e-01],
        [ 4.2789e+00,  8.7351e-02],
        [ 2.0651e+00, -5.0064e-01],
        [ 2.5365e+00, -1.3938e+00],
        [ 2.2453e+00, -6.1086e-01],
        [ 3.5108e+00, -1.7948e+00],
        [ 2.8420e+00,  2.6300e+00],
        [ 1.3966e+00,  8.5309e-01],
        [ 2.1099e+00,  1.7433e+00],
        [ 2.9270e+00, -1.6875e-01],
        [ 4.4542e-01, -2.0865e+00],
        [ 1.3065e+00,  9.2941e-02],
        [ 2.9367e+00,  1.6111e+00],
        [ 2.3105e+00,  3.4311e-01],
        [ 6.9174e-01,  1.3168e-02],
        [ 3.0718e+00,  1.2363e+00],
        [ 5.3286e-01,  5.6079e-01],
        [ 3.8179e+00,  4.5692e-01],
        [ 2.2750e+00, -7.2733e-01],
        [ 2.2142e+00, -8.3803e-01],
        [ 1.1800e+00, -4.1098e-01],
        [ 3.7552e+00,  4.4848e-01],
        [ 1.5942e+00, -1.4880e+00],
        [ 2.7175e+00, -3.2825e-01],
        [ 2.3663e+00,  9.6473e-01],
        [ 3.6263e+00,  1.5845e+00],
        [ 3.4163e+00, -2.0853e-01],
        [ 1.4394e+00,  7.5855e-01],
        [ 1.9666e+00, -3.6441e-01],
        [ 3.7503e+00, -1.6680e-01],
        [ 2.3445e+00, -9.6749e-01],
        [ 3.2293e+00, -7.4986e-01],
        [ 2.6143e+00,  1.2320e+00],
        [ 1.7346e+00, -9.4639e-01],
        [ 2.5089e+00, -6.6315e-02],
        [ 2.0065e+00, -4.3757e-01],
        [ 2.7247e+00,  3.6275e-01],
        [ 4.2996e+00, -8.5383e-01],
        [ 2.8253e+00, -3.7046e-01],
        [ 2.6905e+00,  5.5180e-01],
        [ 2.7842e+00, -3.9170e-01],
        [ 2.1701e+00,  4.4063e-01],
        [ 2.7426e+00, -7.8742e-02],
        [ 1.8263e+00,  9.3675e-01],
        [ 1.4849e+00, -1.3374e-01],
        [ 3.4245e+00, -2.0739e+00],
        [ 4.5409e+00,  1.5119e-02],
        [ 2.2470e+00, -2.8184e-01],
        [ 2.2247e+00, -1.7873e-01],
        [ 3.3136e+00,  1.0288e+00],
        [ 1.6108e+00,  4.4682e-01],
        [ 3.9134e+00, -1.1257e+00],
        [ 2.9378e+00,  8.8820e-01],
        [ 2.5173e+00,  1.6977e-02],
        [ 2.5058e+00,  1.4311e+00],
        [ 2.3559e+00,  1.6702e-01],
        [ 3.1017e+00, -8.6207e-01],
        [ 2.9962e+00, -1.4620e-01],
        [ 1.8722e+00, -5.1925e-01],
        [ 2.8121e+00, -2.2185e+00],
        [ 1.5823e+00, -1.2643e-01],
        [ 1.7340e+00, -2.6859e-01],
        [ 3.7766e+00, -1.3757e+00],
        [ 8.1859e-01,  4.3183e-01],
        [ 2.1376e+00, -2.3597e-01],
        [ 3.7650e+00, -1.1217e+00],
        [ 2.9830e+00, -2.4547e+00],
        [ 1.1424e+00, -1.2870e+00],
        [ 2.7281e+00,  9.9171e-01],
        [ 4.3198e+00,  8.7906e-01],
        [ 2.5075e+00, -1.7945e+00],
        [ 3.7235e+00, -1.7012e+00],
        [ 7.3998e-01, -6.9610e-01],
        [ 2.1621e+00, -8.2707e-01],
        [ 3.5142e+00, -1.1992e+00],
        [ 2.1270e-01,  1.2673e+00],
        [ 1.5767e+00,  5.8122e-01],
        [ 4.6978e+00,  1.3795e-01],
        [ 7.9195e-01,  1.4828e-01],
        [ 1.4151e+00,  6.9674e-01],
        [ 1.2125e+00, -1.0282e+00],
        [ 1.2214e+00,  1.8473e-03],
        [ 3.0564e+00, -8.8628e-01],
        [ 1.4226e+00,  1.4861e-01],
        [ 1.9247e+00, -1.7999e-02],
        [ 1.3163e+00,  1.0148e+00],
        [ 2.3334e+00,  6.3973e-02],
        [ 1.4075e+00, -1.4631e+00],
        [ 1.5970e+00,  1.4726e-02],
        [ 1.4320e+00,  7.9244e-01],
        [ 3.4438e+00,  1.4105e-01],
        [ 1.6273e+00,  1.4173e+00],
        [ 3.3910e+00, -6.8120e-02],
        [ 3.1721e+00, -1.0727e+00],
        [ 2.0858e+00, -1.3484e+00],
        [ 2.6880e+00,  1.2567e+00],
        [ 3.7773e+00,  1.0677e+00],
        [ 3.0011e+00, -4.3459e-02],
        [ 3.2131e+00,  8.0539e-01],
        [ 3.2038e+00, -1.0171e+00],
        [ 1.8982e+00,  2.1511e-01],
        [ 3.1325e+00, -8.2946e-01],
        [ 1.2064e+00, -6.7851e-02],
        [ 3.7280e+00,  9.0026e-01],
        [ 2.4264e+00,  7.1333e-01],
        [ 3.9168e+00, -1.1046e+00],
        [ 3.3685e+00, -1.8537e-01],
        [ 3.0096e+00, -1.5759e+00],
        [ 2.8632e+00, -9.9409e-01],
        [ 2.1603e+00,  6.3715e-01],
        [ 2.5074e+00,  1.1188e+00],
        [ 2.4751e+00,  2.4049e-01],
        [ 2.4080e+00, -5.2561e-01],
        [ 2.8650e+00,  7.4574e-01],
        [ 2.3519e+00, -8.0385e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[6.1636e-03, 1.6784e-02, 1.6850e-02,  ..., 9.8934e-01, 9.9642e-01,
         1.0000e+00],
        [6.5194e-04, 3.5668e-03, 3.6117e-03,  ..., 9.7318e-01, 9.9998e-01,
         1.0000e+00],
        [6.9815e-02, 7.2701e-02, 3.0898e-01,  ..., 9.8129e-01, 9.9892e-01,
         1.0000e+00],
        ...,
        [2.6592e-06, 5.6185e-02, 1.0586e-01,  ..., 8.5868e-01, 8.5868e-01,
         1.0000e+00],
        [4.4585e-02, 4.4585e-02, 1.9517e-01,  ..., 9.9787e-01, 9.9914e-01,
         1.0000e+00],
        [7.5458e-02, 1.6915e-01, 2.1447e-01,  ..., 7.9696e-01, 9.9751e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.8435],
        [0.4485],
        [0.8962],
        [0.4267],
        [0.4878],
        [0.2262],
        [0.0619],
        [0.9569],
        [0.3586],
        [0.3820],
        [0.8918],
        [0.8782],
        [0.3504],
        [0.1298],
        [0.7344],
        [0.1334],
        [0.4679],
        [0.8437],
        [0.9366],
        [0.8777],
        [0.6276],
        [0.1286],
        [0.4840],
        [0.3697],
        [0.9808],
        [0.9024],
        [0.8468],
        [0.2197],
        [0.0633],
        [0.3518],
        [0.2854],
        [0.7017],
        [0.2884],
        [0.2103],
        [0.5870],
        [0.6304],
        [0.2251],
        [0.0774],
        [0.2870],
        [0.6932],
        [0.3193],
        [0.0402],
        [0.9686],
        [0.4886],
        [0.5439],
        [0.0409],
        [0.7419],
        [0.2753],
        [0.9132],
        [0.7007],
        [0.3024],
        [0.8726],
        [0.6682],
        [0.9887],
        [0.5707],
        [0.2724],
        [0.9606],
        [0.6425],
        [0.5627],
        [0.4195],
        [0.5446],
        [0.7668],
        [0.5673],
        [0.0399],
        [0.4014],
        [0.8697],
        [0.0657],
        [0.9340],
        [0.0859],
        [0.5482],
        [0.0751],
        [0.6760],
        [0.1341],
        [0.7190],
        [0.0584],
        [0.9557],
        [0.0651],
        [0.3217],
        [0.2046],
        [0.1919],
        [0.7569],
        [0.2527],
        [0.1728],
        [0.7594],
        [0.9525],
        [0.7791],
        [0.4512],
        [0.8157],
        [0.3979],
        [0.3988],
        [0.7562],
        [0.4522],
        [0.1109],
        [0.1841],
        [0.7176],
        [0.3975],
        [0.8529],
        [0.4454],
        [0.1256],
        [0.6627],
        [0.8022],
        [0.8365],
        [0.7997],
        [0.6245],
        [0.9230],
        [0.2552],
        [0.4531],
        [0.7769],
        [0.5309],
        [0.0470],
        [0.5554],
        [0.8117],
        [0.9564],
        [0.3774],
        [0.5231],
        [0.6251],
        [0.8625],
        [0.2458],
        [0.9808],
        [0.2850],
        [0.9560],
        [0.6140],
        [0.6345],
        [0.6957],
        [0.9393],
        [0.5791],
        [0.9448],
        [0.2374],
        [0.0365],
        [0.8105],
        [0.9158],
        [0.1933],
        [0.1134],
        [0.0793],
        [0.2920],
        [0.0632],
        [0.0056],
        [0.8578],
        [0.3031],
        [0.3843],
        [0.7664],
        [0.7579],
        [0.6757],
        [0.3574],
        [0.3375],
        [0.8272],
        [0.2720],
        [0.6348],
        [0.2616],
        [0.2452],
        [0.6913],
        [0.1239],
        [0.8491],
        [0.0445],
        [0.6109],
        [0.5810],
        [0.6908],
        [0.7668],
        [0.4827],
        [0.5119],
        [0.7805],
        [0.7910],
        [0.7156],
        [0.9705],
        [0.6035],
        [0.3595],
        [0.4488],
        [0.7831],
        [0.3677],
        [0.0535],
        [0.6372],
        [0.2900],
        [0.3048],
        [0.2933],
        [0.7434],
        [0.2356],
        [0.9283],
        [0.1911],
        [0.7423],
        [0.6344],
        [0.0143],
        [0.3658],
        [0.2819],
        [0.6924],
        [0.8601],
        [0.3807],
        [0.9741],
        [0.1993],
        [0.1641],
        [0.4688],
        [0.3770],
        [0.3167],
        [0.3112],
        [0.0142],
        [0.9725],
        [0.4501],
        [0.4075],
        [0.1331],
        [0.6897],
        [0.1561],
        [0.6601],
        [0.2602],
        [0.9405],
        [0.0692],
        [0.9502],
        [0.8044],
        [0.2823],
        [0.8450],
        [0.3080],
        [0.2028],
        [0.3314],
        [0.8544],
        [0.7840],
        [0.6097],
        [0.7162],
        [0.1354],
        [0.6373],
        [0.5098],
        [0.4347],
        [0.6930],
        [0.5354],
        [0.5293],
        [0.4095],
        [0.4049],
        [0.5996],
        [0.1079],
        [0.1195],
        [0.3514],
        [0.9569],
        [0.5639],
        [0.0424],
        [0.1096],
        [0.2538],
        [0.8935],
        [0.6541],
        [0.0048],
        [0.3147],
        [0.5516],
        [0.2429],
        [0.2892],
        [0.6549],
        [0.6725],
        [0.5476],
        [0.5760],
        [0.6758],
        [0.6368],
        [0.1396],
        [0.9985],
        [0.1789],
        [0.1620],
        [0.0844],
        [0.8396],
        [0.4153],
        [0.5326],
        [0.9896],
        [0.2971],
        [0.6903],
        [0.7774],
        [0.2419],
        [0.5934],
        [0.6998],
        [0.2347],
        [0.7215],
        [0.9314],
        [0.5709],
        [0.6539],
        [0.9555],
        [0.7955],
        [0.1825],
        [0.9211],
        [0.9816],
        [0.0500],
        [0.7112],
        [0.7878],
        [0.8319],
        [0.8756],
        [0.7133],
        [0.9518],
        [0.6066],
        [0.5452],
        [0.1872],
        [0.8590],
        [0.2236],
        [0.6182],
        [0.7396],
        [0.5262],
        [0.7879],
        [0.9506],
        [0.0798],
        [0.6786],
        [0.9899],
        [0.5460],
        [0.8091],
        [0.9249],
        [0.1499],
        [0.1756],
        [0.7952],
        [0.7772],
        [0.5291],
        [0.8490],
        [0.1693],
        [0.8970],
        [0.2496],
        [0.5876],
        [0.8337],
        [0.2728],
        [0.0012],
        [0.3817],
        [0.8781],
        [0.8716],
        [0.2743],
        [0.0592]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False,  True],
        [False, False, False,  ..., False, False, False],
        [ True, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 0.1099,  0.1492],
        [ 1.6421,  2.0162],
        [-1.0607,  1.5947],
        ...,
        [-4.0304,  0.5826],
        [ 2.2170, -0.5443],
        [ 0.1219,  0.4578]]) torch.Size([9984, 2])
samples tensor([[ 2.9657e+00, -2.2872e+00],
        [ 2.3530e+00,  4.3963e-01],
        [ 1.1388e+00, -2.3566e-01],
        [ 3.1339e+00, -1.0403e+00],
        [ 3.0376e+00,  7.9671e-01],
        [ 3.5525e+00, -1.4021e+00],
        [ 4.3002e-01,  1.7392e+00],
        [ 2.3270e+00, -1.9986e+00],
        [ 2.1370e+00, -8.1543e-01],
        [ 1.7168e+00,  5.7614e-01],
        [ 3.2795e+00,  7.5839e-02],
        [ 3.4566e+00,  8.1547e-01],
        [ 1.5234e+00, -1.3324e-01],
        [ 4.0582e+00, -1.4643e+00],
        [ 3.1957e+00,  1.8051e+00],
        [ 2.4840e+00,  1.4400e+00],
        [ 1.8162e+00,  1.4347e+00],
        [ 4.1521e+00,  2.1002e-01],
        [ 3.4108e+00, -4.5181e-03],
        [ 5.1155e-01, -8.4804e-01],
        [ 2.1484e+00, -2.2702e+00],
        [ 1.4928e+00, -3.7655e-01],
        [ 3.1368e+00, -2.3925e-01],
        [ 3.2901e+00, -7.0252e-01],
        [ 7.6993e-01, -7.5179e-01],
        [ 1.9462e+00, -2.4434e-01],
        [ 3.0506e+00,  8.3386e-01],
        [ 2.9336e+00, -1.4991e+00],
        [ 3.4457e+00,  6.7513e-02],
        [ 2.0453e+00,  2.9507e-01],
        [ 3.6458e+00, -7.4538e-01],
        [ 2.2230e+00,  8.7649e-01],
        [ 1.1389e+00, -3.4560e-01],
        [ 7.8356e-01,  1.9940e+00],
        [ 2.2975e+00, -7.7888e-01],
        [ 3.1538e+00, -1.0969e+00],
        [ 2.8097e+00,  1.1846e+00],
        [ 1.5646e+00,  2.5253e+00],
        [ 2.7589e+00, -2.7790e-01],
        [ 2.3286e+00, -3.8714e-01],
        [ 3.5047e+00, -2.5401e-01],
        [ 1.7483e+00,  1.1951e+00],
        [ 9.4268e-01,  7.6729e-02],
        [ 1.2216e+00,  1.5396e+00],
        [ 2.0324e+00, -1.0091e+00],
        [ 2.0018e+00,  4.5439e-01],
        [ 2.7107e+00, -1.7071e+00],
        [ 3.8258e+00, -1.9209e+00],
        [ 2.5283e+00,  1.3017e+00],
        [ 3.8680e+00, -6.8939e-01],
        [ 4.2915e+00, -1.3337e+00],
        [ 1.0993e+00,  8.5924e-01],
        [ 3.1021e+00, -7.2094e-01],
        [ 2.3822e+00,  1.8721e+00],
        [ 4.4876e+00,  1.2056e+00],
        [ 4.1170e+00, -1.1943e+00],
        [ 1.8479e+00,  4.7472e-01],
        [ 1.6388e+00,  1.2324e+00],
        [ 2.2607e+00,  6.5706e-01],
        [ 2.5680e+00, -2.4062e-01],
        [ 4.5750e+00, -1.6723e+00],
        [ 2.6623e+00, -1.8610e+00],
        [ 1.0512e+00,  1.2274e+00],
        [ 2.5989e+00,  5.5973e-01],
        [ 2.1530e+00, -4.5815e-01],
        [ 2.7300e+00,  6.9093e-01],
        [ 6.4152e-01,  9.2202e-02],
        [ 3.0435e+00,  3.9221e-01],
        [ 3.1845e+00,  3.2683e-01],
        [ 2.2725e+00, -6.2572e-01],
        [ 3.1611e+00, -1.7398e+00],
        [ 1.1645e+00,  6.2799e-02],
        [ 1.9492e+00, -2.9392e-01],
        [ 4.3089e+00, -2.5495e+00],
        [ 8.0646e-01,  1.5030e+00],
        [ 1.9281e+00, -7.7953e-01],
        [ 2.2634e+00,  1.4472e+00],
        [ 2.9961e+00,  1.3259e+00],
        [ 3.1255e+00, -7.8176e-01],
        [ 4.1665e+00, -7.9732e-01],
        [ 2.5931e+00,  3.1515e-02],
        [ 2.7059e+00, -5.7742e-01],
        [ 1.9162e+00, -1.0909e+00],
        [ 2.7963e+00, -3.5605e-01],
        [ 1.5620e+00,  2.0002e-03],
        [ 4.0743e+00, -3.6243e-01],
        [ 2.5128e+00, -4.5114e-01],
        [ 3.3915e+00,  1.6647e-01],
        [ 2.7303e+00,  7.6949e-01],
        [ 3.9574e+00,  6.8896e-01],
        [ 2.9409e+00, -3.5249e-01],
        [ 2.9053e+00, -9.1766e-01],
        [ 7.3981e-01, -7.2854e-01],
        [ 1.4433e+00,  7.6577e-01],
        [ 1.7906e+00, -1.6196e+00],
        [ 8.5764e-01, -1.2297e+00],
        [ 2.1775e+00,  1.7914e-01],
        [ 1.7538e+00, -1.5727e+00],
        [ 2.1101e+00, -5.7969e-01],
        [ 1.8247e+00, -1.8827e+00],
        [ 2.2812e+00, -1.6893e-01],
        [ 3.5136e+00,  3.0335e-01],
        [ 2.0143e+00,  9.5310e-01],
        [ 2.4745e+00, -3.9636e-01],
        [ 2.4381e+00,  4.8259e-01],
        [ 4.3644e+00, -5.8027e-01],
        [ 3.3497e+00, -7.7300e-01],
        [ 2.9026e+00,  3.7432e-01],
        [ 2.6809e+00, -1.3215e+00],
        [ 2.8784e+00, -4.9218e-01],
        [ 1.7801e+00,  6.2658e-01],
        [ 3.0323e-01, -5.1247e-01],
        [ 1.8107e+00, -6.0530e-01],
        [ 3.0382e+00,  1.4276e+00],
        [ 2.5316e+00, -4.2038e-01],
        [ 2.2184e+00, -2.0604e-02],
        [ 2.7242e+00, -3.8620e-01],
        [ 3.6129e+00, -1.0842e+00],
        [ 2.5676e+00,  2.5641e-01],
        [ 2.1661e+00, -1.1357e+00],
        [ 4.3436e-01, -5.4120e-01],
        [ 2.7900e+00, -2.2682e+00],
        [ 1.5614e+00, -1.5451e+00],
        [ 2.3727e+00, -9.9162e-01],
        [ 9.5625e-01, -7.2706e-01],
        [ 8.0146e-01, -1.2978e-01],
        [ 1.0081e+00,  8.1571e-01],
        [ 2.6416e+00, -9.8118e-01],
        [ 2.3898e+00, -3.5043e-01],
        [ 1.8701e+00,  4.7798e-01],
        [ 1.3639e+00, -1.2627e+00],
        [ 9.5572e-01, -9.3707e-01],
        [ 2.3749e+00,  1.3755e+00],
        [ 2.1659e+00,  1.1081e-01],
        [ 2.0824e+00,  5.3115e-01],
        [ 2.5198e+00, -1.1751e+00],
        [ 3.5575e+00, -1.3541e+00],
        [ 2.9779e+00, -2.3551e-02],
        [ 1.6525e+00, -1.7198e-01],
        [ 2.9999e+00, -2.0764e-01],
        [ 2.7795e+00, -1.2982e+00],
        [ 1.9418e+00,  1.0371e+00],
        [ 2.7592e+00, -5.0463e-01],
        [ 3.0367e+00, -3.6818e-01],
        [ 1.1250e+00, -5.9455e-01],
        [ 2.0576e-01, -1.2643e+00],
        [ 3.3428e+00,  7.0896e-01],
        [ 1.2861e+00,  6.7099e-01],
        [ 3.4451e-02, -1.0264e+00],
        [ 3.7692e+00, -4.8635e-01],
        [ 9.9138e-01, -4.6335e-01],
        [ 3.0677e+00, -3.7799e-01],
        [ 2.6798e+00,  1.0502e+00],
        [ 9.6844e-01,  8.9024e-02],
        [ 4.3714e+00, -2.4618e-01],
        [ 3.4464e+00, -1.1598e+00],
        [ 2.7309e+00, -7.3896e-01],
        [ 2.1785e+00, -1.2509e+00],
        [ 1.1845e+00,  3.8009e-01],
        [ 3.1762e-01, -1.2373e+00],
        [ 4.3364e+00, -5.2662e-01],
        [ 6.7095e-01,  1.2239e-01],
        [ 1.6576e+00, -1.5527e-01],
        [ 3.3566e+00,  1.9983e+00],
        [ 1.9011e+00, -2.9758e-01],
        [ 9.4850e-01, -3.2394e-01],
        [ 3.2564e+00,  6.5815e-01],
        [ 2.0119e+00,  5.2770e-02],
        [ 2.1160e+00,  2.9776e-01],
        [ 3.9874e+00, -5.5869e-01],
        [ 4.2195e+00, -3.1988e-01],
        [ 3.2535e+00, -1.1819e+00],
        [ 3.0359e+00,  5.6345e-01],
        [ 2.6826e+00,  1.5262e+00],
        [ 2.0739e+00, -1.6738e+00],
        [ 1.3986e+00,  7.3159e-03],
        [ 2.4231e+00, -4.0420e-01],
        [ 2.6612e+00,  1.6407e-01],
        [ 4.3172e+00, -2.3403e-01],
        [ 3.7476e+00, -7.2244e-02],
        [ 1.1408e+00,  1.4352e+00],
        [ 2.1293e+00, -2.5382e+00],
        [ 1.9435e+00,  3.0485e-01],
        [ 1.1548e+00, -6.2491e-01],
        [ 1.1492e+00, -1.9763e+00],
        [ 2.0250e+00, -7.4576e-01],
        [ 2.9400e+00,  1.5066e+00],
        [ 2.8737e+00,  2.0071e+00],
        [ 2.5289e+00, -1.9478e-01],
        [ 3.1963e+00,  1.2596e-01],
        [ 2.4323e+00, -2.5952e-01],
        [ 3.4132e+00,  2.4380e+00],
        [ 2.9337e+00, -1.2908e+00],
        [ 2.9322e+00,  4.2660e-01],
        [ 1.8456e+00, -5.5211e-01],
        [ 9.9292e-01, -8.7653e-01],
        [ 3.1459e+00,  3.3836e-01],
        [ 2.3248e+00, -1.2616e+00],
        [ 5.0722e-01,  1.9755e+00],
        [ 3.2719e+00, -4.2506e-01],
        [ 3.4641e+00, -2.7503e-01],
        [ 3.3118e+00, -3.2873e-01],
        [ 2.0246e+00, -5.1943e-01],
        [ 3.5263e+00,  1.5689e+00],
        [ 3.4541e+00, -2.2962e+00],
        [ 1.6579e+00, -1.5403e+00],
        [ 1.9991e+00, -1.8926e+00],
        [ 1.4147e+00,  2.1552e+00],
        [ 3.2007e+00, -9.7527e-01],
        [ 3.9824e+00,  7.5457e-01],
        [ 2.3416e+00, -1.2115e+00],
        [ 2.1285e+00,  1.3661e+00],
        [ 6.0898e-01, -6.0028e-01],
        [ 1.8496e+00, -1.4520e+00],
        [ 2.4312e+00,  8.4721e-01],
        [ 3.9684e+00,  8.5949e-01],
        [ 2.6525e+00,  9.7864e-01],
        [ 1.3807e+00, -6.9088e-01],
        [ 2.7525e+00, -6.8729e-02],
        [ 2.8847e+00, -1.7152e-01],
        [ 2.6045e+00, -9.0113e-01],
        [ 3.5573e+00, -4.6582e-01],
        [ 3.2486e+00, -9.2187e-01],
        [ 2.3346e+00, -8.5906e-01],
        [ 4.5876e+00,  3.0823e-01],
        [ 2.6428e+00,  4.3773e-01],
        [ 2.5436e+00, -4.8757e-01],
        [ 3.5289e+00,  1.4123e-01],
        [ 1.7028e+00,  1.6054e+00],
        [ 1.9901e+00, -6.3124e-01],
        [ 3.3373e+00,  2.9931e+00],
        [ 2.7666e+00,  1.0056e+00],
        [ 2.5438e+00,  1.1695e+00],
        [ 4.1372e+00, -1.1980e-01],
        [ 3.4739e+00,  6.7403e-01],
        [ 1.6990e+00,  9.7458e-01],
        [ 1.5680e+00,  8.9833e-01],
        [ 7.6078e-01, -1.6647e+00],
        [ 2.1727e+00,  9.4705e-01],
        [ 1.2996e+00, -1.3542e-01],
        [ 3.9253e+00, -9.4386e-01],
        [ 2.9312e+00, -1.0675e+00],
        [ 3.5424e+00,  1.0659e+00],
        [ 2.9808e+00, -1.4539e+00],
        [ 1.4555e+00, -1.1875e+00],
        [ 2.8250e+00, -2.3087e-01],
        [ 3.1814e+00,  1.3798e+00],
        [ 1.3185e+00,  1.9447e+00],
        [ 2.3657e+00, -1.0358e+00],
        [ 2.7741e+00, -8.9056e-02],
        [ 2.9895e+00,  7.6625e-01],
        [ 2.0813e+00,  1.1837e+00],
        [ 2.9717e+00,  2.3711e-01],
        [ 1.2834e+00, -1.4328e+00],
        [ 2.0853e+00,  1.3163e+00],
        [ 1.1174e+00, -5.5195e-01],
        [ 3.0021e+00, -1.0072e+00],
        [ 3.5776e+00, -2.1068e+00],
        [ 4.4485e+00, -1.4867e+00],
        [ 1.2077e+00,  1.0401e-01],
        [ 2.4157e+00,  4.0483e-01],
        [ 1.9433e+00,  6.7962e-01],
        [ 2.5700e+00, -2.1094e+00],
        [ 1.4092e+00, -6.3303e-01],
        [ 8.3063e-01, -6.3792e-01],
        [ 3.9916e+00,  1.4767e+00],
        [ 9.6432e-01,  7.5697e-01],
        [ 3.1185e+00, -2.1934e+00],
        [ 2.8763e+00,  1.5925e-01],
        [ 1.8170e+00,  6.1499e-01],
        [ 9.4739e-02,  5.0273e-01],
        [ 1.7620e+00, -3.2654e-01],
        [ 1.3427e+00,  2.1228e-01],
        [ 2.9656e+00, -1.3997e+00],
        [ 2.0383e+00, -6.5744e-02],
        [ 2.9594e+00, -7.6985e-01],
        [ 3.0409e+00, -1.7213e+00],
        [ 2.8874e+00,  1.5842e+00],
        [ 2.0407e+00, -9.3427e-01],
        [-1.3326e-01,  1.6925e+00],
        [ 2.8247e+00, -1.0042e+00],
        [ 2.7533e+00, -1.3468e+00],
        [ 1.6370e+00, -1.0413e-01],
        [ 3.1834e+00,  3.9136e-01],
        [ 1.8812e+00, -2.5528e-01],
        [ 2.1982e+00, -8.4741e-01],
        [ 2.8393e+00, -7.1381e-02],
        [ 2.1204e+00,  4.5792e-02],
        [ 9.2738e-01, -6.6420e-01],
        [ 3.3926e+00, -6.1388e-02],
        [ 1.2266e+00,  5.2923e-01],
        [ 1.6717e+00, -2.8657e-01],
        [ 3.0695e+00, -4.3460e-02],
        [ 3.1287e+00, -9.6450e-03],
        [ 4.4655e+00,  5.7535e-01],
        [ 3.6313e+00, -3.7899e-02],
        [ 7.5281e-01, -7.1040e-01],
        [ 1.8608e+00,  6.9243e-01],
        [ 2.2796e+00,  2.4851e+00],
        [ 2.7397e+00,  1.2802e-01],
        [ 1.8498e+00,  1.6494e+00],
        [ 3.7722e+00,  1.7106e-01],
        [ 1.9090e+00, -4.4204e-01],
        [ 3.3886e+00,  2.3962e-02],
        [ 3.6682e+00,  4.0805e-01],
        [ 2.1415e+00,  1.3123e+00],
        [ 2.0704e+00,  9.7459e-01],
        [ 1.0864e+00, -6.2759e-01],
        [ 3.3033e+00,  6.2499e-01],
        [ 2.5065e+00, -5.3080e-01],
        [ 2.3758e+00,  3.3807e-01],
        [ 1.4961e+00, -1.9197e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.0552e-01, 1.2652e-01, 1.2671e-01,  ..., 9.9570e-01, 1.0000e+00,
         1.0000e+00],
        [5.3999e-02, 5.4026e-02, 5.4026e-02,  ..., 9.2778e-01, 9.2778e-01,
         1.0000e+00],
        [7.7411e-07, 4.9654e-02, 4.9654e-02,  ..., 9.5128e-01, 9.5128e-01,
         1.0000e+00],
        ...,
        [1.8276e-02, 3.0427e-02, 3.0503e-02,  ..., 9.6812e-01, 9.8823e-01,
         1.0000e+00],
        [2.5354e-01, 6.1418e-01, 6.2429e-01,  ..., 9.8513e-01, 9.9962e-01,
         1.0000e+00],
        [1.3276e-02, 1.6500e-02, 1.6500e-02,  ..., 9.4120e-01, 9.7638e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.1125],
        [0.8988],
        [0.0641],
        [0.8922],
        [0.6369],
        [0.0160],
        [0.6496],
        [0.9575],
        [0.5712],
        [0.6179],
        [0.1671],
        [0.9701],
        [0.2936],
        [0.6792],
        [0.5107],
        [0.6065],
        [0.4229],
        [0.8082],
        [0.6681],
        [0.2062],
        [0.7477],
        [0.5120],
        [0.9033],
        [0.6881],
        [0.7898],
        [0.3288],
        [0.8786],
        [0.1466],
        [0.7308],
        [0.8924],
        [0.6720],
        [0.6511],
        [0.8237],
        [0.1804],
        [0.7133],
        [0.2724],
        [0.2279],
        [0.7538],
        [0.6608],
        [0.7998],
        [0.2509],
        [0.2469],
        [0.1740],
        [0.8356],
        [0.2006],
        [0.7280],
        [0.0971],
        [0.4101],
        [0.5764],
        [0.9370],
        [0.4190],
        [0.4312],
        [0.7422],
        [0.3258],
        [0.5785],
        [0.8581],
        [0.9248],
        [0.1705],
        [0.8992],
        [0.9922],
        [0.1140],
        [0.0446],
        [0.3710],
        [0.1557],
        [0.0567],
        [0.1739],
        [0.9689],
        [0.9389],
        [0.4609],
        [0.6797],
        [0.0703],
        [0.3225],
        [0.6535],
        [0.8343],
        [0.8395],
        [0.2795],
        [0.7023],
        [0.2837],
        [0.8030],
        [0.8491],
        [0.1165],
        [0.3822],
        [0.3087],
        [0.6745],
        [0.7919],
        [0.7112],
        [0.0111],
        [0.1866],
        [0.5621],
        [0.7099],
        [0.3575],
        [0.4920],
        [0.4846],
        [0.1188],
        [0.5066],
        [0.2353],
        [0.2812],
        [0.0507],
        [0.6346],
        [0.9382],
        [0.7837],
        [0.5637],
        [0.6067],
        [0.9793],
        [0.7047],
        [0.7520],
        [0.1162],
        [0.6711],
        [0.9877],
        [0.3096],
        [0.3340],
        [0.0361],
        [0.2920],
        [0.3884],
        [0.6124],
        [0.0383],
        [0.1149],
        [0.4916],
        [0.0592],
        [0.8013],
        [0.8377],
        [0.1302],
        [0.4447],
        [0.5925],
        [0.0694],
        [0.3008],
        [0.4262],
        [0.7356],
        [0.1409],
        [0.1127],
        [0.0875],
        [0.0452],
        [0.9952],
        [0.2432],
        [0.4918],
        [0.3332],
        [0.6087],
        [0.5151],
        [0.4689],
        [0.0674],
        [0.1224],
        [0.2686],
        [0.7732],
        [0.0312],
        [0.7441],
        [0.4427],
        [0.1710],
        [0.6243],
        [0.1213],
        [0.5081],
        [0.8795],
        [0.4691],
        [0.4158],
        [0.8953],
        [0.7609],
        [0.6195],
        [0.4867],
        [0.9467],
        [0.3175],
        [0.6760],
        [0.2210],
        [0.7146],
        [0.1188],
        [0.2135],
        [0.2545],
        [0.5339],
        [0.5606],
        [0.7681],
        [0.1149],
        [0.2043],
        [0.7243],
        [0.6404],
        [0.3913],
        [0.9802],
        [0.7672],
        [0.3694],
        [0.5979],
        [0.1777],
        [0.3086],
        [0.7300],
        [0.0792],
        [0.9131],
        [0.2686],
        [0.5125],
        [0.2540],
        [0.7999],
        [0.5820],
        [0.1591],
        [0.9962],
        [0.3506],
        [0.3125],
        [0.5298],
        [0.1862],
        [0.2147],
        [0.3374],
        [0.0932],
        [0.3956],
        [0.2911],
        [0.0442],
        [0.7658],
        [0.0501],
        [0.6184],
        [0.8278],
        [0.1905],
        [0.5220],
        [0.4267],
        [0.6764],
        [0.9387],
        [0.8691],
        [0.0539],
        [0.1616],
        [0.1701],
        [0.4167],
        [0.4565],
        [0.1300],
        [0.5684],
        [0.0633],
        [0.5804],
        [0.5855],
        [0.9938],
        [0.5638],
        [0.6598],
        [0.6675],
        [0.1273],
        [0.6023],
        [0.9159],
        [0.1705],
        [0.5693],
        [0.4900],
        [0.1976],
        [0.7779],
        [0.9812],
        [0.0315],
        [0.4459],
        [0.1086],
        [0.7369],
        [0.4787],
        [0.6493],
        [0.4575],
        [0.6569],
        [0.3884],
        [0.1782],
        [0.8821],
        [0.6643],
        [0.9410],
        [0.9685],
        [0.8136],
        [0.0358],
        [0.3139],
        [0.6382],
        [0.5413],
        [0.3979],
        [0.1204],
        [0.1072],
        [0.0693],
        [0.8096],
        [0.3023],
        [0.6192],
        [0.0294],
        [0.3354],
        [0.4144],
        [0.4387],
        [0.3803],
        [0.7301],
        [0.0602],
        [0.4525],
        [0.2205],
        [0.7501],
        [0.3368],
        [0.4773],
        [0.1195],
        [0.6422],
        [0.2867],
        [0.3390],
        [0.5343],
        [0.3218],
        [0.6394],
        [0.8000],
        [0.0776],
        [0.5664],
        [0.6044],
        [0.0992],
        [0.0074],
        [0.9989],
        [0.8587],
        [0.0790],
        [0.6304],
        [0.8713],
        [0.5655],
        [0.2660],
        [0.4989],
        [0.4503],
        [0.9125],
        [0.9619],
        [0.8825],
        [0.2695],
        [0.1579],
        [0.7867],
        [0.4123],
        [0.4739],
        [0.9112],
        [0.7234],
        [0.5596],
        [0.0062],
        [0.0710],
        [0.6461],
        [0.3476],
        [0.5028],
        [0.6287],
        [0.3559],
        [0.5593],
        [0.3043]]) torch.Size([312, 1])
mask tensor([[False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 1.9902,  0.2575],
        [ 0.4965, -0.1970],
        [-0.8788,  0.6341],
        ...,
        [ 0.8854, -0.2468],
        [ 0.8544,  0.0981],
        [ 4.8383,  1.5133]]) torch.Size([9984, 2])
samples tensor([[ 4.9654e-01, -1.9702e-01],
        [ 2.6673e+00,  7.4623e-01],
        [ 6.8400e-01, -3.7153e-01],
        [ 2.7622e+00,  2.2776e-01],
        [ 3.4825e+00,  3.2074e-01],
        [ 4.5861e+00,  1.3170e+00],
        [ 2.2975e+00, -1.4211e+00],
        [ 2.0168e+00,  1.2184e+00],
        [ 1.5898e+00,  7.1762e-01],
        [ 3.1529e+00, -8.9702e-01],
        [ 3.1953e+00,  2.4822e+00],
        [ 2.0056e+00,  9.5282e-01],
        [ 6.9424e-01, -1.8124e+00],
        [ 2.4043e+00, -7.5692e-01],
        [ 1.9949e+00, -5.3584e-01],
        [ 1.6248e+00, -1.4770e+00],
        [ 3.2743e+00,  7.4022e-01],
        [ 1.8165e+00, -4.0394e-01],
        [ 3.5427e+00, -8.6947e-01],
        [ 2.0457e+00, -1.4224e+00],
        [ 1.2374e+00, -9.9061e-01],
        [ 3.4599e+00, -1.0417e+00],
        [ 1.2198e+00, -2.8369e-01],
        [ 3.4766e+00,  6.3923e-01],
        [ 1.3954e+00, -7.2690e-01],
        [ 3.3330e+00, -1.7335e+00],
        [ 4.0543e+00,  7.4271e-01],
        [ 4.3271e+00, -1.5756e+00],
        [ 4.3188e+00,  1.1342e+00],
        [ 9.8683e-01, -1.2212e+00],
        [ 1.9415e+00, -1.4586e+00],
        [ 3.1242e+00, -1.5702e+00],
        [ 2.0196e+00,  1.3151e-01],
        [ 2.1918e+00,  8.9454e-01],
        [ 2.1423e+00,  1.4781e-01],
        [ 1.5997e+00, -9.4240e-01],
        [ 2.4163e+00,  1.2930e+00],
        [ 3.9379e+00,  2.5614e-01],
        [ 6.3305e-01, -1.8688e+00],
        [ 3.8023e+00, -2.0168e+00],
        [ 2.9694e+00,  1.0280e+00],
        [ 3.0111e+00, -5.1519e-01],
        [ 2.7112e+00, -4.9070e-01],
        [ 2.6831e+00, -1.7767e+00],
        [ 2.6058e+00,  1.2614e+00],
        [ 3.4712e+00, -1.0907e+00],
        [ 2.5415e+00, -8.1490e-01],
        [ 4.0595e+00,  3.6419e-01],
        [ 3.4123e+00, -6.8384e-01],
        [ 3.9031e+00, -1.0606e-01],
        [ 7.6360e-01,  2.3862e-01],
        [ 2.6917e+00, -2.3534e+00],
        [ 1.6933e+00, -2.6118e-01],
        [ 1.9458e+00,  9.2672e-01],
        [ 2.9013e+00,  3.7131e-01],
        [ 1.8196e+00,  3.2028e-01],
        [ 3.3359e+00, -2.5478e+00],
        [ 3.0237e+00,  3.7865e-01],
        [ 3.8524e-01,  4.7566e-01],
        [ 3.1456e+00,  4.8345e-01],
        [ 3.3835e+00, -8.6039e-01],
        [ 1.3186e+00, -9.1735e-01],
        [ 2.1144e+00,  5.7335e-01],
        [ 3.1902e+00, -4.0049e+00],
        [ 1.7011e+00, -1.0008e+00],
        [ 1.9057e+00, -1.1573e+00],
        [ 2.5390e+00, -1.7687e-02],
        [ 2.8074e+00, -1.1030e+00],
        [ 1.9801e+00,  2.6442e-01],
        [ 2.6212e+00,  5.0771e-01],
        [ 1.9866e+00,  1.5112e+00],
        [ 2.1378e+00, -7.8147e-01],
        [-2.0265e-02, -6.3579e-01],
        [ 3.5994e+00, -1.3515e+00],
        [ 1.9020e+00,  1.2432e-01],
        [ 2.4121e+00,  7.8750e-03],
        [ 2.3665e+00, -2.9335e+00],
        [ 3.7855e-01,  8.6429e-01],
        [ 2.5035e+00,  2.5819e-01],
        [ 1.4028e+00, -7.4659e-01],
        [ 1.6725e+00,  4.5093e-01],
        [ 3.6412e+00, -1.0188e+00],
        [ 1.7736e+00,  1.0934e+00],
        [ 3.1573e+00, -1.6438e+00],
        [ 2.6123e+00,  9.2290e-01],
        [ 2.3847e+00,  1.6111e-01],
        [ 1.6588e+00,  6.2662e-01],
        [ 3.0679e+00,  1.6340e+00],
        [ 2.8932e+00, -5.3648e-01],
        [ 2.5231e+00,  2.4630e-03],
        [ 5.5865e-01, -8.3290e-01],
        [ 2.9262e+00, -4.0825e-01],
        [ 3.4097e+00, -7.5496e-01],
        [ 3.1374e+00,  8.8319e-02],
        [ 2.6285e+00, -7.1583e-01],
        [ 1.9456e+00,  1.0117e+00],
        [ 2.8965e+00, -1.8875e+00],
        [ 2.5530e+00,  8.2268e-01],
        [ 3.2064e+00, -1.9025e-01],
        [ 2.3959e+00, -5.0412e-02],
        [ 2.8147e+00,  6.9314e-01],
        [ 2.2059e+00,  1.6913e-02],
        [ 3.5692e+00,  3.6714e-01],
        [ 2.1456e+00, -2.1722e-02],
        [ 1.3923e+00, -1.0417e+00],
        [ 2.3890e+00, -2.9156e-01],
        [ 4.5723e+00, -7.3750e-02],
        [ 4.2779e+00, -1.1435e+00],
        [ 9.6068e-02, -8.6624e-01],
        [ 2.5147e+00, -1.6484e+00],
        [ 3.9199e+00, -1.7574e+00],
        [ 1.5666e+00,  4.2622e-01],
        [ 1.8638e+00, -4.1939e-01],
        [ 3.3967e+00,  1.2599e+00],
        [ 1.2842e+00, -4.2579e-01],
        [ 1.3386e+00,  1.0444e+00],
        [ 1.7404e+00,  5.5149e-01],
        [ 2.8011e+00, -2.0462e+00],
        [ 3.1753e+00,  1.6265e-01],
        [ 5.4251e-01,  4.7261e-01],
        [ 7.9057e-01,  7.3752e-01],
        [ 2.1105e+00,  6.4739e-01],
        [ 1.7754e+00, -2.1142e+00],
        [ 3.6394e+00,  3.1429e-01],
        [ 1.9607e+00,  5.3502e-01],
        [ 4.9713e+00, -8.7853e-01],
        [ 4.0548e+00, -2.3470e+00],
        [ 3.5695e+00, -2.7595e-01],
        [ 1.7115e+00, -1.3397e+00],
        [ 4.1620e+00,  6.5348e-01],
        [-5.1460e-01,  3.4327e-01],
        [ 9.3894e-02,  2.0467e-01],
        [ 2.7688e+00,  8.0378e-01],
        [ 2.5718e+00,  1.0324e-01],
        [ 2.6741e+00,  4.5355e-01],
        [ 2.2068e+00, -1.1324e+00],
        [ 3.8165e+00, -1.2208e+00],
        [ 1.8124e+00,  7.8222e-01],
        [ 1.6442e+00, -1.1857e+00],
        [ 1.9452e+00, -4.6321e-01],
        [ 1.5131e+00, -1.3933e+00],
        [ 7.2433e-01, -1.2261e+00],
        [ 4.2867e+00,  1.6959e-01],
        [ 3.7881e+00,  7.7483e-01],
        [ 3.2253e+00,  1.2021e-01],
        [ 2.1800e+00,  6.7049e-01],
        [ 2.1660e+00,  1.8152e+00],
        [ 3.2286e+00,  2.3269e-01],
        [ 2.2540e+00, -1.1817e+00],
        [ 2.1430e+00, -3.3501e-02],
        [ 2.7116e+00, -1.4358e+00],
        [ 4.3270e+00,  1.4934e+00],
        [ 2.8182e+00,  1.5823e-01],
        [ 2.3078e+00, -4.2261e-01],
        [ 2.7674e+00, -1.2112e+00],
        [ 3.4348e+00,  1.3274e-01],
        [ 9.9928e-01, -2.5908e-01],
        [ 3.1551e+00,  7.5563e-03],
        [ 1.3151e+00,  1.3834e-01],
        [ 3.0624e+00, -3.5574e-01],
        [ 4.5316e-01,  9.7019e-02],
        [ 3.1173e+00,  1.1262e+00],
        [ 6.5210e-01, -2.9295e-01],
        [ 2.9865e+00,  4.8254e-01],
        [ 3.6554e+00,  3.1929e-01],
        [ 2.4845e+00, -1.3669e-01],
        [ 1.9505e+00, -2.6949e+00],
        [ 3.0004e+00, -1.3608e-01],
        [ 9.4948e-01, -9.3284e-01],
        [ 2.5946e+00,  2.0194e-01],
        [ 2.6567e+00, -1.1034e+00],
        [ 2.3896e+00, -6.5041e-01],
        [ 3.5944e+00,  2.1711e-01],
        [ 1.7366e+00,  3.1546e-01],
        [ 3.3669e+00,  8.1736e-01],
        [ 2.1663e+00, -3.4544e-01],
        [ 1.2019e+00, -1.5180e+00],
        [ 3.9139e+00,  4.4212e-02],
        [ 1.2218e+00, -4.9754e-01],
        [ 1.8440e+00, -6.3070e-01],
        [ 9.9737e-01, -4.0178e-01],
        [ 2.4091e+00, -5.2592e-01],
        [ 3.9178e+00, -1.6497e+00],
        [ 1.9287e+00,  3.5642e-01],
        [ 1.0123e+00, -4.6850e-01],
        [ 3.0487e+00, -3.7758e-01],
        [ 4.4998e+00, -4.7381e-01],
        [-1.1697e+00,  1.5663e-01],
        [ 1.1941e+00,  1.5805e+00],
        [ 3.1698e+00, -2.8283e-01],
        [ 1.9299e+00, -5.6455e-01],
        [ 1.4224e+00,  3.2209e-01],
        [ 9.3844e-01, -1.4300e-01],
        [ 1.1953e+00,  5.2479e-01],
        [ 3.1426e+00, -2.7835e-01],
        [ 7.6982e-01,  6.9494e-01],
        [ 2.1209e+00,  3.8925e-01],
        [ 3.8624e+00,  1.1000e-01],
        [ 2.7818e+00,  8.2527e-01],
        [ 2.1266e+00,  1.8707e+00],
        [ 1.4643e+00, -1.0112e+00],
        [ 2.8275e+00,  7.8550e-01],
        [ 2.9548e+00,  3.6114e-01],
        [ 2.0100e+00, -8.2690e-01],
        [ 3.6454e+00, -2.5933e-01],
        [ 1.9396e+00, -1.4811e-01],
        [ 4.7469e+00,  9.4971e-01],
        [ 2.3904e+00, -6.8059e-01],
        [ 4.5866e+00, -3.0081e-01],
        [ 1.9797e+00,  8.3684e-01],
        [ 2.1561e+00,  2.2719e+00],
        [ 1.3222e+00, -1.3607e+00],
        [ 4.2623e+00,  1.1892e+00],
        [ 3.2377e+00,  2.7784e-01],
        [ 3.1731e-01,  1.2933e-02],
        [ 3.4998e+00,  4.3428e-01],
        [ 2.1577e+00,  3.0244e-01],
        [ 4.0632e+00, -8.6530e-01],
        [ 1.0030e+00, -2.9199e-01],
        [ 2.9077e+00,  1.5502e-03],
        [ 6.8857e-01, -1.6368e+00],
        [ 3.2865e+00, -1.9061e+00],
        [ 2.3967e+00,  4.2014e-02],
        [ 1.1772e+00, -1.2222e-01],
        [ 3.1677e+00,  6.5371e-01],
        [ 2.8696e+00, -7.0473e-01],
        [ 3.7392e+00, -1.7419e+00],
        [ 2.0727e+00,  5.4913e-01],
        [ 2.5441e+00, -8.3165e-01],
        [ 1.9064e+00, -7.0854e-01],
        [ 1.9896e+00, -1.0756e+00],
        [ 1.2783e-01, -2.8169e-01],
        [ 3.4464e+00,  9.3078e-01],
        [ 1.8894e+00, -9.2216e-01],
        [ 3.0782e+00, -1.0067e+00],
        [ 2.0754e+00,  5.2953e-01],
        [ 2.8030e+00,  9.8116e-01],
        [ 2.7712e+00, -2.9538e-01],
        [ 2.0594e+00, -1.3823e+00],
        [ 3.5097e+00, -5.6231e-02],
        [ 3.2894e+00,  9.8677e-01],
        [ 4.9048e+00, -4.0197e-01],
        [ 3.3190e+00, -9.7977e-01],
        [ 3.6615e+00, -1.5448e-01],
        [ 2.8383e+00,  1.0162e-01],
        [ 2.8883e+00,  3.7198e-01],
        [ 3.4482e+00, -9.6283e-01],
        [ 3.2339e+00, -3.0207e-01],
        [ 9.2425e-01, -1.6301e+00],
        [ 2.7571e+00,  1.1026e-01],
        [ 1.7498e+00, -1.1635e+00],
        [ 3.2491e+00,  3.4144e-01],
        [ 2.5182e+00, -7.9460e-01],
        [ 3.3258e+00,  3.6808e-01],
        [ 2.2754e+00,  6.5024e-01],
        [ 2.2749e+00,  1.0154e-01],
        [ 1.0400e+00,  1.3930e+00],
        [ 2.7492e+00, -4.8264e-01],
        [ 3.3246e+00,  1.3992e+00],
        [ 1.7606e+00, -1.8385e+00],
        [ 1.1852e+00, -3.3301e-01],
        [ 2.7679e+00, -3.1409e-01],
        [ 3.6315e+00, -8.0895e-02],
        [ 3.6538e+00, -6.1554e-01],
        [ 1.2058e+00,  1.0887e+00],
        [ 2.6159e+00, -1.0199e+00],
        [ 1.9385e+00, -7.8014e-01],
        [ 5.4272e-01,  1.5334e+00],
        [ 3.1592e+00, -1.3876e+00],
        [ 3.1392e+00, -1.0036e+00],
        [ 2.2305e+00, -1.5007e+00],
        [ 3.7161e+00, -1.7968e-01],
        [ 2.0418e+00,  2.2796e-01],
        [ 4.3008e+00, -2.7451e-01],
        [ 3.1464e+00, -1.6793e-01],
        [ 3.3730e+00, -4.5294e-01],
        [ 3.8503e+00,  1.3407e+00],
        [ 3.5458e+00,  1.8180e+00],
        [ 2.4730e+00, -1.1465e+00],
        [ 1.3054e+00, -5.7421e-01],
        [ 4.0239e+00, -1.3977e+00],
        [ 2.1184e+00,  1.0144e+00],
        [ 3.8625e+00,  1.0415e+00],
        [ 2.8061e+00,  1.0023e+00],
        [ 3.7003e+00, -1.1987e+00],
        [ 1.5156e+00, -4.7096e-01],
        [ 1.9272e+00, -3.3029e-02],
        [ 2.9438e+00, -5.3766e-01],
        [ 3.4507e+00, -3.4172e-01],
        [ 2.3724e+00, -7.3532e-01],
        [ 2.3807e+00, -4.0331e-01],
        [ 2.8734e+00, -9.2605e-01],
        [ 2.3928e+00, -4.6690e-01],
        [ 2.6395e+00, -2.7299e+00],
        [ 2.8487e+00,  7.6402e-01],
        [ 3.4645e+00, -4.0915e-01],
        [ 1.9548e+00, -3.9780e-01],
        [ 3.6911e+00, -3.1119e-02],
        [ 2.6071e+00, -1.2465e+00],
        [ 2.8214e+00, -6.4985e-01],
        [ 1.5930e+00,  2.9120e+00],
        [ 1.4605e+00,  7.2332e-01],
        [ 1.7990e+00,  1.4443e+00],
        [ 2.9508e+00,  2.7149e+00],
        [ 2.8324e+00,  9.6945e-01],
        [ 2.7792e+00, -8.7107e-01],
        [ 2.8536e+00, -6.4021e-01],
        [ 1.9764e+00, -7.1593e-01],
        [ 2.8083e+00, -2.2212e+00],
        [ 4.5912e+00,  1.0887e+00],
        [ 1.7598e+00, -1.4101e+00],
        [ 3.6951e+00, -1.2749e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[5.3881e-03, 9.5553e-03, 1.1751e-02,  ..., 9.2907e-01, 9.2945e-01,
         1.0000e+00],
        [1.1783e-04, 3.6637e-02, 3.9891e-02,  ..., 9.9944e-01, 1.0000e+00,
         1.0000e+00],
        [3.6439e-06, 1.1590e-03, 4.1941e-03,  ..., 9.8275e-01, 9.8281e-01,
         1.0000e+00],
        ...,
        [7.1364e-03, 7.8323e-03, 9.1220e-03,  ..., 9.9685e-01, 9.9993e-01,
         1.0000e+00],
        [8.0499e-02, 8.1992e-02, 8.1992e-02,  ..., 9.8542e-01, 9.8635e-01,
         1.0000e+00],
        [1.2392e-02, 1.8121e-02, 4.5993e-02,  ..., 8.5928e-01, 9.9992e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.5515],
        [0.2050],
        [0.7769],
        [0.9022],
        [0.1066],
        [0.6453],
        [0.3740],
        [0.8030],
        [0.9355],
        [0.8922],
        [0.0845],
        [0.5956],
        [0.0758],
        [0.7367],
        [0.6199],
        [0.9223],
        [0.1130],
        [0.4162],
        [0.4367],
        [0.2591],
        [0.2569],
        [0.0199],
        [0.3331],
        [0.8123],
        [0.3657],
        [0.9459],
        [0.0788],
        [0.9786],
        [0.9167],
        [0.5480],
        [0.1334],
        [0.6340],
        [0.8727],
        [0.2404],
        [0.0529],
        [0.9177],
        [0.2879],
        [0.4434],
        [0.7627],
        [0.3803],
        [0.0102],
        [0.8116],
        [0.8493],
        [0.4431],
        [0.6770],
        [0.9923],
        [0.7249],
        [0.4307],
        [0.7503],
        [0.4056],
        [0.4129],
        [0.1103],
        [0.6370],
        [0.6708],
        [0.5074],
        [0.8922],
        [0.1531],
        [0.7515],
        [0.9309],
        [0.2046],
        [0.5800],
        [0.9415],
        [0.9428],
        [0.0786],
        [0.3130],
        [0.8553],
        [0.4668],
        [0.7037],
        [0.0748],
        [0.8609],
        [0.4734],
        [0.6957],
        [0.5366],
        [0.1771],
        [0.5889],
        [0.4014],
        [0.2405],
        [0.0630],
        [0.4399],
        [0.2195],
        [0.3917],
        [0.3809],
        [0.2423],
        [0.9577],
        [0.2944],
        [0.4517],
        [0.6668],
        [0.5011],
        [0.1120],
        [0.1703],
        [0.1101],
        [0.8013],
        [0.8050],
        [0.8622],
        [0.0959],
        [0.2777],
        [0.6783],
        [0.0420],
        [0.2120],
        [0.4836],
        [0.5213],
        [0.3535],
        [0.7868],
        [0.2239],
        [0.0376],
        [0.2175],
        [0.5544],
        [0.1051],
        [0.0199],
        [0.3543],
        [0.9344],
        [0.8660],
        [0.7016],
        [0.9871],
        [0.5023],
        [0.0034],
        [0.9560],
        [0.5768],
        [0.1428],
        [0.3708],
        [0.9375],
        [0.4582],
        [0.3934],
        [0.0772],
        [0.5898],
        [0.2382],
        [0.6696],
        [0.9430],
        [0.7239],
        [0.7353],
        [0.8341],
        [0.5738],
        [0.5383],
        [0.6063],
        [0.7215],
        [0.6842],
        [0.9461],
        [0.2516],
        [0.9974],
        [0.5988],
        [0.0602],
        [0.9842],
        [0.1293],
        [0.3597],
        [0.9793],
        [0.4072],
        [0.9644],
        [0.0506],
        [0.3462],
        [0.3667],
        [0.0607],
        [0.9854],
        [0.3852],
        [0.9721],
        [0.7428],
        [0.0438],
        [0.6725],
        [0.8368],
        [0.9855],
        [0.2745],
        [0.2830],
        [0.2265],
        [0.1088],
        [0.8453],
        [0.3988],
        [0.7612],
        [0.9109],
        [0.2050],
        [0.0075],
        [0.2217],
        [0.9295],
        [0.9185],
        [0.5791],
        [0.0906],
        [0.2242],
        [0.6919],
        [0.3258],
        [0.4345],
        [0.8168],
        [0.6043],
        [0.1367],
        [0.1255],
        [0.1571],
        [0.5253],
        [0.3607],
        [0.3141],
        [0.3850],
        [0.9469],
        [0.8480],
        [0.8154],
        [0.0664],
        [0.0234],
        [0.9560],
        [0.2360],
        [0.0098],
        [0.7375],
        [0.9661],
        [0.9767],
        [0.6775],
        [0.7742],
        [0.0499],
        [0.0905],
        [0.5615],
        [0.8813],
        [0.5116],
        [0.1514],
        [0.0201],
        [0.4271],
        [0.1902],
        [0.4816],
        [0.4926],
        [0.5648],
        [0.9272],
        [0.6151],
        [0.8318],
        [0.0797],
        [0.9117],
        [0.0776],
        [0.0985],
        [0.7809],
        [0.6075],
        [0.8557],
        [0.8578],
        [0.5291],
        [0.6153],
        [0.3437],
        [0.4644],
        [0.8560],
        [0.1311],
        [0.4925],
        [0.8432],
        [0.6097],
        [0.0452],
        [0.6075],
        [0.7728],
        [0.9285],
        [0.9252],
        [0.2753],
        [0.9664],
        [0.2547],
        [0.5873],
        [0.3667],
        [0.8065],
        [0.7395],
        [0.0453],
        [0.5106],
        [0.1121],
        [0.0461],
        [0.8033],
        [0.5444],
        [0.5722],
        [0.7544],
        [0.0093],
        [0.2225],
        [0.2155],
        [0.2285],
        [0.9128],
        [0.3645],
        [0.5404],
        [0.1754],
        [0.9583],
        [0.9423],
        [0.7475],
        [0.0880],
        [0.1153],
        [0.4829],
        [0.3743],
        [0.2263],
        [0.5450],
        [0.1099],
        [0.6247],
        [0.9879],
        [0.0245],
        [0.3693],
        [0.5520],
        [0.8169],
        [0.5421],
        [0.0842],
        [0.3687],
        [0.7625],
        [0.3382],
        [0.4495],
        [0.0502],
        [0.6245],
        [0.3083],
        [0.7559],
        [0.4016],
        [0.1992],
        [0.5324],
        [0.5472],
        [0.9670],
        [0.2400],
        [0.6629],
        [0.6726],
        [0.3213],
        [0.0868],
        [0.9965],
        [0.0814],
        [0.3140],
        [0.7982],
        [0.6531],
        [0.0050],
        [0.0617],
        [0.5610],
        [0.4759],
        [0.3318],
        [0.0461],
        [0.6751],
        [0.9833],
        [0.0574],
        [0.0609],
        [0.2162]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [ True, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 1.9081,  2.1155],
        [ 1.4174,  1.9191],
        [ 0.1824,  0.4497],
        ...,
        [-2.4527,  0.8042],
        [ 1.6655,  0.1224],
        [-1.0616,  1.8027]]) torch.Size([9984, 2])
samples tensor([[ 3.4910e+00, -1.0214e+00],
        [ 3.4039e+00, -2.7295e-01],
        [ 2.3346e+00,  2.4065e+00],
        [ 1.2875e+00, -7.0271e-02],
        [ 4.2176e+00,  2.4986e-01],
        [ 3.5399e+00,  1.1058e+00],
        [ 2.3248e+00,  8.7043e-01],
        [ 3.1149e+00, -8.7953e-02],
        [ 1.3024e+00, -2.2292e-02],
        [ 3.1385e+00,  1.7708e-01],
        [ 2.9863e+00,  1.2411e+00],
        [ 3.8513e+00, -2.1914e-01],
        [-4.9084e-02, -4.3625e-01],
        [ 1.8932e+00,  8.3057e-01],
        [ 3.7854e+00, -3.2673e-01],
        [ 1.5912e+00, -9.4559e-02],
        [ 9.2092e-02, -1.5324e+00],
        [ 4.6135e+00, -1.1176e-01],
        [ 3.7589e+00,  1.1406e-03],
        [ 1.8038e+00, -1.3242e+00],
        [ 3.6852e+00, -1.8309e+00],
        [ 7.1960e-01, -6.0245e-01],
        [ 2.4749e+00, -4.1172e-02],
        [ 3.7083e+00, -8.6996e-01],
        [-1.8608e-01,  3.1384e-01],
        [ 2.0446e+00,  4.7686e-01],
        [ 2.4449e+00, -3.9601e-02],
        [ 1.8766e+00,  1.8285e+00],
        [ 2.4163e+00,  6.5195e-01],
        [ 4.5724e+00, -7.9077e-01],
        [ 3.4171e+00, -1.1262e-01],
        [ 1.8170e+00,  4.5933e-01],
        [ 9.1201e-01, -8.8020e-01],
        [ 2.4211e+00,  7.4373e-01],
        [ 2.3136e+00, -5.7132e-01],
        [ 7.7536e-01,  2.3645e-01],
        [ 3.3453e+00, -1.6011e+00],
        [ 1.2223e+00, -2.7409e-01],
        [ 2.6255e+00, -5.1415e-01],
        [ 3.3324e+00, -3.1840e-01],
        [ 1.1918e+00,  6.5407e-01],
        [ 3.2010e+00,  1.1623e+00],
        [ 2.1415e+00, -1.9406e+00],
        [ 2.2928e+00, -1.8218e+00],
        [ 4.0054e+00,  1.1516e+00],
        [ 3.6441e+00,  9.2169e-01],
        [ 3.3665e+00, -1.5554e+00],
        [ 3.2944e+00,  3.3045e-01],
        [ 2.9003e+00,  2.5989e-01],
        [ 3.0240e+00,  7.8888e-01],
        [ 4.0777e+00, -9.5715e-01],
        [ 2.1092e+00, -3.6543e-01],
        [ 2.1715e+00,  1.2089e+00],
        [ 2.7647e+00, -1.7410e+00],
        [ 1.5441e+00, -1.2846e+00],
        [ 1.8629e+00, -1.1535e+00],
        [ 3.2751e+00,  1.0648e+00],
        [ 1.6161e+00, -2.2426e-01],
        [ 2.2573e+00,  9.7751e-01],
        [ 2.8799e+00,  8.0116e-01],
        [ 2.6110e+00,  1.0596e+00],
        [ 4.8635e+00, -5.4322e-01],
        [ 1.1612e+00, -5.5141e-01],
        [ 1.4003e+00, -6.8177e-01],
        [ 2.6522e+00,  5.7432e-01],
        [ 6.2913e-01,  9.1708e-01],
        [ 4.6525e+00, -9.2554e-01],
        [ 1.7068e+00, -9.7142e-02],
        [ 1.4124e+00,  6.3037e-01],
        [ 3.2094e+00,  3.4943e-02],
        [ 1.4322e+00, -1.8807e+00],
        [ 1.5560e+00,  2.0780e+00],
        [ 1.6564e+00,  4.1225e-01],
        [ 2.5723e+00, -2.3553e-01],
        [ 2.4330e+00,  7.0475e-01],
        [ 1.1404e+00, -9.6819e-01],
        [ 1.0381e+00, -5.9237e-01],
        [ 1.7422e+00,  9.0652e-01],
        [ 4.0072e+00,  5.1901e-01],
        [ 2.4029e-01, -6.5568e-02],
        [ 4.7369e+00,  3.6778e-01],
        [ 2.7950e+00,  3.5129e-01],
        [ 8.9195e-01,  9.0342e-01],
        [ 7.5095e-01,  7.0513e-01],
        [ 1.5081e+00,  7.9827e-01],
        [ 3.1168e+00, -1.5965e+00],
        [ 2.5471e+00,  6.3711e-01],
        [ 4.2538e+00,  8.3094e-01],
        [ 4.7092e+00, -7.3433e-01],
        [ 1.9516e+00, -4.2042e-01],
        [ 2.9595e+00,  1.5539e+00],
        [ 3.1917e+00, -2.6855e-02],
        [ 1.8491e+00, -1.5392e+00],
        [ 1.7825e+00,  3.7046e-02],
        [ 1.2202e+00, -2.2622e-01],
        [ 3.0266e+00, -6.8109e-01],
        [ 2.1036e+00,  6.1134e-02],
        [ 2.0974e+00, -7.1276e-01],
        [ 3.4988e+00, -1.3675e+00],
        [ 1.3236e+00,  3.1437e-01],
        [ 2.9552e+00, -5.5463e-01],
        [ 3.6625e+00,  7.8612e-01],
        [ 3.7229e+00, -1.0143e-01],
        [ 3.0639e+00,  1.9247e-01],
        [ 1.7015e+00,  3.3108e-01],
        [ 3.2579e+00, -1.1259e-01],
        [ 1.1933e+00, -5.5410e-01],
        [-5.8820e-01,  4.6463e-02],
        [ 2.4728e+00, -9.6498e-01],
        [ 4.2641e+00, -1.1620e+00],
        [ 2.0482e+00,  1.2758e+00],
        [ 1.9490e+00,  5.4661e-01],
        [ 3.5838e+00, -1.4876e+00],
        [ 1.9826e+00,  4.6379e-01],
        [ 2.0541e+00,  4.2310e-01],
        [ 1.3113e-01, -3.2591e-01],
        [ 2.7419e+00, -1.6235e+00],
        [ 1.6593e+00, -5.8311e-01],
        [ 3.2042e+00, -1.1703e+00],
        [ 2.4873e+00,  5.0757e-01],
        [ 1.1491e+00,  2.3024e-01],
        [ 2.9800e+00, -9.7596e-01],
        [ 3.2843e+00,  3.7862e-02],
        [ 3.1104e+00, -1.1027e+00],
        [ 4.0424e+00, -2.0428e+00],
        [ 2.9085e+00, -5.7540e-01],
        [ 2.3900e+00, -8.8108e-01],
        [ 1.7475e+00, -1.5868e-01],
        [ 1.8624e+00, -8.7663e-01],
        [ 2.7858e+00, -5.3039e-01],
        [ 1.4902e+00, -1.5565e-01],
        [ 2.5156e+00,  4.3528e-01],
        [ 3.2296e+00,  2.8918e-01],
        [ 2.4575e+00,  2.5259e-02],
        [ 2.6074e+00, -2.9363e-01],
        [ 7.4484e-01,  4.4004e-01],
        [ 2.3958e+00, -7.1288e-01],
        [ 3.3959e+00,  6.0162e-01],
        [ 2.1878e-01,  1.0119e+00],
        [ 2.4148e+00, -1.5629e+00],
        [ 3.4639e+00,  6.2884e-01],
        [ 5.9314e-02,  1.7508e+00],
        [-1.1538e-01, -1.9342e+00],
        [ 1.3975e+00,  4.5996e-01],
        [ 2.4459e+00, -5.9868e-02],
        [ 1.5271e+00, -1.4542e+00],
        [ 2.7373e+00, -6.2065e-01],
        [ 2.4563e+00,  1.6331e-01],
        [ 2.8560e+00, -1.5227e+00],
        [ 6.0167e-01,  5.7847e-01],
        [ 1.4351e+00, -7.0172e-01],
        [ 7.2750e-01,  4.2194e-01],
        [ 2.6555e+00,  1.5185e-01],
        [ 2.9630e+00,  1.2618e+00],
        [ 1.1558e+00,  1.1803e+00],
        [ 1.1070e+00,  1.7362e-01],
        [ 9.1202e-02, -1.0894e+00],
        [ 2.5898e+00,  9.3583e-01],
        [ 8.0948e-01,  9.4554e-01],
        [ 2.5053e+00, -1.1952e+00],
        [ 2.5117e+00, -6.0612e-01],
        [ 2.5785e+00, -6.3633e-01],
        [ 2.5857e+00, -3.9342e-01],
        [ 2.2887e+00, -7.0153e-01],
        [ 3.6916e+00,  6.0719e-01],
        [ 1.5299e+00,  8.9884e-01],
        [ 1.4908e+00,  3.9284e-01],
        [ 3.8239e+00, -2.1485e+00],
        [ 1.0615e+00,  1.0150e+00],
        [ 4.0547e+00, -4.2256e-01],
        [ 2.0186e+00, -4.7741e-01],
        [ 2.7140e+00,  1.2654e+00],
        [ 4.3260e-01, -3.4470e-01],
        [ 1.2497e+00, -4.8899e-02],
        [ 2.1474e+00, -1.8907e-01],
        [ 3.0490e+00, -1.7016e+00],
        [ 1.2179e+00,  5.3832e-01],
        [ 3.3932e+00, -9.2216e-01],
        [ 3.4355e+00, -4.4809e-01],
        [ 1.8392e+00, -9.5104e-01],
        [ 2.9972e+00, -2.3223e+00],
        [ 2.0642e+00, -2.1716e-01],
        [ 2.2368e+00,  6.7824e-02],
        [ 3.6458e+00, -1.6722e+00],
        [ 1.9041e+00, -1.3404e+00],
        [ 1.8744e+00, -7.3056e-01],
        [ 3.3390e+00, -1.7242e+00],
        [ 1.6857e+00, -9.0906e-01],
        [ 1.5496e+00, -3.7633e-01],
        [ 2.2925e+00, -2.6797e-01],
        [ 3.4618e+00, -7.2592e-01],
        [ 1.6620e+00,  1.5505e+00],
        [ 1.3135e+00, -8.9612e-01],
        [ 3.8239e+00, -3.7795e-01],
        [ 1.9866e+00, -1.7202e-01],
        [ 1.3849e+00,  1.1538e+00],
        [ 1.6235e+00,  2.1696e-01],
        [ 2.4163e+00, -5.4890e-01],
        [ 2.2023e+00,  2.2190e+00],
        [ 2.3689e+00,  7.3476e-01],
        [ 2.3807e+00, -3.2975e-01],
        [ 2.8979e+00,  5.6296e-02],
        [ 2.3192e+00, -8.7893e-01],
        [ 1.7816e+00, -1.6414e+00],
        [ 2.8692e+00, -3.1716e-01],
        [ 1.6844e+00, -5.5007e-01],
        [ 2.0938e+00,  6.8984e-01],
        [ 3.0989e+00, -1.4107e+00],
        [ 8.5921e-01,  3.7692e-01],
        [ 3.2510e+00,  1.5254e+00],
        [ 3.0448e+00,  1.3045e+00],
        [ 3.7098e+00,  8.5547e-01],
        [ 1.4430e+00, -4.5272e-01],
        [ 2.1730e+00, -1.7967e+00],
        [ 3.9643e+00, -9.0256e-01],
        [ 2.3192e+00,  8.5416e-01],
        [ 2.6194e+00, -2.5412e+00],
        [ 4.3972e+00, -8.4899e-01],
        [ 3.6228e-01,  5.1934e-01],
        [ 1.2354e+00,  1.6448e+00],
        [ 1.9180e+00,  1.3271e+00],
        [ 3.5124e+00, -1.2495e+00],
        [ 1.9439e+00, -1.0221e-01],
        [ 5.7263e-01,  9.2942e-02],
        [ 3.0724e+00,  7.5728e-02],
        [ 1.1517e+00,  4.3854e-01],
        [ 3.3541e+00, -1.8273e+00],
        [ 4.2810e+00, -1.0235e+00],
        [ 3.7598e+00, -2.2958e+00],
        [ 2.7517e+00, -6.4229e-01],
        [ 2.8816e+00,  1.4803e+00],
        [ 4.8327e+00, -1.4837e+00],
        [ 1.3287e+00,  7.3569e-02],
        [ 1.3872e+00,  1.7141e+00],
        [ 4.2304e+00,  1.7187e+00],
        [ 3.4340e+00,  1.2151e+00],
        [ 3.0483e+00, -2.1350e-02],
        [ 2.2719e+00, -5.7726e-01],
        [ 1.7694e+00,  5.3153e-01],
        [ 3.9534e+00,  2.2975e-02],
        [ 8.3230e-01, -1.1450e-01],
        [ 2.1145e+00,  3.3615e-01],
        [ 3.2651e+00, -8.8922e-01],
        [ 2.2952e+00,  2.4903e-01],
        [ 2.7394e+00,  8.9943e-01],
        [ 1.6045e+00, -1.4143e-01],
        [ 1.8102e+00,  1.1255e+00],
        [ 1.5285e+00, -4.9481e-02],
        [ 1.4555e+00, -6.9074e-01],
        [ 2.1476e+00,  9.7111e-01],
        [ 3.2339e+00, -6.2839e-01],
        [ 2.6793e+00, -1.3101e+00],
        [ 3.1866e+00,  1.3379e+00],
        [ 2.9149e+00, -2.5570e+00],
        [ 2.4725e+00,  1.2256e+00],
        [ 4.2048e+00, -1.3942e-01],
        [ 1.8422e+00, -2.5712e-01],
        [ 3.0517e+00, -1.1166e+00],
        [ 2.0547e+00,  4.9988e-01],
        [ 2.5120e-01,  1.2785e+00],
        [ 4.8348e+00,  6.2996e-01],
        [ 2.6165e+00,  8.7798e-02],
        [ 1.8746e+00, -2.0197e+00],
        [ 2.2152e+00,  7.1293e-01],
        [ 3.4468e+00,  3.9470e-01],
        [ 1.5884e+00, -4.0722e-01],
        [ 1.6322e+00, -2.4750e-01],
        [ 2.9113e+00,  2.6620e-01],
        [ 2.7155e+00,  8.8158e-01],
        [ 4.0361e+00, -1.2050e+00],
        [ 2.2052e+00, -1.1035e+00],
        [ 3.9220e+00,  7.0902e-01],
        [ 2.5193e+00,  1.5410e+00],
        [ 3.8928e+00,  1.6063e+00],
        [ 4.6423e+00, -1.9194e+00],
        [ 4.2645e-02,  1.5347e+00],
        [ 1.3459e+00,  7.9952e-01],
        [ 2.9572e+00, -3.0111e+00],
        [ 2.2008e+00, -1.6214e-01],
        [ 3.6044e+00, -9.0270e-02],
        [ 1.2518e+00, -2.3489e-02],
        [ 3.0019e+00, -8.5311e-01],
        [ 1.2006e+00,  6.1982e-01],
        [ 4.0785e+00, -2.1904e+00],
        [ 4.5858e+00,  2.8241e-01],
        [ 2.5740e+00, -4.1256e-01],
        [ 1.7070e+00, -3.4894e-01],
        [ 2.6882e+00,  1.3497e+00],
        [ 2.8410e+00, -5.7220e-01],
        [ 1.2267e+00, -1.4461e+00],
        [ 4.1964e+00,  1.5485e-01],
        [ 2.0954e+00, -6.7152e-01],
        [ 1.9531e+00, -6.4096e-01],
        [ 3.3861e+00,  8.3614e-01],
        [ 2.7840e+00,  5.1296e-01],
        [ 3.3902e+00, -5.0006e-02],
        [ 4.0441e-01,  2.9270e-01],
        [ 6.2647e-01, -1.5851e-01],
        [ 1.4774e+00,  6.0640e-01],
        [ 2.3725e+00, -1.9652e+00],
        [ 3.3831e+00, -2.6351e+00],
        [ 4.2987e+00,  1.4161e+00],
        [ 2.1165e+00,  5.9748e-01],
        [ 2.2876e+00,  5.6507e-01],
        [ 1.2180e+00,  8.9575e-02],
        [ 4.5850e+00, -8.2417e-01],
        [ 1.0985e+00,  1.2025e+00],
        [ 9.0942e-01,  2.1945e-01],
        [ 2.5312e+00, -1.0454e+00],
        [ 4.4510e+00,  5.5817e-01],
        [ 2.1198e+00,  8.7577e-02],
        [ 2.1147e+00,  5.3310e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.0480e-05, 9.1579e-03, 9.1593e-03,  ..., 7.8211e-01, 7.8211e-01,
         1.0000e+00],
        [2.6235e-01, 2.6918e-01, 2.6919e-01,  ..., 9.8517e-01, 9.9972e-01,
         1.0000e+00],
        [3.1159e-03, 3.1159e-03, 3.1179e-03,  ..., 9.8155e-01, 9.8168e-01,
         1.0000e+00],
        ...,
        [1.2766e-02, 9.8028e-02, 3.2263e-01,  ..., 9.4350e-01, 9.9981e-01,
         1.0000e+00],
        [1.5616e-02, 2.5547e-02, 3.0690e-02,  ..., 9.7076e-01, 9.7098e-01,
         1.0000e+00],
        [2.4125e-02, 6.0157e-02, 8.0333e-02,  ..., 6.8885e-01, 1.0000e+00,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[1.1368e-01],
        [8.0328e-01],
        [7.0734e-01],
        [6.1283e-01],
        [6.1254e-01],
        [9.2263e-01],
        [1.9592e-01],
        [2.7831e-02],
        [9.2064e-01],
        [7.6709e-01],
        [5.4901e-01],
        [5.0012e-01],
        [6.0578e-02],
        [7.9843e-01],
        [8.3898e-01],
        [5.8131e-01],
        [5.9457e-01],
        [4.1703e-01],
        [3.8152e-01],
        [5.5572e-01],
        [1.8892e-01],
        [8.8371e-01],
        [8.1851e-01],
        [2.5960e-01],
        [2.0035e-01],
        [6.2438e-01],
        [4.8211e-01],
        [4.0551e-01],
        [3.6075e-01],
        [1.0728e-01],
        [5.5372e-01],
        [8.1822e-01],
        [7.3936e-01],
        [8.4483e-01],
        [2.9351e-01],
        [7.6290e-01],
        [5.5175e-01],
        [7.5689e-02],
        [4.9033e-01],
        [9.4573e-01],
        [3.2903e-01],
        [4.2679e-01],
        [6.5404e-01],
        [6.9512e-01],
        [4.1128e-01],
        [2.3566e-01],
        [9.1101e-01],
        [6.2977e-01],
        [8.3895e-01],
        [1.8643e-01],
        [6.7724e-01],
        [6.3487e-01],
        [8.2948e-01],
        [9.1943e-01],
        [5.2893e-02],
        [2.4085e-02],
        [3.5275e-01],
        [2.2092e-01],
        [5.8152e-01],
        [4.3176e-01],
        [4.9782e-01],
        [7.7740e-01],
        [6.3447e-01],
        [3.1557e-01],
        [5.1986e-01],
        [4.5436e-01],
        [4.7714e-04],
        [1.4984e-01],
        [4.5133e-01],
        [8.6161e-01],
        [9.3426e-01],
        [3.5768e-01],
        [2.8230e-01],
        [2.9538e-01],
        [7.1157e-01],
        [3.1519e-01],
        [3.4575e-01],
        [3.9103e-01],
        [8.4812e-01],
        [8.1170e-01],
        [2.7052e-01],
        [5.1668e-01],
        [3.0836e-01],
        [8.4355e-01],
        [6.4778e-01],
        [3.1048e-01],
        [4.1361e-01],
        [2.1173e-01],
        [4.6221e-01],
        [2.5491e-01],
        [5.7195e-01],
        [3.8298e-01],
        [8.1384e-01],
        [7.9827e-01],
        [5.5425e-01],
        [3.2199e-01],
        [8.5807e-01],
        [6.5182e-01],
        [5.2781e-01],
        [5.6193e-01],
        [5.9902e-01],
        [6.0504e-01],
        [1.3025e-01],
        [3.1439e-01],
        [9.2379e-01],
        [9.6461e-01],
        [8.9041e-01],
        [7.0841e-01],
        [5.8772e-01],
        [3.6306e-01],
        [2.4889e-01],
        [1.7784e-01],
        [4.2854e-01],
        [2.9289e-01],
        [5.7276e-01],
        [4.1333e-01],
        [2.4902e-02],
        [2.4811e-02],
        [1.1123e-01],
        [1.1338e-01],
        [7.7945e-01],
        [9.9660e-01],
        [3.1673e-02],
        [7.6689e-01],
        [3.3675e-01],
        [1.0264e-01],
        [6.7335e-01],
        [3.6027e-01],
        [3.6295e-01],
        [1.5402e-01],
        [4.3898e-01],
        [2.1475e-01],
        [7.4418e-02],
        [8.0396e-01],
        [7.9845e-01],
        [2.0862e-01],
        [7.5586e-01],
        [4.4935e-01],
        [8.6343e-01],
        [8.4486e-01],
        [4.4410e-01],
        [6.2034e-01],
        [5.8802e-01],
        [9.6520e-01],
        [7.6713e-01],
        [7.7933e-01],
        [8.5319e-01],
        [1.5321e-01],
        [2.8843e-01],
        [7.1650e-01],
        [9.0835e-01],
        [1.0138e-01],
        [4.0779e-01],
        [6.9579e-01],
        [1.2564e-01],
        [6.3601e-01],
        [1.2586e-01],
        [8.2475e-01],
        [7.0323e-01],
        [4.9992e-01],
        [3.6512e-01],
        [7.3676e-01],
        [6.8384e-01],
        [8.3085e-01],
        [6.8850e-01],
        [1.4580e-01],
        [7.9316e-02],
        [3.5962e-01],
        [9.6776e-01],
        [8.3355e-01],
        [2.5647e-01],
        [2.2824e-01],
        [6.0658e-01],
        [9.2604e-01],
        [9.5341e-01],
        [5.4583e-01],
        [8.7091e-01],
        [3.3238e-01],
        [9.9007e-01],
        [8.3103e-01],
        [4.1906e-01],
        [2.7753e-01],
        [4.0082e-01],
        [1.8049e-01],
        [5.0701e-01],
        [5.6964e-01],
        [9.3901e-02],
        [4.4689e-01],
        [3.9192e-01],
        [2.0408e-01],
        [6.1545e-01],
        [6.2711e-01],
        [2.0452e-02],
        [2.7901e-01],
        [8.0599e-01],
        [9.3379e-01],
        [2.4565e-02],
        [7.4521e-01],
        [2.5339e-01],
        [1.8440e-01],
        [4.3947e-01],
        [6.0913e-01],
        [8.7246e-01],
        [8.7232e-01],
        [3.6463e-01],
        [9.4850e-02],
        [1.4826e-01],
        [5.2255e-01],
        [1.2628e-01],
        [7.0766e-01],
        [3.3275e-01],
        [8.8254e-02],
        [2.4751e-01],
        [4.6802e-01],
        [3.3811e-01],
        [4.9717e-01],
        [8.7497e-01],
        [7.7611e-01],
        [6.7738e-01],
        [9.9810e-01],
        [6.3502e-02],
        [8.5801e-02],
        [6.5372e-02],
        [3.5134e-01],
        [8.2047e-01],
        [7.8804e-01],
        [4.7712e-01],
        [8.1728e-01],
        [7.1320e-01],
        [9.7672e-01],
        [3.0383e-01],
        [2.7257e-01],
        [7.5653e-01],
        [5.7108e-01],
        [8.4686e-01],
        [2.5468e-02],
        [9.0153e-01],
        [7.8131e-01],
        [2.3200e-01],
        [3.6936e-03],
        [4.3578e-01],
        [6.1021e-01],
        [5.5584e-01],
        [8.1437e-01],
        [6.3077e-01],
        [3.2558e-01],
        [3.3332e-01],
        [3.8896e-01],
        [6.0916e-01],
        [3.5429e-01],
        [2.6838e-01],
        [9.6175e-01],
        [4.9011e-01],
        [5.5499e-02],
        [6.0488e-01],
        [4.8616e-01],
        [4.5787e-01],
        [5.2923e-01],
        [5.9962e-01],
        [6.8479e-01],
        [9.1560e-01],
        [2.1120e-01],
        [5.7247e-01],
        [6.3001e-01],
        [9.0616e-01],
        [2.0796e-01],
        [8.5608e-02],
        [8.0027e-01],
        [9.2597e-01],
        [7.4018e-01],
        [4.3141e-01],
        [8.0532e-02],
        [5.9587e-01],
        [7.8150e-01],
        [6.9589e-01],
        [2.9608e-01],
        [5.0232e-01],
        [6.6433e-01],
        [9.7149e-01],
        [1.6575e-01],
        [3.3500e-01],
        [5.6543e-01],
        [3.6174e-01],
        [9.7311e-01],
        [8.4927e-01],
        [1.1824e-01],
        [8.0337e-01],
        [7.6170e-01],
        [4.1714e-01],
        [9.2213e-01],
        [7.2387e-01],
        [3.9447e-01],
        [4.3912e-02],
        [8.1913e-01],
        [9.1463e-01],
        [8.0546e-01],
        [1.3526e-01],
        [2.2567e-01],
        [3.6386e-02],
        [7.8333e-01],
        [8.4444e-01],
        [5.3511e-01],
        [1.3359e-01],
        [7.3419e-01],
        [6.9231e-01],
        [8.7928e-01],
        [3.3755e-01],
        [8.1745e-01],
        [1.1096e-01],
        [6.1702e-02],
        [3.1974e-01],
        [6.0868e-01]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-1.6412,  0.2751],
        [ 2.3041,  1.8457],
        [-2.4406, -1.2745],
        ...,
        [ 0.4426,  1.5861],
        [ 1.2182, -0.7733],
        [-3.2265, -1.2060]]) torch.Size([9984, 2])
samples tensor([[ 1.6107e+00,  1.7543e+00],
        [ 3.2679e+00,  1.1383e+00],
        [ 3.4498e+00, -4.7116e-01],
        [ 2.3141e+00, -6.7450e-01],
        [ 3.1987e+00,  2.2466e-02],
        [ 1.7621e+00, -1.1722e-01],
        [ 2.3273e+00, -3.2082e-01],
        [ 2.3198e+00,  4.0046e-01],
        [ 3.1924e+00,  8.7169e-02],
        [ 3.7909e+00, -1.7314e-03],
        [ 1.5525e+00, -1.2259e+00],
        [ 3.7713e+00, -1.0085e+00],
        [ 3.7754e+00, -6.1703e-01],
        [ 1.1943e+00, -6.7990e-01],
        [ 3.0132e+00,  4.9080e-01],
        [ 1.9369e+00, -2.3613e+00],
        [ 2.5562e+00, -5.8475e-01],
        [ 1.3281e+00, -2.2484e+00],
        [ 1.2034e+00, -1.4812e+00],
        [ 3.2734e+00,  2.7828e-01],
        [ 2.4448e+00,  7.4573e-01],
        [ 1.2557e+00,  2.1885e-01],
        [ 3.7531e+00, -2.2179e+00],
        [ 3.6393e+00,  1.4013e-01],
        [ 1.9104e+00, -2.3892e-01],
        [ 2.2398e+00,  1.5136e+00],
        [ 3.3593e+00, -3.4195e-01],
        [ 1.5801e+00, -1.3616e-01],
        [ 1.2008e+00, -7.0856e-01],
        [ 1.6018e+00,  2.0200e+00],
        [ 2.9636e+00,  5.1524e-01],
        [ 1.8832e+00, -1.3185e+00],
        [ 1.8644e+00,  6.3538e-01],
        [ 3.1734e+00, -1.0139e+00],
        [ 1.7403e+00,  1.4841e-02],
        [ 1.6429e+00, -1.0873e+00],
        [ 1.4366e+00, -3.9373e-01],
        [ 1.3022e+00,  1.0590e+00],
        [ 1.4992e+00, -6.2495e-01],
        [ 3.7488e+00,  5.2619e-04],
        [ 1.5959e+00, -1.7351e+00],
        [ 3.3969e+00,  4.6130e-02],
        [ 2.5824e-01, -1.2673e+00],
        [ 1.9390e+00,  6.2858e-02],
        [ 2.2835e+00,  4.8466e-01],
        [ 3.3559e+00,  4.2578e-01],
        [ 1.9561e+00,  5.3418e-01],
        [ 3.3378e+00, -5.9040e-01],
        [ 2.9597e+00, -5.6861e-01],
        [ 2.2736e+00,  3.2088e-01],
        [ 1.5213e+00, -2.0211e-01],
        [ 1.5520e+00, -3.5462e-01],
        [ 4.1436e+00, -1.3906e+00],
        [ 2.0833e+00,  7.9508e-01],
        [ 3.0072e+00, -1.1925e+00],
        [ 2.4221e-01, -1.9797e-01],
        [ 1.8451e+00,  1.0680e+00],
        [ 2.1035e+00, -3.9498e-01],
        [ 1.9368e+00, -7.6734e-01],
        [ 1.7252e+00,  2.5573e-01],
        [ 3.4765e+00,  2.1622e-01],
        [ 7.2219e-01,  9.5384e-01],
        [ 1.5619e+00,  3.6627e-01],
        [ 2.2044e+00,  9.8983e-02],
        [ 3.8189e+00, -1.1084e+00],
        [ 3.3714e+00,  1.1026e+00],
        [ 4.4423e+00,  1.3989e+00],
        [ 2.2326e+00, -1.5563e+00],
        [ 3.5369e+00, -2.2650e+00],
        [ 1.6899e+00,  8.6057e-01],
        [ 8.0025e-01, -4.2684e-01],
        [ 3.3069e+00,  2.1244e-01],
        [ 3.5239e+00, -1.6315e+00],
        [ 3.1478e+00, -1.0475e-01],
        [ 2.4175e+00,  2.0234e-01],
        [ 3.1667e+00, -1.1670e+00],
        [ 1.4560e+00, -1.1105e+00],
        [ 2.6674e+00,  9.2572e-01],
        [ 1.0318e+00,  1.2334e+00],
        [ 3.0254e+00,  1.3371e+00],
        [ 3.1138e+00,  3.8725e-01],
        [ 2.3333e+00,  1.8057e+00],
        [ 3.0026e+00,  4.2380e-01],
        [ 4.8026e+00,  8.4022e-01],
        [ 2.5706e+00,  7.9353e-01],
        [ 2.7205e+00, -2.9419e-01],
        [ 1.4472e+00, -5.6805e-02],
        [ 3.0832e+00,  2.6261e-03],
        [ 2.1471e+00, -2.0733e-01],
        [ 2.5620e+00, -1.5578e+00],
        [ 3.6542e+00, -2.8502e-01],
        [ 4.3774e+00, -2.1559e+00],
        [ 3.0864e+00, -1.7521e-01],
        [ 1.0201e+00,  4.8795e-01],
        [ 2.0967e+00,  8.4569e-01],
        [ 2.7582e+00,  1.5513e+00],
        [ 2.0107e+00, -7.6153e-01],
        [ 2.9285e+00,  3.8994e-01],
        [ 2.7975e+00, -7.6225e-01],
        [ 2.8908e+00,  3.2272e-01],
        [ 2.1061e+00, -8.9255e-02],
        [ 5.3723e-02, -2.0379e+00],
        [ 1.5958e+00, -5.2836e-01],
        [ 2.0389e+00, -1.8074e-02],
        [ 3.8468e+00,  8.8245e-01],
        [ 2.0026e+00,  8.8209e-01],
        [ 3.6846e+00,  4.4218e-01],
        [ 1.9455e-01,  1.6204e+00],
        [ 2.6176e+00, -6.9602e-01],
        [ 2.5337e+00, -5.1589e-01],
        [ 2.6721e+00,  9.7708e-01],
        [ 1.6768e+00,  9.1712e-01],
        [ 2.7617e+00, -2.0519e+00],
        [ 2.3114e+00,  3.9389e-01],
        [ 2.2723e+00, -2.0674e+00],
        [ 1.7968e+00, -2.2093e-01],
        [ 1.5291e+00, -1.8418e-01],
        [ 1.9780e+00,  3.7928e-01],
        [ 1.2728e+00, -1.4303e+00],
        [ 3.5176e+00, -2.0135e+00],
        [ 2.8823e+00,  5.2125e-01],
        [ 3.3429e-01,  1.3407e+00],
        [ 1.8185e+00,  1.5795e+00],
        [ 2.4884e+00, -5.8330e-01],
        [ 4.1175e+00,  1.2266e+00],
        [ 3.4770e+00,  4.0060e-01],
        [ 1.6467e+00, -1.2096e+00],
        [ 2.6906e+00,  8.3443e-01],
        [ 2.7330e+00, -1.7805e+00],
        [ 3.0516e+00,  5.3932e-01],
        [ 2.3474e+00,  6.2744e-01],
        [ 1.9332e+00, -1.2769e+00],
        [ 4.0020e+00,  5.6700e-01],
        [ 2.8113e+00, -8.0084e-02],
        [ 2.4484e+00,  3.0130e-01],
        [ 1.5711e+00,  7.2864e-01],
        [ 2.6836e+00,  2.7900e-01],
        [ 1.4628e+00,  1.1863e+00],
        [ 3.4725e+00,  4.4775e-03],
        [ 1.5382e+00,  2.5132e-01],
        [ 3.4325e+00, -6.0852e-01],
        [ 2.9709e+00, -7.0374e-01],
        [ 2.2009e+00, -8.0923e-01],
        [ 1.8744e+00,  3.9548e-01],
        [ 2.9878e+00, -4.7810e-01],
        [ 2.1707e+00, -1.9909e+00],
        [ 2.6399e+00,  5.6728e-01],
        [ 3.0134e+00, -8.9889e-01],
        [ 2.3594e+00,  1.5015e+00],
        [ 1.9802e+00, -1.5395e+00],
        [ 2.7024e+00,  1.3127e+00],
        [ 1.0664e+00, -1.0281e+00],
        [-1.6546e-01, -1.2265e+00],
        [ 2.7928e+00, -5.7746e-01],
        [ 1.8677e+00, -6.1325e-01],
        [ 3.2196e+00, -8.7625e-01],
        [ 1.7288e+00, -1.6143e+00],
        [ 4.0579e+00, -1.3518e+00],
        [ 2.5948e+00,  4.0497e-01],
        [ 3.9061e+00,  4.0619e-01],
        [ 2.5777e+00, -6.7774e-01],
        [ 6.9329e-01,  6.1501e-02],
        [ 2.3830e+00,  4.4987e-01],
        [ 2.5390e+00,  6.0030e-01],
        [ 3.1441e+00, -1.1002e+00],
        [ 2.5608e+00, -3.7566e-01],
        [ 3.3631e+00,  5.8807e-02],
        [ 2.1385e+00, -7.4840e-01],
        [ 5.8238e-01, -4.3666e-01],
        [ 2.8355e+00, -2.1869e+00],
        [ 1.0818e+00, -6.6732e-01],
        [ 2.8196e+00, -6.8184e-01],
        [ 1.3662e+00, -4.3124e-01],
        [ 1.4588e+00,  5.2219e-02],
        [ 2.5222e+00,  1.2878e+00],
        [ 4.1822e+00, -8.7614e-01],
        [ 2.1167e+00,  7.1614e-01],
        [ 1.1030e+00, -1.7384e+00],
        [ 1.8117e+00, -1.1048e+00],
        [ 3.2357e+00, -1.8286e-01],
        [ 3.1457e+00, -7.6594e-01],
        [ 2.1485e+00, -3.3992e-01],
        [ 3.9256e+00, -2.0172e+00],
        [ 1.0079e+00, -3.2315e-01],
        [ 2.6506e+00, -1.0241e+00],
        [ 3.9483e+00, -8.3570e-01],
        [ 1.5973e+00,  2.4598e-01],
        [ 2.5524e+00, -9.0580e-01],
        [ 2.2254e+00, -6.8258e-01],
        [ 2.9601e+00, -7.5528e-01],
        [ 3.7086e+00, -1.0361e+00],
        [ 2.2231e+00, -2.2816e+00],
        [ 3.0982e+00, -1.6444e-01],
        [ 4.0787e+00, -1.0035e+00],
        [ 1.4478e+00,  3.2384e-01],
        [ 3.2347e+00,  2.3684e-01],
        [ 2.6978e+00,  2.0943e+00],
        [ 1.9888e+00,  4.2139e-01],
        [ 1.7118e+00, -2.2149e-01],
        [ 4.0893e+00, -2.2024e-01],
        [ 1.5785e+00, -1.0998e+00],
        [ 2.7090e+00,  1.1220e+00],
        [ 3.4617e+00,  2.9829e-01],
        [ 2.1291e+00, -8.0922e-01],
        [ 2.6078e+00, -1.3765e+00],
        [ 1.5028e+00, -1.9084e-01],
        [ 2.5219e+00,  1.6451e+00],
        [ 1.9080e+00, -4.2445e-01],
        [ 2.8100e+00, -1.7613e+00],
        [ 2.8095e+00, -6.4911e-01],
        [ 2.5827e+00, -2.4494e-01],
        [ 2.2622e+00, -4.3414e-02],
        [ 3.3067e+00,  1.1433e-03],
        [ 2.9447e+00, -4.5461e-01],
        [ 3.6178e+00,  5.4237e-01],
        [ 1.9342e+00, -2.0203e-01],
        [ 2.4615e+00, -3.5877e-01],
        [ 1.8859e+00, -4.0405e-01],
        [ 2.0975e+00,  8.1371e-01],
        [ 2.3416e+00,  8.7546e-01],
        [ 1.7639e+00,  1.0208e+00],
        [ 1.2355e+00, -7.6153e-01],
        [ 3.6623e+00, -1.7534e-01],
        [ 2.7673e+00,  6.2920e-01],
        [ 2.6957e+00, -5.9907e-01],
        [ 1.1190e+00,  1.4035e+00],
        [ 2.1190e+00, -1.5853e+00],
        [ 2.8759e+00, -8.7622e-01],
        [ 3.6747e+00, -2.5487e-01],
        [ 2.0105e+00, -4.0623e-01],
        [ 3.9647e+00,  6.1095e-02],
        [ 3.0137e+00,  6.3697e-01],
        [ 2.1328e+00,  1.1870e+00],
        [ 1.8517e+00, -1.1201e+00],
        [ 3.3808e+00,  4.4926e-02],
        [ 2.5230e+00,  1.1297e+00],
        [ 1.9082e+00, -1.4459e+00],
        [ 3.8394e+00, -3.2500e-01],
        [ 1.9758e+00, -2.0467e-01],
        [ 1.9053e+00,  5.3483e-01],
        [ 2.8421e+00,  4.5590e-01],
        [ 2.5049e+00, -2.2377e+00],
        [ 1.6595e+00, -6.6694e-01],
        [ 1.1364e+00, -5.8145e-01],
        [ 3.0586e+00,  4.1963e-01],
        [ 1.8517e+00,  1.1950e+00],
        [ 2.1876e+00, -7.1510e-01],
        [ 2.3221e+00, -2.2923e+00],
        [ 1.8872e+00, -9.9882e-01],
        [ 1.4636e+00,  2.4124e-01],
        [ 2.8801e+00, -1.0363e+00],
        [ 3.2976e+00, -7.5910e-01],
        [ 4.1600e+00, -7.5609e-01],
        [ 1.8572e+00,  1.3352e+00],
        [ 3.6064e+00, -1.5576e+00],
        [ 1.8647e+00,  9.6239e-02],
        [ 2.7008e+00,  5.3639e-01],
        [ 1.1804e+00,  5.7341e-01],
        [ 4.6135e+00, -2.4807e-01],
        [ 1.5991e+00, -6.3096e-01],
        [ 2.0637e+00,  1.1770e+00],
        [ 2.2272e+00,  5.5170e-01],
        [ 3.4880e+00, -1.5615e+00],
        [ 2.8085e+00, -1.8065e+00],
        [ 3.1385e+00,  4.5782e-01],
        [ 1.2445e+00, -1.1284e-01],
        [ 1.6817e+00,  3.1243e-02],
        [ 1.9717e+00, -1.2180e-01],
        [ 1.7078e+00,  4.5085e-02],
        [ 2.7271e+00,  1.0352e+00],
        [ 1.6043e+00, -7.7987e-02],
        [ 2.4496e+00,  4.3656e-01],
        [ 3.6313e+00, -2.4463e+00],
        [ 2.1688e+00, -5.7722e-01],
        [ 2.9793e+00, -4.6916e-02],
        [ 2.6514e+00, -2.3068e+00],
        [ 2.9126e+00, -1.2170e+00],
        [ 3.5452e+00, -9.8789e-01],
        [ 1.7225e+00,  8.3430e-01],
        [ 1.2992e+00, -7.7382e-01],
        [ 2.7251e+00, -1.5618e+00],
        [ 2.8648e+00, -3.6411e-01],
        [ 3.3422e+00,  2.3918e+00],
        [ 2.4279e+00,  8.2738e-01],
        [ 2.8353e+00,  8.3343e-01],
        [ 2.8075e+00, -6.9591e-01],
        [ 3.4124e+00,  7.0894e-01],
        [ 3.6857e+00,  9.7078e-01],
        [ 3.8209e+00, -9.5713e-01],
        [ 3.9684e+00,  3.5995e-01],
        [ 2.7312e+00, -9.7465e-02],
        [ 1.0752e+00,  3.4272e-01],
        [ 2.9635e+00,  1.7545e+00],
        [ 9.1765e-01, -1.6185e+00],
        [ 1.4086e+00,  7.6033e-01],
        [ 3.1702e+00, -1.2532e+00],
        [ 2.2659e+00, -4.3149e-01],
        [ 2.9083e+00, -1.7388e+00],
        [ 1.3575e+00, -7.6018e-01],
        [ 2.6259e+00,  2.4057e-01],
        [ 1.0884e+00,  4.1037e-01],
        [ 2.1268e+00, -6.8240e-03],
        [ 3.9133e+00, -9.1963e-01],
        [ 4.1305e+00, -6.5484e-02],
        [ 1.3200e+00, -6.4187e-01],
        [ 1.2912e+00, -1.0940e+00],
        [ 4.4451e-01, -9.8308e-01],
        [ 6.7259e-01,  4.1188e-01],
        [ 1.5337e+00,  1.6446e-01],
        [ 1.8501e+00,  7.8987e-02],
        [ 2.4267e+00, -2.4595e-01],
        [ 1.4010e+00,  2.4782e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[5.6397e-03, 6.9490e-02, 9.8130e-02,  ..., 9.8910e-01, 9.9998e-01,
         1.0000e+00],
        [4.8861e-05, 1.4089e-02, 1.4089e-02,  ..., 8.9789e-01, 1.0000e+00,
         1.0000e+00],
        [9.8638e-05, 6.9199e-03, 6.9221e-03,  ..., 9.8262e-01, 9.8262e-01,
         1.0000e+00],
        ...,
        [3.9622e-03, 3.9654e-03, 3.9655e-03,  ..., 9.6204e-01, 9.6204e-01,
         1.0000e+00],
        [2.0545e-02, 2.0651e-02, 2.0651e-02,  ..., 9.1268e-01, 9.1279e-01,
         1.0000e+00],
        [7.7495e-02, 7.7495e-02, 7.7496e-02,  ..., 1.0000e+00, 1.0000e+00,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.7826],
        [0.0908],
        [0.4442],
        [0.1009],
        [0.4540],
        [0.4409],
        [0.4720],
        [0.3508],
        [0.0232],
        [0.9534],
        [0.4378],
        [0.4459],
        [0.4977],
        [0.7702],
        [0.4494],
        [0.8219],
        [0.1453],
        [0.6914],
        [0.1475],
        [0.6979],
        [0.4761],
        [0.9967],
        [0.1074],
        [0.4630],
        [0.7676],
        [0.0159],
        [0.3910],
        [0.1145],
        [0.3134],
        [0.7378],
        [0.1970],
        [0.1952],
        [0.8699],
        [0.8379],
        [0.6548],
        [0.7883],
        [0.0212],
        [0.3196],
        [0.9320],
        [0.3069],
        [0.9652],
        [0.0131],
        [0.8530],
        [0.2706],
        [0.7228],
        [0.2047],
        [0.1445],
        [0.4728],
        [0.2416],
        [0.9013],
        [0.1897],
        [0.2525],
        [0.0784],
        [0.4541],
        [0.8440],
        [0.9527],
        [0.8593],
        [0.2710],
        [0.6986],
        [0.6471],
        [0.4280],
        [0.0388],
        [0.9031],
        [0.0988],
        [0.0513],
        [0.5172],
        [0.1278],
        [0.8314],
        [0.3170],
        [0.4182],
        [0.5175],
        [0.4229],
        [0.2367],
        [0.4257],
        [0.5417],
        [0.7754],
        [0.2463],
        [0.8944],
        [0.1181],
        [0.0920],
        [0.1203],
        [0.9768],
        [0.5212],
        [0.4632],
        [0.6069],
        [0.9245],
        [0.8549],
        [0.0664],
        [0.7394],
        [0.1693],
        [0.4704],
        [0.5112],
        [0.1400],
        [0.4272],
        [0.4801],
        [0.9875],
        [0.0719],
        [0.3959],
        [0.3078],
        [0.1707],
        [0.3358],
        [0.0218],
        [0.2003],
        [0.4640],
        [0.1250],
        [0.2429],
        [0.6638],
        [0.0027],
        [0.4616],
        [0.4406],
        [0.4455],
        [0.9756],
        [0.9124],
        [0.2585],
        [0.5544],
        [0.9792],
        [0.1020],
        [0.9438],
        [0.6551],
        [0.0863],
        [0.1944],
        [0.4197],
        [0.0741],
        [0.0301],
        [0.0606],
        [0.8983],
        [0.7689],
        [0.2970],
        [0.7643],
        [0.5341],
        [0.6755],
        [0.2849],
        [0.2691],
        [0.3975],
        [0.9590],
        [0.7031],
        [0.3348],
        [0.3033],
        [0.9060],
        [0.4548],
        [0.0068],
        [0.8557],
        [0.4473],
        [0.7241],
        [0.7886],
        [0.6795],
        [0.5135],
        [0.8600],
        [0.8810],
        [0.8109],
        [0.1614],
        [0.7557],
        [0.8907],
        [0.9653],
        [0.5187],
        [0.8145],
        [0.4253],
        [0.8973],
        [0.0511],
        [0.4406],
        [0.6844],
        [0.9478],
        [0.7415],
        [0.3286],
        [0.0353],
        [0.1688],
        [0.9588],
        [0.6639],
        [0.0904],
        [0.8825],
        [0.6955],
        [0.9342],
        [0.0866],
        [0.7589],
        [0.0438],
        [0.5296],
        [0.4667],
        [0.9715],
        [0.0556],
        [0.7591],
        [0.7856],
        [0.7338],
        [0.1834],
        [0.0742],
        [0.6506],
        [0.2423],
        [0.3906],
        [0.8061],
        [0.0136],
        [0.1325],
        [0.3006],
        [0.9684],
        [0.7216],
        [0.7323],
        [0.2179],
        [0.6030],
        [0.0958],
        [0.1629],
        [0.2441],
        [0.6720],
        [0.4076],
        [0.4979],
        [0.3306],
        [0.3344],
        [0.2536],
        [0.8324],
        [0.0460],
        [0.1184],
        [0.8438],
        [0.3221],
        [0.8448],
        [0.6350],
        [0.3101],
        [0.8482],
        [0.1561],
        [0.6424],
        [0.4813],
        [0.6533],
        [0.2131],
        [0.8531],
        [0.9548],
        [0.4962],
        [0.3795],
        [0.8875],
        [0.7193],
        [0.9758],
        [0.7595],
        [0.5974],
        [0.3131],
        [0.1117],
        [0.7958],
        [0.9710],
        [0.8661],
        [0.4304],
        [0.3944],
        [0.1086],
        [0.0134],
        [0.3728],
        [0.2980],
        [0.4793],
        [0.6866],
        [0.8545],
        [0.8717],
        [0.6517],
        [0.7825],
        [0.7208],
        [0.6274],
        [0.7983],
        [0.8914],
        [0.0570],
        [0.8931],
        [0.2271],
        [0.0705],
        [0.3198],
        [0.5320],
        [0.3078],
        [0.6187],
        [0.6601],
        [0.0860],
        [0.0216],
        [0.6492],
        [0.5456],
        [0.9024],
        [0.5339],
        [0.7640],
        [0.9206],
        [0.8972],
        [0.8635],
        [0.1270],
        [0.5385],
        [0.1668],
        [0.8188],
        [0.0681],
        [0.9973],
        [0.1026],
        [0.4285],
        [0.2173],
        [0.6656],
        [0.6196],
        [0.0989],
        [0.6252],
        [0.7006],
        [0.2936],
        [0.3914],
        [0.0355],
        [0.6490],
        [0.5693],
        [0.0441],
        [0.4918],
        [0.5342],
        [0.2316],
        [0.4293],
        [0.6443],
        [0.9580],
        [0.8219],
        [0.0868],
        [0.6524],
        [0.4118],
        [0.0308],
        [0.3550],
        [0.3853],
        [0.8862],
        [0.3825],
        [0.7045],
        [0.6256],
        [0.2841],
        [0.0703],
        [0.9025],
        [0.2737],
        [0.5740],
        [0.9866],
        [0.9593]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ...,  True, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False,  True],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-0.1975, -0.6961],
        [ 1.8554,  0.1248],
        [ 1.6902,  0.6187],
        ...,
        [ 0.6484,  0.4715],
        [-3.3867,  0.7532],
        [-4.2365, -2.1256]]) torch.Size([9984, 2])
samples tensor([[ 3.3390, -0.6555],
        [ 3.6977, -0.4443],
        [ 2.6783, -1.6186],
        [ 1.7039,  0.7320],
        [ 2.7680,  0.7561],
        [ 2.6001,  0.3567],
        [ 4.2690, -0.5834],
        [ 2.4403,  0.4944],
        [ 1.6692, -1.7265],
        [ 2.2107, -0.3569],
        [ 3.1518, -0.2413],
        [ 1.6447,  0.7189],
        [ 3.5744,  1.8925],
        [ 1.9363, -0.2771],
        [ 1.1920, -0.0110],
        [ 2.0786, -0.5000],
        [ 1.7173, -1.2758],
        [ 3.5905,  0.3970],
        [ 3.4299, -1.2886],
        [ 1.2345,  0.7771],
        [ 3.7781,  0.1812],
        [ 1.7465,  2.1576],
        [ 1.3901, -0.8769],
        [ 2.6142, -1.6993],
        [ 2.1504, -1.3021],
        [ 0.9436,  0.2802],
        [ 2.6301, -0.7443],
        [ 1.8490, -0.0351],
        [ 3.0039, -0.6054],
        [ 2.6748, -0.6478],
        [ 2.2770, -0.0382],
        [ 0.6270,  1.0858],
        [ 0.6387,  0.6481],
        [ 2.9078,  1.3346],
        [ 0.6305, -1.4586],
        [ 1.8431,  0.1695],
        [ 3.2258,  0.0992],
        [ 2.2244, -1.9165],
        [ 2.7420,  0.7831],
        [ 1.8700,  1.1849],
        [ 2.9480, -1.5515],
        [ 0.7147, -0.8365],
        [ 3.4787, -0.4095],
        [ 1.4146,  0.4172],
        [ 1.1641,  0.1367],
        [ 0.8204, -0.3123],
        [ 2.3651,  0.4342],
        [ 2.1760,  0.9465],
        [ 2.6293, -0.5539],
        [ 3.0281, -0.8283],
        [ 2.1283,  2.2773],
        [ 2.1617,  1.4459],
        [ 1.4611, -0.1272],
        [ 2.3369,  0.0153],
        [ 3.4278, -0.5820],
        [ 3.1852,  1.5111],
        [ 3.2096, -0.7834],
        [ 3.7386, -2.2570],
        [ 4.3932, -1.2027],
        [ 2.9012, -0.8286],
        [ 3.1219, -0.8863],
        [ 1.4527,  0.4151],
        [-0.1533,  0.7111],
        [ 2.5512, -0.1289],
        [ 1.8614, -0.7276],
        [ 3.7927, -0.0352],
        [ 1.1778, -0.9368],
        [ 3.8833, -1.2631],
        [ 2.2434, -0.7342],
        [ 2.3325,  1.3405],
        [ 2.1982, -1.3177],
        [ 2.1503, -0.8869],
        [ 1.7303, -0.4506],
        [ 3.2102,  0.5028],
        [ 1.4488,  0.1148],
        [ 3.8278, -1.7641],
        [ 1.2508,  1.0992],
        [ 2.9274, -0.7920],
        [ 2.0544, -0.1948],
        [ 0.9983,  0.2315],
        [ 1.7144, -0.5259],
        [ 3.7835,  0.9226],
        [ 3.7486,  1.3012],
        [ 2.5099, -1.3571],
        [ 2.4459,  0.0527],
        [ 3.1961,  0.8947],
        [ 1.2140, -1.1670],
        [ 0.6741, -0.4878],
        [ 1.8284, -0.1677],
        [ 1.0254,  0.1357],
        [ 1.7428, -1.1122],
        [ 3.2205, -1.0670],
        [ 2.4684,  1.3559],
        [ 4.0473, -1.5038],
        [ 4.5443,  0.2025],
        [ 2.6366,  0.8487],
        [ 1.9101, -0.8038],
        [ 3.4757, -0.3960],
        [ 4.0467, -0.5074],
        [ 3.1671,  0.6584],
        [ 2.9507, -1.5662],
        [ 2.9905, -1.9713],
        [ 2.2340,  0.1977],
        [ 2.0157, -0.4641],
        [ 3.2824,  0.6428],
        [ 3.6873,  0.3849],
        [ 3.4161,  0.3858],
        [ 0.7139,  0.9417],
        [ 2.7688,  0.4018],
        [ 2.9042, -0.0745],
        [ 2.9054,  0.4347],
        [ 1.2654,  0.8800],
        [ 2.0287,  0.6845],
        [ 3.5138,  0.3506],
        [ 2.6633, -0.2869],
        [ 1.8993,  0.0286],
        [ 3.5642, -1.6073],
        [ 2.9861, -1.0011],
        [ 1.7665, -1.9375],
        [ 2.4511, -0.7719],
        [ 3.4567, -0.4797],
        [ 2.4910,  0.4647],
        [ 1.2827, -0.8262],
        [ 1.6685, -1.7377],
        [ 3.5731,  0.9656],
        [ 3.1433,  1.3953],
        [ 1.8938, -2.0044],
        [ 2.7339,  0.6008],
        [ 3.2304,  0.5812],
        [ 2.0808, -0.4274],
        [ 3.6678, -1.2851],
        [ 2.5051, -1.5635],
        [ 2.3257,  1.5543],
        [ 2.1599, -0.6028],
        [ 1.2295,  0.4055],
        [ 3.3439, -0.2172],
        [ 1.0374, -0.6039],
        [ 3.4888,  0.6530],
        [ 3.0730, -0.5336],
        [ 2.8949, -1.7429],
        [ 0.9040,  1.1458],
        [ 0.4915, -0.6736],
        [ 2.0709, -0.8800],
        [ 1.9736, -0.9432],
        [ 1.9880, -1.7728],
        [ 1.9809, -0.3657],
        [ 3.0125, -1.6333],
        [ 3.0412,  0.7153],
        [ 3.4509,  0.7865],
        [ 0.6864, -0.4868],
        [ 3.1259, -1.1040],
        [ 1.8351, -0.8470],
        [ 0.9784,  0.6568],
        [ 0.3871, -0.7749],
        [ 4.0384, -1.3336],
        [ 3.7352, -0.9269],
        [ 3.4481, -0.4668],
        [ 2.1369,  0.5183],
        [ 2.7998,  0.8221],
        [ 0.4232, -1.2193],
        [ 2.1673, -1.9495],
        [ 1.8305,  0.6476],
        [ 3.2110,  1.1400],
        [ 1.1044, -0.1957],
        [ 3.7948,  1.4272],
        [ 2.2830,  0.2336],
        [ 1.0761,  0.9949],
        [ 2.4903,  0.2635],
        [ 2.6002, -0.9455],
        [ 3.4941, -0.6328],
        [ 1.1801, -1.2352],
        [ 2.4779,  1.0737],
        [ 1.8651,  0.2770],
        [ 3.4048,  1.2932],
        [ 1.3425,  0.8264],
        [ 1.4103,  0.1291],
        [ 2.1199, -0.5565],
        [ 3.3021,  0.5332],
        [ 4.1333, -0.9550],
        [ 2.5795,  0.8399],
        [ 1.9797,  1.3616],
        [ 2.6522, -0.3093],
        [ 1.6128, -1.1707],
        [ 2.1860,  0.9852],
        [ 1.7950, -0.7769],
        [ 0.8738, -0.1575],
        [ 1.8283,  0.2713],
        [ 2.5464, -0.5211],
        [ 1.4018, -0.3517],
        [ 1.5601,  0.1202],
        [ 2.5103, -0.8911],
        [ 1.4991,  0.3674],
        [ 2.5663, -0.9983],
        [ 1.3663, -0.2178],
        [ 2.3682, -1.2834],
        [ 2.6519, -0.8909],
        [ 2.9195, -1.2489],
        [ 3.5315, -0.6370],
        [ 3.0102,  0.3014],
        [ 1.0734,  0.7101],
        [ 2.4433, -1.1437],
        [ 3.7260, -0.3911],
        [ 2.0608,  0.1903],
        [ 1.7579,  0.0427],
        [ 1.8811, -1.9150],
        [ 2.3335, -0.8117],
        [ 2.3162, -0.6918],
        [ 1.0523,  0.9845],
        [ 3.8296,  0.5876],
        [ 4.2494, -0.4855],
        [ 2.0086, -0.2231],
        [ 3.1937, -1.1324],
        [ 2.0677, -0.4425],
        [ 2.5605, -0.0648],
        [ 3.1764, -0.9590],
        [ 0.4127, -0.5647],
        [ 4.1483,  0.7848],
        [ 2.1121,  0.3835],
        [ 2.2447, -1.2289],
        [ 2.0137, -0.4870],
        [ 4.5436, -0.1784],
        [ 2.7068, -1.3325],
        [ 1.8324, -0.8088],
        [ 2.4187,  0.0064],
        [ 2.4141,  0.8154],
        [ 2.5626,  1.4814],
        [ 2.0766, -2.4591],
        [ 2.7688,  0.3229],
        [ 1.2694, -1.1933],
        [ 2.2734, -0.0480],
        [ 0.9197,  1.2585],
        [ 1.4920, -0.1410],
        [ 4.8906, -0.1523],
        [ 2.8250, -1.7994],
        [ 1.1578,  0.7222],
        [ 3.5042, -0.2227],
        [ 0.9335,  1.7886],
        [-0.4133, -0.1154],
        [ 1.7484, -0.7898],
        [ 1.2694,  0.8426],
        [ 3.5448, -1.5004],
        [ 1.2383,  0.1198],
        [ 2.4550,  0.5981],
        [ 3.5047, -2.2242],
        [ 1.7853, -0.9914],
        [ 1.7142, -2.4116],
        [ 2.8683, -0.4392],
        [ 4.2186,  0.6701],
        [ 2.4742, -0.9431],
        [ 3.8292, -0.7366],
        [ 3.0103,  0.0334],
        [ 4.2905,  1.2220],
        [ 2.0405, -0.6383],
        [ 2.1142, -2.7764],
        [ 4.2060, -0.1562],
        [ 2.8158, -1.1159],
        [ 3.8432, -0.0329],
        [ 2.9680,  0.5791],
        [ 1.4245, -0.6069],
        [ 2.2240,  1.1619],
        [ 3.2683, -1.1563],
        [ 2.6410, -1.4789],
        [ 2.1046, -0.7146],
        [ 1.9557,  0.0855],
        [ 1.4104, -0.1167],
        [ 3.4778,  0.1062],
        [ 0.7194, -0.4670],
        [ 2.4459, -0.1307],
        [ 2.3302,  0.8829],
        [ 1.7395, -0.5261],
        [ 2.7146, -1.7700],
        [ 1.7540,  0.1264],
        [ 2.8636, -0.7033],
        [ 1.4287,  0.1211],
        [ 2.3919,  0.1103],
        [ 2.1515,  0.3920],
        [ 1.2733, -0.2642],
        [ 3.1550, -1.7088],
        [ 1.7272,  0.0252],
        [ 2.4042,  0.5007],
        [ 2.0845, -0.9230],
        [ 1.9289, -0.7350],
        [ 3.2523,  3.3171],
        [ 1.0281, -0.9632],
        [ 0.8898,  0.1139],
        [ 1.6367, -0.4815],
        [ 2.3537, -1.3009],
        [ 1.8105,  0.0442],
        [ 3.2515,  2.0359],
        [ 2.3178, -0.2730],
        [ 1.3123, -1.0020],
        [ 3.8512,  0.8510],
        [ 2.3621,  0.9572],
        [ 0.1417, -0.7695],
        [ 1.5010, -0.5359],
        [ 4.0066,  0.5873],
        [ 2.5914,  0.4949],
        [ 1.2379, -1.1537],
        [ 2.9060, -1.2541],
        [ 3.1054, -1.4218],
        [ 2.9221, -3.1560],
        [ 3.1091, -0.4441],
        [ 1.3614, -1.3611],
        [ 3.7345, -1.7788],
        [ 1.9352, -0.8539],
        [ 2.9265, -1.4872],
        [ 3.0219,  0.0085],
        [ 1.2999, -0.7663],
        [ 3.4663,  1.0381],
        [-0.2884, -0.5060],
        [ 1.4292,  0.3242],
        [ 1.4964, -0.0081]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.9009e-05, 3.9851e-05, 1.2733e-04,  ..., 9.9836e-01, 9.9836e-01,
         1.0000e+00],
        [1.5702e-01, 1.5702e-01, 1.9162e-01,  ..., 5.4812e-01, 9.5383e-01,
         1.0000e+00],
        [6.2417e-05, 4.8168e-03, 1.9778e-01,  ..., 9.3532e-01, 9.9999e-01,
         1.0000e+00],
        ...,
        [6.8974e-02, 6.9461e-02, 6.9624e-02,  ..., 9.9951e-01, 1.0000e+00,
         1.0000e+00],
        [1.8067e-02, 2.3106e-02, 2.3175e-02,  ..., 9.9662e-01, 9.9960e-01,
         1.0000e+00],
        [1.4190e-04, 1.7694e-03, 8.3601e-03,  ..., 9.9971e-01, 9.9993e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.9818],
        [0.4729],
        [0.0453],
        [0.1583],
        [0.2304],
        [0.0372],
        [0.8012],
        [0.7168],
        [0.2055],
        [0.5484],
        [0.7470],
        [0.3458],
        [0.6307],
        [0.2216],
        [0.0861],
        [0.0858],
        [0.0886],
        [0.0903],
        [0.1292],
        [0.0100],
        [0.3511],
        [0.3585],
        [0.6212],
        [0.6866],
        [0.3236],
        [0.5237],
        [0.2755],
        [0.1633],
        [0.0315],
        [0.5274],
        [0.7633],
        [0.2561],
        [0.9843],
        [0.1958],
        [0.5916],
        [0.2203],
        [0.9996],
        [0.0555],
        [0.8885],
        [0.2411],
        [0.3737],
        [0.6352],
        [0.4795],
        [0.4718],
        [0.6776],
        [0.0234],
        [0.5247],
        [0.7975],
        [0.9808],
        [0.5879],
        [0.5287],
        [0.8631],
        [0.8367],
        [0.9726],
        [0.5258],
        [0.2546],
        [0.4174],
        [0.0099],
        [0.7326],
        [0.7404],
        [0.4282],
        [0.3637],
        [0.6532],
        [0.9473],
        [0.1323],
        [0.2984],
        [0.2550],
        [0.8458],
        [0.8991],
        [0.1550],
        [0.9093],
        [0.9828],
        [0.0654],
        [0.1941],
        [0.2084],
        [0.1141],
        [0.4400],
        [0.8622],
        [0.4581],
        [0.9825],
        [0.0954],
        [0.8016],
        [0.2330],
        [0.7147],
        [0.8919],
        [0.8914],
        [0.0638],
        [0.1860],
        [0.1566],
        [0.6339],
        [0.7591],
        [0.5128],
        [0.4034],
        [0.0412],
        [0.2286],
        [0.3767],
        [0.5044],
        [0.0234],
        [0.6191],
        [0.8340],
        [0.4947],
        [0.0822],
        [0.9730],
        [0.1679],
        [0.5003],
        [0.3592],
        [0.5471],
        [0.2290],
        [0.8100],
        [0.6088],
        [0.0322],
        [0.1850],
        [0.5777],
        [0.1196],
        [0.5529],
        [0.0716],
        [0.4748],
        [0.4329],
        [0.4841],
        [0.6713],
        [0.2012],
        [0.0503],
        [0.5711],
        [0.8007],
        [0.2903],
        [0.0215],
        [0.3618],
        [0.8736],
        [0.3412],
        [0.0449],
        [0.3034],
        [0.5254],
        [0.4058],
        [0.0956],
        [0.3328],
        [0.3536],
        [0.7657],
        [0.1269],
        [0.8494],
        [0.3054],
        [0.9263],
        [0.8888],
        [0.4694],
        [0.3631],
        [0.5243],
        [0.4888],
        [0.7006],
        [0.7660],
        [0.0948],
        [0.8956],
        [0.1281],
        [0.7839],
        [0.3320],
        [0.2502],
        [0.3011],
        [0.6200],
        [0.9473],
        [0.2347],
        [0.8400],
        [0.5499],
        [0.4948],
        [0.6986],
        [0.0223],
        [0.5162],
        [0.2191],
        [0.2596],
        [0.8008],
        [0.0965],
        [0.8842],
        [0.8471],
        [0.3713],
        [0.2527],
        [0.9597],
        [0.6933],
        [0.7796],
        [0.4297],
        [0.7593],
        [0.6953],
        [0.9218],
        [0.2227],
        [0.3942],
        [0.1337],
        [0.9363],
        [0.0420],
        [0.1025],
        [0.4961],
        [0.9844],
        [0.7539],
        [0.3347],
        [0.6726],
        [0.5682],
        [0.5932],
        [0.1910],
        [0.0993],
        [0.5502],
        [0.1498],
        [0.6192],
        [0.0016],
        [0.2351],
        [0.9639],
        [0.5953],
        [0.9955],
        [0.5428],
        [0.2084],
        [0.6798],
        [0.2165],
        [0.4713],
        [0.4629],
        [0.8548],
        [0.2935],
        [0.7929],
        [0.6793],
        [0.3143],
        [0.9028],
        [0.4204],
        [0.9012],
        [0.5473],
        [0.8434],
        [0.7969],
        [0.3559],
        [0.3299],
        [0.7353],
        [0.4845],
        [0.5487],
        [0.7038],
        [0.4342],
        [0.1333],
        [0.0185],
        [0.9145],
        [0.1801],
        [0.4780],
        [0.1479],
        [0.4745],
        [0.6489],
        [0.7281],
        [0.4996],
        [0.5769],
        [0.7503],
        [0.7734],
        [0.2899],
        [0.8852],
        [0.4760],
        [0.4485],
        [0.6069],
        [0.2103],
        [0.5968],
        [0.3190],
        [0.0989],
        [0.3247],
        [0.6186],
        [0.3651],
        [0.8676],
        [0.6147],
        [0.0129],
        [0.6579],
        [0.2946],
        [0.3014],
        [0.1694],
        [0.4834],
        [0.2946],
        [0.9297],
        [0.4836],
        [0.6325],
        [0.7141],
        [0.2197],
        [0.5994],
        [0.7527],
        [0.2886],
        [0.1561],
        [0.2836],
        [0.5754],
        [0.0701],
        [0.6432],
        [0.4586],
        [0.5492],
        [0.3946],
        [0.1961],
        [0.8890],
        [0.3407],
        [0.0600],
        [0.7567],
        [0.7685],
        [0.1920],
        [0.5911],
        [0.3185],
        [0.5710],
        [0.4826],
        [0.1011],
        [0.4222],
        [0.1939],
        [0.5360],
        [0.1788],
        [0.6662],
        [0.5642],
        [0.7375],
        [0.9091],
        [0.6605],
        [0.0082],
        [0.8861],
        [0.8806],
        [0.1618],
        [0.1932],
        [0.1697],
        [0.1325],
        [0.2913],
        [0.3154],
        [0.3918],
        [0.0650],
        [0.8180],
        [0.1955],
        [0.3895],
        [0.4604]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False,  True,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-1.4748,  0.5823],
        [-1.1687,  2.1220],
        [-1.2317, -0.1138],
        ...,
        [ 0.5863,  0.1726],
        [-0.5489,  1.3029],
        [-0.8271,  2.0497]]) torch.Size([9984, 2])
samples tensor([[ 3.8296,  0.0343],
        [ 2.0745,  0.6239],
        [ 2.2474,  0.0779],
        [ 1.3235,  0.1572],
        [ 3.1680, -0.5199],
        [ 2.1691, -0.3465],
        [ 2.2348,  0.2173],
        [ 1.2999,  0.7104],
        [ 2.3340,  0.6137],
        [ 2.8282, -0.5028],
        [ 2.1320, -1.8904],
        [ 3.5509, -0.7314],
        [ 3.4143,  0.8696],
        [ 2.9777, -1.1154],
        [ 3.5472,  0.3414],
        [ 1.9168,  0.4765],
        [ 0.8444, -0.1732],
        [ 1.6845,  0.1855],
        [ 2.6654,  0.2497],
        [ 2.5694, -0.5013],
        [ 1.0225, -1.7583],
        [ 1.7377, -0.7190],
        [ 0.4582, -2.0044],
        [ 1.2261,  0.1674],
        [ 3.4085, -1.5600],
        [ 2.2125,  0.4092],
        [ 2.9199, -0.7909],
        [ 3.0672,  1.2591],
        [ 1.7773, -0.3559],
        [ 1.7173, -2.1789],
        [ 3.4898, -0.6967],
        [ 3.5443, -1.1020],
        [ 2.1419, -3.2433],
        [ 2.4272,  0.7106],
        [ 3.0558, -0.3240],
        [ 3.2011,  0.1488],
        [ 2.1247,  2.5211],
        [ 2.2919,  0.1610],
        [ 2.6654,  0.9468],
        [ 1.7803, -1.4685],
        [ 3.6618,  0.0062],
        [ 3.5517, -1.7581],
        [ 2.4396, -0.1649],
        [ 2.5327,  0.1482],
        [ 3.3751, -1.4489],
        [ 2.0244,  0.9755],
        [ 3.9656, -0.6047],
        [ 3.4588, -0.2577],
        [ 0.9035,  0.5680],
        [ 1.4949,  0.1799],
        [ 2.6722, -1.9947],
        [ 0.1408, -1.7069],
        [ 2.0968, -0.7670],
        [ 1.2206,  1.9542],
        [ 3.3522, -1.3852],
        [ 2.8864, -1.1185],
        [ 1.3733,  0.7869],
        [ 1.8692, -0.1405],
        [ 2.4064,  1.0613],
        [ 1.6337,  0.7446],
        [ 1.8411, -0.4558],
        [ 2.2445, -2.3763],
        [ 2.8330,  0.2482],
        [ 0.9305,  1.6722],
        [ 2.8169, -0.6721],
        [ 2.5754, -0.9047],
        [ 1.5294, -0.4974],
        [ 2.8269, -0.2968],
        [ 1.5319, -0.1144],
        [ 1.8304,  1.4489],
        [ 4.6581,  0.7743],
        [-0.3377, -0.3132],
        [ 2.0133,  1.2163],
        [ 2.0146, -1.3349],
        [ 1.6648,  0.5889],
        [ 4.1097, -1.8171],
        [ 0.3835, -2.2922],
        [ 2.0086, -0.7994],
        [ 1.4388, -0.3353],
        [ 3.8186, -0.1606],
        [ 3.0463,  1.5571],
        [ 2.7942,  0.0921],
        [ 1.7926,  1.8079],
        [ 2.0915, -0.8563],
        [ 2.5799,  0.1825],
        [ 1.6125, -0.0648],
        [ 2.9719,  0.0698],
        [ 1.8810,  0.8784],
        [ 1.8979,  0.3517],
        [ 3.3899, -0.0925],
        [ 2.0255,  0.1943],
        [ 2.5724, -0.3042],
        [ 3.3958, -0.1264],
        [ 1.6554,  0.4199],
        [ 1.3878,  1.5683],
        [ 2.9126, -0.6100],
        [ 2.7760, -0.5848],
        [ 3.0745, -0.7813],
        [ 3.9648, -1.3737],
        [ 4.0649, -1.4866],
        [ 3.2470,  0.9976],
        [ 1.4551, -0.2590],
        [ 0.4243,  0.7357],
        [ 0.9130,  0.1271],
        [ 0.1784,  0.2129],
        [ 0.5715,  0.5619],
        [ 2.2467,  1.5619],
        [ 3.3120,  0.5801],
        [ 2.1541, -0.2775],
        [ 1.2081, -0.6860],
        [ 1.8208,  0.8735],
        [ 1.4760,  0.2057],
        [ 1.4298, -0.6762],
        [ 2.7880,  1.1375],
        [ 4.2284, -1.1595],
        [ 2.7943,  1.5195],
        [ 2.2568, -1.1539],
        [ 2.1691, -0.0891],
        [ 1.1190,  0.9687],
        [ 1.1293,  0.0241],
        [ 2.5090, -1.7162],
        [ 1.5872,  1.4261],
        [ 4.1306, -0.8231],
        [ 2.1430, -0.3544],
        [ 3.6427, -0.3302],
        [ 2.5224, -1.5612],
        [ 2.3245, -0.5156],
        [ 2.6941, -0.1473],
        [ 1.4408, -0.6368],
        [ 1.9931,  0.7839],
        [ 2.3052, -2.1096],
        [ 2.2132,  0.3384],
        [ 4.7060, -0.8762],
        [ 0.7824, -0.1645],
        [ 2.5515, -1.5128],
        [ 3.1394, -1.2986],
        [ 1.3097,  0.3072],
        [ 0.6217, -0.1793],
        [ 4.2023, -0.0980],
        [ 3.4198, -0.9059],
        [ 2.7078,  0.3194],
        [ 1.7533,  0.3481],
        [ 1.4002, -0.5403],
        [ 3.6511,  0.2969],
        [ 2.6937, -1.1323],
        [ 2.4533,  0.3725],
        [ 1.7274,  1.8479],
        [ 4.4795, -0.2281],
        [ 3.3173, -1.8647],
        [ 1.5969,  1.0669],
        [ 4.3572,  0.2456],
        [ 4.0053,  0.1089],
        [ 3.6099,  0.5114],
        [ 1.5685, -0.4197],
        [ 2.4671, -1.2996],
        [ 2.6467, -0.1056],
        [ 1.7846, -0.1074],
        [ 0.8999, -0.9982],
        [ 3.1669, -0.1229],
        [ 1.8244, -2.1554],
        [ 4.5966, -1.4619],
        [ 1.9934, -0.6004],
        [ 1.3323,  0.0063],
        [ 2.3953, -0.4629],
        [ 4.0488, -2.3800],
        [ 2.3433, -1.1724],
        [ 2.1904, -0.6619],
        [ 3.1360, -0.4988],
        [ 2.0022, -1.2346],
        [ 2.9688, -0.2634],
        [ 3.7216, -0.6083],
        [ 2.7183,  0.3894],
        [ 1.0719, -0.1806],
        [ 1.3221,  0.0443],
        [ 1.4119, -0.9890],
        [ 1.4262, -1.6419],
        [ 3.7295,  0.5082],
        [ 2.7093, -0.0109],
        [ 1.7851, -0.3335],
        [ 2.3578, -0.2087],
        [ 4.4055, -1.3194],
        [ 3.7019,  0.3519],
        [ 1.5798,  1.3181],
        [ 4.2871,  0.8921],
        [ 2.0045,  0.2020],
        [ 3.1624,  1.1235],
        [ 0.0811, -0.7623],
        [ 2.9155, -0.8479],
        [ 2.8995,  1.9451],
        [ 3.0547, -1.7518],
        [ 3.0428, -0.0248],
        [ 2.5985,  0.0823],
        [ 3.1872, -2.3368],
        [ 2.3491,  0.7127],
        [ 2.4144, -0.6718],
        [ 2.0556,  0.2756],
        [ 3.5238,  0.5471],
        [ 0.8240,  2.8788],
        [ 4.4009,  0.9733],
        [ 3.8646,  0.8826],
        [ 2.4038,  0.2062],
        [ 0.1843,  1.1979],
        [ 3.8462, -0.0630],
        [ 1.2278,  0.0660],
        [ 1.1262, -0.6438],
        [ 1.1170,  0.4442],
        [ 3.3224,  0.4609],
        [ 2.1315, -1.7203],
        [ 0.0822,  0.8654],
        [ 2.9526, -0.7122],
        [ 1.5624,  0.8633],
        [ 3.3055,  0.8896],
        [ 2.2119, -0.9159],
        [ 3.2946, -1.6101],
        [ 2.2987, -0.4832],
        [ 2.8205, -0.6481],
        [ 1.7051, -0.7754],
        [ 2.2625,  2.4633],
        [ 1.3485,  1.6794],
        [ 2.4338, -0.7713],
        [ 1.6705, -0.7917],
        [ 2.5596,  0.0083],
        [ 2.6712, -0.3213],
        [ 3.2777, -0.7190],
        [ 1.6490,  0.3308],
        [ 2.2135, -0.8757],
        [ 2.4423,  0.9059],
        [ 0.5619,  0.1831],
        [ 0.9888, -0.3529],
        [ 3.4890,  0.4072],
        [ 3.5036, -0.9744],
        [ 3.9063, -0.1710],
        [ 1.6424, -0.7940],
        [ 3.3527, -0.2982],
        [ 1.7538, -0.4672],
        [ 3.0190,  1.5292],
        [ 3.0426,  1.4920],
        [ 1.6220,  0.0691],
        [ 2.3168, -1.1412],
        [ 2.5884,  0.7068],
        [ 2.0928,  0.6037],
        [ 2.1160,  0.1181],
        [ 1.8729, -1.4674],
        [ 0.8758, -1.1253],
        [ 4.6661, -1.9904],
        [ 2.9295,  0.4893],
        [ 3.2401,  0.1667],
        [ 2.5424, -0.4833],
        [ 3.0473, -0.1996],
        [ 1.4382,  0.4205],
        [ 2.7121, -1.8060],
        [ 3.0666, -0.1828],
        [ 1.0951, -1.3569],
        [-0.1043,  0.2223],
        [ 2.2561,  0.8115],
        [ 1.6046, -1.0389],
        [ 0.3723, -1.2681],
        [ 3.0223, -0.9723],
        [ 2.0124,  0.2285],
        [ 3.9224, -0.8614],
        [ 2.9321, -0.7975],
        [ 2.4105, -0.4866],
        [ 3.6442, -2.3562],
        [ 1.5032, -1.3106],
        [ 3.9605, -0.8801],
        [ 1.7597, -1.2436],
        [ 4.1847, -0.7777],
        [ 1.2384,  0.3388],
        [ 2.2980,  0.4346],
        [ 1.8613, -1.8122],
        [ 3.5366, -0.5567],
        [ 1.8579, -0.7339],
        [ 2.1261, -0.2404],
        [ 0.9793, -0.0568],
        [ 2.7548, -0.9992],
        [ 1.4421, -1.2440],
        [ 0.8182, -1.3018],
        [ 3.7993, -0.9611],
        [ 0.6471, -0.7378],
        [ 1.8781,  0.7037],
        [ 2.3249, -1.8673],
        [ 0.9613,  1.5319],
        [ 2.1306,  1.1091],
        [ 1.0712, -0.0791],
        [ 2.9737,  0.2267],
        [ 3.0649,  0.1527],
        [ 3.4148, -0.2448],
        [ 2.6914,  0.0075],
        [ 3.8512,  1.1334],
        [ 3.8083,  0.5901],
        [ 1.9114,  1.9635],
        [ 3.5368, -3.4048],
        [ 1.3980, -1.6603],
        [ 2.7586, -1.4160],
        [ 1.9115, -0.6871],
        [ 1.4159,  0.3872],
        [ 2.7761, -0.2450],
        [ 1.0728,  0.3563],
        [ 2.8812, -0.4919],
        [ 3.8481, -1.1987],
        [ 2.0792, -0.8706],
        [ 4.0543,  1.4809],
        [ 3.1431, -1.0976],
        [ 2.3414, -0.0654],
        [ 1.7224, -1.8210],
        [ 1.8914,  1.1483],
        [ 2.5195, -0.8388],
        [ 3.0594,  0.1268],
        [ 2.9865, -1.1868],
        [ 1.7337,  0.2231],
        [ 2.6260, -0.6473],
        [ 3.7161, -1.0011]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.4764e-06, 4.9913e-03, 4.9940e-03,  ..., 9.6819e-01, 1.0000e+00,
         1.0000e+00],
        [3.5097e-05, 1.1944e-04, 1.9666e-03,  ..., 9.9312e-01, 1.0000e+00,
         1.0000e+00],
        [1.4991e-08, 2.3417e-01, 2.3444e-01,  ..., 8.0033e-01, 8.0044e-01,
         1.0000e+00],
        ...,
        [4.1289e-03, 5.5454e-03, 2.5080e-02,  ..., 8.0757e-01, 9.9523e-01,
         1.0000e+00],
        [6.8802e-11, 2.1033e-01, 2.2005e-01,  ..., 8.6326e-01, 9.9845e-01,
         1.0000e+00],
        [3.7046e-02, 3.7201e-02, 2.9872e-01,  ..., 8.2104e-01, 9.9831e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[7.6437e-01],
        [3.7008e-01],
        [7.6155e-01],
        [9.6648e-01],
        [8.0871e-01],
        [1.6877e-01],
        [2.6704e-01],
        [5.8707e-01],
        [9.3961e-01],
        [4.3517e-01],
        [1.6043e-01],
        [9.5886e-01],
        [1.4350e-01],
        [9.1048e-01],
        [3.4258e-03],
        [3.8203e-01],
        [5.3942e-01],
        [8.2861e-01],
        [1.2916e-01],
        [5.1084e-01],
        [7.2814e-01],
        [3.4317e-01],
        [4.3471e-01],
        [8.4752e-01],
        [4.6122e-01],
        [9.5521e-01],
        [8.5796e-01],
        [4.3893e-01],
        [8.4336e-01],
        [8.5594e-01],
        [7.6512e-01],
        [9.0143e-01],
        [3.1971e-01],
        [9.8050e-02],
        [7.6821e-01],
        [3.5172e-01],
        [7.0311e-01],
        [2.1182e-01],
        [7.7301e-01],
        [8.6748e-01],
        [9.0467e-01],
        [5.1062e-01],
        [7.4790e-01],
        [2.7130e-01],
        [7.6700e-01],
        [2.7198e-02],
        [5.1151e-01],
        [5.3348e-01],
        [8.8127e-01],
        [5.8615e-01],
        [9.1320e-01],
        [6.1374e-01],
        [7.9277e-01],
        [3.3929e-01],
        [5.0212e-03],
        [3.8750e-01],
        [2.0866e-01],
        [7.6421e-01],
        [5.4456e-01],
        [2.2257e-01],
        [5.8907e-01],
        [8.1336e-02],
        [4.7314e-01],
        [4.8959e-01],
        [2.2143e-01],
        [3.7809e-01],
        [9.2481e-01],
        [9.3903e-01],
        [2.6836e-01],
        [9.4745e-01],
        [5.3366e-01],
        [4.0082e-01],
        [2.8621e-01],
        [2.5919e-02],
        [3.4248e-01],
        [9.0190e-01],
        [5.9174e-01],
        [4.7430e-01],
        [8.9775e-01],
        [5.7943e-01],
        [4.7336e-01],
        [9.0694e-02],
        [6.8778e-01],
        [2.8645e-01],
        [9.2571e-01],
        [9.1145e-02],
        [4.4042e-01],
        [4.2001e-01],
        [8.1102e-01],
        [6.0643e-01],
        [7.1917e-01],
        [4.8091e-01],
        [6.9772e-01],
        [2.7779e-01],
        [8.9117e-01],
        [9.2924e-01],
        [5.7261e-01],
        [3.1558e-02],
        [5.4026e-01],
        [9.6521e-01],
        [5.0925e-01],
        [7.5173e-02],
        [8.5199e-01],
        [4.5936e-01],
        [8.4240e-01],
        [9.1614e-02],
        [3.2777e-01],
        [9.5617e-02],
        [1.4506e-01],
        [7.3607e-01],
        [2.2773e-02],
        [4.7580e-01],
        [8.0478e-01],
        [5.9757e-01],
        [7.7738e-01],
        [6.5120e-01],
        [3.6425e-01],
        [1.7842e-01],
        [2.4909e-01],
        [3.6885e-01],
        [7.2452e-01],
        [5.9392e-02],
        [1.3957e-02],
        [3.5614e-01],
        [1.8901e-01],
        [1.6680e-01],
        [1.1978e-01],
        [1.1563e-05],
        [4.5100e-02],
        [3.7624e-01],
        [9.3784e-01],
        [5.6677e-01],
        [7.3420e-01],
        [5.4531e-01],
        [5.9350e-01],
        [3.2600e-01],
        [4.1058e-01],
        [6.4756e-01],
        [5.9710e-01],
        [9.4538e-01],
        [2.4673e-01],
        [8.2147e-01],
        [7.3262e-02],
        [9.4656e-01],
        [8.7340e-01],
        [3.3416e-01],
        [5.4552e-01],
        [1.0287e-01],
        [9.6386e-02],
        [7.6132e-01],
        [8.5923e-01],
        [5.1107e-01],
        [3.0148e-01],
        [6.9382e-01],
        [3.5273e-01],
        [9.6469e-01],
        [4.0103e-01],
        [3.1003e-02],
        [3.6635e-01],
        [1.7494e-01],
        [2.3431e-01],
        [4.2669e-03],
        [5.9687e-01],
        [8.6149e-01],
        [1.1718e-01],
        [6.8200e-01],
        [9.9247e-01],
        [9.2106e-01],
        [1.2572e-01],
        [4.1426e-01],
        [9.7218e-01],
        [9.4450e-01],
        [9.5333e-01],
        [9.2124e-01],
        [8.8980e-01],
        [4.0629e-01],
        [9.6491e-01],
        [3.8127e-01],
        [5.7320e-01],
        [9.9294e-01],
        [7.7627e-01],
        [2.5583e-01],
        [7.0096e-01],
        [2.6332e-01],
        [8.3009e-01],
        [7.9138e-01],
        [3.8876e-01],
        [4.0831e-01],
        [6.7509e-01],
        [8.5885e-01],
        [3.3794e-01],
        [1.5322e-01],
        [7.0481e-01],
        [5.1953e-02],
        [5.3477e-01],
        [6.9682e-01],
        [9.2567e-01],
        [1.8437e-01],
        [7.6013e-02],
        [7.3913e-01],
        [9.2612e-01],
        [5.0288e-01],
        [2.7325e-01],
        [4.9695e-01],
        [3.3359e-01],
        [4.2151e-01],
        [4.4843e-01],
        [9.5452e-02],
        [1.6070e-01],
        [3.6349e-01],
        [2.5064e-01],
        [7.2307e-02],
        [6.6338e-01],
        [7.7319e-01],
        [4.6809e-01],
        [3.5545e-02],
        [7.6185e-01],
        [6.9815e-01],
        [2.4950e-01],
        [8.4247e-01],
        [2.0281e-01],
        [6.1349e-01],
        [2.0847e-02],
        [7.5221e-01],
        [4.9356e-01],
        [1.7126e-01],
        [9.2133e-01],
        [7.8323e-01],
        [4.2434e-01],
        [3.8487e-01],
        [3.2300e-01],
        [8.2351e-01],
        [3.8430e-01],
        [5.5644e-01],
        [6.0977e-01],
        [5.5576e-01],
        [2.1146e-01],
        [2.8560e-01],
        [7.1439e-01],
        [1.5165e-01],
        [6.7428e-01],
        [8.8644e-01],
        [4.8006e-01],
        [5.3019e-01],
        [8.4109e-01],
        [5.8886e-01],
        [4.1431e-01],
        [7.3815e-01],
        [7.6808e-01],
        [9.2969e-01],
        [7.3576e-02],
        [5.0190e-01],
        [2.5106e-01],
        [9.4249e-01],
        [5.6339e-01],
        [3.8293e-01],
        [4.4601e-01],
        [9.8132e-01],
        [7.9424e-02],
        [8.6079e-01],
        [6.6289e-01],
        [5.8360e-01],
        [4.3303e-01],
        [5.4897e-01],
        [3.0297e-01],
        [3.0659e-01],
        [2.9852e-01],
        [8.5157e-02],
        [6.2865e-01],
        [7.3585e-01],
        [9.1314e-01],
        [3.4587e-01],
        [4.7125e-01],
        [5.5556e-01],
        [9.4055e-01],
        [4.3972e-01],
        [8.8846e-01],
        [6.8061e-01],
        [3.5135e-01],
        [2.2280e-01],
        [8.1447e-01],
        [9.4905e-01],
        [5.0695e-01],
        [3.0212e-01],
        [3.5145e-01],
        [5.9865e-01],
        [1.0430e-01],
        [5.0982e-01],
        [8.4201e-01],
        [1.1505e-01],
        [6.0726e-01],
        [9.1814e-01],
        [2.2972e-01],
        [5.3832e-01],
        [8.6030e-01],
        [1.2457e-01],
        [8.4382e-01],
        [7.8676e-02],
        [7.7052e-01],
        [1.1393e-01],
        [3.1710e-01],
        [7.3137e-01],
        [7.0454e-01],
        [3.2746e-01],
        [8.5307e-01],
        [5.0154e-01],
        [3.1778e-01],
        [1.7383e-01],
        [8.1495e-01],
        [3.7348e-01],
        [2.0359e-02],
        [8.1984e-01]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-2.4127,  0.0125],
        [ 0.6448,  1.3712],
        [-1.9227,  2.0855],
        ...,
        [-0.8400,  0.4430],
        [ 3.8974, -0.6023],
        [-0.0893,  0.1132]]) torch.Size([9984, 2])
samples tensor([[ 2.9154e+00, -1.1147e+00],
        [ 2.5138e+00, -1.9887e-01],
        [ 1.5275e+00, -5.7573e-01],
        [ 1.2427e-01,  8.5127e-01],
        [ 2.5183e+00,  8.1407e-01],
        [ 1.4535e+00, -1.9816e-01],
        [ 1.1743e+00, -1.2943e+00],
        [ 1.0935e+00, -2.8163e-01],
        [ 3.9513e-01, -1.0184e+00],
        [ 2.1402e+00, -6.3080e-01],
        [ 1.9882e+00, -3.0916e-01],
        [ 2.4446e+00,  1.3779e+00],
        [ 1.6414e+00,  5.3263e-01],
        [ 2.3768e+00, -5.8180e-01],
        [ 4.3829e-02, -6.9819e-01],
        [ 2.5639e+00,  1.4681e-01],
        [ 1.9820e+00, -1.1688e+00],
        [ 3.7666e-01,  9.4831e-01],
        [ 1.8062e+00, -1.9838e+00],
        [ 4.0085e+00,  2.5109e-01],
        [ 2.3885e+00,  1.2023e+00],
        [ 3.0152e+00,  5.0419e-01],
        [ 3.2235e+00, -1.6976e+00],
        [ 1.5385e+00,  3.7255e-01],
        [ 1.7990e+00, -2.9030e-01],
        [ 3.0928e+00,  8.5351e-01],
        [ 9.6914e-01, -5.2224e-01],
        [ 9.1107e-01, -9.7714e-02],
        [ 1.9646e+00, -3.6262e-01],
        [ 3.2037e+00, -1.2935e+00],
        [ 1.6902e+00, -4.4638e-01],
        [ 2.8859e+00, -3.2569e-01],
        [ 4.4588e+00, -7.1289e-01],
        [ 2.0108e+00, -1.7612e-02],
        [ 3.4250e+00, -7.4901e-01],
        [ 2.3891e+00, -7.9899e-01],
        [ 3.1766e+00,  5.5768e-01],
        [ 2.6666e+00, -2.3079e+00],
        [ 2.2828e+00, -1.1203e+00],
        [ 6.6977e-01, -1.2891e+00],
        [ 2.5787e+00, -4.3556e-01],
        [ 2.3361e+00,  8.7673e-01],
        [ 1.5645e+00, -6.3480e-01],
        [ 4.5785e+00,  4.1089e-03],
        [ 5.3378e-01,  2.3495e-01],
        [ 2.0115e+00,  1.1116e+00],
        [ 2.7491e+00, -8.0485e-01],
        [ 2.3331e+00,  3.3483e-01],
        [ 1.2925e+00,  2.9222e-01],
        [ 2.8095e+00,  6.3001e-01],
        [ 1.8620e+00,  1.0614e+00],
        [ 2.3587e+00, -1.9810e+00],
        [ 3.6370e+00, -1.0407e-01],
        [ 3.2214e+00, -3.7381e-01],
        [ 1.3879e+00,  9.2538e-01],
        [ 3.3711e+00,  6.6298e-01],
        [ 3.6207e+00, -1.5781e+00],
        [ 3.1294e+00, -1.2672e+00],
        [ 2.6843e+00, -5.8977e-01],
        [ 3.1601e+00, -7.3573e-02],
        [ 2.6756e+00,  5.4888e-01],
        [ 3.3679e+00,  2.8125e-01],
        [ 2.7247e+00,  1.0914e+00],
        [ 1.7930e+00, -1.2166e+00],
        [ 1.7726e+00, -7.2047e-01],
        [ 1.4980e+00,  2.7524e-01],
        [ 2.0510e+00, -2.2077e-01],
        [ 1.9512e+00,  3.9894e-01],
        [ 3.5209e+00, -1.1573e-01],
        [ 6.8236e-01, -2.6598e-02],
        [ 2.6781e+00,  4.7586e-01],
        [ 1.6048e+00, -5.2297e-03],
        [ 2.9625e+00, -3.1533e-02],
        [ 1.2237e+00, -1.6057e-01],
        [ 2.5779e+00,  4.4984e-02],
        [ 3.2030e+00,  8.9023e-01],
        [ 1.4212e+00,  1.2710e+00],
        [ 2.1048e+00, -7.4354e-02],
        [ 2.5223e+00,  2.3769e-02],
        [ 9.5785e-01,  7.0107e-01],
        [ 1.7748e+00, -2.1704e-01],
        [ 1.5786e+00, -1.0077e+00],
        [ 3.5722e+00, -1.3845e+00],
        [ 2.5543e+00,  4.3813e-01],
        [ 2.7465e+00, -8.9712e-01],
        [ 4.2892e+00, -7.7342e-01],
        [ 2.4267e+00, -7.1780e-01],
        [ 2.1278e+00, -2.8876e-01],
        [ 2.2358e+00,  1.6467e-01],
        [ 2.1157e+00, -6.9341e-01],
        [ 8.0262e-01, -1.0846e+00],
        [ 2.4147e+00,  8.9948e-01],
        [ 1.7140e+00, -1.7383e+00],
        [ 1.4578e+00, -8.4659e-01],
        [ 1.5233e+00, -6.9036e-01],
        [ 3.2526e+00, -1.4551e+00],
        [ 3.5308e+00, -4.9682e-01],
        [ 4.1570e+00, -2.1219e+00],
        [ 2.4617e+00,  1.5159e-01],
        [ 2.3182e+00,  1.7673e+00],
        [ 3.7393e+00,  1.5523e+00],
        [ 3.0316e+00,  3.8643e-02],
        [ 2.3947e+00,  4.8437e-01],
        [ 1.0605e+00,  1.1138e+00],
        [ 1.5329e+00, -1.4011e-01],
        [ 1.5921e+00,  3.2652e-01],
        [ 1.0330e+00,  8.0847e-01],
        [ 1.6596e+00, -1.7496e+00],
        [ 2.6242e+00,  9.7787e-01],
        [ 4.3385e+00, -1.2848e+00],
        [ 1.6672e+00,  1.8513e+00],
        [ 7.6163e-01, -1.2384e+00],
        [ 1.4557e+00,  2.2114e+00],
        [ 1.5769e+00, -1.1141e+00],
        [ 3.2047e+00, -8.6375e-02],
        [ 1.7931e+00, -2.1673e+00],
        [ 4.4698e+00, -7.0039e-01],
        [ 1.6836e+00, -5.0195e-01],
        [ 3.0965e+00, -3.1700e-01],
        [ 1.7424e+00, -4.7220e-01],
        [ 1.8758e+00, -6.5669e-01],
        [ 2.3604e+00, -2.1122e-01],
        [ 1.0698e+00, -1.0814e+00],
        [ 2.9981e+00,  3.7886e-01],
        [ 3.5736e+00, -1.8374e-01],
        [ 1.3321e+00, -8.2630e-01],
        [ 3.8677e+00,  1.1583e+00],
        [ 5.4609e-01,  2.4758e+00],
        [ 1.4660e+00,  1.0212e+00],
        [ 2.5302e+00, -1.6013e+00],
        [ 4.2201e+00, -9.0801e-01],
        [ 1.9985e+00, -1.3201e+00],
        [ 1.9423e+00,  1.1560e+00],
        [ 2.4685e+00, -4.3492e-01],
        [ 2.4892e+00, -1.2629e+00],
        [ 3.6645e+00, -2.4596e+00],
        [ 3.7178e+00,  1.8134e+00],
        [ 1.4808e+00,  3.9307e-01],
        [ 1.3856e+00, -2.4860e-01],
        [ 2.3389e+00, -1.1632e+00],
        [ 2.5795e+00,  8.7814e-01],
        [ 2.2366e+00,  3.1932e-02],
        [ 2.2105e+00, -3.1563e-01],
        [ 3.0109e+00,  2.0959e-01],
        [ 2.3133e+00,  1.5218e-01],
        [ 1.5424e+00, -1.0569e+00],
        [ 2.7930e+00,  3.8707e-01],
        [ 2.3843e+00, -1.0494e+00],
        [ 1.3602e+00, -7.1424e-01],
        [ 2.6283e+00, -2.8043e+00],
        [ 1.2417e+00, -1.1358e+00],
        [ 1.6345e+00,  4.9214e-01],
        [ 1.2601e+00, -1.8975e+00],
        [ 1.8845e+00,  1.0258e+00],
        [ 2.8619e+00, -6.7091e-01],
        [ 7.8672e-01,  9.7017e-01],
        [ 2.0948e+00,  1.3023e+00],
        [ 3.6859e-01, -6.2385e-01],
        [ 7.3587e-01,  6.3263e-01],
        [ 4.8809e+00, -4.2142e-01],
        [ 1.9746e+00,  1.1717e-02],
        [ 1.9353e+00,  1.5620e+00],
        [ 1.9040e-01,  2.1542e-01],
        [ 2.8647e+00,  1.7487e+00],
        [ 3.1655e+00, -7.4393e-01],
        [ 6.4156e-01, -8.6656e-01],
        [ 3.9467e-01, -1.4481e-01],
        [ 1.9136e+00, -3.9622e-01],
        [ 3.7966e+00, -1.4662e-01],
        [ 2.0725e+00,  3.4562e-01],
        [ 1.0730e+00, -4.0471e-02],
        [ 2.7082e+00,  1.1950e+00],
        [ 3.3891e+00, -9.8295e-01],
        [ 1.5446e+00, -5.3675e-01],
        [ 3.7703e+00,  4.5385e-01],
        [ 2.5751e+00,  7.9110e-01],
        [ 3.1025e+00, -1.8224e-02],
        [ 1.5187e+00,  2.6981e-01],
        [ 2.8971e+00,  2.2031e+00],
        [ 8.7840e-01, -5.6193e-01],
        [ 1.5651e+00, -6.6087e-01],
        [ 2.0562e+00,  6.5938e-01],
        [ 3.2120e+00, -2.1574e+00],
        [ 1.9579e+00, -2.2832e+00],
        [ 3.3252e+00,  9.7624e-01],
        [ 3.8502e+00, -2.0162e+00],
        [ 1.9663e+00,  2.7084e-01],
        [ 1.9940e+00,  1.7064e+00],
        [ 2.8268e+00, -2.1000e+00],
        [ 3.4826e+00,  1.9525e+00],
        [ 3.2091e+00,  5.9003e-01],
        [ 3.9875e+00, -1.6823e+00],
        [ 1.9363e+00,  1.7909e+00],
        [ 3.8926e+00, -5.1747e-01],
        [ 1.4659e+00, -1.3762e+00],
        [ 2.0575e+00, -9.4607e-01],
        [ 3.0450e+00,  1.0696e+00],
        [ 1.6949e+00, -1.1965e+00],
        [ 1.2354e+00,  1.3220e+00],
        [ 2.7754e+00,  1.7449e-02],
        [ 2.5933e+00, -1.0004e-01],
        [ 3.4017e+00, -1.3096e+00],
        [ 1.9072e+00, -1.3918e+00],
        [ 1.9786e+00, -4.6527e-01],
        [ 3.0143e+00, -4.7479e-01],
        [ 1.3557e+00,  6.5306e-01],
        [ 3.0885e+00, -6.6642e-01],
        [ 4.3674e+00,  1.1853e+00],
        [ 3.4751e+00, -1.9477e+00],
        [ 3.3801e+00,  2.4268e-01],
        [ 2.8891e+00, -8.3483e-01],
        [ 3.8126e+00,  6.2986e-01],
        [ 2.6752e+00,  8.2829e-01],
        [ 2.4740e+00, -1.3250e+00],
        [ 2.6372e+00, -6.2915e-01],
        [ 1.3884e+00, -7.6629e-01],
        [ 1.5266e+00,  1.6032e-01],
        [ 2.4023e+00, -2.1489e+00],
        [ 2.0721e+00, -1.2721e+00],
        [ 3.4678e+00,  1.0246e+00],
        [ 3.0551e+00, -4.9164e-01],
        [ 2.5231e+00, -4.4351e-01],
        [ 2.1583e+00,  9.5597e-01],
        [ 2.8406e+00, -1.4480e+00],
        [ 3.6025e+00,  8.3289e-02],
        [ 2.6915e+00, -1.8585e+00],
        [ 1.8948e-01, -1.8767e+00],
        [ 1.7624e+00,  8.5475e-02],
        [ 2.7426e+00, -8.3100e-01],
        [ 1.9038e+00,  4.9687e-01],
        [ 2.2625e-01, -6.4178e-01],
        [ 2.8622e+00,  4.8320e-01],
        [ 7.7169e-01,  9.8914e-02],
        [ 1.8306e+00, -1.0853e+00],
        [ 1.6353e+00, -4.7624e-01],
        [ 2.1949e+00, -1.4866e+00],
        [ 1.4952e+00,  7.6974e-01],
        [ 2.5029e+00,  2.4402e-01],
        [ 3.2695e+00, -1.1241e-01],
        [ 2.5116e+00, -1.4112e+00],
        [ 2.4091e+00, -4.2111e-01],
        [ 1.0275e+00, -8.3054e-01],
        [ 1.5514e+00,  7.5599e-01],
        [ 2.6747e+00,  1.3814e+00],
        [ 4.2442e+00, -7.4956e-01],
        [ 3.1577e+00,  4.5051e-01],
        [ 3.2644e+00,  6.5486e-01],
        [ 1.5494e+00, -1.2060e+00],
        [ 2.1954e+00,  9.7872e-01],
        [ 3.0990e+00,  4.7143e-01],
        [ 2.6165e+00,  8.5457e-01],
        [ 1.7254e+00, -5.6815e-01],
        [ 2.8121e+00,  1.8216e+00],
        [ 3.4172e+00,  5.9134e-01],
        [ 2.9585e+00, -7.1745e-01],
        [ 8.1047e-01, -2.1799e+00],
        [ 2.9588e+00, -1.9043e+00],
        [ 2.5244e+00,  2.1683e+00],
        [ 2.0966e+00,  2.2168e-01],
        [ 2.6091e+00,  1.3447e-01],
        [ 2.2558e+00, -6.5299e-01],
        [ 1.9317e+00, -6.2048e-01],
        [ 2.7399e+00, -3.3260e-01],
        [ 4.7660e+00, -1.1163e+00],
        [ 3.0244e+00,  1.1320e+00],
        [ 3.9174e+00, -7.1865e-01],
        [ 2.2859e+00,  3.6959e-01],
        [ 2.6671e+00, -7.8180e-01],
        [ 1.9178e+00, -1.4292e+00],
        [ 4.5866e+00, -5.0831e-01],
        [ 2.0390e+00,  1.4112e-01],
        [ 1.2206e+00, -1.0388e+00],
        [ 1.8533e+00,  8.6248e-01],
        [ 2.6119e+00, -2.5382e-01],
        [ 2.2307e+00, -7.4737e-01],
        [ 1.9130e+00, -1.6935e+00],
        [ 2.9628e+00, -1.7294e+00],
        [ 1.8120e+00,  1.4477e+00],
        [ 2.8339e+00, -7.3319e-01],
        [ 3.5135e+00,  1.6549e-01],
        [ 3.5385e+00, -2.7562e+00],
        [ 3.0189e+00, -9.8457e-01],
        [ 3.6727e+00,  6.1228e-01],
        [ 1.7613e+00, -1.5316e+00],
        [ 2.2832e+00, -1.5133e+00],
        [ 3.3223e+00, -6.2639e-01],
        [ 3.5899e+00,  8.3277e-01],
        [ 2.8375e+00, -1.1077e+00],
        [ 2.1764e+00, -9.6561e-03],
        [ 1.3971e+00, -5.3625e-01],
        [ 1.4108e+00, -2.4159e+00],
        [ 1.6264e+00, -1.0556e+00],
        [ 2.8749e+00, -2.6482e-01],
        [ 1.1971e+00, -3.4742e-01],
        [ 9.8789e-01,  8.2471e-02],
        [ 2.8799e+00, -2.4708e-01],
        [ 1.5923e+00, -7.1421e-01],
        [ 3.2975e+00, -9.8036e-01],
        [ 2.8070e+00, -2.6347e+00],
        [ 3.7840e+00, -1.5413e+00],
        [ 2.1583e+00, -8.3219e-01],
        [ 1.8735e+00, -1.2826e-01],
        [ 1.7423e+00, -1.5099e+00],
        [ 3.0631e+00,  1.2982e-01],
        [ 1.9795e+00, -3.5662e-01],
        [ 3.3177e+00,  2.9263e-01],
        [ 2.3193e+00,  5.4573e-01],
        [ 3.0059e+00, -8.5417e-01],
        [ 1.2870e+00, -1.5354e-01],
        [ 1.9492e+00,  1.9587e+00],
        [ 3.1434e+00,  1.3759e-01],
        [ 1.3131e+00,  2.3977e+00]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[3.3378e-01, 3.3378e-01, 3.3897e-01,  ..., 9.0414e-01, 9.8803e-01,
         1.0000e+00],
        [1.5182e-03, 4.1415e-02, 5.0087e-02,  ..., 9.5888e-01, 9.6228e-01,
         1.0000e+00],
        [1.2603e-05, 1.2618e-05, 3.3791e-02,  ..., 9.8945e-01, 9.9991e-01,
         1.0000e+00],
        ...,
        [5.8308e-02, 6.0533e-02, 9.1436e-02,  ..., 9.3163e-01, 9.7782e-01,
         1.0000e+00],
        [2.0527e-05, 1.1146e-01, 1.1536e-01,  ..., 9.8621e-01, 9.9245e-01,
         1.0000e+00],
        [3.2710e-03, 3.2710e-03, 4.4582e-03,  ..., 5.6362e-01, 9.9989e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.6054],
        [0.3237],
        [0.4830],
        [0.4285],
        [0.5214],
        [0.6048],
        [0.6707],
        [0.0924],
        [0.3563],
        [0.4746],
        [0.3600],
        [0.1290],
        [0.9496],
        [0.5129],
        [0.3299],
        [0.7369],
        [0.5549],
        [0.1613],
        [0.6392],
        [0.3401],
        [0.7644],
        [0.6027],
        [0.8432],
        [0.6981],
        [0.0272],
        [0.6304],
        [0.4830],
        [0.6533],
        [0.1688],
        [0.4866],
        [0.4310],
        [0.9792],
        [0.7697],
        [0.8708],
        [0.5051],
        [0.7953],
        [0.4231],
        [0.3108],
        [0.3049],
        [0.0255],
        [0.2050],
        [0.1936],
        [0.4694],
        [0.7300],
        [0.3388],
        [0.0605],
        [0.7168],
        [0.9075],
        [0.6871],
        [0.0067],
        [0.4248],
        [0.1624],
        [0.3457],
        [0.6591],
        [0.6874],
        [0.6595],
        [0.0058],
        [0.6421],
        [0.5400],
        [0.4430],
        [0.2299],
        [0.4165],
        [0.6327],
        [0.7768],
        [0.9159],
        [0.3877],
        [0.3141],
        [0.9646],
        [0.8184],
        [0.4624],
        [0.5094],
        [0.2276],
        [0.8896],
        [0.4930],
        [0.7467],
        [0.7528],
        [0.7902],
        [0.2851],
        [0.0265],
        [0.0158],
        [0.5330],
        [0.4240],
        [0.8513],
        [0.7079],
        [0.4460],
        [0.6045],
        [0.6174],
        [0.5700],
        [0.8925],
        [0.1183],
        [0.9071],
        [0.4230],
        [0.3170],
        [0.9163],
        [0.4693],
        [0.6510],
        [0.4420],
        [0.3522],
        [0.0014],
        [0.9402],
        [0.7441],
        [0.2006],
        [0.8634],
        [0.4436],
        [0.6430],
        [0.6856],
        [0.1893],
        [0.5036],
        [0.1201],
        [0.7405],
        [0.7301],
        [0.4308],
        [0.1167],
        [0.0535],
        [0.2474],
        [0.4073],
        [0.2692],
        [0.5681],
        [0.6093],
        [0.2943],
        [0.9076],
        [0.6208],
        [0.2874],
        [0.7909],
        [0.7077],
        [0.1564],
        [0.7481],
        [0.5625],
        [0.6379],
        [0.3294],
        [0.1513],
        [0.5926],
        [0.3544],
        [0.3976],
        [0.2987],
        [0.6684],
        [0.3501],
        [0.8445],
        [0.9894],
        [0.1700],
        [0.1976],
        [0.7719],
        [0.5476],
        [0.6330],
        [0.8361],
        [0.5998],
        [0.7902],
        [0.8138],
        [0.2842],
        [0.0905],
        [0.6646],
        [0.0238],
        [0.5389],
        [0.6696],
        [0.4768],
        [0.8665],
        [0.3817],
        [0.8774],
        [0.8200],
        [0.9904],
        [0.3439],
        [0.1573],
        [0.1519],
        [0.0844],
        [0.8866],
        [0.3740],
        [0.7062],
        [0.2102],
        [0.9357],
        [0.3166],
        [0.8145],
        [0.9317],
        [0.6571],
        [0.6014],
        [0.9005],
        [0.8755],
        [0.8775],
        [0.8914],
        [0.0047],
        [0.7118],
        [0.8988],
        [0.6686],
        [0.8879],
        [0.3060],
        [0.8661],
        [0.0225],
        [0.5200],
        [0.3213],
        [0.9559],
        [0.9735],
        [0.6352],
        [0.7309],
        [0.8415],
        [0.6445],
        [0.6079],
        [0.9387],
        [0.3827],
        [0.0240],
        [0.1002],
        [0.9009],
        [0.2543],
        [0.5491],
        [0.0980],
        [0.5234],
        [0.8258],
        [0.0883],
        [0.1573],
        [0.0246],
        [0.2031],
        [0.5181],
        [0.2556],
        [0.2358],
        [0.6016],
        [0.5113],
        [0.5818],
        [0.6349],
        [0.4784],
        [0.6300],
        [0.4406],
        [0.6061],
        [0.3294],
        [0.7612],
        [0.1809],
        [0.6119],
        [0.3848],
        [0.7116],
        [0.5834],
        [0.2486],
        [0.9514],
        [0.1721],
        [0.4359],
        [0.5258],
        [0.3163],
        [0.5731],
        [0.5803],
        [0.0444],
        [0.8131],
        [0.6127],
        [0.7848],
        [0.6964],
        [0.7193],
        [0.7629],
        [0.1845],
        [0.5879],
        [0.9118],
        [0.7360],
        [0.4270],
        [0.7450],
        [0.9978],
        [0.7288],
        [0.8031],
        [0.7058],
        [0.7534],
        [0.0934],
        [0.1444],
        [0.4827],
        [0.2851],
        [0.0688],
        [0.8393],
        [0.4336],
        [0.1438],
        [0.9883],
        [0.3351],
        [0.2169],
        [0.4253],
        [0.1140],
        [0.5947],
        [0.4866],
        [0.4142],
        [0.0080],
        [0.1295],
        [0.8545],
        [0.9613],
        [0.4901],
        [0.9242],
        [0.1417],
        [0.1567],
        [0.8206],
        [0.4748],
        [0.8282],
        [0.5074],
        [0.9923],
        [0.7947],
        [0.1939],
        [0.6113],
        [0.4002],
        [0.0850],
        [0.3159],
        [0.1493],
        [0.3872],
        [0.0853],
        [0.8605],
        [0.1215],
        [0.0363],
        [0.6068],
        [0.6096],
        [0.2019],
        [0.9709],
        [0.4269],
        [0.8286],
        [0.4506],
        [0.8020],
        [0.4350],
        [0.2880],
        [0.4859],
        [0.9578],
        [0.3627],
        [0.3919],
        [0.7149],
        [0.2087],
        [0.6906],
        [0.0819]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 2.2583, -1.2859],
        [-2.3290,  0.9433],
        [ 0.9494,  1.3667],
        ...,
        [ 1.1004,  1.5744],
        [ 2.8758, -0.1972],
        [-1.0834,  1.0219]]) torch.Size([9984, 2])
samples tensor([[ 1.9667, -0.3441],
        [ 2.4330, -0.6400],
        [ 2.1845,  0.0144],
        [ 2.6215, -1.7794],
        [ 2.9919,  0.7827],
        [ 2.0676,  1.8002],
        [ 1.9479, -0.4202],
        [ 2.8259,  0.5239],
        [ 2.2259, -0.3024],
        [ 1.2655,  0.1556],
        [ 3.9312, -0.5818],
        [ 4.7625, -0.9572],
        [ 1.5149,  1.4935],
        [ 4.6009, -1.4266],
        [ 3.6047, -1.0462],
        [ 2.5188, -0.4731],
        [ 2.0713, -0.1481],
        [ 2.3516,  0.3258],
        [ 1.9864, -0.1750],
        [ 2.6881,  0.9106],
        [ 1.7035, -0.2965],
        [ 1.9643, -0.9687],
        [ 2.9900,  0.4292],
        [ 2.4009, -0.3780],
        [ 0.9859, -0.0279],
        [ 2.8826, -0.6575],
        [ 2.8228, -1.2831],
        [ 3.2575, -2.3666],
        [ 2.7296, -0.2679],
        [ 2.4208, -0.0198],
        [ 2.8482, -0.5938],
        [ 2.9129, -0.0977],
        [ 1.4365, -0.5869],
        [ 3.3231, -0.1144],
        [ 3.8486, -0.9878],
        [ 1.8419,  1.3092],
        [ 3.7652,  0.9802],
        [ 1.2952, -1.0030],
        [ 1.9738, -0.6014],
        [ 2.5930,  1.3656],
        [ 3.4219, -0.6178],
        [ 3.0250,  0.9286],
        [ 1.3712,  0.9422],
        [ 3.5780,  0.0670],
        [ 1.9039,  0.2970],
        [ 1.9097, -0.7144],
        [ 2.2054,  0.7161],
        [ 2.0844, -0.3651],
        [ 3.1573, -0.3622],
        [ 2.0708,  2.3124],
        [ 2.5618, -1.2361],
        [ 3.0257,  0.4540],
        [ 2.9665,  1.0700],
        [ 0.8717,  0.6470],
        [ 2.2201, -1.2577],
        [ 1.7214,  1.1592],
        [ 0.0992, -0.3121],
        [ 1.1158, -2.4725],
        [ 2.5984, -0.2203],
        [ 3.4147, -0.5659],
        [ 2.1241,  0.0338],
        [ 3.8757, -0.1296],
        [ 0.9765, -0.0228],
        [ 3.1047, -1.0931],
        [ 3.4356,  2.3990],
        [ 2.2620, -0.5016],
        [ 2.7747, -0.2627],
        [ 1.5277,  0.6504],
        [ 1.8165, -1.3634],
        [ 3.8225, -1.9706],
        [ 1.7425, -0.6980],
        [ 2.2953,  0.0571],
        [ 1.1452,  1.0257],
        [ 1.8231,  0.1838],
        [ 1.8648,  0.1551],
        [ 3.5851, -1.7252],
        [ 1.4919, -0.1447],
        [ 3.7744, -1.5017],
        [ 1.5677, -0.8753],
        [ 1.5156,  2.6682],
        [ 3.0599, -1.0512],
        [ 2.5135, -1.0585],
        [ 2.9114, -0.3778],
        [ 4.0800,  1.0894],
        [ 3.0821,  0.5700],
        [ 1.8003, -0.8698],
        [ 3.5749, -1.0242],
        [ 4.0784,  1.1294],
        [ 2.9046,  0.6174],
        [ 2.8046, -0.2352],
        [ 2.5992,  0.3227],
        [ 1.8586, -1.3364],
        [ 1.7249, -0.5397],
        [ 2.5549,  0.1639],
        [-0.2158, -0.6566],
        [ 2.7059, -0.8253],
        [ 3.8375,  0.1252],
        [ 1.0876, -0.7181],
        [ 1.5462,  0.8833],
        [ 3.8501,  0.1278],
        [ 2.0950,  0.4892],
        [ 1.7778,  0.3757],
        [ 2.2641,  0.0997],
        [ 1.1419,  0.1365],
        [ 2.2673, -2.2586],
        [ 1.2848,  0.8463],
        [ 3.4703,  0.3490],
        [ 3.8560,  1.1179],
        [ 0.9000, -0.3342],
        [ 0.4741,  1.6692],
        [ 1.8633, -0.5492],
        [ 3.9884, -0.6847],
        [ 2.2185,  1.3232],
        [ 1.3018, -0.5127],
        [ 2.3558,  1.5323],
        [ 1.4620, -0.2229],
        [ 1.8380,  0.6198],
        [ 1.9884, -1.8710],
        [ 3.2215, -0.4766],
        [ 3.1439,  0.3484],
        [ 2.2657,  0.3577],
        [ 2.9623, -0.6897],
        [ 1.8116, -0.6296],
        [ 1.7292, -0.7201],
        [ 0.4341,  1.4018],
        [ 0.2566, -0.1232],
        [ 2.4393,  0.2094],
        [ 2.3215, -0.1005],
        [-0.4939,  0.7165],
        [ 3.9334, -1.6673],
        [ 0.5590, -0.9132],
        [ 3.1503, -1.5634],
        [ 2.0150,  0.2536],
        [ 3.0967, -2.1268],
        [ 2.4091, -1.0277],
        [ 2.1307, -0.6206],
        [ 3.1310, -0.5044],
        [ 2.2932,  0.4099],
        [ 3.6469, -0.5211],
        [ 2.1170, -0.2275],
        [ 2.8824,  1.6719],
        [ 3.6186, -0.6070],
        [ 2.8200,  1.0344],
        [ 2.8758, -0.9713],
        [ 2.4120, -1.3588],
        [ 1.7962,  0.4678],
        [ 3.3376, -0.3899],
        [ 2.7107,  0.3570],
        [ 1.3527, -0.0913],
        [ 1.8225, -0.2262],
        [ 2.0813, -1.6306],
        [ 2.4338,  0.7406],
        [ 3.3333,  1.2467],
        [ 1.6594, -1.0442],
        [ 2.3853, -0.8186],
        [ 2.8160, -0.0179],
        [ 1.6495, -1.3900],
        [ 1.9607, -2.4444],
        [ 3.2629, -0.3678],
        [ 2.8107,  1.2797],
        [ 1.5637, -1.4142],
        [ 2.4063,  1.4785],
        [ 2.9953, -0.4202],
        [ 1.5265, -0.9949],
        [ 1.7890,  0.2144],
        [ 2.0210, -0.9893],
        [ 3.7142, -0.6855],
        [ 3.1431, -0.0723],
        [ 0.8499,  0.1468],
        [ 2.0542,  0.7120],
        [ 1.3029,  0.3466],
        [ 2.1430,  0.8286],
        [ 3.4080,  0.8544],
        [ 2.7241, -0.3594],
        [ 0.5272, -0.0434],
        [ 2.2124, -1.0335],
        [ 2.1405,  0.0913],
        [ 2.2336, -0.8491],
        [ 2.9668,  2.2955],
        [ 3.6295, -2.1881],
        [ 1.8939, -0.3270],
        [ 2.0627,  2.0307],
        [ 4.0016, -1.6862],
        [ 2.2255, -1.1083],
        [ 3.0338, -1.6939],
        [ 2.2689,  0.2854],
        [ 2.2644,  0.3119],
        [ 0.7097, -1.8758],
        [ 3.5829, -0.2749],
        [ 1.1995,  1.2961],
        [ 2.1998, -0.0361],
        [ 1.7080, -0.5253],
        [ 1.2093,  0.1052],
        [ 1.0307,  0.4790],
        [ 1.3989,  0.4175],
        [ 2.2817,  0.9495],
        [ 1.3370,  0.0782],
        [ 2.2157,  1.7695],
        [ 1.2890, -0.3956],
        [ 3.7034,  0.8676],
        [ 3.3123, -1.2890],
        [ 2.9372,  1.7967],
        [ 2.3836, -0.7830],
        [ 0.8852,  0.0192],
        [ 1.7344, -0.9968],
        [ 1.5585,  0.6863],
        [ 1.4124, -0.3540],
        [ 1.2745,  0.0946],
        [ 1.8941, -0.5876],
        [ 2.0599,  0.8465],
        [-0.2454,  0.4163],
        [ 2.1659,  0.3958],
        [ 3.4518, -0.6045],
        [ 2.7237, -1.1660],
        [ 1.7607, -0.5171],
        [ 1.9961, -0.0418],
        [ 3.6018,  0.3499],
        [ 2.8700, -1.3005],
        [ 1.4712, -0.2431],
        [ 2.0491, -2.3844],
        [ 3.5424, -1.7017],
        [ 2.2419,  0.1637],
        [ 0.8524,  0.9923],
        [ 2.7424,  1.0494],
        [ 1.6606,  1.5116],
        [ 2.5152,  1.7980],
        [ 3.3078, -1.2446],
        [ 2.4340, -0.2246],
        [-0.3093, -1.3151],
        [ 4.8413,  0.2065],
        [ 1.1954, -0.0904],
        [ 3.7054, -1.2177],
        [ 2.0709, -1.2656],
        [ 0.1255, -2.2068],
        [ 2.4332,  0.2123],
        [ 3.4782,  1.3128],
        [ 2.0052,  0.7258],
        [ 3.6725, -0.6561],
        [ 3.7448, -0.3790],
        [ 4.2799, -1.3575],
        [ 2.5520, -0.7444],
        [ 2.5926, -0.7954],
        [ 0.8668,  1.4067],
        [ 3.8148,  0.2600],
        [ 2.5462, -0.9884],
        [ 3.0394, -0.2864],
        [ 2.1651,  0.9824],
        [ 2.5558, -0.4910],
        [ 3.2476,  2.0025],
        [ 3.3788,  0.1170],
        [ 2.8318,  1.2219],
        [ 3.4819, -1.4178],
        [ 2.1657, -1.0967],
        [ 1.3618, -1.4176],
        [-0.0852, -1.7778],
        [ 2.4715, -0.5707],
        [ 0.6935, -1.7783],
        [ 1.4971,  0.3318],
        [ 1.3318, -0.7199],
        [ 2.6475, -0.8391],
        [ 2.0768,  0.7564],
        [ 2.4435,  0.8676],
        [ 1.6627, -0.9171],
        [ 1.7295, -0.7534],
        [ 0.6732,  0.1899],
        [ 3.3480, -0.6215],
        [ 2.5038,  0.9942],
        [ 1.9798,  0.1261],
        [ 3.4497, -0.9849],
        [ 1.7019,  1.4712],
        [ 2.4859, -0.1672],
        [ 3.2719, -0.4002],
        [ 1.5948, -0.2130],
        [ 1.7272,  0.4377],
        [ 1.4809, -0.2554],
        [ 3.3612, -0.1724],
        [ 2.0069,  0.5267],
        [ 2.9107,  0.8383],
        [ 0.9342,  0.0815],
        [ 2.4069,  1.1339],
        [ 3.0328,  0.1535],
        [ 3.4584,  2.0677],
        [ 2.0729,  0.2484],
        [ 1.6123,  0.1836],
        [ 1.7457, -1.3028],
        [ 4.1647,  0.4514],
        [ 1.4538,  0.3861],
        [ 0.6179, -1.2548],
        [ 3.1405,  1.6754],
        [ 1.9820,  1.6247],
        [ 2.2688, -0.8261],
        [ 1.9119,  0.2298],
        [ 2.0406, -0.4262],
        [ 1.8561,  0.0227],
        [ 3.0070,  1.6537],
        [ 2.9270,  0.9101],
        [ 3.0711, -0.1947],
        [ 4.5161,  0.3590],
        [ 1.5227, -1.5817],
        [ 3.3480,  0.0766],
        [ 2.5304,  2.9907],
        [ 2.2029, -0.4029],
        [ 2.4962,  0.7478],
        [ 4.0666, -0.0103],
        [ 3.5057,  0.7046],
        [ 3.0840,  0.3112],
        [ 3.2363,  0.4371],
        [ 2.0409, -3.5024],
        [ 1.7077,  0.4815],
        [ 1.9391,  0.5000],
        [ 2.8601, -0.0812],
        [ 1.6963,  0.1370]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.1152e-04, 1.1270e-04, 3.4227e-02,  ..., 9.5519e-01, 9.9971e-01,
         1.0000e+00],
        [3.9503e-08, 7.1822e-08, 1.1688e-07,  ..., 8.5425e-01, 9.0357e-01,
         1.0000e+00],
        [1.3824e-02, 1.9124e-02, 1.9242e-02,  ..., 9.9847e-01, 9.9903e-01,
         1.0000e+00],
        ...,
        [3.9010e-01, 3.9321e-01, 3.9462e-01,  ..., 7.9528e-01, 9.9937e-01,
         1.0000e+00],
        [6.7782e-03, 6.3294e-02, 9.3413e-02,  ..., 9.9840e-01, 9.9990e-01,
         1.0000e+00],
        [1.1124e-05, 3.1000e-04, 3.1110e-04,  ..., 9.9578e-01, 9.9960e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.5059],
        [0.2129],
        [0.4640],
        [0.6371],
        [0.9537],
        [0.6182],
        [0.7141],
        [0.0470],
        [0.7700],
        [0.4732],
        [0.9037],
        [0.1460],
        [0.9293],
        [0.8171],
        [0.7578],
        [0.9639],
        [0.0251],
        [0.6925],
        [0.4623],
        [0.3116],
        [0.5459],
        [0.6562],
        [0.9415],
        [0.0602],
        [0.1916],
        [0.5851],
        [0.2833],
        [0.4094],
        [0.6525],
        [0.3846],
        [0.9695],
        [0.2479],
        [0.7576],
        [0.2800],
        [0.8645],
        [0.3234],
        [0.0705],
        [0.2441],
        [0.3513],
        [0.7798],
        [0.2639],
        [0.2890],
        [0.2198],
        [0.5580],
        [0.0103],
        [0.0274],
        [0.7972],
        [0.4200],
        [0.4250],
        [0.2869],
        [0.9614],
        [0.9727],
        [0.7532],
        [0.6442],
        [0.2555],
        [0.3940],
        [0.2867],
        [0.6468],
        [0.0372],
        [0.4611],
        [0.8339],
        [0.1553],
        [0.8225],
        [0.1519],
        [0.3307],
        [0.6783],
        [0.4751],
        [0.0596],
        [0.4151],
        [0.2944],
        [0.4259],
        [0.9728],
        [0.3114],
        [0.5727],
        [0.2332],
        [0.8927],
        [0.1448],
        [0.1074],
        [0.7626],
        [0.1256],
        [0.6812],
        [0.9184],
        [0.6746],
        [0.0501],
        [0.7589],
        [0.5067],
        [0.1010],
        [0.3027],
        [0.6905],
        [0.7431],
        [0.8024],
        [0.3198],
        [0.4081],
        [0.8318],
        [0.5959],
        [0.4723],
        [0.2922],
        [0.8234],
        [0.7939],
        [0.4373],
        [0.6571],
        [0.0927],
        [0.8368],
        [0.4902],
        [0.3758],
        [0.8599],
        [0.4384],
        [0.2913],
        [0.2804],
        [0.9963],
        [0.5291],
        [0.6115],
        [0.2554],
        [0.1595],
        [0.6128],
        [0.3204],
        [0.8595],
        [0.4312],
        [0.7683],
        [0.0252],
        [0.6044],
        [0.9278],
        [0.1847],
        [0.0756],
        [0.3987],
        [0.0236],
        [0.7732],
        [0.1656],
        [0.5420],
        [0.5166],
        [0.6768],
        [0.3207],
        [0.8368],
        [0.0693],
        [0.7865],
        [0.0361],
        [0.2842],
        [0.5547],
        [0.4177],
        [0.8280],
        [0.5332],
        [0.1694],
        [0.2266],
        [0.6558],
        [0.5964],
        [0.7944],
        [0.1860],
        [0.1848],
        [0.2248],
        [0.5011],
        [0.6753],
        [0.3679],
        [0.8869],
        [0.5018],
        [0.9005],
        [0.2583],
        [0.1823],
        [0.1285],
        [0.3665],
        [0.9485],
        [0.2762],
        [0.0067],
        [0.9229],
        [0.9637],
        [0.4157],
        [0.1197],
        [0.0749],
        [0.5982],
        [0.3981],
        [0.8243],
        [0.8489],
        [0.0541],
        [0.8551],
        [0.2568],
        [0.6215],
        [0.5221],
        [0.7189],
        [0.2119],
        [0.1824],
        [0.2095],
        [0.3431],
        [0.6963],
        [0.5436],
        [0.2718],
        [0.1138],
        [0.9098],
        [0.0322],
        [0.2600],
        [0.7470],
        [0.8935],
        [0.9955],
        [0.0588],
        [0.5847],
        [0.8087],
        [0.6275],
        [0.9646],
        [0.6942],
        [0.6874],
        [0.8084],
        [0.6779],
        [0.3514],
        [0.2585],
        [0.3164],
        [0.0788],
        [0.5351],
        [0.0081],
        [0.0716],
        [0.5316],
        [0.8059],
        [0.7365],
        [0.9149],
        [0.3092],
        [0.4211],
        [0.8484],
        [0.3579],
        [0.1021],
        [0.2964],
        [0.0963],
        [0.0738],
        [0.2869],
        [0.6206],
        [0.7677],
        [0.7096],
        [0.8557],
        [0.2326],
        [0.9420],
        [0.6053],
        [0.0795],
        [0.1423],
        [0.5693],
        [0.9141],
        [0.1995],
        [0.7236],
        [0.5105],
        [0.7536],
        [0.4904],
        [0.5135],
        [0.5160],
        [0.7631],
        [0.1691],
        [0.2199],
        [0.2340],
        [0.6359],
        [0.0660],
        [0.0066],
        [0.9735],
        [0.9624],
        [0.9996],
        [0.9937],
        [0.2522],
        [0.1391],
        [0.4762],
        [0.5462],
        [0.5112],
        [0.2751],
        [0.7898],
        [0.9345],
        [0.1149],
        [0.6306],
        [0.0251],
        [0.4573],
        [0.7994],
        [0.5625],
        [0.6668],
        [0.8031],
        [0.7929],
        [0.4375],
        [0.5467],
        [0.0943],
        [0.5477],
        [0.4961],
        [0.0220],
        [0.7359],
        [0.1204],
        [0.5912],
        [0.5394],
        [0.9339],
        [0.5487],
        [0.9535],
        [0.2078],
        [0.4885],
        [0.9420],
        [0.1564],
        [0.3352],
        [0.2381],
        [0.9904],
        [0.5018],
        [0.0439],
        [0.0377],
        [0.5588],
        [0.9296],
        [0.2467],
        [0.2730],
        [0.1031],
        [0.2059],
        [0.1770],
        [0.1910],
        [0.6217],
        [0.1968],
        [0.6763],
        [0.4711],
        [0.8082],
        [0.4903],
        [0.0256],
        [0.7923],
        [0.9018],
        [0.7750],
        [0.6118],
        [0.0050],
        [0.1444],
        [0.0266],
        [0.9775]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [ True, False, False,  ..., False, False, False],
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-1.2856,  0.1764],
        [-2.3470,  0.9328],
        [ 2.7224,  1.7669],
        ...,
        [ 0.7833,  0.6550],
        [ 0.8992,  2.1191],
        [-0.6031,  0.8031]]) torch.Size([9984, 2])
samples tensor([[ 5.1506e-01,  3.4665e-01],
        [ 2.0021e+00, -4.9508e-01],
        [ 1.3426e+00, -2.2087e+00],
        [ 1.2332e+00,  9.3672e-01],
        [ 3.8524e+00, -1.8289e+00],
        [ 6.5353e-01, -5.2019e-01],
        [ 1.1718e+00, -6.8337e-01],
        [ 2.2419e+00,  8.4405e-01],
        [ 2.4629e+00, -6.9910e-01],
        [ 1.3326e+00, -9.8512e-01],
        [ 1.7853e+00,  3.5495e-01],
        [ 1.8985e+00, -2.8182e-02],
        [ 3.3018e+00,  1.3368e+00],
        [ 2.8032e+00,  1.6744e+00],
        [ 3.8948e-01,  1.5820e-01],
        [ 2.7186e+00, -2.7641e+00],
        [ 2.0486e+00,  4.1934e-01],
        [ 3.1274e+00,  2.9284e-01],
        [ 1.6885e+00, -2.8407e-01],
        [ 2.6567e+00, -2.2527e+00],
        [ 3.8508e+00, -6.2335e-01],
        [ 1.8575e+00,  1.4681e-01],
        [ 3.3159e+00, -9.1140e-02],
        [ 1.8701e+00, -1.2243e-01],
        [ 2.4081e+00,  1.0430e-02],
        [ 3.9949e+00, -4.7340e-02],
        [ 2.3231e+00, -6.5343e-01],
        [ 3.3595e+00,  3.9047e-01],
        [ 2.4919e+00, -1.0703e-01],
        [ 2.7374e+00,  4.8721e-01],
        [ 2.9183e+00,  8.0813e-01],
        [ 1.9063e+00, -4.4793e-01],
        [ 9.0589e-01, -2.5617e-01],
        [ 2.2049e+00, -8.8016e-01],
        [ 1.9447e+00, -1.0767e+00],
        [ 1.8335e+00, -1.7532e-02],
        [ 2.0996e+00,  7.1530e-02],
        [ 8.9480e-01,  5.5396e-01],
        [ 2.0604e+00, -2.4015e+00],
        [ 1.4456e+00,  5.6282e-01],
        [ 1.9781e+00, -1.0010e+00],
        [ 2.2493e+00, -2.0557e-01],
        [ 1.6291e+00,  1.6058e+00],
        [ 2.1382e+00,  4.8175e-01],
        [ 1.1945e+00,  5.5066e-01],
        [ 2.8647e+00, -3.4455e-01],
        [ 2.2323e+00, -3.3268e-01],
        [ 2.5250e+00,  3.0491e-01],
        [ 1.6105e+00, -1.3472e+00],
        [ 3.8744e+00, -1.2267e+00],
        [ 2.3604e+00,  1.1132e+00],
        [ 1.6861e+00,  1.6406e+00],
        [-4.7687e-01, -6.3156e-02],
        [ 3.8597e+00, -5.4731e-02],
        [ 1.7458e+00, -7.3101e-01],
        [ 2.2339e+00,  1.2074e+00],
        [ 2.4402e+00, -7.1639e-01],
        [ 3.9108e+00,  2.3835e-01],
        [ 2.4413e+00,  5.6576e-01],
        [ 4.3996e+00, -7.9333e-01],
        [ 3.9496e+00, -1.9236e-01],
        [ 2.0407e+00,  7.9631e-01],
        [ 4.1749e-03, -4.7054e-02],
        [ 3.0400e+00,  5.9048e-01],
        [ 6.9695e-03, -7.0783e-01],
        [ 3.4772e+00, -1.9842e+00],
        [ 1.6955e+00,  8.8785e-01],
        [ 3.0265e+00,  2.9077e-01],
        [ 2.8147e+00,  1.3583e-01],
        [ 1.8596e+00, -1.2664e+00],
        [ 3.2969e+00, -8.2434e-01],
        [ 2.0520e+00, -2.2918e-01],
        [ 2.2624e+00, -1.7358e+00],
        [ 4.9091e-01, -1.2205e+00],
        [ 1.7899e+00, -1.0485e+00],
        [ 2.5265e+00, -1.3673e+00],
        [ 1.9323e+00, -1.7250e+00],
        [ 2.0164e+00,  1.2427e-01],
        [ 3.2325e+00, -6.9230e-01],
        [ 2.2280e+00,  1.6270e+00],
        [ 2.9395e+00, -4.2287e-01],
        [ 1.2307e+00,  1.0421e+00],
        [ 2.0160e+00, -3.3279e-01],
        [ 2.9155e+00,  3.1117e-01],
        [-3.5250e-01, -1.4841e+00],
        [ 4.9485e+00, -1.1870e+00],
        [ 2.9451e+00, -3.1781e-01],
        [ 2.8741e+00, -4.7892e-01],
        [ 2.2731e+00, -3.2376e-01],
        [ 4.0655e+00, -1.1528e-01],
        [ 2.1168e+00, -1.8562e+00],
        [ 3.0339e+00,  7.7677e-01],
        [ 3.5381e+00,  9.7507e-01],
        [ 3.3857e+00,  1.7305e-01],
        [ 3.6884e-01,  5.8931e-01],
        [ 2.4510e+00,  3.5053e-01],
        [ 1.9764e+00,  1.3089e-01],
        [ 4.6274e-01,  1.6121e-01],
        [ 1.6325e+00,  9.5897e-02],
        [ 1.8812e+00, -3.4542e-01],
        [ 2.7255e+00, -2.3348e-01],
        [ 1.3709e-01,  9.6237e-01],
        [ 1.9910e+00, -6.3727e-01],
        [ 3.4969e+00, -1.7092e+00],
        [ 2.0599e+00,  7.3449e-01],
        [ 3.9518e+00,  1.4657e-01],
        [ 2.5211e+00,  1.0830e+00],
        [ 1.5748e+00,  1.2077e+00],
        [ 1.4825e+00, -7.4905e-01],
        [ 2.9460e+00, -1.1835e-02],
        [ 3.3682e+00,  4.6352e-01],
        [ 1.9376e+00, -8.1862e-01],
        [ 3.4387e+00,  3.7330e-01],
        [ 1.6351e+00,  8.5621e-01],
        [ 2.9087e+00, -9.1786e-01],
        [ 3.5648e+00, -2.7981e-01],
        [ 2.3806e+00, -2.1203e+00],
        [ 3.0296e+00, -2.2571e+00],
        [ 3.4818e+00, -7.1026e-01],
        [ 1.1939e+00,  1.3691e+00],
        [ 1.4148e+00, -4.5654e-01],
        [ 2.1283e+00,  1.4530e+00],
        [ 2.7186e+00, -7.6624e-02],
        [ 3.3736e+00, -1.0961e+00],
        [ 3.0098e+00, -1.2505e-01],
        [ 2.4063e+00, -1.3977e+00],
        [ 3.6772e+00,  6.0680e-01],
        [ 2.7670e+00, -6.5587e-01],
        [ 1.6723e+00, -1.1756e+00],
        [ 3.4727e+00, -5.3464e-01],
        [ 2.3632e+00, -1.5125e-01],
        [ 2.5014e+00, -4.1747e-01],
        [ 2.4294e+00,  1.4915e+00],
        [ 3.5689e+00,  1.4285e+00],
        [ 2.5779e+00,  7.9535e-01],
        [ 1.3544e+00,  1.2757e+00],
        [ 2.7027e+00,  1.6822e+00],
        [ 3.3103e+00,  6.4760e-01],
        [ 1.8467e+00,  5.7624e-02],
        [ 1.5213e+00,  3.0813e-05],
        [ 3.1212e+00,  1.6568e+00],
        [ 9.4687e-01, -5.6741e-01],
        [ 2.2717e+00,  9.3913e-01],
        [ 3.6988e+00,  2.1680e+00],
        [ 4.1944e+00, -7.0799e-01],
        [ 1.0802e+00, -1.0311e+00],
        [ 2.6291e+00,  6.2336e-01],
        [ 2.0572e+00, -8.2700e-01],
        [ 2.0576e+00,  1.3589e+00],
        [ 2.6962e+00, -5.8369e-01],
        [ 2.0997e+00, -1.7269e+00],
        [ 1.1791e+00, -9.2667e-01],
        [ 3.3734e+00, -1.6252e+00],
        [ 1.6087e+00, -7.5291e-01],
        [ 2.3930e+00, -1.8769e+00],
        [ 3.5039e+00,  4.0164e-01],
        [ 1.9115e+00, -2.0874e+00],
        [ 1.3064e+00, -8.1765e-01],
        [ 1.3345e+00,  1.6946e-02],
        [ 1.9042e+00, -3.2867e-01],
        [ 2.1736e+00, -6.9352e-01],
        [ 1.0597e+00,  1.2926e+00],
        [ 1.9932e+00, -8.7115e-01],
        [ 1.9223e+00,  6.2083e-01],
        [ 2.4244e+00, -1.4770e+00],
        [ 2.7457e+00,  4.0549e-01],
        [ 1.6386e+00, -3.3836e-01],
        [ 4.0021e+00, -4.1119e-01],
        [ 1.3449e+00, -1.5441e-01],
        [ 3.0869e+00, -1.4807e+00],
        [ 1.6522e+00,  1.5692e+00],
        [-6.2334e-01, -8.6582e-01],
        [ 1.7992e+00,  5.0860e-01],
        [ 2.3393e+00,  1.1549e+00],
        [ 3.7811e+00, -1.1584e+00],
        [ 1.0229e+00,  9.7765e-01],
        [ 4.2852e+00,  3.3821e-01],
        [ 3.3171e+00,  2.2558e+00],
        [ 4.1695e+00, -4.1586e-01],
        [ 3.4841e+00,  6.5448e-01],
        [ 3.5988e+00, -1.5612e+00],
        [ 2.0581e+00, -1.0265e+00],
        [ 3.7902e+00, -1.8776e+00],
        [ 2.3121e+00, -3.9663e-01],
        [ 4.6286e+00, -1.6658e-01],
        [ 2.7564e+00, -2.1713e-02],
        [ 2.1534e+00,  7.2090e-01],
        [ 2.2612e+00,  4.4246e-01],
        [ 2.4599e+00,  5.6830e-01],
        [ 2.7693e+00, -2.2482e-01],
        [ 3.0181e+00, -4.4292e-02],
        [ 8.9954e-01, -6.0140e-01],
        [ 1.9559e+00,  2.2035e-01],
        [ 2.5460e+00,  6.0719e-01],
        [ 2.0070e+00, -1.4074e+00],
        [ 3.3768e+00,  1.7265e+00],
        [ 3.4118e+00,  3.5674e-01],
        [ 2.8925e+00,  1.5609e+00],
        [ 2.0403e+00, -1.1309e+00],
        [ 2.1326e+00, -2.9411e+00],
        [ 3.6234e+00, -9.9923e-02],
        [ 3.4571e+00,  6.3712e-02],
        [ 2.6432e+00, -2.0022e+00],
        [ 1.9473e+00,  2.2736e-01],
        [ 2.6772e+00,  4.2183e-01],
        [ 2.2012e+00,  1.2773e+00],
        [ 1.1216e+00, -1.3644e+00],
        [ 2.5129e+00, -2.9592e-01],
        [ 1.4595e+00,  3.2162e-02],
        [ 1.8861e+00, -8.5870e-02],
        [ 3.1445e+00, -8.1383e-03],
        [ 2.1758e+00,  1.3738e+00],
        [ 2.7761e+00, -1.1563e+00],
        [ 2.7649e+00,  4.1992e-01],
        [ 2.4544e+00, -5.5215e-01],
        [ 1.9341e+00, -3.6639e-01],
        [ 2.9533e+00, -5.2839e-01],
        [ 1.9706e+00,  9.1857e-01],
        [ 1.6994e+00, -7.5203e-01],
        [ 2.3209e+00, -1.2259e+00],
        [ 3.5582e+00, -1.0217e-01],
        [ 8.1951e-01, -1.0190e-01],
        [ 2.0198e+00, -1.0676e-01],
        [ 3.9817e+00,  1.5458e+00],
        [ 2.5361e+00, -5.3271e-01],
        [ 1.4512e+00,  2.2548e-01],
        [ 2.0500e-01, -6.7410e-01],
        [ 1.2384e+00, -1.1150e+00],
        [ 3.3144e+00, -1.7389e+00],
        [ 2.7783e+00,  9.2863e-01],
        [ 4.3958e+00, -1.1588e+00],
        [ 1.6882e+00, -6.9570e-01],
        [ 2.0556e+00,  1.1055e+00],
        [ 3.8716e+00,  2.9754e-01],
        [ 2.2091e-02, -3.9938e-01],
        [ 3.9254e+00, -2.0885e+00],
        [ 9.2647e-01,  4.7011e-01],
        [ 3.4499e+00,  1.4718e+00],
        [ 2.4338e+00, -3.9640e-01],
        [ 1.3856e+00,  1.6626e+00],
        [ 1.2114e+00, -1.5580e+00],
        [ 7.8953e-01,  1.8192e-01],
        [ 1.9003e+00,  8.9485e-01],
        [ 1.5904e+00,  1.1042e-01],
        [ 3.4718e+00,  2.0597e+00],
        [ 2.4339e+00, -1.2198e-01],
        [ 2.1050e+00,  9.0814e-01],
        [ 1.7794e+00,  1.5867e+00],
        [ 1.0900e+00,  1.2553e-01],
        [ 1.8492e+00,  4.2855e-01],
        [ 3.9403e+00, -1.1860e+00],
        [ 3.0693e+00,  5.2146e-01],
        [ 2.2654e+00,  5.4045e-01],
        [ 3.2685e+00, -1.7681e+00],
        [ 4.5641e+00, -1.5326e+00],
        [ 3.0374e+00, -1.2416e+00],
        [ 1.0002e+00, -5.9463e-01],
        [ 3.1746e+00, -3.1059e-01],
        [ 1.1195e+00,  8.4642e-01],
        [ 2.4911e+00,  8.6121e-01],
        [ 1.8901e+00, -9.6535e-01],
        [ 2.1381e+00, -4.2530e-01],
        [ 1.0364e+00,  2.2946e-01],
        [ 1.5708e+00,  4.4776e-01],
        [ 3.6426e+00,  2.1358e+00],
        [ 4.2361e+00, -8.1435e-01],
        [ 4.5228e+00,  1.5397e+00],
        [ 1.2055e+00, -1.3141e+00],
        [ 1.1148e+00, -9.4993e-02],
        [ 2.9895e+00,  7.1128e-02],
        [ 3.2991e+00, -1.0161e+00],
        [ 3.6693e+00,  1.5628e+00],
        [ 2.6515e+00, -1.6150e-01],
        [ 2.2667e+00, -2.0898e+00],
        [ 2.0042e+00, -1.3775e-01],
        [ 2.7214e+00, -2.2640e-01],
        [ 1.7709e+00, -1.4838e+00],
        [ 2.2047e+00, -9.0473e-01],
        [ 3.4493e+00, -1.8295e-01],
        [ 2.5290e+00,  3.9547e-02],
        [ 1.8019e+00,  2.1723e-02],
        [ 1.2831e+00, -2.7741e-02],
        [ 2.9025e+00, -4.0863e-01],
        [ 1.5585e+00, -4.0986e-01],
        [ 4.7798e+00, -5.7036e-01],
        [ 8.8649e-01, -1.0285e+00],
        [ 4.4586e-01, -1.8721e+00],
        [ 1.7398e+00, -1.8506e-01],
        [ 1.2902e+00,  9.1257e-01],
        [ 3.0065e+00,  1.0786e-01],
        [ 2.3085e+00,  1.4918e+00],
        [ 2.0072e+00,  4.8902e-01],
        [ 2.9234e+00,  7.5458e-03],
        [ 2.7572e+00, -3.3705e-01],
        [ 1.8369e+00, -1.0935e-01],
        [ 3.7976e+00,  7.1052e-01],
        [ 2.8979e+00, -8.3950e-01],
        [ 2.7680e+00,  6.2929e-02],
        [ 1.0285e+00,  1.1065e+00],
        [ 7.6610e-01, -1.4545e+00],
        [ 1.8851e+00,  1.8519e+00],
        [ 3.8000e+00,  1.3887e-01],
        [ 1.9458e+00, -9.4978e-01],
        [ 1.4139e+00,  1.6051e-01],
        [ 2.2958e+00,  4.7624e-01],
        [ 1.9833e+00, -1.0599e+00],
        [ 1.6407e+00, -2.1449e-01],
        [ 3.2318e+00,  6.1744e-01],
        [ 4.5529e+00,  1.6176e+00],
        [ 2.3411e+00, -2.2642e+00],
        [ 1.4638e+00,  4.5912e-01],
        [ 1.7310e+00,  1.2007e+00]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.3988e-01, 2.7526e-01, 2.7811e-01,  ..., 9.9941e-01, 9.9999e-01,
         1.0000e+00],
        [4.2633e-03, 5.1806e-03, 5.2177e-03,  ..., 9.9267e-01, 1.0000e+00,
         1.0000e+00],
        [6.2214e-07, 6.2291e-07, 2.6938e-02,  ..., 9.0391e-01, 9.8770e-01,
         1.0000e+00],
        ...,
        [2.0393e-08, 6.7118e-03, 1.0529e-02,  ..., 9.7701e-01, 9.9330e-01,
         1.0000e+00],
        [9.1115e-03, 9.1742e-03, 3.6169e-01,  ..., 9.9910e-01, 9.9940e-01,
         1.0000e+00],
        [3.2407e-06, 3.3290e-04, 1.3447e-03,  ..., 8.4644e-01, 9.9889e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.1215],
        [0.3513],
        [0.2325],
        [0.9850],
        [0.7181],
        [0.5638],
        [0.3893],
        [0.5010],
        [0.8238],
        [0.0295],
        [0.3031],
        [0.0115],
        [0.0853],
        [0.4381],
        [0.0968],
        [0.4308],
        [0.4845],
        [0.3498],
        [0.1390],
        [0.8666],
        [0.3555],
        [0.9787],
        [0.9544],
        [0.4466],
        [0.9181],
        [0.4044],
        [0.5098],
        [0.8866],
        [0.4480],
        [0.9123],
        [0.9020],
        [0.3869],
        [0.6372],
        [0.7997],
        [0.3245],
        [0.8314],
        [0.9680],
        [0.8849],
        [0.7149],
        [0.2779],
        [0.7106],
        [0.8229],
        [0.7343],
        [0.6162],
        [0.6238],
        [0.5672],
        [0.0213],
        [0.4712],
        [0.5766],
        [0.4736],
        [0.1485],
        [0.8255],
        [0.5429],
        [0.3391],
        [0.1160],
        [0.6804],
        [0.1566],
        [0.3595],
        [0.6157],
        [0.0065],
        [0.6089],
        [0.2674],
        [0.6867],
        [0.7924],
        [0.0649],
        [0.1737],
        [0.2584],
        [0.6698],
        [0.5580],
        [0.2269],
        [0.9173],
        [0.5335],
        [0.8494],
        [0.8813],
        [0.4151],
        [0.4175],
        [0.9020],
        [0.1900],
        [0.5443],
        [0.5589],
        [0.3049],
        [0.3520],
        [0.4473],
        [0.8117],
        [0.9020],
        [0.5424],
        [0.4146],
        [0.2406],
        [0.8161],
        [0.1445],
        [0.0735],
        [0.7580],
        [0.2979],
        [0.0160],
        [0.6612],
        [0.4639],
        [0.7953],
        [0.4036],
        [0.3688],
        [0.3923],
        [0.3993],
        [0.2230],
        [0.5124],
        [0.1953],
        [0.3839],
        [0.7062],
        [0.3357],
        [0.1017],
        [0.6258],
        [0.5928],
        [0.8846],
        [0.7619],
        [0.6089],
        [0.5267],
        [0.7847],
        [0.2160],
        [0.0159],
        [0.1041],
        [0.2581],
        [0.0076],
        [0.7168],
        [0.8952],
        [0.5464],
        [0.1726],
        [0.1732],
        [0.4546],
        [0.0841],
        [0.0866],
        [0.3561],
        [0.2209],
        [0.8622],
        [0.8087],
        [0.9282],
        [0.8595],
        [0.2355],
        [0.8259],
        [0.0235],
        [0.5695],
        [0.7125],
        [0.6446],
        [0.4395],
        [0.5835],
        [0.6949],
        [0.0176],
        [0.8529],
        [0.8681],
        [0.5044],
        [0.6685],
        [0.8515],
        [0.8871],
        [0.5138],
        [0.7466],
        [0.6670],
        [0.4888],
        [0.3705],
        [0.2474],
        [0.9502],
        [0.3385],
        [0.9740],
        [0.3541],
        [0.6611],
        [0.3191],
        [0.7686],
        [0.7824],
        [0.6674],
        [0.4602],
        [0.3422],
        [0.7948],
        [0.8886],
        [0.2475],
        [0.1280],
        [0.6954],
        [0.3411],
        [0.1727],
        [0.0927],
        [0.2484],
        [0.1060],
        [0.8213],
        [0.8192],
        [0.9266],
        [0.0400],
        [0.3383],
        [0.1212],
        [0.7974],
        [0.5413],
        [0.1244],
        [0.0937],
        [0.6453],
        [0.6618],
        [0.1376],
        [0.6468],
        [0.9754],
        [0.9280],
        [0.5176],
        [0.4030],
        [0.4740],
        [0.0887],
        [0.4321],
        [0.3347],
        [0.9737],
        [0.3313],
        [0.3856],
        [0.0885],
        [0.7460],
        [0.0311],
        [0.6357],
        [0.5677],
        [0.0547],
        [0.9715],
        [0.3011],
        [0.5984],
        [0.6718],
        [0.7718],
        [0.6009],
        [0.1752],
        [0.7774],
        [0.2190],
        [0.6329],
        [0.6928],
        [0.7029],
        [0.1350],
        [0.4117],
        [0.0938],
        [0.6204],
        [0.4792],
        [0.9669],
        [0.2451],
        [0.6399],
        [0.6881],
        [0.6905],
        [0.1867],
        [0.9524],
        [0.4288],
        [0.4651],
        [0.3760],
        [0.3267],
        [0.7880],
        [0.4924],
        [0.3517],
        [0.0189],
        [0.6783],
        [0.7662],
        [0.9741],
        [0.7077],
        [0.6514],
        [0.0572],
        [0.3690],
        [0.0198],
        [0.2083],
        [0.6459],
        [0.9061],
        [0.0850],
        [0.9382],
        [0.9571],
        [0.0128],
        [0.2031],
        [0.4888],
        [0.7420],
        [0.1525],
        [0.6997],
        [0.5073],
        [0.0043],
        [0.0576],
        [0.7742],
        [0.5410],
        [0.5389],
        [0.9669],
        [0.9972],
        [0.0955],
        [0.4313],
        [0.4467],
        [0.3025],
        [0.6086],
        [0.5561],
        [0.5783],
        [0.9802],
        [0.2652],
        [0.0106],
        [0.0903],
        [0.7621],
        [0.7795],
        [0.3401],
        [0.6732],
        [0.0237],
        [0.0318],
        [0.7682],
        [0.4253],
        [0.7791],
        [0.9553],
        [0.5355],
        [0.8165],
        [0.1659],
        [0.2367],
        [0.8399],
        [0.4165],
        [0.0454],
        [0.1743],
        [0.2630],
        [0.6311],
        [0.0566],
        [0.1107],
        [0.0690],
        [0.3906],
        [0.4268],
        [0.1269],
        [0.4800],
        [0.1945],
        [0.5649],
        [0.4162],
        [0.2674],
        [0.0839],
        [0.2066]]) torch.Size([312, 1])
mask tensor([[ True, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False,  True,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 2.4284,  0.4415],
        [ 1.9357,  0.0957],
        [ 0.3693,  1.2637],
        ...,
        [-2.0347,  1.2922],
        [ 2.0894, -0.3232],
        [ 0.3961,  2.0878]]) torch.Size([9984, 2])
samples tensor([[ 2.4284e+00,  4.4147e-01],
        [ 1.8005e+00, -9.4111e-01],
        [ 2.7945e+00,  9.9437e-02],
        [ 2.4656e+00,  2.5182e+00],
        [ 3.8378e+00, -9.2235e-01],
        [ 1.4698e+00, -2.4068e+00],
        [ 2.8156e+00, -9.6662e-01],
        [ 2.7668e+00,  9.4257e-01],
        [ 2.0141e+00,  1.3472e+00],
        [ 2.7535e-01, -3.7750e-02],
        [ 3.7059e+00, -2.5330e+00],
        [-4.4246e-01,  9.7576e-01],
        [ 1.7362e+00,  8.7901e-01],
        [ 2.1959e+00,  4.4159e-01],
        [ 1.7982e+00,  9.1974e-01],
        [ 2.5463e+00,  1.7560e+00],
        [-2.6137e-02,  2.0490e-01],
        [ 1.7490e+00, -1.7120e-01],
        [ 3.5091e+00,  1.0751e+00],
        [ 2.6952e+00,  2.1500e+00],
        [ 2.0329e+00,  4.6007e-01],
        [ 1.9672e+00,  1.3196e+00],
        [ 1.2455e+00,  1.0554e+00],
        [ 1.6673e+00, -1.5843e+00],
        [ 3.6109e+00, -1.4225e-01],
        [ 4.4998e+00, -2.1217e+00],
        [ 1.9206e+00,  1.1050e+00],
        [ 3.4584e+00, -1.5364e+00],
        [ 2.3978e+00, -7.1998e-02],
        [ 2.2475e+00, -3.7546e-01],
        [ 2.4165e+00, -2.4229e-01],
        [ 2.9350e+00, -4.9382e-01],
        [ 1.1098e+00, -2.5399e-01],
        [ 1.8408e+00,  1.7554e+00],
        [ 3.6985e+00, -3.2490e-04],
        [ 3.9133e+00,  8.6593e-01],
        [ 5.8949e-01, -3.2574e-01],
        [ 7.4049e-01,  1.7719e+00],
        [ 3.2172e+00, -1.6874e+00],
        [ 2.9376e+00, -9.2428e-01],
        [ 8.5926e-01, -4.8115e-01],
        [ 1.2282e+00,  2.7879e-01],
        [ 3.7640e+00,  4.6727e-01],
        [ 3.8149e-01,  1.4848e+00],
        [ 3.2692e+00,  1.8806e+00],
        [ 2.4491e+00, -2.0240e+00],
        [ 2.1300e+00,  4.3893e-01],
        [ 1.8535e+00, -2.3643e-01],
        [ 1.8520e-01, -8.1088e-01],
        [ 2.1003e+00, -9.3956e-01],
        [ 7.6290e-01, -3.4114e-01],
        [ 2.5586e+00,  1.6519e-02],
        [ 2.5263e+00,  7.0955e-01],
        [ 2.6076e+00, -8.7950e-02],
        [ 2.6408e+00,  8.6204e-01],
        [ 3.5984e+00,  9.0649e-01],
        [ 2.8218e+00,  7.0561e-01],
        [ 2.4972e+00, -1.3557e+00],
        [ 1.9680e+00, -8.2427e-01],
        [ 5.0028e-01, -3.9081e-01],
        [ 3.5005e+00,  3.8157e-01],
        [ 1.6375e+00, -4.5231e-01],
        [ 3.2594e+00, -1.7154e-01],
        [ 3.4257e+00, -9.3122e-01],
        [ 2.9115e+00,  9.4802e-01],
        [ 2.7722e+00,  2.5718e-02],
        [ 2.5168e-01, -9.9863e-01],
        [ 3.9754e+00, -7.5197e-01],
        [ 4.2814e+00,  6.9104e-01],
        [ 9.5264e-01, -1.5521e+00],
        [ 3.4454e+00, -5.7516e-01],
        [ 4.0263e+00, -3.3284e-01],
        [ 1.5805e+00,  1.1308e+00],
        [ 3.9531e+00, -9.5538e-01],
        [ 3.7211e+00,  8.3460e-02],
        [ 1.7539e+00,  1.7082e+00],
        [ 2.1842e+00, -6.0604e-01],
        [ 2.0899e+00,  3.1127e-01],
        [ 2.8415e+00, -1.5863e+00],
        [ 9.6315e-01, -1.3252e+00],
        [ 1.0117e+00,  1.3826e-01],
        [ 2.1995e+00,  8.9366e-01],
        [ 2.2549e+00, -3.3163e-02],
        [ 3.2544e+00, -5.5605e-01],
        [ 2.9964e+00, -1.0047e+00],
        [ 2.9040e+00, -1.2580e-01],
        [ 1.9629e+00,  3.9698e-01],
        [ 1.4588e+00,  3.1636e-01],
        [ 2.3410e+00,  3.6282e-01],
        [ 1.4427e+00,  6.3626e-01],
        [ 1.5995e+00,  1.4260e-01],
        [ 7.3521e-01, -2.0211e-01],
        [ 3.0001e+00, -8.7900e-01],
        [ 3.3976e+00,  1.4854e+00],
        [ 3.1263e+00, -1.4551e+00],
        [ 3.3018e+00,  1.2832e+00],
        [ 1.1798e+00, -1.9058e-01],
        [ 3.0660e+00,  3.7229e-01],
        [ 3.0009e+00,  1.5784e+00],
        [ 3.5698e+00,  5.9156e-01],
        [ 1.5028e+00,  3.6351e-01],
        [ 1.6803e+00, -1.5688e+00],
        [ 2.7020e-01, -5.6287e-01],
        [ 7.9767e-01, -7.5497e-01],
        [ 4.4625e+00, -7.9427e-01],
        [ 2.0313e+00, -5.1022e-01],
        [ 1.1736e+00, -7.9999e-01],
        [ 1.7817e+00,  5.0923e-01],
        [ 1.6121e+00,  3.6167e-02],
        [ 6.1422e-01, -6.1770e-01],
        [ 3.8603e+00, -1.2189e+00],
        [ 1.5867e+00,  6.6039e-02],
        [ 1.7426e+00, -3.3209e-01],
        [ 2.5014e+00,  1.1966e+00],
        [ 2.4536e+00, -5.4327e-01],
        [ 2.5317e+00, -2.0314e+00],
        [ 2.6207e+00,  1.4110e+00],
        [ 3.4129e+00, -1.3149e-01],
        [ 3.0927e+00,  4.6125e-01],
        [ 3.6803e+00,  7.3403e-01],
        [ 2.0034e+00,  7.1812e-01],
        [ 3.1299e+00, -1.4304e+00],
        [ 1.5377e+00,  5.0106e-02],
        [ 2.6009e+00,  3.8439e-01],
        [ 2.4326e+00, -7.8388e-01],
        [ 2.4410e+00, -3.4818e-01],
        [ 1.8059e+00,  1.3973e+00],
        [ 1.6118e+00, -7.7441e-02],
        [ 2.5179e+00, -1.8970e-01],
        [ 3.7863e+00, -7.6497e-01],
        [ 1.5478e+00,  7.0153e-01],
        [ 2.9152e+00,  5.7322e-01],
        [ 3.6691e+00,  2.3109e+00],
        [ 4.1605e+00,  6.8639e-01],
        [ 3.0399e+00,  2.2812e-01],
        [ 9.3853e-01, -1.3746e+00],
        [ 7.6083e-01, -4.5945e-02],
        [ 2.6240e+00, -1.3537e+00],
        [ 3.6478e+00, -1.8972e-01],
        [ 1.9346e+00,  1.7022e-01],
        [ 2.8800e+00, -8.3831e-01],
        [ 4.0258e+00,  5.5603e-02],
        [ 1.3973e+00, -8.1436e-02],
        [ 2.1904e+00,  1.4114e+00],
        [ 2.3240e+00,  8.4348e-01],
        [ 6.8724e-01,  8.7228e-01],
        [ 1.6461e+00,  1.3432e+00],
        [ 2.6157e+00, -6.9654e-01],
        [ 2.4506e+00, -1.6415e+00],
        [ 1.3944e+00, -6.4990e-01],
        [ 6.6707e-01,  5.3819e-02],
        [ 3.0661e+00,  3.3817e-01],
        [ 1.0621e+00,  1.0098e+00],
        [ 3.8841e+00,  1.4277e+00],
        [ 2.0736e+00, -1.2312e+00],
        [ 3.7010e+00, -1.0145e+00],
        [ 7.2293e-01,  4.7879e-01],
        [ 2.1530e+00,  1.2069e-01],
        [ 1.7356e+00,  8.0489e-01],
        [ 3.6908e+00, -1.5732e+00],
        [ 7.2508e-01, -2.9306e-01],
        [ 2.0420e-01,  7.6190e-01],
        [ 3.0251e+00, -1.5670e+00],
        [ 2.2118e+00, -2.7635e+00],
        [ 8.7628e-01,  1.4884e+00],
        [ 8.6703e-01, -2.6454e-01],
        [ 1.8469e+00, -2.2767e+00],
        [ 2.5646e+00,  1.8054e-01],
        [ 2.7169e+00, -2.1695e+00],
        [ 1.5504e+00, -6.7182e-01],
        [ 8.3257e-01, -5.5502e-01],
        [ 4.0784e+00,  1.2350e+00],
        [ 4.4419e+00,  1.9840e-01],
        [ 2.8835e+00, -8.4324e-01],
        [ 2.0748e+00,  3.5660e-02],
        [ 3.8820e+00,  6.6648e-01],
        [ 1.3753e+00,  1.2540e+00],
        [ 2.6476e+00,  9.6211e-01],
        [ 4.4036e+00, -9.2292e-01],
        [ 3.1931e+00,  8.1548e-01],
        [ 2.7322e+00,  5.5641e-01],
        [ 4.0327e+00,  1.4243e+00],
        [ 3.6988e+00,  3.2446e-01],
        [ 3.2756e+00, -1.0024e+00],
        [ 1.1407e+00, -1.9262e+00],
        [ 3.3187e+00, -8.4543e-02],
        [ 2.5199e+00,  1.2694e+00],
        [ 2.0095e+00, -5.7753e-01],
        [ 2.6004e+00, -3.6238e-01],
        [ 2.4811e+00, -1.2367e+00],
        [ 2.7990e+00, -9.4177e-01],
        [ 3.1120e+00, -6.0180e-01],
        [ 2.1768e+00,  1.2769e+00],
        [ 1.5683e+00, -3.6013e-02],
        [ 2.6912e+00,  5.4506e-01],
        [ 3.2691e+00, -1.9637e+00],
        [ 2.5551e+00, -1.2974e+00],
        [ 3.0402e+00,  1.0464e+00],
        [ 2.9389e+00, -7.9072e-01],
        [ 1.6771e+00,  4.2810e-01],
        [ 3.7523e+00, -1.9073e+00],
        [ 2.5323e+00, -1.9907e+00],
        [ 2.0541e+00, -3.4918e-01],
        [ 2.8858e+00, -1.0039e+00],
        [ 5.7118e-01, -3.2785e-01],
        [ 3.0724e+00, -8.4690e-01],
        [ 2.0656e+00, -1.5098e+00],
        [ 1.1237e+00,  1.2477e-01],
        [ 2.2506e+00,  4.7226e-01],
        [ 1.3489e+00, -1.0709e+00],
        [ 2.3938e+00,  5.4302e-01],
        [ 3.0981e+00, -1.6982e+00],
        [ 1.4196e+00,  8.8132e-01],
        [ 4.1498e+00, -2.5181e-01],
        [ 2.3911e+00, -2.4789e-01],
        [ 2.6216e+00, -3.4779e-01],
        [ 3.6905e+00, -5.1463e-01],
        [ 1.3660e+00, -6.7700e-01],
        [ 1.5319e+00, -1.2509e+00],
        [ 1.6379e+00,  1.1651e+00],
        [ 3.2269e+00,  6.2750e-01],
        [ 3.1905e+00, -1.6881e+00],
        [ 3.8091e+00, -7.9297e-01],
        [ 1.4358e+00, -6.3175e-01],
        [ 3.1174e+00, -9.0077e-01],
        [ 1.8761e+00,  4.4373e-01],
        [ 3.2689e+00,  1.0833e+00],
        [ 1.7721e+00, -7.2570e-02],
        [ 3.1599e+00, -5.4269e-01],
        [ 2.5623e+00,  2.8168e-01],
        [ 2.9538e+00, -1.0296e+00],
        [ 1.9316e+00,  8.7313e-01],
        [ 2.2526e+00, -3.1955e-01],
        [ 2.7226e+00, -1.9761e+00],
        [ 2.7100e+00, -3.4409e-01],
        [ 2.2218e+00, -2.1120e-01],
        [ 3.8547e+00, -3.4042e+00],
        [ 4.1148e+00, -1.0449e+00],
        [ 1.2561e+00,  2.2030e-01],
        [ 1.8483e+00,  1.0173e+00],
        [ 2.8667e+00, -1.3120e+00],
        [ 1.9048e+00, -4.0383e-01],
        [ 1.7834e+00,  4.0059e-01],
        [ 2.0997e+00,  5.6811e-01],
        [ 1.9978e+00, -1.2060e+00],
        [ 1.7960e+00,  3.6339e-01],
        [ 2.8216e+00, -3.8730e-01],
        [ 1.8770e+00,  1.0654e+00],
        [ 2.4235e+00, -1.2395e+00],
        [ 3.5628e+00,  6.2980e-01],
        [ 2.3397e+00, -1.2716e-01],
        [ 2.6664e-01, -1.6922e+00],
        [ 1.3634e+00, -4.1072e-01],
        [ 2.3503e+00,  9.1747e-01],
        [ 2.9622e+00,  1.9962e+00],
        [ 2.5811e+00,  1.3259e+00],
        [ 4.2905e+00, -9.9507e-02],
        [ 1.7792e+00, -7.5298e-01],
        [ 2.3880e+00,  1.2279e+00],
        [ 2.5648e+00, -1.2082e+00],
        [ 2.7957e+00, -3.9447e-01],
        [ 1.1227e+00,  1.8064e+00],
        [ 2.8389e+00,  1.1406e+00],
        [ 8.9440e-01,  3.7964e-01],
        [ 2.6028e-01, -1.5960e+00],
        [ 2.4487e+00, -3.4535e-01],
        [ 1.7938e+00, -4.5060e-01],
        [ 1.5724e+00,  1.7055e+00],
        [ 2.4870e+00, -4.2131e-02],
        [ 3.1036e+00, -5.7308e-03],
        [ 3.8601e+00, -4.9236e-03],
        [ 2.5286e+00, -6.6110e-01],
        [ 3.4520e+00, -8.9595e-01],
        [ 3.4655e+00, -1.7037e+00],
        [ 9.3596e-01,  1.9069e-01],
        [-4.3686e-02, -4.1413e-01],
        [ 1.9856e+00,  4.5942e-01],
        [ 2.9055e+00,  1.6943e+00],
        [ 4.1629e+00, -1.9704e+00],
        [ 2.4049e+00, -1.9538e+00],
        [ 4.9882e-01,  4.1684e-01],
        [ 4.8058e+00, -4.5641e-01],
        [ 1.8427e+00, -2.5114e-01],
        [ 1.1357e+00,  2.3032e-01],
        [ 2.1599e+00,  1.1228e+00],
        [ 2.9721e+00, -3.0270e-01],
        [ 2.6849e+00, -7.6494e-01],
        [ 2.1944e-01, -1.2697e+00],
        [ 1.6487e+00, -4.5607e-02],
        [ 3.3403e+00, -1.0210e+00],
        [ 1.4143e+00, -7.0883e-01],
        [ 7.4679e-01, -7.1061e-01],
        [ 2.7401e+00, -5.3879e-01],
        [ 2.7180e+00, -9.4648e-01],
        [ 3.2019e+00, -1.1327e+00],
        [ 2.7569e+00, -8.1751e-01],
        [ 3.2624e+00,  9.4096e-01],
        [ 2.8455e+00,  4.4745e-01],
        [ 3.0119e+00, -4.7753e-01],
        [ 1.5944e+00, -8.2489e-02],
        [ 1.2773e+00, -4.8832e-01],
        [ 2.4708e+00,  2.2710e-01],
        [ 1.1369e+00,  3.9788e-01],
        [ 1.0087e+00,  2.0698e-01],
        [ 2.1021e+00, -1.3122e-01],
        [ 1.4593e+00, -2.4659e+00],
        [ 2.4191e+00,  1.0348e+00],
        [ 3.8084e+00,  6.0623e-01],
        [ 1.3135e+00, -7.5097e-01],
        [ 2.6244e+00, -1.9823e-01],
        [ 3.2436e+00, -1.2575e+00],
        [ 2.6871e+00, -1.0244e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[2.8220e-04, 3.0330e-04, 3.1546e-04,  ..., 8.6007e-01, 8.6430e-01,
         1.0000e+00],
        [2.9395e-03, 1.0207e-02, 1.0304e-02,  ..., 9.9096e-01, 9.9286e-01,
         1.0000e+00],
        [3.2607e-04, 3.2796e-04, 2.6677e-02,  ..., 8.3987e-01, 8.3987e-01,
         1.0000e+00],
        ...,
        [3.6706e-10, 1.1878e-05, 1.7809e-01,  ..., 9.7405e-01, 9.8946e-01,
         1.0000e+00],
        [2.7234e-03, 3.1426e-01, 3.1426e-01,  ..., 9.9999e-01, 9.9999e-01,
         1.0000e+00],
        [1.3059e-04, 4.8825e-03, 9.4988e-03,  ..., 9.8985e-01, 9.9969e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[3.9658e-01],
        [1.4348e-01],
        [9.8412e-01],
        [2.8307e-01],
        [8.2284e-01],
        [9.4636e-01],
        [1.2660e-01],
        [7.8941e-01],
        [6.4850e-01],
        [1.9245e-01],
        [4.3459e-01],
        [4.4697e-01],
        [6.9247e-01],
        [3.5812e-01],
        [7.2403e-01],
        [1.1244e-01],
        [3.9952e-01],
        [4.7314e-01],
        [3.3337e-02],
        [8.4402e-01],
        [9.0742e-01],
        [9.1490e-01],
        [1.8429e-01],
        [6.0554e-02],
        [4.1434e-01],
        [6.4015e-01],
        [1.7982e-01],
        [9.1889e-01],
        [7.7073e-01],
        [4.4345e-01],
        [3.0685e-01],
        [2.5095e-01],
        [2.9747e-01],
        [1.3677e-01],
        [2.3502e-01],
        [1.5475e-01],
        [9.3984e-01],
        [6.6299e-01],
        [5.4710e-01],
        [6.3947e-01],
        [3.3923e-01],
        [2.0400e-01],
        [5.0081e-01],
        [6.6418e-01],
        [5.2340e-01],
        [7.9784e-01],
        [9.8962e-01],
        [3.2587e-01],
        [9.2955e-01],
        [9.1911e-01],
        [4.4531e-01],
        [3.0090e-01],
        [8.0559e-01],
        [6.6545e-01],
        [4.1821e-01],
        [7.2450e-02],
        [5.7479e-01],
        [1.1314e-01],
        [6.5409e-01],
        [6.7316e-01],
        [5.8368e-01],
        [6.5646e-01],
        [4.1129e-01],
        [5.2842e-01],
        [5.8851e-01],
        [8.3066e-01],
        [8.4846e-01],
        [8.0279e-01],
        [8.8795e-01],
        [7.8261e-01],
        [5.7585e-02],
        [5.7481e-01],
        [1.5990e-01],
        [7.3849e-01],
        [3.1629e-01],
        [1.5427e-01],
        [4.8989e-01],
        [8.8989e-01],
        [4.9441e-01],
        [2.8968e-01],
        [6.2564e-01],
        [5.0186e-01],
        [3.3045e-01],
        [4.0369e-01],
        [8.9071e-01],
        [9.2349e-01],
        [6.2443e-01],
        [3.7611e-01],
        [2.5485e-01],
        [1.0685e-01],
        [8.4584e-01],
        [8.3128e-01],
        [6.9564e-01],
        [1.7080e-01],
        [7.1333e-01],
        [7.5933e-01],
        [6.6714e-01],
        [7.7735e-01],
        [9.0777e-02],
        [3.1618e-01],
        [9.4356e-01],
        [3.9641e-01],
        [3.7560e-01],
        [1.4411e-01],
        [6.1342e-01],
        [2.1467e-01],
        [6.3620e-01],
        [1.9957e-01],
        [3.1187e-01],
        [6.3651e-01],
        [4.7085e-01],
        [9.4248e-01],
        [6.2696e-02],
        [1.6058e-01],
        [5.5555e-01],
        [9.2466e-01],
        [9.9214e-01],
        [4.4012e-01],
        [4.9625e-01],
        [7.2302e-01],
        [1.3604e-01],
        [7.9169e-01],
        [9.9345e-01],
        [5.8564e-01],
        [2.2399e-01],
        [3.0743e-01],
        [3.5241e-02],
        [6.4386e-01],
        [9.9724e-01],
        [5.7219e-01],
        [2.1815e-01],
        [4.0244e-01],
        [1.0825e-01],
        [9.2274e-01],
        [7.3998e-01],
        [1.4509e-01],
        [7.2995e-01],
        [4.7498e-02],
        [8.2993e-01],
        [3.5450e-01],
        [2.1467e-01],
        [3.1511e-01],
        [6.4488e-01],
        [1.3220e-01],
        [1.8045e-01],
        [6.5802e-01],
        [8.8241e-01],
        [2.6304e-01],
        [9.5333e-02],
        [4.3337e-01],
        [2.8463e-01],
        [3.4746e-01],
        [2.1651e-02],
        [4.0330e-01],
        [6.1874e-01],
        [9.1542e-01],
        [8.1889e-01],
        [7.9288e-01],
        [6.2604e-01],
        [4.6038e-01],
        [6.8036e-01],
        [4.2120e-01],
        [3.9243e-01],
        [6.8164e-01],
        [5.1529e-02],
        [6.6533e-01],
        [8.6060e-01],
        [8.4753e-01],
        [4.6876e-01],
        [3.6008e-01],
        [6.6343e-01],
        [5.7860e-01],
        [1.1958e-01],
        [1.4587e-01],
        [2.3011e-01],
        [4.2771e-02],
        [6.8061e-02],
        [5.9210e-01],
        [6.5660e-01],
        [6.4789e-01],
        [8.8819e-01],
        [2.6945e-01],
        [5.4836e-01],
        [1.1513e-01],
        [5.3365e-01],
        [4.4625e-01],
        [8.0820e-01],
        [6.5001e-01],
        [7.9075e-02],
        [9.5467e-01],
        [6.4179e-01],
        [5.3883e-01],
        [6.7269e-01],
        [9.7091e-01],
        [7.6701e-01],
        [2.5433e-02],
        [6.2224e-01],
        [9.6329e-01],
        [7.4151e-01],
        [9.0289e-01],
        [8.4353e-01],
        [7.5043e-01],
        [8.0511e-01],
        [2.6253e-01],
        [8.8034e-01],
        [5.4317e-01],
        [5.3387e-01],
        [1.9579e-01],
        [4.3638e-01],
        [1.2477e-01],
        [2.8889e-01],
        [8.7326e-01],
        [4.5852e-01],
        [8.2340e-01],
        [2.3453e-01],
        [1.2124e-01],
        [9.0511e-01],
        [1.8483e-01],
        [4.9513e-01],
        [2.1746e-01],
        [5.8947e-01],
        [3.0441e-01],
        [2.1032e-01],
        [1.2935e-01],
        [5.3200e-01],
        [9.9085e-01],
        [5.6419e-01],
        [2.8953e-01],
        [7.2960e-01],
        [3.0517e-01],
        [4.3783e-01],
        [9.1864e-01],
        [4.1760e-01],
        [6.7870e-02],
        [1.0123e-02],
        [1.1247e-04],
        [2.1638e-02],
        [9.4735e-01],
        [8.0877e-01],
        [1.7017e-01],
        [4.3632e-01],
        [6.7382e-01],
        [8.0421e-01],
        [3.9731e-01],
        [2.8739e-01],
        [2.1309e-01],
        [8.5938e-01],
        [7.7110e-01],
        [3.9159e-01],
        [4.4587e-01],
        [7.9362e-01],
        [2.3526e-01],
        [3.4207e-01],
        [5.3163e-02],
        [9.6853e-01],
        [1.6482e-02],
        [9.2614e-01],
        [9.8726e-01],
        [6.4590e-01],
        [1.6528e-02],
        [9.0729e-01],
        [7.3849e-01],
        [7.1975e-01],
        [3.0669e-01],
        [4.2977e-02],
        [2.3151e-02],
        [3.6460e-01],
        [2.4548e-02],
        [5.1638e-02],
        [5.7131e-01],
        [7.2929e-01],
        [2.6113e-01],
        [5.6228e-02],
        [3.7492e-01],
        [7.5003e-01],
        [9.1598e-01],
        [5.3681e-01],
        [1.7353e-01],
        [8.6741e-01],
        [7.6456e-01],
        [4.4732e-01],
        [6.6569e-01],
        [2.3427e-01],
        [8.1458e-01],
        [3.4212e-01],
        [3.6794e-02],
        [3.4897e-02],
        [2.2556e-01],
        [8.9128e-01],
        [1.7224e-01],
        [4.0921e-02],
        [7.3878e-01],
        [6.4530e-01],
        [6.7460e-01],
        [7.1279e-01],
        [4.0640e-01],
        [2.8746e-01],
        [7.7826e-01],
        [7.0893e-01],
        [2.5979e-01],
        [5.3256e-01],
        [4.5154e-01],
        [5.8069e-01],
        [3.8786e-02],
        [1.0988e-01],
        [8.0776e-01],
        [5.0349e-01],
        [1.5551e-01],
        [6.4590e-01],
        [5.7419e-01],
        [7.6577e-01],
        [6.4893e-01]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False,  True],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-0.7720,  2.3805],
        [-1.6508,  1.6977],
        [-1.7359,  2.1554],
        ...,
        [-0.8962,  1.8369],
        [ 0.5081,  0.4378],
        [-0.5548,  1.3839]]) torch.Size([9984, 2])
samples tensor([[ 2.4291e+00,  6.9529e-01],
        [ 2.6621e+00, -2.6540e-01],
        [ 2.0900e+00,  3.7689e-01],
        [ 2.1228e+00, -5.0926e-01],
        [ 2.9194e+00,  7.0339e-02],
        [ 1.6321e+00, -9.4037e-01],
        [ 2.5017e+00, -9.5704e-01],
        [ 1.8201e+00,  1.8835e+00],
        [ 1.7498e+00,  1.3610e-02],
        [ 1.7330e+00, -2.5898e-02],
        [ 2.1846e+00,  7.5876e-01],
        [ 9.4465e-01,  5.7052e-01],
        [ 1.0003e+00, -6.6266e-01],
        [ 2.1996e+00, -6.3326e-01],
        [ 2.4646e+00, -4.1351e-01],
        [ 3.8598e+00,  6.8688e-01],
        [ 1.0453e+00,  6.0685e-01],
        [ 7.2263e-01, -1.2067e+00],
        [ 2.9733e+00,  6.9249e-01],
        [ 2.0275e+00, -3.3354e-01],
        [ 1.1604e+00, -5.3967e-01],
        [ 2.3296e+00,  2.3377e-01],
        [ 1.0498e+00,  3.4940e-01],
        [ 2.5047e+00,  1.7776e+00],
        [ 1.6771e+00, -2.1661e-01],
        [ 3.8341e+00,  6.4085e-01],
        [ 3.2012e+00,  2.2813e+00],
        [ 2.0751e+00,  9.5329e-02],
        [ 3.1962e+00,  9.7189e-01],
        [ 3.1977e+00, -1.1772e+00],
        [ 4.4778e+00, -5.8848e-01],
        [ 1.3033e+00, -9.9320e-02],
        [ 2.5045e+00,  4.0159e-01],
        [ 3.0398e+00, -1.1432e-01],
        [ 1.1853e+00,  7.7194e-01],
        [ 1.8693e+00, -4.3651e-01],
        [ 2.3758e+00,  2.3997e-01],
        [ 2.2374e+00,  8.3355e-01],
        [ 8.5599e-01, -1.8235e+00],
        [ 2.7076e+00,  1.2512e+00],
        [ 3.4415e+00,  1.3386e+00],
        [ 9.4802e-01,  1.3545e-01],
        [ 1.9646e+00, -1.7799e+00],
        [ 2.8315e+00, -1.3758e+00],
        [ 2.1259e+00, -8.6525e-01],
        [ 1.9037e+00,  1.7113e+00],
        [ 9.8185e-01,  3.9340e-01],
        [ 2.9652e+00, -1.5666e+00],
        [ 1.6474e+00,  1.5696e-01],
        [ 1.9522e+00,  5.9202e-01],
        [ 3.0060e+00,  2.9928e-01],
        [ 2.5178e+00, -2.1352e+00],
        [ 2.5395e+00, -9.7331e-02],
        [ 2.9384e+00,  5.8239e-01],
        [ 3.6632e+00, -1.8945e+00],
        [ 2.2983e+00, -1.6999e-01],
        [ 4.8339e+00, -1.4749e-01],
        [ 1.1092e+00, -1.3450e+00],
        [ 2.5863e+00, -2.3169e+00],
        [-8.5725e-01,  4.9469e-01],
        [ 1.3167e+00, -3.4387e-01],
        [ 2.4839e+00, -5.8003e-01],
        [ 2.5974e+00, -7.9735e-01],
        [ 1.0273e+00, -3.8088e-01],
        [ 2.4968e+00, -2.5000e-01],
        [ 1.3631e+00,  6.6559e-01],
        [ 3.2835e+00, -1.6057e-01],
        [ 1.5698e+00, -8.9840e-01],
        [ 2.1748e+00,  4.9574e-01],
        [ 3.0358e+00, -6.5488e-01],
        [ 2.3747e+00, -9.4489e-01],
        [ 2.7025e+00, -9.5588e-01],
        [ 1.4145e+00,  1.2651e-01],
        [ 2.9615e+00,  1.6157e+00],
        [ 3.6903e+00,  2.0958e+00],
        [ 2.6234e+00,  1.7536e+00],
        [ 2.8584e+00,  2.5960e-01],
        [ 1.4236e+00, -2.6015e-01],
        [ 2.0648e+00, -2.8053e-01],
        [ 3.2493e+00, -1.2982e+00],
        [ 2.3896e+00, -1.4448e+00],
        [ 2.2872e+00, -6.1432e-01],
        [ 2.0758e+00, -2.1685e-01],
        [ 2.2372e+00,  2.2712e-01],
        [ 2.3669e+00, -3.5301e-01],
        [ 1.9386e+00,  1.8114e+00],
        [ 2.1614e+00, -1.2069e+00],
        [ 2.7356e+00,  7.5201e-01],
        [ 2.0240e+00,  7.6140e-01],
        [ 1.2193e+00, -6.7835e-01],
        [ 3.2504e+00, -3.2131e-01],
        [ 3.2214e+00,  4.7043e-02],
        [ 2.0778e+00, -1.3119e+00],
        [ 2.5031e+00,  1.3069e+00],
        [ 3.1948e+00,  2.2995e-01],
        [ 3.1811e+00,  1.1590e+00],
        [ 2.8874e+00, -1.4409e-02],
        [ 2.9224e+00,  7.2065e-01],
        [ 1.7351e+00,  2.5143e-01],
        [ 2.2776e+00, -5.9093e-01],
        [ 2.8865e+00,  1.3327e+00],
        [ 4.1165e+00, -7.4095e-02],
        [ 1.7106e+00,  1.4761e+00],
        [ 1.9249e+00,  1.4002e+00],
        [ 2.6849e+00,  5.7687e-01],
        [ 2.3569e+00,  8.5259e-02],
        [ 2.0880e+00, -1.6723e+00],
        [ 3.1430e+00, -2.0290e+00],
        [ 2.5128e+00, -1.5007e+00],
        [ 1.1202e+00,  4.2956e-01],
        [ 3.2210e+00, -1.6258e+00],
        [ 1.5592e+00, -2.3232e-02],
        [ 3.5240e+00,  8.8288e-01],
        [ 2.6273e+00, -1.2901e-01],
        [ 8.8670e-01,  1.5290e+00],
        [ 1.8114e+00, -1.0707e+00],
        [ 2.1466e+00,  1.9389e+00],
        [ 2.2314e+00, -5.8581e-01],
        [-1.5694e-01,  1.5079e-01],
        [ 2.2784e+00,  1.5962e+00],
        [ 2.0914e+00, -1.6563e-01],
        [ 2.5728e+00, -6.4431e-02],
        [ 2.3600e+00,  3.8600e-02],
        [ 3.0487e+00, -2.2950e+00],
        [ 5.4060e-01,  5.6297e-01],
        [ 3.0885e+00, -1.3541e+00],
        [ 3.0526e+00,  5.4334e-01],
        [ 2.3986e+00, -1.7688e+00],
        [ 3.5586e+00, -5.9623e-01],
        [ 1.3055e+00,  1.0769e-01],
        [ 2.0913e+00, -1.4648e-02],
        [ 2.2150e+00,  7.7385e-01],
        [ 2.3126e+00, -4.7194e-01],
        [ 2.5370e+00,  4.2484e-03],
        [ 3.5708e+00,  3.6257e-01],
        [ 2.0084e+00,  3.0871e-01],
        [ 3.1933e+00, -3.5165e-02],
        [ 1.9507e+00,  1.1861e+00],
        [ 1.5828e+00,  3.2767e-01],
        [ 2.8349e+00,  4.2469e-01],
        [ 2.9093e+00, -1.2803e+00],
        [ 3.4477e+00, -1.5972e+00],
        [ 3.6467e+00, -1.3840e+00],
        [ 1.0640e+00, -1.8609e+00],
        [ 3.2280e+00,  1.1186e+00],
        [ 2.0299e+00, -1.5105e+00],
        [ 3.0090e+00,  4.0436e-01],
        [ 2.2507e+00,  8.9812e-01],
        [ 3.6476e+00,  1.4610e+00],
        [ 1.3090e+00,  1.4058e+00],
        [ 8.6788e-01,  4.8082e-01],
        [ 2.4862e+00, -5.5862e-01],
        [ 3.6297e+00, -2.7253e+00],
        [ 2.9094e+00, -6.7618e-02],
        [ 7.9176e-01, -5.2870e-01],
        [ 4.3788e+00,  7.9606e-01],
        [ 3.7625e+00, -5.8012e-01],
        [ 1.3727e+00, -1.2263e+00],
        [ 2.1809e+00, -2.1148e-01],
        [ 1.7914e+00, -1.0187e+00],
        [ 3.0024e+00, -6.1637e-01],
        [ 2.2011e+00, -9.2083e-01],
        [ 2.0700e+00,  2.7536e-01],
        [ 2.1457e+00, -2.1956e+00],
        [ 4.0524e+00, -1.1347e+00],
        [ 3.9669e+00, -1.5780e+00],
        [ 3.2608e+00, -1.4902e-02],
        [ 2.4707e+00,  4.3752e-01],
        [ 5.2033e-01, -8.0129e-01],
        [ 1.8680e+00, -7.8695e-01],
        [ 2.1115e+00, -6.5372e-01],
        [ 3.5144e+00,  3.4925e-01],
        [ 1.7534e+00, -6.9358e-01],
        [ 3.7856e+00, -2.0072e+00],
        [ 2.9980e+00, -1.5405e+00],
        [ 3.1363e+00, -3.3390e+00],
        [ 1.5475e+00,  3.9785e-01],
        [ 1.7395e+00, -8.0545e-01],
        [ 9.9599e-01, -1.0085e-01],
        [ 3.0004e+00,  3.2630e-01],
        [ 4.4673e-01, -1.3268e+00],
        [ 1.2906e+00,  6.9387e-01],
        [ 1.8369e+00,  1.5442e+00],
        [ 3.6160e+00, -4.1583e-01],
        [ 2.3427e+00, -4.5789e-01],
        [ 2.9072e+00,  1.2640e+00],
        [ 1.8679e+00, -1.6454e+00],
        [ 2.6632e+00,  1.8271e+00],
        [ 1.3330e+00,  1.5595e+00],
        [ 2.8886e+00,  5.8128e-01],
        [ 3.1419e+00, -7.4987e-01],
        [ 1.6637e+00, -1.3783e-01],
        [ 1.3835e+00, -9.7951e-01],
        [ 2.2521e+00,  1.0592e+00],
        [ 3.8340e+00,  6.3888e-02],
        [ 3.5899e+00,  2.8332e-01],
        [ 2.5282e+00,  5.9373e-01],
        [ 1.1775e+00,  1.2121e-01],
        [ 1.7309e+00, -2.9302e-01],
        [ 2.7668e+00,  4.6217e-01],
        [ 3.3402e+00, -1.0462e+00],
        [ 4.1079e+00, -7.1038e-01],
        [ 2.5308e+00,  4.0190e-01],
        [ 2.8251e+00, -9.0767e-01],
        [ 2.0805e+00, -5.2472e-01],
        [ 1.1039e+00, -1.2670e-01],
        [ 8.4986e-01,  1.7366e-02],
        [ 2.4731e+00,  2.1879e+00],
        [ 2.9668e+00,  2.1049e+00],
        [ 1.7468e+00,  7.8952e-01],
        [ 2.7259e+00, -1.9115e+00],
        [ 2.6073e-01,  3.2961e-01],
        [ 1.3860e+00, -2.6865e-02],
        [ 1.3943e+00, -5.6730e-01],
        [ 1.2733e+00,  2.0157e-01],
        [ 2.1338e+00,  3.2679e-01],
        [ 3.0509e+00, -4.6194e-01],
        [ 3.9766e+00, -2.4982e-01],
        [ 3.3120e+00,  1.5320e-01],
        [ 1.6993e+00, -2.7153e-01],
        [ 3.2165e+00, -4.2832e-01],
        [ 2.5400e+00, -2.2985e-01],
        [ 1.9394e+00, -5.4004e-01],
        [ 2.4310e+00, -1.9803e+00],
        [ 3.8291e+00, -1.6693e+00],
        [ 1.1799e+00,  1.5122e+00],
        [ 3.2873e+00, -2.4993e-01],
        [ 3.1653e+00, -6.8119e-01],
        [ 2.1498e+00,  5.6245e-01],
        [ 2.2188e+00, -2.1075e+00],
        [ 1.2005e+00, -3.5600e-01],
        [ 1.0825e+00, -1.3392e-01],
        [ 2.0345e+00,  1.0439e+00],
        [ 4.0149e+00,  6.4808e-01],
        [ 7.2774e-01, -4.1916e-01],
        [ 1.7262e+00,  7.9313e-01],
        [ 8.9609e-01,  3.3160e-02],
        [ 1.5539e+00, -6.5417e-01],
        [ 9.1075e-01, -1.2557e+00],
        [ 2.0244e+00, -5.8445e-02],
        [ 3.5745e+00, -5.3745e-01],
        [ 2.4713e+00, -2.7284e-01],
        [ 2.3272e+00, -2.8308e-01],
        [ 3.8948e+00, -5.2976e-01],
        [ 1.0965e+00, -1.8475e+00],
        [ 1.4599e+00, -9.7348e-01],
        [ 1.5546e+00, -6.6453e-01],
        [ 2.4727e+00,  3.2752e-01],
        [ 2.2525e+00, -1.8136e+00],
        [ 1.0962e+00, -6.1178e-01],
        [ 2.6255e+00, -9.6623e-01],
        [ 2.1760e+00, -6.2941e-01],
        [ 2.0308e+00, -9.4468e-02],
        [ 1.0117e+00, -1.0446e+00],
        [ 2.9149e+00,  1.0759e+00],
        [ 8.8687e-01,  6.3811e-01],
        [ 4.2950e+00,  5.0499e-01],
        [ 1.5434e+00,  1.9503e-01],
        [ 2.4896e+00,  5.8359e-02],
        [ 2.2531e+00,  1.4105e+00],
        [ 2.1013e+00, -4.2672e-01],
        [ 2.2008e+00,  1.0456e+00],
        [ 7.1597e-01, -4.1625e-01],
        [ 2.7776e+00, -9.2978e-02],
        [ 1.8367e+00,  1.5702e+00],
        [ 1.3597e+00,  6.1811e-01],
        [ 1.6451e+00,  4.4317e-01],
        [ 2.0928e+00,  6.3781e-02],
        [ 1.3808e+00,  1.2961e-01],
        [ 4.3493e+00,  5.5402e-01],
        [ 3.4133e+00, -6.2588e-01],
        [ 1.9187e+00,  1.5428e-01],
        [ 3.6824e+00, -1.7491e+00],
        [ 1.9156e+00,  4.4027e-01],
        [ 3.6026e+00,  2.4775e-01],
        [ 1.2495e+00, -7.6757e-02],
        [ 9.8599e-01, -2.9373e-01],
        [ 2.1774e+00, -6.3958e-01],
        [ 2.9113e+00, -9.0830e-02],
        [ 2.6390e+00,  7.2301e-02],
        [ 1.5381e+00, -1.1105e+00],
        [ 7.0527e-01, -1.7167e+00],
        [ 1.9373e+00,  8.4936e-01],
        [ 2.8048e+00, -1.8146e+00],
        [ 3.1518e+00,  8.9033e-01],
        [ 2.8264e+00, -4.1352e-01],
        [ 1.4989e+00, -5.7349e-01],
        [ 1.7965e+00,  1.0074e+00],
        [ 1.1394e+00,  3.2728e-01],
        [ 2.6033e+00, -5.9746e-02],
        [ 6.4050e-01, -3.6759e-01],
        [ 4.0355e+00,  5.3413e-01],
        [ 2.1147e+00,  2.7531e-01],
        [ 2.9727e+00, -2.3493e-01],
        [ 3.2277e+00,  3.9746e-01],
        [ 2.3295e+00, -1.4309e-01],
        [ 3.2691e+00, -5.8294e-01],
        [ 2.2936e+00, -2.6953e+00],
        [ 1.5272e+00,  8.0464e-02],
        [ 4.7447e+00, -5.1496e-01],
        [ 2.4335e+00, -3.9417e-01],
        [ 3.0541e+00,  1.6558e+00],
        [ 2.1259e+00, -2.6180e-01],
        [ 1.1217e+00,  1.7438e-01],
        [ 2.8454e+00,  2.7035e-01],
        [ 3.2138e+00,  1.3040e+00],
        [ 2.3178e+00,  1.6696e-01],
        [ 2.5609e+00,  4.9978e-01],
        [ 2.8944e+00, -2.4825e-01],
        [ 1.2788e+00, -6.4154e-01],
        [ 4.3844e+00, -1.7461e-01],
        [ 2.2480e+00,  4.3266e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[2.6829e-02, 2.9475e-02, 1.0153e-01,  ..., 9.8127e-01, 9.9888e-01,
         1.0000e+00],
        [7.9384e-04, 4.7925e-03, 2.4097e-02,  ..., 9.4131e-01, 9.8316e-01,
         1.0000e+00],
        [2.5669e-01, 2.5669e-01, 2.5670e-01,  ..., 9.9931e-01, 1.0000e+00,
         1.0000e+00],
        ...,
        [8.1842e-05, 3.7627e-02, 3.7627e-02,  ..., 9.9997e-01, 9.9999e-01,
         1.0000e+00],
        [9.5189e-03, 3.0082e-02, 3.0082e-02,  ..., 9.9811e-01, 9.9825e-01,
         1.0000e+00],
        [4.5347e-05, 4.5347e-05, 4.6539e-05,  ..., 9.8860e-01, 9.9879e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.2496],
        [0.4289],
        [0.9689],
        [0.4675],
        [0.4255],
        [0.6002],
        [0.8062],
        [0.9069],
        [0.2765],
        [0.8659],
        [0.3870],
        [0.6962],
        [0.7387],
        [0.9072],
        [0.5132],
        [0.3331],
        [0.6887],
        [0.6379],
        [0.8255],
        [0.2663],
        [0.5015],
        [0.4580],
        [0.4749],
        [0.7059],
        [0.7932],
        [0.8745],
        [0.8865],
        [0.1313],
        [0.7215],
        [0.9089],
        [0.6793],
        [0.2937],
        [0.7083],
        [0.4030],
        [0.6300],
        [0.7125],
        [0.8380],
        [0.4214],
        [0.9860],
        [0.5570],
        [0.1053],
        [0.5953],
        [0.1758],
        [0.1076],
        [0.9486],
        [0.8529],
        [0.1256],
        [0.1220],
        [0.6611],
        [0.0827],
        [0.1944],
        [0.3307],
        [0.0462],
        [0.2365],
        [0.3261],
        [0.1967],
        [0.7562],
        [0.6265],
        [0.2024],
        [0.4973],
        [0.3566],
        [0.3292],
        [0.3122],
        [0.9602],
        [0.7403],
        [0.6396],
        [0.8857],
        [0.4896],
        [0.8915],
        [0.1644],
        [0.4381],
        [0.3822],
        [0.3534],
        [0.9843],
        [0.1669],
        [0.5164],
        [0.7082],
        [0.0398],
        [0.7299],
        [0.1329],
        [0.9275],
        [0.7149],
        [0.7464],
        [0.1089],
        [0.7120],
        [0.9815],
        [0.1255],
        [0.7264],
        [0.8504],
        [0.6232],
        [0.1514],
        [0.3612],
        [0.2712],
        [0.8230],
        [0.3901],
        [0.5558],
        [0.3448],
        [0.5723],
        [0.2658],
        [0.9443],
        [0.3232],
        [0.8244],
        [0.6647],
        [0.7503],
        [0.4166],
        [0.5439],
        [0.9405],
        [0.7508],
        [0.4304],
        [0.2511],
        [0.9797],
        [0.9412],
        [0.9206],
        [0.3260],
        [0.7431],
        [0.9226],
        [0.0111],
        [0.7556],
        [0.0370],
        [0.4492],
        [0.5758],
        [0.8635],
        [0.5318],
        [0.8250],
        [0.5284],
        [0.9264],
        [0.4455],
        [0.9368],
        [0.6718],
        [0.2223],
        [0.6359],
        [0.5478],
        [0.8055],
        [0.4676],
        [0.5812],
        [0.2729],
        [0.8619],
        [0.9233],
        [0.1673],
        [0.6945],
        [0.9026],
        [0.8809],
        [0.7538],
        [0.6485],
        [0.3066],
        [0.0527],
        [0.0690],
        [0.9280],
        [0.2838],
        [0.6377],
        [0.1160],
        [0.6298],
        [0.7149],
        [0.7560],
        [0.6752],
        [0.7061],
        [0.3966],
        [0.0113],
        [0.9307],
        [0.2388],
        [0.9790],
        [0.8863],
        [0.1375],
        [0.4845],
        [0.3706],
        [0.6025],
        [0.2909],
        [0.1574],
        [0.7833],
        [0.9315],
        [0.2094],
        [0.3337],
        [0.8431],
        [0.7055],
        [0.8305],
        [0.0029],
        [0.3603],
        [0.3179],
        [0.3794],
        [0.3598],
        [0.6316],
        [0.4847],
        [0.7408],
        [0.3943],
        [0.3482],
        [0.7633],
        [0.4604],
        [0.2603],
        [0.4109],
        [0.0507],
        [0.1122],
        [0.7343],
        [0.4215],
        [0.3366],
        [0.7993],
        [0.4904],
        [0.8729],
        [0.0350],
        [0.7719],
        [0.2244],
        [0.1043],
        [0.1832],
        [0.3629],
        [0.4381],
        [0.2935],
        [0.8839],
        [0.6822],
        [0.0374],
        [0.7824],
        [0.3732],
        [0.2291],
        [0.7834],
        [0.7369],
        [0.7664],
        [0.2355],
        [0.4681],
        [0.3719],
        [0.4757],
        [0.5103],
        [0.7006],
        [0.7613],
        [0.9990],
        [0.5802],
        [0.7761],
        [0.8013],
        [0.8940],
        [0.2414],
        [0.0560],
        [0.7105],
        [0.7483],
        [0.6331],
        [0.8638],
        [0.6960],
        [0.3521],
        [0.6043],
        [0.5028],
        [0.1741],
        [0.1728],
        [0.3524],
        [0.4886],
        [0.9159],
        [0.6557],
        [0.9770],
        [0.8967],
        [0.8092],
        [0.5702],
        [0.7415],
        [0.5008],
        [0.9056],
        [0.6660],
        [0.7951],
        [0.2235],
        [0.2251],
        [0.9759],
        [0.6654],
        [0.3679],
        [0.8146],
        [0.8841],
        [0.3304],
        [0.6085],
        [0.1600],
        [0.4533],
        [0.5423],
        [0.9045],
        [0.0271],
        [0.1262],
        [0.8767],
        [0.8901],
        [0.2377],
        [0.5829],
        [0.2184],
        [0.1458],
        [0.8390],
        [0.1000],
        [0.2748],
        [0.2590],
        [0.0686],
        [0.4081],
        [0.7439],
        [0.1905],
        [0.7577],
        [0.9005],
        [0.7656],
        [0.4554],
        [0.8869],
        [0.7786],
        [0.8146],
        [0.2386],
        [0.5684],
        [0.2836],
        [0.2319],
        [0.5535],
        [0.2860],
        [0.7974],
        [0.6854],
        [0.1468],
        [0.8234],
        [0.7022],
        [0.2643],
        [0.8823],
        [0.3601],
        [0.7931],
        [0.5469],
        [0.4412],
        [0.1408],
        [0.5926],
        [0.2537],
        [0.4775],
        [0.5090],
        [0.8218],
        [0.4049],
        [0.7845]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ...,  True, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ...,  True, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 0.7931, -0.1914],
        [ 1.1115,  2.5199],
        [ 2.4975,  0.6721],
        ...,
        [-1.8712, -1.0377],
        [ 0.7771,  0.8825],
        [-0.0026,  1.4443]]) torch.Size([9984, 2])
samples tensor([[ 3.7219, -0.8718],
        [ 1.7594, -1.5174],
        [ 0.9024, -1.0041],
        [ 2.4318,  0.8536],
        [ 2.7030,  0.4548],
        [ 4.1593, -1.2760],
        [ 2.1603,  1.6436],
        [ 1.9454,  0.2851],
        [ 3.8422,  0.9963],
        [ 2.4503, -0.4428],
        [ 3.2329, -0.8647],
        [ 1.6890,  0.0098],
        [ 1.4329, -1.1358],
        [ 2.7681, -1.1507],
        [ 3.8895,  0.4776],
        [ 3.6750, -0.6322],
        [ 4.1030,  0.2334],
        [ 1.5171, -1.4751],
        [ 2.3089, -0.9170],
        [-0.9025, -1.2112],
        [ 3.9311, -0.8433],
        [ 2.3291,  1.2620],
        [ 2.3491, -1.5256],
        [ 3.7403,  0.1578],
        [ 2.4108, -0.1063],
        [ 1.1198, -0.7902],
        [ 2.7261, -1.4860],
        [ 2.5132,  0.5642],
        [ 1.2514, -1.5749],
        [ 4.9267, -0.7367],
        [ 2.6687, -0.2667],
        [ 2.2671,  1.4873],
        [ 2.9481, -0.3052],
        [ 2.9033, -0.2122],
        [ 3.2244, -1.1622],
        [ 2.8872, -0.3923],
        [ 2.1727,  0.2269],
        [ 2.1193,  2.0285],
        [ 1.3869,  1.8442],
        [ 3.8630,  0.0409],
        [-0.3359, -1.9507],
        [ 2.3130, -0.0562],
        [ 2.9567,  0.7174],
        [ 1.9450, -0.6008],
        [ 1.6857, -0.3490],
        [ 4.6055, -1.9888],
        [ 3.3060,  1.2251],
        [ 2.2498, -0.3167],
        [ 2.9040,  0.2238],
        [ 3.4573,  0.3350],
        [ 2.0521,  0.2612],
        [ 2.2633,  0.0596],
        [ 0.9692,  0.3288],
        [ 2.5257, -0.1593],
        [ 1.9859, -1.4289],
        [ 3.4550,  0.9667],
        [ 4.2066, -0.0051],
        [ 2.2838, -0.3185],
        [ 3.8132,  1.7676],
        [ 3.9099, -1.2411],
        [ 2.3617,  1.2281],
        [ 2.3268,  0.7352],
        [ 2.3609,  0.6926],
        [ 3.2874, -0.7025],
        [ 2.7595, -0.2918],
        [ 2.9108, -0.8662],
        [ 3.2390, -1.7805],
        [ 2.9423, -0.0919],
        [ 1.3469,  0.0138],
        [ 2.0791, -0.4785],
        [ 1.7684, -0.6041],
        [ 3.1432,  0.7155],
        [ 1.7353,  0.5844],
        [ 3.0153,  0.4032],
        [ 3.2366,  0.6122],
        [ 3.1312,  1.9567],
        [ 0.9987,  1.5176],
        [ 1.2687,  0.4716],
        [ 1.6982, -2.0431],
        [ 1.0169, -0.1961],
        [ 2.0362,  1.0877],
        [ 3.3772,  1.2262],
        [ 4.0006, -0.9955],
        [ 2.9062, -2.2851],
        [ 1.5013, -0.9359],
        [ 1.7682,  1.4111],
        [ 2.0642, -0.0096],
        [ 4.2362,  0.1696],
        [ 2.9752,  1.1502],
        [ 3.8934, -0.5823],
        [ 1.5166, -1.5097],
        [ 3.1628,  1.8390],
        [ 3.8149, -1.3072],
        [ 3.1986,  0.0370],
        [ 2.3991, -2.5353],
        [ 4.0160, -1.3619],
        [ 1.5606, -0.1640],
        [ 2.2427, -0.1873],
        [ 2.1331,  0.6669],
        [ 3.1646,  1.2692],
        [ 2.0215, -0.1585],
        [ 2.4805, -0.3463],
        [ 0.7831, -0.3169],
        [ 1.1888, -1.0257],
        [ 1.8790, -0.1135],
        [ 2.3402, -1.0601],
        [ 2.7871,  0.0176],
        [ 2.3743,  0.6987],
        [ 1.5524, -0.5534],
        [ 2.5481, -0.1224],
        [ 1.5871,  0.8857],
        [ 2.0134,  1.2132],
        [ 1.9124, -1.4195],
        [ 3.5845, -0.1613],
        [ 1.9934, -0.6097],
        [ 2.5198,  1.0840],
        [ 3.2617,  1.9061],
        [ 2.9160, -0.0606],
        [ 1.0550, -0.2788],
        [ 1.6605, -1.5546],
        [ 2.5536, -1.1923],
        [ 2.2045,  0.3843],
        [-0.1830, -1.1350],
        [ 2.3391,  0.4564],
        [ 1.5227,  0.1807],
        [ 1.6079, -0.4995],
        [ 2.2400, -1.4583],
        [ 1.4568, -0.9924],
        [ 3.4138,  0.7997],
        [ 1.1852,  1.2034],
        [ 3.9265, -1.0330],
        [ 2.7975, -1.3669],
        [ 2.0394,  2.3060],
        [ 1.6437,  0.7579],
        [ 1.4861, -1.8314],
        [ 2.6678,  0.1379],
        [ 2.4160,  0.1626],
        [ 4.5770, -2.1256],
        [ 0.9292, -1.4625],
        [ 2.0355,  0.2501],
        [ 1.2459,  0.1651],
        [ 2.6616, -0.3366],
        [ 2.1365, -0.4317],
        [ 2.8960, -1.3652],
        [ 1.9596,  0.0279],
        [ 3.6628, -2.9988],
        [ 4.4581, -0.1889],
        [ 3.3801,  0.7341],
        [ 1.9949,  0.0136],
        [ 3.0836, -0.6010],
        [ 3.5217,  0.0500],
        [ 1.8072, -1.7200],
        [ 1.4876, -0.0578],
        [ 2.0611,  1.0858],
        [ 1.6495,  0.7641],
        [ 2.1323, -1.3029],
        [ 2.2922,  1.0011],
        [ 3.3525,  1.9411],
        [ 1.2743, -0.5343],
        [ 2.6742, -0.5663],
        [ 0.4782, -0.9788],
        [ 4.3751, -0.6883],
        [ 1.7807,  0.5539],
        [ 2.1547, -0.3216],
        [ 2.4912, -1.3705],
        [ 1.7956, -0.4432],
        [ 1.0584, -0.3703],
        [ 2.0536,  0.3366],
        [ 3.5162,  1.5359],
        [ 0.7568, -0.0578],
        [ 2.6179,  0.1614],
        [ 0.6809, -0.3003],
        [ 3.8995, -0.2742],
        [ 2.2130, -0.6041],
        [ 4.4298, -2.5710],
        [ 1.1672,  0.6543],
        [ 4.3836, -0.6713],
        [ 0.6046, -0.6790],
        [ 1.0840,  0.7407],
        [ 2.1373, -2.1166],
        [ 2.8618, -0.3523],
        [ 3.0540, -0.0064],
        [ 2.4211,  0.1138],
        [ 2.9914, -1.3965],
        [ 1.5560,  0.2222],
        [ 3.6383,  1.1408],
        [-0.4623, -0.5834],
        [ 3.0360, -1.2194],
        [ 2.1847, -0.2319],
        [ 4.2992, -1.6789],
        [ 3.1927, -0.7081],
        [ 1.9288,  0.6344],
        [ 1.3634, -1.8396],
        [ 3.8250,  1.3725],
        [ 2.8182,  2.1420],
        [ 4.3607,  1.4372],
        [ 1.6832,  0.4162],
        [ 0.1397, -0.0471],
        [ 1.0036,  0.9973],
        [ 2.3730, -1.3005],
        [ 3.1379, -1.6159],
        [ 3.1400, -0.5216],
        [ 0.9453, -1.6909],
        [ 3.4804,  2.7577],
        [ 2.9620, -0.3116],
        [ 0.8264,  0.5589],
        [ 2.4671, -0.4569],
        [ 1.7674,  1.9516],
        [ 2.6801, -0.7391],
        [ 2.2838,  0.3075],
        [ 2.0715, -0.6620],
        [ 1.5895,  0.1925],
        [ 2.0192, -0.9832],
        [ 3.4230,  0.0621],
        [ 1.5758,  1.4901],
        [ 1.2831,  0.3042],
        [ 3.3973, -0.6760],
        [ 3.4792, -0.8934],
        [ 2.6764, -0.4576],
        [ 3.4894,  0.3328],
        [ 0.8933,  0.6061],
        [ 3.1256,  0.5452],
        [ 1.6229, -2.1027],
        [ 3.6147, -1.7540],
        [ 2.6696,  0.3410],
        [ 2.9255,  0.3416],
        [ 1.5887, -0.2336],
        [ 3.0923, -1.7866],
        [ 2.9236, -0.8209],
        [ 3.0795, -2.4146],
        [ 2.6430, -0.8184],
        [ 2.9440,  0.3589],
        [ 1.5369,  0.1083],
        [ 3.9066,  0.0710],
        [ 2.4510,  0.5327],
        [ 3.1533, -1.7787],
        [ 3.1403, -0.2525],
        [ 3.8791,  0.1222],
        [ 4.7282,  1.8827],
        [ 2.6041, -0.1864],
        [ 4.0424, -0.1042],
        [ 0.7530, -0.3885],
        [ 3.3612,  2.0269],
        [ 1.1705,  0.0323],
        [ 1.3820,  0.6186],
        [ 2.8125, -0.5431],
        [ 1.8391,  0.1080],
        [ 2.2265,  1.9802],
        [ 1.3091, -0.5141],
        [ 2.6551, -2.1858],
        [ 1.6408,  1.1582],
        [ 2.9807, -0.6466],
        [ 3.1479,  0.8821],
        [ 3.5953, -2.1451],
        [ 3.2349, -0.3113],
        [ 1.7759,  0.6651],
        [ 2.7579, -1.0053],
        [ 3.3833,  0.6322],
        [ 3.2621, -0.9139],
        [ 0.8691, -1.2655],
        [ 1.7296, -1.0685],
        [ 1.4945,  0.4137],
        [ 2.6975, -0.5728],
        [ 2.9779, -0.1558],
        [ 3.1439, -0.1960],
        [ 2.5251,  2.1939],
        [ 0.2797, -1.4822],
        [ 1.1593, -0.5407],
        [ 3.1648, -0.7485],
        [ 1.9555, -1.2416],
        [ 3.9289,  1.2978],
        [ 2.6960, -0.6278],
        [ 1.5125, -0.5406],
        [ 1.4741,  1.2660],
        [ 0.3843, -0.4432],
        [ 0.9652, -0.7011],
        [ 2.0174,  0.7104],
        [ 4.1251, -0.7391],
        [ 3.5097,  1.5516],
        [ 2.0582,  0.1333],
        [ 3.5520, -0.3527],
        [ 1.1641,  0.1343],
        [ 3.0437, -0.6221],
        [ 3.0594, -3.3468],
        [ 2.3403, -0.0707],
        [ 3.2847, -0.9657],
        [ 1.6799, -0.8914],
        [ 2.8318, -0.1817],
        [ 1.3199, -0.8807],
        [ 0.2073,  0.1595],
        [ 0.8407,  0.0514],
        [ 3.1142, -0.6504],
        [ 2.7692, -0.2135],
        [ 2.4761,  0.1160],
        [ 0.4848, -1.4035],
        [ 0.8593,  0.2907],
        [ 1.8925, -0.3551],
        [ 1.7183,  0.5257],
        [ 3.6375, -0.4760],
        [ 2.6761,  1.1950],
        [ 3.6603, -0.4404],
        [ 0.0947,  1.1755],
        [ 1.9453,  1.0125],
        [ 3.2448, -0.2449],
        [ 3.0624,  1.5597],
        [ 1.7797,  0.1977],
        [ 3.1007, -1.0227],
        [ 1.5286, -0.9493],
        [ 1.2473, -0.3294],
        [ 2.3807, -0.3078],
        [ 3.6631, -1.8102],
        [ 2.5860, -1.0657]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[4.3517e-06, 4.4223e-06, 2.3965e-01,  ..., 9.9705e-01, 9.9709e-01,
         1.0000e+00],
        [1.6780e-07, 7.4497e-02, 7.8425e-02,  ..., 9.9570e-01, 9.9935e-01,
         1.0000e+00],
        [4.9843e-06, 1.5934e-03, 1.2692e-01,  ..., 8.1363e-01, 8.1726e-01,
         1.0000e+00],
        ...,
        [4.5703e-08, 8.1236e-03, 3.3101e-01,  ..., 9.9895e-01, 1.0000e+00,
         1.0000e+00],
        [4.4434e-02, 5.9721e-02, 5.9722e-02,  ..., 8.5534e-01, 9.6069e-01,
         1.0000e+00],
        [1.1209e-04, 1.4046e-04, 2.7648e-03,  ..., 8.9039e-01, 9.0414e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[2.1037e-01],
        [4.8854e-01],
        [4.4504e-01],
        [7.1581e-02],
        [5.8959e-01],
        [3.9871e-01],
        [8.5341e-01],
        [8.8302e-01],
        [8.3237e-01],
        [8.3777e-01],
        [8.2625e-01],
        [3.3264e-01],
        [7.4715e-01],
        [5.1705e-01],
        [6.1588e-01],
        [9.1550e-01],
        [1.3513e-01],
        [6.1782e-01],
        [1.8897e-02],
        [1.6533e-02],
        [8.9690e-01],
        [2.2649e-01],
        [7.3524e-02],
        [7.6176e-01],
        [2.7376e-01],
        [7.6249e-01],
        [2.3532e-01],
        [7.0580e-01],
        [1.1907e-01],
        [5.6403e-02],
        [2.3343e-01],
        [7.2509e-02],
        [3.5645e-01],
        [4.8117e-01],
        [9.5673e-01],
        [7.5768e-01],
        [4.2933e-01],
        [4.2643e-01],
        [2.2119e-01],
        [3.2539e-01],
        [4.8334e-01],
        [9.3229e-01],
        [9.5642e-01],
        [1.1203e-01],
        [7.5093e-01],
        [1.8174e-01],
        [7.7094e-01],
        [1.2379e-01],
        [6.8595e-01],
        [4.7776e-02],
        [3.0353e-01],
        [4.5487e-01],
        [9.4829e-01],
        [9.3815e-01],
        [3.9943e-01],
        [4.8051e-02],
        [3.7880e-01],
        [6.1655e-01],
        [7.4880e-01],
        [3.6849e-01],
        [3.3861e-04],
        [5.9983e-01],
        [9.1660e-01],
        [8.2217e-01],
        [6.9957e-01],
        [8.0093e-01],
        [1.9628e-01],
        [2.7102e-01],
        [5.1448e-01],
        [6.4342e-02],
        [8.4603e-01],
        [2.9947e-01],
        [4.1205e-01],
        [1.0280e-01],
        [4.0771e-02],
        [4.9100e-01],
        [3.2951e-01],
        [9.5586e-01],
        [3.7909e-01],
        [7.7966e-02],
        [1.5669e-01],
        [5.3861e-01],
        [1.8582e-01],
        [7.5168e-01],
        [7.1459e-01],
        [2.3138e-01],
        [8.9844e-01],
        [9.7256e-01],
        [9.4563e-01],
        [5.3358e-03],
        [6.5132e-01],
        [4.0805e-01],
        [9.2408e-01],
        [3.1659e-01],
        [6.4864e-01],
        [5.8018e-01],
        [7.8632e-01],
        [4.5453e-01],
        [9.2273e-01],
        [4.2277e-01],
        [1.1947e-01],
        [3.7762e-01],
        [3.9350e-01],
        [6.3092e-02],
        [4.7504e-01],
        [6.0460e-01],
        [3.7535e-01],
        [4.8729e-01],
        [5.2638e-01],
        [4.0154e-01],
        [7.7971e-01],
        [3.9719e-01],
        [3.6690e-01],
        [6.9017e-01],
        [1.5678e-01],
        [5.8848e-01],
        [7.5023e-01],
        [3.8071e-01],
        [9.1890e-01],
        [6.2945e-01],
        [8.6131e-01],
        [5.4474e-01],
        [3.0162e-01],
        [3.0632e-01],
        [4.4039e-01],
        [9.9176e-01],
        [8.0190e-01],
        [8.0688e-01],
        [5.0358e-01],
        [9.3834e-02],
        [7.6853e-01],
        [5.1049e-01],
        [7.8085e-01],
        [9.7044e-01],
        [4.2326e-01],
        [9.4551e-01],
        [2.2519e-01],
        [4.5035e-01],
        [9.4036e-01],
        [1.2902e-01],
        [3.1161e-01],
        [4.1557e-01],
        [6.5790e-02],
        [2.9341e-01],
        [4.4749e-01],
        [8.3459e-01],
        [1.7991e-02],
        [8.5244e-01],
        [8.5527e-01],
        [3.6592e-01],
        [7.4595e-01],
        [5.5871e-02],
        [3.5273e-01],
        [1.3846e-01],
        [7.3337e-01],
        [1.7460e-01],
        [5.0715e-01],
        [8.1707e-01],
        [3.1265e-01],
        [9.1762e-01],
        [1.7263e-01],
        [9.7916e-02],
        [6.7575e-01],
        [3.9367e-02],
        [3.5627e-01],
        [9.0088e-01],
        [6.3131e-01],
        [2.9765e-01],
        [5.0700e-01],
        [5.3722e-01],
        [4.5097e-01],
        [8.7448e-01],
        [7.7629e-01],
        [1.3425e-01],
        [5.5863e-01],
        [1.8039e-01],
        [7.6831e-01],
        [9.8027e-02],
        [1.2482e-01],
        [8.6248e-01],
        [5.8548e-01],
        [5.8874e-01],
        [9.9348e-01],
        [8.0047e-02],
        [9.1270e-01],
        [2.8080e-01],
        [7.0776e-01],
        [4.6631e-01],
        [1.1233e-02],
        [8.0687e-01],
        [2.4108e-01],
        [4.1544e-01],
        [9.4475e-01],
        [5.3446e-02],
        [9.0789e-01],
        [2.1428e-01],
        [3.2541e-01],
        [3.3688e-01],
        [2.4120e-01],
        [7.9610e-01],
        [9.9777e-01],
        [5.7759e-01],
        [9.1718e-01],
        [5.5086e-01],
        [3.9482e-01],
        [1.2890e-02],
        [8.6824e-01],
        [9.8210e-02],
        [9.0589e-01],
        [3.3627e-01],
        [4.0868e-01],
        [1.0497e-01],
        [1.9461e-01],
        [8.7000e-02],
        [6.5221e-01],
        [4.5843e-02],
        [8.1883e-01],
        [5.7446e-01],
        [7.3601e-01],
        [5.9427e-01],
        [9.7043e-01],
        [6.4272e-01],
        [2.5351e-01],
        [2.4622e-01],
        [9.9018e-01],
        [9.6498e-01],
        [6.7486e-01],
        [9.0827e-01],
        [6.8858e-01],
        [6.6951e-01],
        [3.4685e-01],
        [7.1775e-01],
        [1.9525e-01],
        [7.6256e-01],
        [3.1869e-01],
        [1.6449e-01],
        [1.2471e-01],
        [1.8396e-01],
        [5.2263e-01],
        [6.9715e-01],
        [2.6097e-03],
        [4.0688e-01],
        [1.1804e-01],
        [2.8683e-01],
        [4.0999e-01],
        [7.7148e-01],
        [2.0320e-01],
        [9.3724e-01],
        [2.6624e-01],
        [3.9884e-01],
        [6.5505e-01],
        [7.4481e-02],
        [4.6693e-01],
        [8.8670e-01],
        [7.5587e-01],
        [4.9412e-01],
        [6.9958e-01],
        [2.2323e-02],
        [4.1224e-01],
        [8.0303e-01],
        [5.6828e-01],
        [3.2912e-01],
        [6.1094e-01],
        [4.5778e-01],
        [2.2615e-01],
        [4.4012e-01],
        [2.3109e-01],
        [9.0056e-01],
        [2.4104e-01],
        [9.7923e-01],
        [4.4216e-01],
        [9.0755e-01],
        [9.8490e-01],
        [2.0070e-01],
        [6.3072e-01],
        [7.6129e-01],
        [3.9394e-02],
        [3.6697e-01],
        [3.3485e-01],
        [7.0514e-01],
        [7.7112e-01],
        [1.4571e-01],
        [4.1619e-01],
        [2.4014e-01],
        [2.5525e-01],
        [2.6464e-01],
        [7.7031e-01],
        [7.9947e-01],
        [9.8569e-01],
        [4.5948e-01],
        [8.3280e-02],
        [9.6963e-01],
        [1.3469e-01],
        [8.2635e-02],
        [3.2166e-01],
        [4.9774e-01],
        [9.0870e-01],
        [7.4595e-01],
        [4.1036e-01],
        [4.6415e-02],
        [1.1195e-01],
        [6.6350e-02],
        [2.1883e-01],
        [9.2840e-01],
        [9.1674e-01],
        [7.1054e-02],
        [7.2479e-01],
        [3.7579e-01],
        [7.6348e-01],
        [8.4930e-01],
        [6.8681e-01],
        [7.8554e-01]]) torch.Size([312, 1])
mask tensor([[False, False,  True,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-2.0856,  0.4660],
        [-3.1418, -0.6112],
        [ 1.7676, -0.4125],
        ...,
        [ 0.5638,  1.8056],
        [ 0.9554,  0.4793],
        [ 1.4010, -0.4634]]) torch.Size([9984, 2])
samples tensor([[ 1.7676e+00, -4.1251e-01],
        [ 2.5938e+00, -1.0952e+00],
        [ 2.0026e+00, -1.5548e+00],
        [ 2.8278e+00, -7.6848e-01],
        [ 3.7389e+00, -2.2837e-01],
        [ 3.2131e+00, -1.1453e+00],
        [ 1.7190e+00,  5.4816e-01],
        [ 1.4591e+00,  1.4404e+00],
        [ 2.3463e+00,  3.0761e-01],
        [-7.3575e-01,  3.0214e-01],
        [ 2.4887e+00,  3.9944e-01],
        [ 1.7453e+00, -2.3816e-01],
        [ 2.3057e+00, -6.8954e-01],
        [ 2.1761e+00, -1.5035e+00],
        [ 4.4022e+00,  1.0799e+00],
        [ 1.6688e+00,  9.1043e-02],
        [ 2.0426e+00, -1.2529e-01],
        [ 1.2847e+00,  3.5041e-01],
        [ 9.2053e-01, -2.6910e-01],
        [ 1.5874e+00,  5.4099e-01],
        [ 2.3394e+00, -2.2912e-01],
        [ 3.7073e+00, -7.9178e-01],
        [ 2.2028e+00,  1.8559e+00],
        [ 1.1718e+00,  2.3100e-01],
        [ 2.7729e+00,  9.7828e-01],
        [ 1.3083e+00, -8.4443e-01],
        [ 2.8853e+00, -2.1196e-02],
        [ 3.0062e+00, -1.3166e+00],
        [ 1.0303e+00,  4.9189e-01],
        [ 2.9839e+00, -1.1216e+00],
        [ 3.4211e+00, -1.7135e+00],
        [ 1.4620e+00,  4.1472e-01],
        [ 1.2172e+00, -1.1040e+00],
        [ 4.2240e+00, -3.8732e-01],
        [ 2.3505e+00, -4.1669e-01],
        [ 3.1280e+00,  1.4215e+00],
        [-3.7267e-01,  1.1438e+00],
        [ 2.2530e+00,  5.2940e-01],
        [ 3.9741e+00, -5.5078e-01],
        [ 2.9051e+00,  3.3330e-01],
        [ 2.3256e+00,  1.6450e+00],
        [ 2.1658e+00, -1.0183e+00],
        [ 1.9232e+00,  1.3325e+00],
        [ 3.0928e+00, -1.1885e+00],
        [ 2.7404e+00,  2.2901e+00],
        [ 4.5315e+00, -1.8403e+00],
        [-2.9713e-01,  8.3846e-01],
        [ 2.8749e+00, -1.6902e+00],
        [ 3.5342e+00,  1.5920e+00],
        [ 3.5463e+00,  1.1560e-01],
        [ 1.3455e+00,  2.5929e-02],
        [ 3.0341e+00, -1.5303e+00],
        [ 1.6552e+00,  3.0904e-02],
        [ 2.6062e+00,  7.0470e-01],
        [ 1.6564e+00, -2.7676e+00],
        [ 2.5879e+00, -9.8246e-01],
        [ 2.8517e+00, -1.3628e+00],
        [ 4.0663e-01, -1.7387e-01],
        [ 2.0891e+00,  6.9317e-01],
        [ 1.8859e+00,  3.9791e-02],
        [ 1.6461e+00,  1.7486e+00],
        [ 2.2105e+00,  4.0216e-01],
        [ 2.9295e+00,  4.2004e-01],
        [ 2.8251e+00, -2.3053e-01],
        [-4.8669e-01,  4.0887e-01],
        [ 2.9060e+00, -2.0693e+00],
        [ 3.2290e+00,  1.0398e+00],
        [ 2.1610e+00,  4.4260e-01],
        [ 3.2264e+00, -3.0186e-01],
        [ 1.0451e+00, -7.2903e-01],
        [ 3.1906e+00,  9.1579e-01],
        [ 2.4522e+00, -7.4163e-01],
        [ 3.4515e+00, -5.4261e-01],
        [ 3.2381e+00, -1.6064e-01],
        [ 3.9998e-01,  6.9183e-02],
        [ 4.8035e+00,  1.5122e+00],
        [ 3.4141e+00, -6.1158e-02],
        [ 2.3443e+00, -9.1713e-02],
        [ 2.2315e+00, -1.3386e+00],
        [ 1.4393e+00, -1.3596e+00],
        [ 2.3058e+00, -3.9166e-01],
        [ 3.7262e+00, -3.4545e-01],
        [ 1.3748e+00, -8.7994e-01],
        [ 2.7557e+00,  2.0743e-01],
        [ 1.0865e+00,  1.9935e-01],
        [ 3.7034e+00,  3.6216e-01],
        [ 1.9101e+00,  1.7899e-01],
        [ 2.6644e+00,  9.7736e-01],
        [ 7.3567e-01, -7.1720e-01],
        [ 6.6121e-01,  2.8869e-01],
        [ 3.8975e+00,  1.4375e-02],
        [ 2.4139e+00,  1.3863e+00],
        [ 1.6108e+00,  6.5598e-01],
        [ 3.3110e+00, -1.1902e+00],
        [ 3.8915e+00,  3.5566e-01],
        [ 3.6388e+00, -7.8590e-03],
        [ 2.2355e+00, -1.8865e+00],
        [ 1.0951e+00, -1.7488e+00],
        [ 1.5440e+00,  4.2326e-01],
        [ 3.3070e+00, -5.2392e-01],
        [ 3.3434e+00,  1.3344e+00],
        [ 2.8905e+00, -9.9079e-01],
        [ 2.4444e+00,  2.3501e-01],
        [ 2.0770e+00,  4.1993e-01],
        [ 3.2522e+00, -3.2167e-01],
        [ 3.5257e+00,  3.8851e-01],
        [ 1.3422e+00, -1.0184e+00],
        [ 3.1081e+00,  1.3343e-02],
        [ 1.0673e+00,  1.7021e+00],
        [ 2.3094e+00,  1.1506e-01],
        [ 2.1362e+00, -7.2751e-02],
        [ 2.0304e+00, -1.6588e-01],
        [ 2.2371e+00, -2.0707e-01],
        [ 9.8623e-01, -1.6243e+00],
        [ 2.5385e+00,  7.4058e-01],
        [ 3.5370e+00, -1.4965e+00],
        [ 2.6533e+00,  1.1914e+00],
        [ 2.4081e+00,  3.8281e-01],
        [ 2.4481e+00,  1.0356e+00],
        [ 2.2239e+00, -8.3720e-01],
        [ 1.5595e+00,  1.7746e-01],
        [ 2.8108e+00, -1.8106e+00],
        [ 2.2894e+00, -2.1657e+00],
        [ 1.9393e+00,  3.8117e-01],
        [ 2.7111e+00, -1.7914e+00],
        [ 2.0513e+00,  2.7951e-01],
        [ 3.0616e-01, -3.4300e-01],
        [ 1.7245e+00,  2.8350e-01],
        [ 4.2029e+00, -1.5653e+00],
        [ 2.7235e+00,  1.0800e+00],
        [ 2.0819e+00, -1.6674e+00],
        [ 1.9206e+00, -1.0463e+00],
        [ 1.2628e+00,  6.0530e-01],
        [ 1.3814e+00, -4.0041e-01],
        [ 2.4897e+00, -7.2267e-01],
        [ 1.0150e+00, -4.9370e-01],
        [ 2.6954e+00,  1.3649e+00],
        [ 3.7775e+00, -9.3651e-01],
        [ 9.3042e-01,  3.1633e-01],
        [ 1.7392e+00, -3.0390e-01],
        [ 1.6443e+00,  1.8412e+00],
        [ 3.9419e+00,  3.0990e-01],
        [ 1.6279e+00,  5.9072e-01],
        [ 9.5206e-01, -1.1740e+00],
        [ 3.1288e+00,  1.5643e+00],
        [ 4.3021e+00, -2.9873e+00],
        [ 2.3939e+00, -3.3270e-01],
        [ 2.3976e+00, -9.7165e-02],
        [ 1.0257e+00, -8.1170e-02],
        [ 3.7767e+00, -3.8825e-01],
        [ 2.7247e+00, -7.0204e-01],
        [ 1.9406e+00,  2.2178e-01],
        [ 2.6049e+00, -8.3770e-01],
        [ 2.1722e+00, -2.7254e-01],
        [ 1.8344e+00,  1.1062e+00],
        [ 1.1861e-01, -1.2681e+00],
        [ 3.5651e+00, -1.9854e-01],
        [ 3.4023e+00,  1.7014e+00],
        [ 2.7379e+00, -9.5601e-01],
        [ 2.5846e+00, -1.8082e+00],
        [ 2.7615e+00,  1.1168e-01],
        [ 1.2159e+00, -2.3159e-02],
        [ 1.8090e+00,  9.4059e-01],
        [ 1.1594e+00,  1.8024e-01],
        [ 3.2490e+00,  7.7297e-01],
        [ 3.2020e+00,  4.2882e-01],
        [ 2.0403e+00, -1.4960e-01],
        [ 1.7479e+00, -1.1402e-01],
        [ 2.8088e+00,  1.7890e+00],
        [ 3.3078e+00, -5.9760e-01],
        [ 1.8359e+00, -5.0887e-01],
        [ 8.8215e-01, -1.0736e+00],
        [ 2.6752e+00,  1.2430e-01],
        [ 1.9904e+00,  1.1069e-01],
        [ 3.7872e+00, -2.3820e+00],
        [ 2.4760e+00, -1.8380e+00],
        [ 1.4592e+00,  2.2391e-01],
        [ 4.0948e+00,  7.1280e-01],
        [ 1.8776e+00,  4.2448e-01],
        [ 4.2041e+00, -1.6806e+00],
        [ 4.1409e+00,  7.6078e-01],
        [ 3.9677e+00, -1.5119e-01],
        [ 7.5223e-01, -1.4547e-01],
        [ 1.8095e+00,  4.5538e-02],
        [ 2.9026e+00,  1.0284e+00],
        [ 2.7449e+00,  1.2002e+00],
        [ 2.0182e+00, -1.2883e+00],
        [ 3.3603e+00, -1.3927e+00],
        [ 1.6647e-01, -2.7325e-01],
        [ 3.5993e+00,  7.0837e-01],
        [ 1.6826e+00, -6.2602e-01],
        [ 2.0766e+00, -1.8822e+00],
        [ 1.1833e+00,  8.1610e-01],
        [ 2.8237e+00,  1.9755e-01],
        [-5.6852e-01, -4.6325e-01],
        [ 1.4925e+00, -1.0806e+00],
        [ 3.3276e+00,  3.5245e-01],
        [ 2.8026e+00,  2.4920e-01],
        [ 1.9590e+00,  3.2402e-01],
        [ 2.7718e+00,  7.9773e-01],
        [ 1.8239e+00,  9.6325e-01],
        [ 1.1120e+00, -1.4783e+00],
        [ 3.2677e+00,  4.1759e-01],
        [ 2.3482e+00,  3.8567e-01],
        [ 1.7898e+00, -5.1259e-01],
        [ 2.1392e+00,  4.5747e-01],
        [ 3.9744e+00,  1.5796e+00],
        [ 2.6226e+00, -7.7542e-01],
        [ 2.6849e+00,  1.5246e-01],
        [ 2.2120e+00,  2.4019e-01],
        [ 3.0892e+00, -2.6263e-01],
        [ 3.3071e+00,  1.3262e+00],
        [ 6.8177e-01,  1.1874e-01],
        [ 3.4266e+00,  2.3234e+00],
        [ 2.0144e+00, -1.2577e+00],
        [ 2.6501e-01,  5.8203e-01],
        [ 1.9638e+00, -5.0931e-01],
        [ 3.0678e+00, -1.7381e+00],
        [ 3.3150e+00,  2.2236e-01],
        [ 3.7158e+00, -2.8314e-01],
        [ 1.0451e+00,  4.5177e-01],
        [ 2.4421e+00,  1.0403e+00],
        [ 9.6264e-01, -1.0578e+00],
        [ 3.6555e+00, -4.0401e-01],
        [ 7.9030e-01,  9.4187e-01],
        [ 3.2204e+00,  1.3480e+00],
        [ 2.8151e+00, -1.2582e-01],
        [ 1.5386e+00,  5.2453e-01],
        [ 2.9030e+00,  5.4366e-01],
        [ 2.8480e+00,  9.4363e-01],
        [ 2.7235e+00,  1.2166e+00],
        [ 2.1633e+00, -3.5691e-01],
        [ 2.2607e+00, -1.2586e-01],
        [ 1.8923e+00, -3.3203e-01],
        [ 2.7605e+00, -4.7940e-01],
        [ 1.8894e+00,  9.5265e-02],
        [ 3.2086e+00,  3.8209e-01],
        [ 3.6998e+00, -1.8715e+00],
        [ 2.2448e+00, -7.4437e-01],
        [ 2.5077e+00,  1.1412e+00],
        [ 2.9339e+00,  8.0682e-02],
        [ 2.9589e+00,  3.6497e-03],
        [ 4.2392e+00, -7.4090e-01],
        [ 2.3694e+00, -7.2869e-01],
        [ 2.3371e+00, -1.9640e+00],
        [ 1.3909e+00, -4.3752e-01],
        [ 3.8230e+00, -1.8761e+00],
        [ 2.3748e+00,  5.7548e-01],
        [ 1.0710e+00,  1.7504e+00],
        [ 2.2333e+00, -2.4027e+00],
        [ 2.4576e+00, -6.3757e-02],
        [ 3.5163e+00, -1.2092e+00],
        [ 2.0781e+00, -2.5204e+00],
        [ 2.9398e+00, -6.5961e-01],
        [ 1.4907e+00,  4.9196e-03],
        [ 1.8282e+00, -8.8925e-01],
        [ 3.1241e+00, -6.8857e-01],
        [ 3.7101e+00, -7.4022e-01],
        [ 2.4682e+00, -5.8698e-02],
        [ 1.3557e+00, -8.7940e-01],
        [ 1.1957e+00,  1.5220e-01],
        [ 2.5985e+00, -1.8752e+00],
        [ 2.7635e+00, -1.5724e+00],
        [ 2.4310e+00, -3.3787e-01],
        [ 1.3264e+00,  6.3022e-01],
        [ 4.4399e+00,  2.0249e-01],
        [ 4.0961e+00, -6.9291e-01],
        [ 1.3489e+00, -5.6259e-02],
        [ 1.8480e+00,  7.8112e-01],
        [ 3.2531e+00,  1.2177e-01],
        [ 1.3027e+00, -1.8670e+00],
        [ 2.6204e+00, -1.1875e-01],
        [ 1.9151e+00, -3.2138e-01],
        [ 1.8393e+00,  2.8444e-01],
        [ 2.5535e+00, -7.8824e-01],
        [ 3.4511e+00, -1.3167e+00],
        [ 1.4395e+00,  5.9375e-01],
        [ 2.3886e+00, -1.0381e+00],
        [ 2.1961e+00, -8.4131e-01],
        [ 2.8538e+00, -7.4549e-01],
        [ 2.2938e+00, -6.0476e-01],
        [ 2.2303e+00, -1.6669e+00],
        [ 1.5670e+00, -8.6134e-01],
        [ 2.3380e+00,  2.1553e-01],
        [ 2.5943e+00,  2.9833e-01],
        [ 2.7669e+00, -7.9258e-01],
        [ 3.9142e+00,  2.0127e+00],
        [ 3.0623e+00, -1.3814e+00],
        [ 3.2633e+00,  1.6573e+00],
        [ 3.1006e+00,  4.5774e-01],
        [ 9.9503e-01, -2.8637e-01],
        [ 4.1317e+00, -9.3386e-01],
        [ 3.5793e+00, -3.3736e-01],
        [ 6.4580e-01, -7.2377e-01],
        [ 1.9598e+00, -6.8549e-01],
        [ 1.2630e+00, -1.1451e+00],
        [ 3.0289e+00, -1.2295e+00],
        [ 2.8975e+00, -1.3314e+00],
        [ 2.6146e+00, -1.4047e+00],
        [ 2.5372e+00,  9.2588e-01],
        [ 2.4079e+00,  2.2401e-01],
        [ 3.9022e+00, -1.6361e+00],
        [ 3.3869e+00, -1.1193e+00],
        [ 1.4410e+00,  3.3962e-02],
        [ 2.5664e+00,  2.3202e-01],
        [ 1.6592e+00, -5.1198e-02],
        [ 9.6390e-01,  7.3182e-01],
        [ 5.6925e-01, -5.7454e-01],
        [ 4.2066e+00,  1.1461e-01],
        [ 3.4055e+00,  1.1065e+00],
        [ 3.1725e+00,  5.1258e-01],
        [ 2.5813e+00, -1.9140e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[8.4637e-02, 1.3141e-01, 1.3141e-01,  ..., 1.0000e+00, 1.0000e+00,
         1.0000e+00],
        [5.4851e-02, 5.7199e-02, 5.7199e-02,  ..., 9.9748e-01, 9.9970e-01,
         1.0000e+00],
        [4.9304e-04, 5.0665e-04, 5.5242e-03,  ..., 6.6598e-01, 7.2646e-01,
         1.0000e+00],
        ...,
        [6.7540e-04, 6.8146e-04, 3.8608e-02,  ..., 9.6814e-01, 9.9943e-01,
         1.0000e+00],
        [1.0673e-01, 1.1138e-01, 1.1138e-01,  ..., 9.9807e-01, 9.9844e-01,
         1.0000e+00],
        [3.0962e-05, 2.5729e-03, 2.5758e-03,  ..., 9.7827e-01, 9.7956e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.3381],
        [0.1599],
        [0.2598],
        [0.0865],
        [0.8470],
        [0.2724],
        [0.9985],
        [0.0105],
        [0.7858],
        [0.0711],
        [0.2804],
        [0.9489],
        [0.9893],
        [0.5091],
        [0.7275],
        [0.4595],
        [0.1491],
        [0.4142],
        [0.4651],
        [0.8418],
        [0.6773],
        [0.2884],
        [0.8434],
        [0.5582],
        [0.1992],
        [0.8842],
        [0.9178],
        [0.5503],
        [0.1544],
        [0.6855],
        [0.3810],
        [0.4386],
        [0.9708],
        [0.6938],
        [0.0932],
        [0.6538],
        [0.8657],
        [0.7843],
        [0.0898],
        [0.6591],
        [0.1652],
        [0.0134],
        [0.4579],
        [0.3445],
        [0.3872],
        [0.0392],
        [0.9443],
        [0.9387],
        [0.3418],
        [0.9494],
        [0.8503],
        [0.5080],
        [0.9388],
        [0.8968],
        [0.4015],
        [0.8718],
        [0.9001],
        [0.4860],
        [0.7896],
        [0.4112],
        [0.8219],
        [0.8467],
        [0.8084],
        [0.3810],
        [0.7615],
        [0.8081],
        [0.6041],
        [0.8375],
        [0.1001],
        [0.6860],
        [0.7276],
        [0.6934],
        [0.1707],
        [0.9116],
        [0.8910],
        [0.6966],
        [0.7026],
        [0.1576],
        [0.0226],
        [0.7424],
        [0.3396],
        [0.2089],
        [0.8604],
        [0.7970],
        [0.0958],
        [0.7405],
        [0.7911],
        [0.1529],
        [0.5383],
        [0.7093],
        [0.1838],
        [0.6000],
        [0.8980],
        [0.2806],
        [0.9596],
        [0.3384],
        [0.2118],
        [0.5982],
        [0.2940],
        [0.0658],
        [0.4094],
        [0.7848],
        [0.0596],
        [0.3559],
        [0.7072],
        [0.3777],
        [0.5357],
        [0.2535],
        [0.6420],
        [0.7601],
        [0.4188],
        [0.1677],
        [0.4312],
        [0.2697],
        [0.7529],
        [0.0337],
        [0.1959],
        [0.0913],
        [0.6196],
        [0.5408],
        [0.3403],
        [0.2110],
        [0.5829],
        [0.6846],
        [0.9022],
        [0.8170],
        [0.2394],
        [0.6163],
        [0.1963],
        [0.9874],
        [0.7808],
        [0.8303],
        [0.2447],
        [0.9939],
        [0.8685],
        [0.3606],
        [0.2404],
        [0.8383],
        [0.4470],
        [0.0306],
        [0.5175],
        [0.9117],
        [0.0187],
        [0.4973],
        [0.8985],
        [0.6400],
        [0.3463],
        [0.1456],
        [0.3045],
        [0.1302],
        [0.3881],
        [0.3018],
        [0.2870],
        [0.6084],
        [0.4803],
        [0.0776],
        [0.4647],
        [0.5551],
        [0.6345],
        [0.4559],
        [0.5743],
        [0.0146],
        [0.6169],
        [0.0575],
        [0.2035],
        [0.4543],
        [0.3858],
        [0.3532],
        [0.6566],
        [0.2827],
        [0.6410],
        [0.9508],
        [0.0064],
        [0.5960],
        [0.5597],
        [0.1496],
        [0.6219],
        [0.6828],
        [0.9000],
        [0.7197],
        [0.5957],
        [0.5551],
        [0.3828],
        [0.7106],
        [0.2067],
        [0.4871],
        [0.7339],
        [0.0920],
        [0.3629],
        [0.3334],
        [0.6104],
        [0.6545],
        [0.9855],
        [0.1682],
        [0.2843],
        [0.6788],
        [0.0710],
        [0.4575],
        [0.6314],
        [0.6754],
        [0.4968],
        [0.0534],
        [0.1107],
        [0.9316],
        [0.0414],
        [0.7278],
        [0.9681],
        [0.6119],
        [0.0583],
        [0.5179],
        [0.6966],
        [0.4283],
        [0.3959],
        [0.7533],
        [0.5842],
        [0.8673],
        [0.7026],
        [0.8783],
        [0.4198],
        [0.2078],
        [0.9699],
        [0.4172],
        [0.2445],
        [0.6507],
        [0.0875],
        [0.5372],
        [0.7517],
        [0.8282],
        [0.6805],
        [0.1866],
        [0.8664],
        [0.8623],
        [0.6069],
        [0.8548],
        [0.9998],
        [0.1102],
        [0.4830],
        [0.2847],
        [0.4917],
        [0.5445],
        [0.3318],
        [0.8146],
        [0.3314],
        [0.5906],
        [0.0277],
        [0.1958],
        [0.4869],
        [0.7677],
        [0.8128],
        [0.2547],
        [0.8368],
        [0.9580],
        [0.3748],
        [0.8023],
        [0.3361],
        [0.5316],
        [0.4568],
        [0.7140],
        [0.3403],
        [0.2384],
        [0.4600],
        [0.9277],
        [0.9641],
        [0.6584],
        [0.6750],
        [0.0785],
        [0.4361],
        [0.7242],
        [0.2793],
        [0.4713],
        [0.0242],
        [0.8198],
        [0.7271],
        [0.8731],
        [0.9039],
        [0.7498],
        [0.7680],
        [0.3902],
        [0.2982],
        [0.3170],
        [0.4247],
        [0.7543],
        [0.4440],
        [0.2985],
        [0.9391],
        [0.9204],
        [0.3548],
        [0.9245],
        [0.1633],
        [0.7353],
        [0.5275],
        [0.5243],
        [0.6496],
        [0.1251],
        [0.7941],
        [0.8336],
        [0.1924],
        [0.6277],
        [0.2910],
        [0.5536],
        [0.4394],
        [0.6841],
        [0.8890],
        [0.3888],
        [0.0854],
        [0.8007],
        [0.6155],
        [0.3736],
        [0.9842],
        [0.5408],
        [0.0221],
        [0.6949]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [ True, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 1.9107,  0.0454],
        [ 1.4246,  0.0681],
        [-2.8463, -0.6833],
        ...,
        [ 0.8323,  2.5397],
        [-0.1457,  1.6798],
        [ 0.7927,  0.7674]]) torch.Size([9984, 2])
samples tensor([[ 2.6042e+00, -1.4496e+00],
        [ 1.0513e+00, -8.4349e-01],
        [ 2.5342e+00,  1.0227e+00],
        [ 4.1542e+00,  5.9749e-01],
        [ 1.8992e+00, -1.1540e+00],
        [ 1.9268e+00, -9.1223e-01],
        [ 1.8250e+00,  5.8396e-01],
        [ 2.1919e+00,  1.0435e+00],
        [ 2.1221e+00, -1.6983e-02],
        [ 3.9510e+00, -8.3803e-02],
        [ 1.9462e+00,  1.3549e+00],
        [ 2.3189e+00,  3.1638e-01],
        [ 4.6997e+00, -4.8014e-02],
        [ 3.9513e+00,  3.0180e-01],
        [ 1.0768e+00, -7.7335e-01],
        [ 1.2278e+00, -7.3012e-02],
        [ 2.6436e+00,  7.5959e-01],
        [ 1.6075e+00, -8.0281e-01],
        [ 4.7205e+00,  5.9395e-01],
        [ 2.6240e+00, -9.7499e-01],
        [ 8.9731e-01,  8.1150e-01],
        [ 3.6419e+00, -5.7176e-01],
        [ 2.5735e+00,  2.4680e-02],
        [ 1.8915e+00, -1.5777e+00],
        [ 2.3628e+00,  6.8664e-01],
        [ 2.0864e+00,  5.4159e-01],
        [ 1.7871e+00, -8.8223e-01],
        [ 2.5515e+00, -2.1845e-01],
        [ 8.6843e-01, -9.1649e-01],
        [ 2.3147e+00, -1.1955e+00],
        [ 2.2003e+00,  1.0785e+00],
        [ 3.1535e+00, -9.1649e-01],
        [ 1.0058e+00,  4.3986e-01],
        [ 1.9140e+00,  4.5783e-01],
        [ 3.2367e+00, -1.4102e+00],
        [ 6.1828e-01, -8.5051e-01],
        [ 1.1012e+00, -5.5409e-01],
        [ 3.6779e+00, -1.1648e+00],
        [ 6.0309e-01, -1.0012e-01],
        [ 1.6653e+00, -1.2674e+00],
        [ 1.0581e+00, -5.5236e-01],
        [ 3.2149e+00, -5.5492e-02],
        [ 2.5942e+00, -7.5595e-02],
        [ 2.6046e+00, -1.4758e-01],
        [ 1.9102e+00, -5.9775e-01],
        [ 7.0022e-01, -3.6506e-02],
        [ 3.0586e-01,  1.6291e+00],
        [ 2.0465e+00,  1.0376e+00],
        [ 3.3167e+00, -2.9043e-01],
        [ 1.7115e+00,  3.6580e-01],
        [ 1.9399e+00, -5.3446e-01],
        [ 9.0999e-01,  7.9957e-01],
        [ 1.9977e+00,  9.3724e-02],
        [ 2.1785e+00,  6.8509e-01],
        [ 2.1807e+00,  2.9298e-01],
        [ 1.7572e+00,  1.3410e+00],
        [ 1.4425e+00,  1.0049e+00],
        [ 2.7947e+00, -3.8877e-01],
        [ 2.7704e+00, -1.0677e+00],
        [ 2.6553e+00,  2.6068e+00],
        [ 2.5265e+00,  9.4926e-02],
        [ 2.6499e+00,  1.9561e+00],
        [ 3.1487e+00,  8.4965e-01],
        [ 1.4057e+00, -1.4259e-01],
        [ 1.6797e+00,  1.7982e-01],
        [ 1.8592e+00,  5.7409e-01],
        [ 1.4301e+00, -1.0280e+00],
        [-3.8347e-01,  1.6525e-01],
        [ 2.8505e+00,  5.9791e-01],
        [ 3.4237e+00,  3.7868e-02],
        [ 3.5538e+00, -3.1478e-01],
        [ 1.5532e+00,  1.1582e+00],
        [ 1.0615e+00, -5.1210e-01],
        [ 3.1058e+00,  9.2633e-01],
        [ 2.8770e+00,  1.4694e+00],
        [ 1.6454e+00,  1.0186e+00],
        [ 2.2003e+00, -4.3925e-01],
        [ 3.7442e+00, -6.6456e-01],
        [ 1.8468e+00,  7.6307e-01],
        [ 2.1580e+00,  5.8564e-01],
        [ 1.4617e+00,  6.3733e-01],
        [ 4.4767e+00,  1.4669e+00],
        [ 2.4884e+00,  1.5594e-01],
        [ 3.5352e+00, -3.2659e-01],
        [ 2.2056e+00,  2.2465e-01],
        [ 3.0220e+00,  1.1864e-01],
        [ 2.9049e+00,  5.1586e-01],
        [ 1.6735e+00, -1.9149e-01],
        [ 4.9301e+00,  2.2958e-01],
        [ 2.1438e+00, -7.6436e-01],
        [ 7.1652e-01, -1.0114e+00],
        [ 2.0462e+00, -4.2699e-01],
        [ 6.8319e-01, -5.8974e-02],
        [ 3.5891e+00, -1.9274e+00],
        [ 2.3323e+00,  4.4161e-01],
        [ 2.6206e+00, -5.4645e-01],
        [ 3.8424e+00, -1.6196e+00],
        [ 2.2104e+00,  5.8888e-01],
        [ 3.6120e+00, -1.2274e+00],
        [ 1.7967e+00,  6.6922e-01],
        [ 1.4960e+00, -4.3909e-01],
        [ 1.8257e+00, -1.6126e-01],
        [ 3.0592e+00,  8.0077e-01],
        [ 2.7477e+00, -1.5115e+00],
        [ 3.9208e+00, -2.6167e-01],
        [ 2.0500e+00, -9.8951e-01],
        [ 2.3499e+00,  4.9846e-01],
        [ 3.2877e+00, -1.6464e+00],
        [ 2.6948e+00, -9.7651e-01],
        [ 2.0129e+00,  4.8839e-01],
        [ 2.9282e+00, -4.9509e-01],
        [ 2.6989e+00,  8.4669e-01],
        [ 2.9794e+00,  7.4105e-01],
        [ 2.4417e+00, -1.3507e+00],
        [ 1.7151e+00,  3.1098e-01],
        [ 2.9236e+00,  3.5987e-01],
        [ 2.4049e+00, -1.9511e-01],
        [ 2.7024e+00,  7.3281e-01],
        [ 8.8184e-01, -5.6103e-01],
        [ 3.0856e+00,  1.7042e-01],
        [ 2.8568e+00,  7.7464e-01],
        [ 2.3357e+00, -2.1906e-01],
        [ 3.7158e+00, -5.2212e-01],
        [ 1.2439e+00, -8.3641e-01],
        [ 2.8486e+00,  1.8967e-01],
        [ 8.4452e-01, -1.1300e+00],
        [ 2.3591e+00, -1.3767e+00],
        [ 1.6382e+00, -7.1707e-01],
        [ 4.0456e+00,  2.2315e-01],
        [ 7.6835e-01,  1.4255e-01],
        [ 1.3807e+00, -9.5592e-01],
        [ 1.4477e+00, -6.2697e-01],
        [ 2.5389e+00, -8.4457e-01],
        [ 7.6253e-01,  8.7125e-01],
        [ 2.3991e+00,  1.7656e-01],
        [ 2.2424e+00,  1.5667e-01],
        [ 3.8075e-01, -1.8099e-01],
        [ 1.9358e+00,  9.5552e-01],
        [ 2.8433e+00, -9.3175e-01],
        [ 2.5121e+00,  1.6296e+00],
        [ 2.8445e+00, -3.1281e+00],
        [ 1.6745e+00,  9.5745e-01],
        [ 1.0975e+00, -5.2532e-01],
        [ 3.6458e+00, -6.1774e-01],
        [ 3.7015e+00,  8.0548e-01],
        [ 2.0604e+00, -1.2707e+00],
        [ 3.5175e+00, -2.3669e+00],
        [ 1.5418e+00, -4.2362e-01],
        [ 5.9735e-01,  4.6804e-01],
        [ 1.1346e+00,  8.8221e-01],
        [ 1.7907e+00,  3.9347e-01],
        [ 2.4115e+00, -6.6999e-01],
        [ 1.7835e+00, -8.8887e-01],
        [ 2.8346e+00, -5.5101e-01],
        [ 3.7253e+00, -5.3443e-01],
        [ 2.2460e+00,  2.7956e-01],
        [ 2.4336e+00, -1.4861e+00],
        [ 2.8815e+00, -1.4335e+00],
        [ 1.0486e+00,  1.0258e+00],
        [ 1.2125e+00,  8.2057e-01],
        [ 1.7265e+00,  1.0011e+00],
        [ 1.8186e+00,  1.1254e+00],
        [ 3.5175e+00,  1.3986e-01],
        [ 9.4082e-01, -9.3632e-01],
        [ 2.9099e+00, -1.8659e+00],
        [ 4.0070e+00,  3.7028e-01],
        [ 2.1784e+00,  2.5336e-01],
        [ 1.1887e+00, -2.2345e+00],
        [ 3.5544e+00, -4.9113e-01],
        [ 2.7813e+00,  7.6787e-01],
        [ 3.2560e+00,  4.8341e-01],
        [ 2.6008e+00, -4.2901e-01],
        [ 1.4921e+00,  6.3825e-01],
        [ 2.8053e+00,  8.8530e-02],
        [ 3.3611e+00, -9.1370e-01],
        [ 2.1949e+00, -8.9601e-01],
        [ 3.4342e+00,  1.3109e+00],
        [ 2.1813e+00,  4.7091e-01],
        [ 2.7704e+00, -2.9109e-01],
        [ 3.0844e+00, -2.1990e+00],
        [ 3.4467e+00, -5.0475e-01],
        [ 2.5971e+00,  1.0182e-01],
        [ 4.0222e+00, -2.9147e+00],
        [ 2.3133e-01, -9.4506e-01],
        [ 3.0179e+00, -1.2489e-01],
        [ 7.0606e-01, -1.4707e+00],
        [ 2.3505e+00, -5.5221e-02],
        [ 4.2797e+00,  1.6619e+00],
        [ 1.4939e+00, -1.7402e+00],
        [ 1.9737e+00, -1.0928e+00],
        [ 2.8444e+00, -2.6073e+00],
        [ 2.5242e+00, -2.1011e+00],
        [ 1.5474e+00,  3.0573e-01],
        [ 8.3977e-01,  1.1089e-01],
        [ 1.4855e+00, -4.3469e-01],
        [ 2.4767e+00, -9.8900e-01],
        [ 3.3612e+00, -1.1080e+00],
        [ 2.3689e+00,  1.5565e-01],
        [ 1.5601e+00, -3.6810e-01],
        [ 2.2134e+00,  3.7359e-01],
        [ 2.8787e+00, -9.8528e-01],
        [ 2.0584e+00,  4.1823e-01],
        [ 2.2504e+00,  6.3528e-01],
        [ 4.7004e+00, -8.2454e-01],
        [ 1.3574e+00, -5.0954e-01],
        [ 1.9302e+00, -1.2251e+00],
        [ 1.4902e+00,  1.1031e+00],
        [ 2.8450e+00,  1.6023e+00],
        [ 2.3056e+00,  1.6459e+00],
        [ 1.2085e+00, -2.1727e+00],
        [ 1.0084e+00, -1.0797e+00],
        [ 3.0182e+00, -4.3144e-01],
        [ 3.3464e+00,  7.9583e-01],
        [ 5.8528e-01,  2.0323e-01],
        [ 1.9903e+00, -7.2009e-01],
        [ 2.4652e+00, -1.1150e-01],
        [ 1.9213e+00,  1.3791e-01],
        [ 2.6338e+00, -1.8465e-01],
        [ 2.5239e+00, -1.8469e+00],
        [ 1.3663e+00, -9.8077e-01],
        [ 2.5271e+00,  3.8454e-01],
        [ 2.6294e+00,  8.8766e-01],
        [ 4.7398e+00, -2.3283e+00],
        [ 3.4204e+00, -2.5390e-02],
        [ 2.2984e+00,  1.4006e+00],
        [ 4.3952e+00, -6.6069e-01],
        [ 2.5789e+00,  2.4957e-01],
        [ 3.7670e+00,  1.2617e-01],
        [ 1.9500e+00, -2.1182e-01],
        [ 8.4636e-01,  1.3778e-01],
        [ 3.7497e+00, -4.3354e-01],
        [ 3.5826e+00, -1.1341e+00],
        [ 3.4701e+00, -7.8835e-01],
        [ 2.3154e+00,  8.6931e-01],
        [ 6.0742e-01,  1.5952e+00],
        [ 2.1839e+00, -2.5440e-01],
        [ 1.7999e+00, -3.0603e-01],
        [ 1.9031e+00, -1.1451e+00],
        [ 1.5975e+00, -1.5217e+00],
        [ 1.8680e+00, -9.8447e-01],
        [ 4.1627e+00,  1.4700e+00],
        [ 2.2031e+00, -3.6975e-01],
        [ 3.1543e+00, -1.6625e-01],
        [ 1.3204e+00, -1.3641e+00],
        [ 4.6415e+00, -7.3796e-01],
        [ 2.3985e+00, -5.8678e-01],
        [ 2.7564e+00, -3.4336e-02],
        [ 2.0020e+00,  2.7541e-03],
        [ 1.7732e+00, -1.9650e-01],
        [ 3.4695e+00, -9.7171e-01],
        [ 2.0746e+00,  1.2712e+00],
        [ 1.4844e+00,  1.3446e+00],
        [ 8.6967e-01,  6.7957e-01],
        [ 2.6697e+00, -6.8598e-01],
        [ 3.2701e+00, -4.2439e-01],
        [ 2.0472e+00, -4.8200e-01],
        [ 4.7346e-01, -8.2082e-01],
        [-3.7845e-01, -7.0053e-02],
        [ 2.5993e+00, -8.2360e-01],
        [ 3.0706e+00,  8.0829e-01],
        [ 4.4538e+00,  4.8948e-01],
        [ 4.3196e+00,  2.2696e-01],
        [ 3.7050e+00,  1.0713e-01],
        [ 3.4725e+00, -1.5638e+00],
        [ 3.1317e+00,  3.6318e-01],
        [ 3.2349e+00, -1.5738e-01],
        [ 2.6056e+00, -7.7249e-01],
        [ 1.2843e+00,  2.5492e-01],
        [ 1.4723e+00,  1.1765e+00],
        [ 3.2031e+00, -6.3489e-01],
        [ 2.2796e+00,  2.3002e-01],
        [ 1.5794e+00, -7.1935e-01],
        [ 2.2051e+00, -5.6554e-01],
        [ 2.0034e+00, -5.8623e-01],
        [ 2.5969e+00, -1.4272e+00],
        [ 2.3246e+00, -1.3620e-01],
        [ 1.1267e-01,  4.7927e-01],
        [ 2.1406e+00,  1.1122e+00],
        [ 2.7624e+00, -1.0338e+00],
        [ 2.3900e+00, -2.0711e-01],
        [ 1.7202e+00, -2.3752e+00],
        [ 3.2788e+00, -1.0224e+00],
        [ 1.0759e+00, -1.1993e+00],
        [ 2.2929e+00, -3.7038e-01],
        [ 2.8437e+00, -1.6597e+00],
        [ 2.6937e+00,  4.4158e-01],
        [ 1.5526e+00, -5.3538e-01],
        [ 8.2894e-01,  1.9676e-01],
        [ 2.3513e+00, -4.0210e-01],
        [ 2.5547e+00, -1.1165e+00],
        [ 1.5624e+00,  3.4994e-01],
        [ 2.8453e+00,  5.4266e-01],
        [ 2.1371e+00,  5.0818e-02],
        [ 1.7051e+00, -2.8625e-01],
        [ 3.0177e+00,  2.4293e-02],
        [ 1.7647e+00, -3.7133e-01],
        [ 3.1057e+00, -7.3970e-01],
        [ 1.9404e+00,  3.9310e-01],
        [ 2.2872e+00, -1.1568e+00],
        [ 4.0304e+00,  9.1820e-02],
        [ 2.0813e+00, -1.3102e+00],
        [ 3.6297e+00,  2.0136e+00],
        [ 3.0170e+00,  5.2937e-01],
        [ 4.3269e+00, -3.2492e-01],
        [ 1.9891e+00,  6.2406e-02],
        [ 2.0692e+00,  3.6819e-01],
        [ 3.0797e+00,  1.1227e+00],
        [ 3.1613e+00, -8.7979e-01],
        [ 2.2060e+00,  6.9043e-01],
        [ 2.0416e+00, -9.2795e-01],
        [ 1.7313e+00, -1.4181e-01],
        [ 3.0921e+00, -5.9370e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.7709e-02, 1.5511e-01, 1.6176e-01,  ..., 6.4857e-01, 7.0064e-01,
         1.0000e+00],
        [3.9815e-03, 6.8253e-02, 6.8925e-02,  ..., 9.9772e-01, 9.9774e-01,
         1.0000e+00],
        [1.6320e-06, 1.5979e-01, 1.9948e-01,  ..., 9.5373e-01, 9.9988e-01,
         1.0000e+00],
        ...,
        [1.9567e-03, 2.0724e-03, 2.1235e-03,  ..., 9.9925e-01, 9.9927e-01,
         1.0000e+00],
        [2.0624e-03, 2.5707e-03, 5.0051e-03,  ..., 9.9391e-01, 1.0000e+00,
         1.0000e+00],
        [4.8200e-03, 4.8200e-03, 4.8248e-03,  ..., 9.8334e-01, 9.9996e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.8187],
        [0.0504],
        [0.5061],
        [0.0279],
        [0.0583],
        [0.1164],
        [0.1138],
        [0.2897],
        [0.7543],
        [0.0849],
        [0.6442],
        [0.1292],
        [0.3348],
        [0.9150],
        [0.8142],
        [0.7597],
        [0.1321],
        [0.5692],
        [0.8756],
        [0.9405],
        [0.5298],
        [0.3638],
        [0.4819],
        [0.5247],
        [0.5392],
        [0.9142],
        [0.9284],
        [0.3124],
        [0.8814],
        [0.0813],
        [0.2285],
        [0.6687],
        [0.7564],
        [0.0027],
        [0.1090],
        [0.2370],
        [0.6590],
        [0.0738],
        [0.9729],
        [0.7963],
        [0.3378],
        [0.0473],
        [0.9176],
        [0.3263],
        [0.0935],
        [0.6575],
        [0.2524],
        [0.3882],
        [0.0074],
        [0.7247],
        [0.7901],
        [0.3896],
        [0.8022],
        [0.6347],
        [0.5619],
        [0.2334],
        [0.4923],
        [0.4220],
        [0.6413],
        [0.4110],
        [0.4628],
        [0.7732],
        [0.5931],
        [0.6346],
        [0.6370],
        [0.2046],
        [0.9033],
        [0.7490],
        [0.8491],
        [0.2408],
        [0.9107],
        [0.8523],
        [0.8443],
        [0.1645],
        [0.2407],
        [0.9620],
        [0.6987],
        [0.9230],
        [0.7254],
        [0.5226],
        [0.2572],
        [0.5404],
        [0.8194],
        [0.4160],
        [0.6866],
        [0.9968],
        [0.4569],
        [0.2897],
        [0.3942],
        [0.8058],
        [0.8863],
        [0.1059],
        [0.3052],
        [0.4496],
        [0.4817],
        [0.9387],
        [0.3206],
        [0.6845],
        [0.9979],
        [0.2661],
        [0.0051],
        [0.2396],
        [0.3264],
        [0.6596],
        [0.4048],
        [0.0929],
        [0.5897],
        [0.8785],
        [0.2675],
        [0.3964],
        [0.6791],
        [0.0175],
        [0.2706],
        [0.9272],
        [0.8270],
        [0.5431],
        [0.7847],
        [0.9286],
        [0.2193],
        [0.3521],
        [0.0549],
        [0.4114],
        [0.9879],
        [0.9118],
        [0.1603],
        [0.8752],
        [0.9122],
        [0.0679],
        [0.8358],
        [0.6299],
        [0.1921],
        [0.2019],
        [0.2514],
        [0.3535],
        [0.7981],
        [0.3606],
        [0.5189],
        [0.6620],
        [0.3843],
        [0.5416],
        [0.9844],
        [0.5289],
        [0.4262],
        [0.7435],
        [0.8108],
        [0.4648],
        [0.9687],
        [0.1680],
        [0.2586],
        [0.0012],
        [0.4668],
        [0.9994],
        [0.4424],
        [0.3845],
        [0.3889],
        [0.8964],
        [0.7669],
        [0.7627],
        [0.7541],
        [0.6932],
        [0.2989],
        [0.6214],
        [0.0164],
        [0.8776],
        [0.6757],
        [0.5563],
        [0.6492],
        [0.3094],
        [0.3305],
        [0.5489],
        [0.9645],
        [0.2718],
        [0.3178],
        [0.5946],
        [0.7924],
        [0.8112],
        [0.0068],
        [0.7427],
        [0.3478],
        [0.1964],
        [0.0054],
        [0.0618],
        [0.4325],
        [0.3601],
        [0.2213],
        [0.3646],
        [0.1753],
        [0.2259],
        [0.4137],
        [0.1746],
        [0.5243],
        [0.0606],
        [0.3450],
        [0.5231],
        [0.2469],
        [0.7888],
        [0.7775],
        [0.7296],
        [0.0043],
        [0.2497],
        [0.4896],
        [0.8630],
        [0.0187],
        [0.7576],
        [0.8440],
        [0.9635],
        [0.2561],
        [0.4751],
        [0.9347],
        [0.1191],
        [0.4703],
        [0.0876],
        [0.1700],
        [0.1585],
        [0.6042],
        [0.2911],
        [0.2412],
        [0.3552],
        [0.5114],
        [0.0657],
        [0.4488],
        [0.4962],
        [0.7756],
        [0.9162],
        [0.8178],
        [0.0291],
        [0.1158],
        [0.6987],
        [0.5338],
        [0.6396],
        [0.4497],
        [0.4787],
        [0.3213],
        [0.7876],
        [0.2848],
        [0.0903],
        [0.1886],
        [0.8100],
        [0.7958],
        [0.6396],
        [0.0620],
        [0.8267],
        [0.3121],
        [0.6954],
        [0.3475],
        [0.1641],
        [0.1685],
        [0.0926],
        [0.3224],
        [0.8536],
        [0.8631],
        [0.3862],
        [0.2547],
        [0.9962],
        [0.4269],
        [0.9311],
        [0.2286],
        [0.4958],
        [0.2833],
        [0.7552],
        [0.4608],
        [0.2411],
        [0.8101],
        [0.2917],
        [0.5653],
        [0.3801],
        [0.0685],
        [0.4056],
        [0.6668],
        [0.9413],
        [0.2707],
        [0.1163],
        [0.8200],
        [0.1448],
        [0.6739],
        [0.0482],
        [0.6988],
        [0.4282],
        [0.2267],
        [0.5095],
        [0.0941],
        [0.0491],
        [0.2598],
        [0.1071],
        [0.3130],
        [0.1613],
        [0.7650],
        [0.0068],
        [0.9718],
        [0.1979],
        [0.4199],
        [0.8764],
        [0.3576],
        [0.2995],
        [0.3099],
        [0.3359],
        [0.5178],
        [0.3669],
        [0.5876],
        [0.7011],
        [0.6440],
        [0.9495],
        [0.1088],
        [0.7525],
        [0.6026],
        [0.5925],
        [0.6861],
        [0.4366],
        [0.9195],
        [0.1668],
        [0.5746],
        [0.5466]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False,  True],
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 3.7652,  1.7633],
        [ 3.4599,  0.4480],
        [ 4.1341,  2.1321],
        ...,
        [-0.7013,  0.1884],
        [ 2.3236,  1.9197],
        [-1.2032,  1.2192]]) torch.Size([9984, 2])
samples tensor([[ 2.9952, -1.0862],
        [ 1.4273,  0.2182],
        [ 3.4027, -0.0802],
        [ 1.2499,  0.7111],
        [ 3.8468, -0.5971],
        [ 2.7606, -0.6305],
        [ 3.8465, -0.8395],
        [ 1.1333,  0.9986],
        [ 2.7170, -0.4703],
        [ 1.4879,  0.1437],
        [ 1.8775,  0.3976],
        [ 3.2659,  0.0739],
        [ 2.2845, -0.9248],
        [ 0.8568,  0.0685],
        [ 1.6192,  0.1177],
        [ 1.3677,  0.3289],
        [ 2.6127,  0.6180],
        [ 2.2968,  0.8999],
        [ 2.2909, -0.5680],
        [ 1.1085,  0.1085],
        [ 4.7850, -3.4998],
        [ 2.9989,  0.9320],
        [ 1.4950,  0.6227],
        [ 1.0852, -1.6124],
        [ 1.7908, -0.7279],
        [ 3.1961,  0.3506],
        [ 2.9120, -0.0344],
        [ 2.6435, -0.5491],
        [ 0.8096,  1.5642],
        [ 1.3947,  0.3305],
        [ 3.1328,  0.7572],
        [ 1.5822,  1.3093],
        [ 0.4280, -0.1310],
        [ 2.7352, -0.4554],
        [ 1.9264, -0.8222],
        [ 1.1851,  1.3581],
        [ 2.6658, -0.6803],
        [ 4.6541, -0.2798],
        [ 2.8093,  1.2265],
        [ 3.5428,  0.3318],
        [ 4.5960, -1.1362],
        [ 2.7326, -0.2217],
        [ 1.3521, -1.0868],
        [ 1.4440,  0.2901],
        [ 1.8934,  0.0829],
        [ 0.7464, -0.9529],
        [ 1.5011,  0.3542],
        [ 1.7767,  0.3896],
        [ 2.3515,  1.1554],
        [ 1.5895, -0.1956],
        [ 1.6355,  0.0786],
        [ 0.8787, -0.9338],
        [ 1.5970, -0.3445],
        [ 2.7360, -0.2856],
        [ 3.4694, -0.0837],
        [ 2.6843, -0.5910],
        [ 2.2367,  0.1539],
        [ 3.3523,  0.9816],
        [ 1.7946,  0.5980],
        [ 1.9733, -0.3315],
        [ 1.4469, -1.5918],
        [ 2.8716, -0.8145],
        [ 4.3617, -0.7914],
        [ 0.4413, -2.6331],
        [ 2.6590,  0.1472],
        [ 1.8563,  0.7432],
        [ 2.0976,  0.1747],
        [ 2.8380, -0.1669],
        [ 3.6208, -1.2359],
        [ 1.4226,  3.2702],
        [ 1.7964,  0.3757],
        [ 0.9719,  0.4728],
        [ 2.2827, -0.5273],
        [ 3.9776, -0.4067],
        [ 3.8576,  0.2676],
        [ 2.3530,  0.7376],
        [ 1.5861, -0.8609],
        [ 2.6017,  1.1066],
        [ 2.5674,  0.0933],
        [ 1.9027, -0.7221],
        [ 1.5627, -0.1184],
        [ 2.1380, -0.7703],
        [ 1.9647, -0.7728],
        [ 4.0398, -0.9418],
        [ 2.4769, -2.1454],
        [ 1.0219,  0.8022],
        [ 1.7345,  0.0897],
        [ 3.9900,  0.0538],
        [ 0.7604,  1.2944],
        [ 3.3798,  0.3234],
        [ 1.7547,  1.0200],
        [ 4.3116, -0.3197],
        [ 3.2325, -0.0727],
        [ 3.0642,  0.7998],
        [ 2.0691, -0.3080],
        [ 3.2140,  0.0742],
        [ 2.5829,  1.3456],
        [ 2.7834,  0.1352],
        [ 3.2707,  0.9722],
        [ 2.4784, -0.4668],
        [ 1.1466, -0.5296],
        [ 2.5863,  0.1934],
        [ 2.3576,  0.4486],
        [ 2.6519, -0.5139],
        [ 0.7537, -1.3295],
        [ 0.9004, -0.7694],
        [ 3.1478, -0.5590],
        [ 3.8085, -0.5786],
        [ 1.2310, -0.2513],
        [ 1.8048, -0.1910],
        [ 2.1348,  1.2608],
        [ 1.3846,  1.7270],
        [ 2.1881, -0.7942],
        [ 2.9268, -0.6503],
        [ 2.8910, -0.9518],
        [ 2.4120,  0.5134],
        [ 1.6585,  0.0753],
        [ 3.0613,  0.9955],
        [ 1.9072, -0.5136],
        [ 2.7189, -2.0318],
        [ 1.3660, -0.0783],
        [ 2.1423,  0.9600],
        [ 3.2166, -3.2106],
        [ 1.6462,  0.9878],
        [ 3.8222, -1.1055],
        [ 2.6115, -1.4342],
        [ 3.0667, -0.4853],
        [ 4.7574,  0.8712],
        [ 3.5145, -1.2031],
        [ 1.6293,  2.3807],
        [ 3.0658,  0.7727],
        [ 1.4911,  0.6453],
        [ 2.0301,  0.1865],
        [ 1.9746, -0.2835],
        [ 2.0853, -0.9746],
        [ 1.2056,  0.3994],
        [ 2.1257,  0.1357],
        [ 4.0617, -1.8080],
        [ 1.5489, -1.6231],
        [ 3.0942,  0.8717],
        [ 1.9009,  0.7867],
        [ 3.4770,  1.3732],
        [ 0.9736, -0.3509],
        [ 2.0073, -1.0761],
        [ 3.0215,  2.5827],
        [ 3.0109,  0.0771],
        [ 0.5571,  0.6573],
        [ 2.0313,  1.4272],
        [ 3.2574, -2.2257],
        [ 0.7411,  0.8039],
        [ 1.4282, -0.4328],
        [ 3.3028, -0.5181],
        [ 2.4454, -0.3989],
        [ 3.7152,  3.0625],
        [ 3.3404, -0.4426],
        [ 3.4423,  0.2102],
        [ 2.1598,  0.7568],
        [ 0.2660, -0.8571],
        [ 3.5916,  0.1223],
        [ 3.4472, -1.8100],
        [ 2.5454,  0.7566],
        [ 1.9484, -0.4918],
        [ 1.2038,  0.0091],
        [ 2.9408, -1.7127],
        [ 2.7193,  1.2274],
        [ 1.2832, -0.1470],
        [ 1.8798,  1.6000],
        [ 1.3180,  0.0316],
        [ 3.6624, -0.8660],
        [ 2.1255,  2.2051],
        [ 2.1707,  1.6028],
        [ 3.0182,  0.0946],
        [ 1.2738, -1.4633],
        [ 2.3967, -0.6454],
        [ 2.2378,  0.1378],
        [ 2.6749, -0.1563],
        [ 1.3258,  0.1412],
        [ 3.8576, -1.0062],
        [ 1.3007, -0.8418],
        [ 2.2742,  0.3500],
        [ 3.5391,  2.1910],
        [ 2.5781,  0.9898],
        [ 3.6436, -1.3915],
        [ 2.1585, -0.3897],
        [ 2.2877, -1.1320],
        [ 2.3334,  0.1004],
        [ 3.1971, -0.9501],
        [ 2.3547, -0.3575],
        [ 2.6892, -0.4705],
        [ 1.3389, -0.7279],
        [ 2.0136,  1.4965],
        [ 1.9559,  0.5896],
        [ 2.8679, -0.3928],
        [ 3.8447, -0.5424],
        [ 2.6332, -0.6287],
        [ 2.4689,  1.6043],
        [ 2.8509,  0.5685],
        [ 2.1884,  0.1993],
        [ 0.7771,  1.0364],
        [ 2.8785,  0.4683],
        [ 2.9707,  0.4510],
        [ 3.4285,  0.1447],
        [ 1.7482, -0.2957],
        [ 3.4545,  0.1711],
        [ 2.9630, -0.0814],
        [ 2.3594,  1.5340],
        [ 0.7758,  1.5405],
        [ 4.6180, -1.4085],
        [ 1.7411,  0.0638],
        [ 3.1144, -1.6683],
        [ 3.3934, -1.2663],
        [ 1.7104,  1.4756],
        [ 3.5152,  0.3447],
        [ 2.5540, -0.8615],
        [ 2.5628,  0.8618],
        [ 3.0243, -1.3827],
        [ 2.7805,  1.5500],
        [ 3.5285, -0.0103],
        [ 2.6680,  0.5504],
        [ 3.6198, -0.5692],
        [ 0.7526, -0.8611],
        [ 2.1456, -1.6468],
        [ 2.4896,  0.4989],
        [ 1.3722,  0.5351],
        [ 1.4184,  0.9133],
        [ 0.9099, -0.5482],
        [ 2.1302,  0.4331],
        [ 2.2890, -1.0109],
        [ 3.8425, -0.5788],
        [ 2.2814,  1.2714],
        [ 1.8938,  0.0590],
        [ 2.7470, -2.4510],
        [ 1.6399, -0.5341],
        [ 4.4454, -1.7279],
        [ 2.2990, -1.8792],
        [ 2.6799,  0.9307],
        [ 1.7319,  2.1287],
        [ 1.4454, -0.8846],
        [ 2.4793,  0.2558],
        [ 2.7702, -0.0650],
        [ 3.3109,  0.1989],
        [ 1.1138, -0.7247],
        [ 2.2939, -0.6997],
        [ 0.7806,  1.1867],
        [ 3.8503, -1.1382],
        [ 2.3780,  0.5753],
        [ 2.2378,  0.1261],
        [ 2.3090,  0.0939],
        [ 2.1884, -0.4262],
        [ 2.4949, -1.8268],
        [ 2.7617, -0.4481],
        [ 3.7880,  1.3879],
        [ 2.9941,  0.9134],
        [ 3.5486,  2.4444],
        [ 1.9023, -0.0560],
        [ 3.3412,  1.6310],
        [ 0.5363, -0.4195],
        [ 1.6879,  1.1740],
        [ 2.1551, -0.8660],
        [ 2.1057,  2.0761],
        [ 3.8369, -0.6811],
        [ 3.3803,  0.5401],
        [ 2.1532, -0.0623],
        [ 0.6029, -1.7327],
        [ 3.1263,  1.0081],
        [ 2.7858, -1.1567],
        [ 1.9201,  1.0414],
        [ 2.9241, -1.3890],
        [ 1.5669,  1.5193],
        [ 2.1186,  0.2558],
        [ 3.2931, -0.2742],
        [ 3.0269, -0.4697],
        [ 2.0364,  0.3754],
        [ 2.7134, -1.4778],
        [ 2.1564,  0.2741],
        [ 2.5481,  0.7634],
        [ 1.3914, -0.8258],
        [ 2.4283,  0.0598],
        [ 2.5144,  0.5984],
        [ 2.2701,  1.3919],
        [ 3.2452,  0.4352],
        [ 3.5869, -1.1362],
        [ 3.2525, -1.0119],
        [ 1.8785, -0.5878],
        [ 1.4012,  0.5854],
        [ 2.7979,  0.0937],
        [ 1.8194, -0.6679],
        [ 0.9872,  0.8435],
        [ 3.4329, -0.3060],
        [ 2.9934,  1.2392],
        [ 1.5803,  0.3156],
        [ 2.4062,  1.5642],
        [ 3.5750,  1.2494],
        [ 2.4400, -0.3427],
        [ 3.5520, -0.5656],
        [ 2.1085, -0.4127],
        [ 3.3105,  1.5867],
        [ 2.6539, -0.1363],
        [ 3.4125,  0.7517],
        [ 1.7529,  0.6254],
        [ 3.0962, -1.1991],
        [ 3.5522,  0.0942],
        [ 2.3300, -0.1432],
        [ 1.4858, -0.6154],
        [ 1.7292,  0.4575],
        [ 3.5772, -0.6090],
        [ 1.9623,  0.7855],
        [ 3.3971, -0.2633],
        [ 0.3628, -0.3553],
        [ 1.1335,  1.0272],
        [ 0.9061, -1.2872],
        [ 3.7348, -0.2579]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[7.8219e-03, 3.3860e-02, 3.3860e-02,  ..., 5.1607e-01, 5.1607e-01,
         1.0000e+00],
        [1.0493e-03, 1.1866e-03, 1.4165e-02,  ..., 8.9989e-01, 9.9694e-01,
         1.0000e+00],
        [5.6317e-02, 6.0984e-02, 7.2622e-02,  ..., 9.9350e-01, 9.9654e-01,
         1.0000e+00],
        ...,
        [7.5808e-09, 3.5348e-03, 4.6114e-01,  ..., 9.3117e-01, 9.5163e-01,
         1.0000e+00],
        [2.6927e-03, 2.6945e-03, 2.7432e-01,  ..., 8.8075e-01, 9.9956e-01,
         1.0000e+00],
        [3.5665e-01, 3.6573e-01, 3.6574e-01,  ..., 8.1538e-01, 9.9924e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.1832],
        [0.2478],
        [0.8597],
        [0.7866],
        [0.7421],
        [0.4785],
        [0.3269],
        [0.7327],
        [0.0114],
        [0.8252],
        [0.4683],
        [0.3325],
        [0.7850],
        [0.4739],
        [0.5421],
        [0.1546],
        [0.3862],
        [0.5695],
        [0.8941],
        [0.2997],
        [0.2649],
        [0.5276],
        [0.9479],
        [0.4496],
        [0.3862],
        [0.5412],
        [0.1671],
        [0.5646],
        [0.1445],
        [0.0191],
        [0.6624],
        [0.5385],
        [0.7729],
        [0.3949],
        [0.9292],
        [0.5450],
        [0.8517],
        [0.4808],
        [0.4878],
        [0.8175],
        [0.2433],
        [0.1151],
        [0.3079],
        [0.2333],
        [0.8478],
        [0.2687],
        [0.0453],
        [0.8641],
        [0.9082],
        [0.6559],
        [0.5860],
        [0.3232],
        [0.5628],
        [0.6335],
        [0.7705],
        [0.9478],
        [0.9176],
        [0.1220],
        [0.4301],
        [0.7979],
        [0.9837],
        [0.6883],
        [0.5065],
        [0.5035],
        [0.9536],
        [0.5982],
        [0.5463],
        [0.6702],
        [0.1982],
        [0.8094],
        [0.2883],
        [0.5920],
        [0.3699],
        [0.7933],
        [0.4885],
        [0.9141],
        [0.0288],
        [0.0719],
        [0.2020],
        [0.8459],
        [0.9417],
        [0.7660],
        [0.3011],
        [0.2869],
        [0.9306],
        [0.2336],
        [0.5946],
        [0.7806],
        [0.8152],
        [0.3334],
        [0.5289],
        [0.6504],
        [0.6440],
        [0.0814],
        [0.6502],
        [0.6516],
        [0.6938],
        [0.5389],
        [0.5976],
        [0.1374],
        [0.1640],
        [0.9282],
        [0.0268],
        [0.8798],
        [0.7668],
        [0.4519],
        [0.9498],
        [0.9737],
        [0.3227],
        [0.1417],
        [0.7186],
        [0.7668],
        [0.0172],
        [0.3059],
        [0.1081],
        [0.7833],
        [0.2309],
        [0.7685],
        [0.7088],
        [0.3732],
        [0.5476],
        [0.8016],
        [0.9569],
        [0.8087],
        [0.0385],
        [0.9648],
        [0.4256],
        [0.4489],
        [0.1051],
        [0.2934],
        [0.1442],
        [0.7329],
        [0.2177],
        [0.9538],
        [0.8919],
        [0.3991],
        [0.0700],
        [0.3329],
        [0.1524],
        [0.4426],
        [0.6916],
        [0.3297],
        [0.1987],
        [0.8401],
        [0.1239],
        [0.4210],
        [0.8885],
        [0.5517],
        [0.2547],
        [0.0162],
        [0.4693],
        [0.2618],
        [0.3514],
        [0.9731],
        [0.4882],
        [0.1720],
        [0.8215],
        [0.8492],
        [0.9346],
        [0.0183],
        [0.9978],
        [0.2336],
        [0.8945],
        [0.1844],
        [0.8353],
        [0.6834],
        [0.1720],
        [0.4597],
        [0.4047],
        [0.2846],
        [0.8777],
        [0.2568],
        [0.6578],
        [0.2645],
        [0.8147],
        [0.7817],
        [0.5196],
        [0.3147],
        [0.4388],
        [0.4394],
        [0.2191],
        [0.5501],
        [0.2805],
        [0.5709],
        [0.8372],
        [0.8436],
        [0.8264],
        [0.1796],
        [0.6292],
        [0.3052],
        [0.9531],
        [0.2539],
        [0.9577],
        [0.5165],
        [0.5623],
        [0.1363],
        [0.6963],
        [0.2866],
        [0.0621],
        [0.0606],
        [0.3020],
        [0.4248],
        [0.1670],
        [0.4857],
        [0.4864],
        [0.6044],
        [0.0125],
        [0.1375],
        [0.0515],
        [0.1721],
        [0.2113],
        [0.3231],
        [0.1388],
        [0.5797],
        [0.4875],
        [0.3911],
        [0.2705],
        [0.6872],
        [0.4289],
        [0.7394],
        [0.7805],
        [0.3489],
        [0.9382],
        [0.2216],
        [0.9041],
        [0.8978],
        [0.1711],
        [0.2677],
        [0.9569],
        [0.1782],
        [0.6118],
        [0.5216],
        [0.8224],
        [0.9111],
        [0.6422],
        [0.0667],
        [0.7259],
        [0.7174],
        [0.1524],
        [0.1398],
        [0.3565],
        [0.8657],
        [0.5730],
        [0.9899],
        [0.6911],
        [0.1028],
        [0.6894],
        [0.7877],
        [0.6174],
        [0.6950],
        [0.3708],
        [0.6466],
        [0.6800],
        [0.4795],
        [0.3491],
        [0.6416],
        [0.5048],
        [0.3781],
        [0.1631],
        [0.2355],
        [0.7978],
        [0.0807],
        [0.2714],
        [0.5513],
        [0.3929],
        [0.3456],
        [0.4764],
        [0.1051],
        [0.3723],
        [0.9660],
        [0.6701],
        [0.3278],
        [0.8705],
        [0.9062],
        [0.1896],
        [0.7523],
        [0.1158],
        [0.1928],
        [0.7666],
        [0.3151],
        [0.7220],
        [0.2864],
        [0.1862],
        [0.7535],
        [0.5315],
        [0.8047],
        [0.4552],
        [0.4774],
        [0.0751],
        [0.7766],
        [0.6535],
        [0.2226],
        [0.9070],
        [0.5963],
        [0.7545],
        [0.9239],
        [0.6179],
        [0.2444],
        [0.0100],
        [0.4917],
        [0.3195],
        [0.7911],
        [0.7717],
        [0.5531],
        [0.2894],
        [0.3275],
        [0.0909],
        [0.2144],
        [0.2620],
        [0.0505],
        [0.4832],
        [0.4993]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False,  True,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 3.7588,  2.3660],
        [ 2.3851,  1.6753],
        [-3.1976,  0.8242],
        ...,
        [-1.6766, -1.1614],
        [ 2.6885,  0.4121],
        [-0.7690, -0.1165]]) torch.Size([9984, 2])
samples tensor([[ 2.4312e+00,  1.7555e-01],
        [ 3.3847e+00, -8.8001e-01],
        [ 6.3097e-01, -2.4619e-01],
        [ 3.0858e+00, -7.1434e-02],
        [ 1.8396e+00, -8.6225e-01],
        [ 3.1537e+00, -4.7060e-01],
        [ 3.5045e+00, -4.3078e-01],
        [ 2.3210e+00, -1.0115e+00],
        [ 1.9813e+00, -9.0364e-01],
        [ 2.0753e+00,  9.9933e-01],
        [-5.5097e-02, -3.0721e-02],
        [ 2.1968e+00, -1.1153e+00],
        [ 3.9285e+00, -1.9756e+00],
        [ 3.1277e+00,  4.4278e-01],
        [ 4.1212e+00, -2.6847e-01],
        [ 2.0677e+00, -1.7306e+00],
        [ 2.5629e+00,  9.5934e-01],
        [ 1.7087e+00, -5.1190e-01],
        [ 1.1244e+00, -8.5055e-01],
        [ 2.2078e+00, -1.9327e+00],
        [ 3.5908e+00, -2.0888e+00],
        [ 1.0708e+00, -2.3294e+00],
        [ 2.3610e+00, -6.2180e-01],
        [ 1.9010e+00, -1.3765e-01],
        [ 1.2693e+00, -1.6941e+00],
        [ 1.9936e+00,  6.6521e-01],
        [ 1.9013e+00,  7.0413e-01],
        [ 2.6312e+00,  4.3242e-01],
        [ 3.9232e+00, -9.3165e-01],
        [ 1.1315e+00, -2.2636e-01],
        [ 4.4538e+00,  6.0345e-01],
        [ 1.9626e+00, -1.7253e+00],
        [ 4.0078e+00, -1.1920e+00],
        [ 1.8011e+00,  1.0659e+00],
        [ 2.0990e+00, -1.7037e-01],
        [ 2.8604e+00, -1.5373e+00],
        [ 3.3216e+00,  1.6477e+00],
        [ 3.0627e+00, -6.7492e-01],
        [ 1.8901e+00,  9.9901e-01],
        [ 2.4203e+00, -1.2663e+00],
        [ 3.3165e+00, -1.7185e-01],
        [ 1.9362e+00,  6.9278e-01],
        [ 2.2198e+00, -1.1448e+00],
        [ 1.6543e+00,  1.7043e+00],
        [ 2.1787e+00,  3.1648e-01],
        [ 3.8973e+00,  1.9089e-01],
        [ 1.0435e+00, -5.5347e-02],
        [ 2.4027e+00, -1.7060e+00],
        [ 1.0224e+00,  2.7463e-01],
        [ 1.0151e+00,  1.1556e+00],
        [ 1.9029e+00, -4.1269e-01],
        [ 3.6447e+00,  1.4064e-01],
        [ 7.4991e-01,  1.3837e-01],
        [ 1.5746e+00, -1.4045e+00],
        [ 1.7493e+00, -8.7155e-01],
        [ 2.3916e+00,  8.3637e-01],
        [ 3.3436e+00,  4.1832e-01],
        [ 1.9485e+00,  1.3545e+00],
        [ 1.8005e+00, -1.0464e+00],
        [ 3.3971e+00,  7.3422e-01],
        [ 1.1038e+00,  7.4895e-01],
        [ 3.1039e+00,  1.8744e-02],
        [ 3.2469e+00, -7.1908e-01],
        [ 4.0728e+00,  6.0640e-01],
        [ 2.0189e+00,  8.0150e-02],
        [ 3.0900e+00, -1.5456e+00],
        [ 3.0144e+00,  6.1740e-01],
        [ 2.6567e+00, -3.6962e-01],
        [ 3.3376e+00,  1.2647e+00],
        [ 3.2425e+00,  1.8737e-01],
        [ 2.2136e+00,  8.0368e-01],
        [ 2.8200e+00,  8.3222e-01],
        [ 2.8947e+00,  1.2718e+00],
        [ 2.3586e+00,  4.8772e-02],
        [ 4.2629e+00, -7.9319e-01],
        [ 1.0194e+00,  5.2689e-01],
        [ 3.5836e+00, -3.9113e-01],
        [ 1.2598e+00,  2.9110e-02],
        [ 3.1182e+00, -4.5907e-01],
        [ 3.1940e+00,  6.2111e-01],
        [ 2.0449e+00,  3.9258e-01],
        [ 2.2271e+00,  2.2709e+00],
        [ 3.6268e+00, -1.2029e+00],
        [ 4.0089e+00,  2.9437e-01],
        [ 5.8396e-01, -1.1297e-01],
        [ 4.0875e+00, -2.4683e-01],
        [ 1.8525e+00,  9.8961e-01],
        [ 2.4258e+00,  1.5695e-01],
        [ 3.2627e+00, -1.1159e+00],
        [ 2.9474e+00, -6.0164e-01],
        [ 1.1665e+00, -2.1653e-01],
        [ 3.7017e+00,  1.4255e+00],
        [ 3.4385e+00,  1.3058e-01],
        [ 3.5547e+00,  6.9808e-01],
        [ 2.6846e+00, -3.4181e-02],
        [ 1.4556e+00, -3.8778e-01],
        [ 2.8339e+00, -1.3898e+00],
        [ 2.0918e+00,  1.9080e+00],
        [ 3.0725e+00,  1.6244e+00],
        [ 1.3910e+00, -1.8840e+00],
        [-1.1841e+00, -5.4764e-01],
        [ 3.7836e+00,  1.1325e+00],
        [ 1.6406e+00,  1.3465e+00],
        [ 9.4995e-01, -6.6508e-01],
        [ 2.4508e+00,  1.8686e-01],
        [ 1.7199e+00, -5.3127e-01],
        [ 3.7247e+00,  1.4112e-01],
        [ 2.3814e+00,  1.7017e+00],
        [ 1.4487e+00, -1.3886e-01],
        [ 1.5584e+00, -1.8177e+00],
        [ 2.0500e+00, -5.5059e-01],
        [ 3.0220e+00,  6.5052e-01],
        [ 4.3486e+00, -9.5523e-01],
        [ 4.4805e+00, -2.4870e-01],
        [ 2.5571e+00, -5.0547e-01],
        [ 3.4344e+00, -3.7785e-01],
        [ 1.0395e+00, -1.4474e+00],
        [ 3.3938e+00, -2.5924e+00],
        [ 2.7806e+00, -7.8692e-01],
        [ 4.1686e+00, -2.1921e+00],
        [ 3.2572e+00,  2.7586e+00],
        [ 1.1701e+00, -3.7402e-01],
        [ 2.6859e+00,  1.5745e+00],
        [ 1.1426e+00, -8.9663e-02],
        [ 1.0716e+00, -1.6153e-01],
        [ 2.2919e+00, -6.5030e-02],
        [ 2.2787e+00, -1.1478e+00],
        [ 3.0295e+00, -1.0083e+00],
        [ 2.5662e+00,  3.2678e-01],
        [ 1.7469e+00,  3.7807e-01],
        [ 1.9634e+00,  1.9165e+00],
        [ 2.7492e+00,  4.4846e-02],
        [ 1.9418e+00,  5.2567e-01],
        [ 1.3498e+00, -3.4796e-01],
        [ 2.7318e+00, -6.4319e-01],
        [ 2.5183e-01,  1.9270e-01],
        [ 1.7289e+00,  3.0860e-01],
        [ 3.7901e+00,  2.8976e-01],
        [ 2.8722e+00, -5.5821e-01],
        [ 1.6035e+00,  3.1917e-01],
        [ 6.8396e-01, -8.5179e-02],
        [ 7.5286e-01,  4.2447e-01],
        [ 2.3101e+00,  9.3672e-02],
        [ 3.4840e+00, -6.3842e-01],
        [ 2.4712e+00,  6.8801e-01],
        [ 3.1352e+00, -2.5935e-01],
        [ 2.6109e+00, -1.5130e+00],
        [ 2.5449e+00,  6.3307e-01],
        [ 2.1482e+00, -3.1387e-01],
        [ 8.2475e-02,  1.6038e-01],
        [ 2.2745e+00, -1.0115e+00],
        [ 2.0451e+00, -9.1123e-01],
        [ 1.6348e+00,  1.6469e-01],
        [ 9.7812e-01, -6.2545e-01],
        [ 7.4635e-01, -2.6317e+00],
        [ 1.8412e+00, -2.6821e-01],
        [ 1.7233e+00,  4.0174e-01],
        [ 2.2724e+00, -5.3195e-01],
        [ 9.3418e-01, -4.4156e-01],
        [ 1.7260e+00,  1.4701e+00],
        [ 6.9052e-01,  1.1887e+00],
        [ 2.1306e+00,  1.6791e+00],
        [ 3.2164e+00,  5.9150e-01],
        [ 2.2410e+00, -1.8031e-01],
        [ 3.6494e+00,  5.2694e-01],
        [ 2.0607e+00,  7.2014e-02],
        [ 2.6238e+00,  2.3233e-01],
        [ 2.2781e+00,  4.9652e-01],
        [ 3.0273e+00,  1.7531e-01],
        [ 4.9635e+00, -1.0556e-01],
        [ 6.3580e-01, -6.2600e-01],
        [ 2.0838e+00,  5.5702e-01],
        [ 1.1163e+00, -9.4582e-01],
        [ 2.9684e+00, -1.2205e-01],
        [ 6.7835e-01,  6.1673e-01],
        [ 3.6828e+00, -7.1154e-02],
        [ 4.2096e+00, -2.4291e+00],
        [ 3.0955e+00, -1.2460e+00],
        [ 2.5100e+00,  3.6756e-01],
        [ 3.2601e+00, -7.0806e-01],
        [ 1.9557e+00,  1.7227e+00],
        [ 2.8571e+00, -5.6653e-01],
        [ 3.0052e+00,  1.0519e+00],
        [ 2.5309e+00, -2.5223e+00],
        [ 3.1989e+00,  4.0976e-04],
        [-2.0361e-01, -2.5346e-01],
        [ 2.0477e+00,  2.2585e-01],
        [ 2.4178e+00,  2.0193e+00],
        [ 2.3626e+00, -4.6282e-01],
        [ 2.6121e+00, -5.9601e-02],
        [ 2.3783e+00,  7.2936e-01],
        [ 3.2522e+00,  1.6154e-01],
        [ 8.2277e-01,  2.2641e+00],
        [ 2.5473e+00,  7.8647e-01],
        [ 3.9047e-01, -2.3478e-01],
        [ 2.0419e+00, -6.0717e-01],
        [ 3.4612e+00, -1.5166e+00],
        [ 2.4649e+00,  2.1185e+00],
        [ 3.1327e+00,  9.5875e-01],
        [ 1.8567e+00, -7.9201e-01],
        [ 1.9120e+00,  1.6978e+00],
        [ 5.9917e-01, -1.3818e+00],
        [ 2.0144e+00, -8.9961e-01],
        [ 2.9634e+00,  1.7454e+00],
        [ 2.3454e+00, -1.4828e+00],
        [ 1.2853e+00, -1.3923e+00],
        [ 9.5396e-01,  5.3710e-02],
        [ 1.9307e+00,  3.1064e-01],
        [ 3.3113e+00,  2.4639e+00],
        [ 2.0108e+00, -1.3567e-01],
        [ 2.8946e+00,  4.3050e-01],
        [ 2.4954e+00,  4.2148e-02],
        [ 2.1089e+00,  3.4401e-02],
        [ 8.2967e-01, -5.1864e-01],
        [ 2.4063e+00,  9.5084e-01],
        [ 2.6328e+00, -3.3959e-01],
        [ 2.7715e+00, -3.1970e-01],
        [ 1.9837e+00,  1.3082e+00],
        [ 4.0659e+00, -1.6417e+00],
        [ 3.3121e+00,  2.1338e-01],
        [ 1.9931e+00, -2.8100e+00],
        [ 3.8701e+00,  1.4516e+00],
        [ 1.4317e+00,  1.3186e+00],
        [ 3.3456e+00, -6.7934e-01],
        [ 2.3322e+00,  1.8209e+00],
        [ 2.8705e+00,  6.2054e-01],
        [ 2.7556e+00,  2.1015e+00],
        [ 2.8716e+00, -1.2385e+00],
        [ 1.7397e+00, -3.3432e-01],
        [ 2.1377e+00, -2.4455e+00],
        [ 4.1102e+00,  5.4473e-01],
        [ 1.4972e+00,  1.1803e+00],
        [ 4.1288e+00,  1.0342e+00],
        [ 3.6850e+00, -1.2111e+00],
        [ 1.9250e+00, -6.1972e-01],
        [ 2.3777e+00,  1.5009e+00],
        [ 1.3891e+00, -1.2208e-01],
        [ 2.8675e+00, -3.9024e-01],
        [ 9.2281e-01,  1.2407e+00],
        [ 4.0773e+00,  4.9057e-01],
        [ 3.7077e+00,  1.2386e+00],
        [ 3.3312e-02, -1.7263e+00],
        [ 2.0699e+00, -8.1459e-01],
        [ 2.0271e+00,  1.1151e+00],
        [ 2.7548e+00,  9.4252e-01],
        [ 2.0984e+00,  4.0350e-01],
        [ 2.5181e+00,  4.1609e-01],
        [ 2.1296e+00, -3.8541e-02],
        [ 4.1465e+00, -2.3936e-01],
        [ 1.9372e+00, -1.3744e+00],
        [ 1.2483e+00,  3.3924e-01],
        [ 1.4533e+00, -1.5256e+00],
        [ 1.5340e+00,  2.0843e-01],
        [ 2.7496e-01, -2.9180e-01],
        [ 5.6772e-01, -1.5792e+00],
        [ 8.7363e-01, -1.5101e-02],
        [ 2.5951e+00, -9.9796e-01],
        [ 3.4414e+00,  4.6904e-01],
        [ 2.3085e+00,  4.8992e-01],
        [ 3.0663e+00, -5.9098e-01],
        [ 2.3983e-01, -1.8970e-02],
        [ 3.3180e+00, -2.3160e+00],
        [ 1.5002e+00, -1.4109e+00],
        [ 2.5054e+00, -4.6364e-01],
        [ 4.1813e+00, -2.2486e-01],
        [ 3.6030e+00,  2.7145e-02],
        [ 3.0994e+00, -3.6393e+00],
        [ 2.1093e+00,  6.4116e-01],
        [ 2.9506e+00,  1.1066e-01],
        [ 2.3167e+00, -1.7617e+00],
        [ 3.0502e+00, -9.8700e-01],
        [ 1.5604e+00, -1.6374e+00],
        [ 3.1633e+00, -6.1596e-01],
        [ 2.5201e+00, -2.3338e-01],
        [ 2.9903e+00, -8.3184e-01],
        [ 9.3266e-01, -3.2016e-01],
        [ 2.6155e+00,  1.6472e+00],
        [ 2.5687e+00,  3.4367e-01],
        [ 2.5496e+00,  1.1961e+00],
        [ 8.1697e-01,  3.3816e-01],
        [ 2.6948e+00, -6.4277e-01],
        [ 3.2429e+00, -1.5001e+00],
        [ 1.6556e+00, -3.3857e-01],
        [ 3.4679e+00, -6.9329e-01],
        [ 1.4590e+00, -6.9176e-01],
        [ 2.7890e+00, -1.0634e+00],
        [ 4.3553e+00,  7.7961e-01],
        [ 2.8217e+00,  1.9112e-01],
        [ 2.5173e+00, -1.3542e+00],
        [ 3.5408e+00,  6.7350e-01],
        [ 1.2055e+00, -8.3769e-01],
        [ 2.6817e+00, -2.1447e+00],
        [ 2.7979e+00, -1.7105e-01],
        [ 3.9159e-01, -2.7754e-01],
        [ 1.3383e+00, -2.2139e+00],
        [ 1.2002e+00, -1.6005e-01],
        [ 1.6731e+00, -6.7375e-02],
        [ 1.8941e+00, -2.0555e-01],
        [ 1.5957e+00,  6.2620e-01],
        [ 3.1577e+00, -2.5145e-01],
        [ 3.7425e+00,  1.2068e+00],
        [ 1.0511e+00,  1.5226e+00],
        [ 3.4698e+00, -2.3224e+00],
        [ 3.4744e+00, -3.0785e-01],
        [ 2.1409e+00, -1.7861e+00],
        [ 2.6594e+00, -1.8287e+00],
        [ 3.7606e+00, -6.1912e-01],
        [ 2.5626e+00,  3.5665e-01],
        [ 2.2332e+00,  6.1253e-01],
        [ 2.3171e+00, -1.4612e-01],
        [ 3.4204e+00,  8.4991e-01],
        [ 8.9755e-01,  1.3082e-03]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[3.5359e-05, 1.1546e-02, 2.5151e-02,  ..., 9.7997e-01, 9.9029e-01,
         1.0000e+00],
        [1.0394e-01, 1.2660e-01, 1.3062e-01,  ..., 9.8731e-01, 9.9985e-01,
         1.0000e+00],
        [2.5046e-01, 2.5098e-01, 2.5924e-01,  ..., 8.8428e-01, 9.9961e-01,
         1.0000e+00],
        ...,
        [2.9732e-10, 4.3704e-03, 3.8974e-02,  ..., 9.9837e-01, 1.0000e+00,
         1.0000e+00],
        [4.4452e-04, 4.0721e-02, 4.7601e-02,  ..., 9.9529e-01, 9.9656e-01,
         1.0000e+00],
        [6.0668e-04, 1.2737e-03, 2.7009e-02,  ..., 9.9817e-01, 9.9830e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.7183],
        [0.8884],
        [0.9204],
        [0.9044],
        [0.7173],
        [0.9545],
        [0.8702],
        [0.4546],
        [0.3683],
        [0.9843],
        [0.6255],
        [0.6919],
        [0.4114],
        [0.8414],
        [0.5259],
        [0.1235],
        [0.5509],
        [0.0322],
        [0.0039],
        [0.6811],
        [0.6942],
        [0.0300],
        [0.7092],
        [0.5935],
        [0.4279],
        [0.3517],
        [0.1826],
        [0.6736],
        [0.7949],
        [0.6249],
        [0.6748],
        [0.8504],
        [0.0145],
        [0.1943],
        [0.6319],
        [0.8012],
        [0.9693],
        [0.7432],
        [0.5097],
        [0.2447],
        [0.6019],
        [0.3043],
        [0.9024],
        [0.9269],
        [0.6470],
        [0.6828],
        [0.9043],
        [0.7321],
        [0.3051],
        [0.7009],
        [0.5421],
        [0.6070],
        [0.4153],
        [0.5438],
        [0.2129],
        [0.8491],
        [0.7330],
        [0.0821],
        [0.1488],
        [0.4460],
        [0.1419],
        [0.9111],
        [0.2834],
        [0.2098],
        [0.7604],
        [0.5494],
        [0.6953],
        [0.8331],
        [0.0760],
        [0.4436],
        [0.9004],
        [0.1254],
        [0.4044],
        [0.7094],
        [0.2039],
        [0.4801],
        [0.4188],
        [0.1895],
        [0.7621],
        [0.9805],
        [0.2420],
        [0.9029],
        [0.0345],
        [0.4329],
        [0.4400],
        [0.5737],
        [0.0743],
        [0.6102],
        [0.7617],
        [0.4295],
        [0.7591],
        [0.1323],
        [0.4869],
        [0.1787],
        [0.2815],
        [0.4880],
        [0.4920],
        [0.3439],
        [0.8026],
        [0.7721],
        [0.6984],
        [0.3893],
        [0.6297],
        [0.3003],
        [0.0133],
        [0.7733],
        [0.9877],
        [0.6765],
        [0.2951],
        [0.7468],
        [0.1348],
        [0.0134],
        [0.4897],
        [0.2932],
        [0.7232],
        [0.4018],
        [0.5172],
        [0.1804],
        [0.8243],
        [0.0110],
        [0.7214],
        [0.0160],
        [0.9690],
        [0.0661],
        [0.8582],
        [0.2377],
        [0.1282],
        [0.4168],
        [0.8929],
        [0.4066],
        [0.8175],
        [0.2726],
        [0.7539],
        [0.9247],
        [0.7088],
        [0.0013],
        [0.6706],
        [0.9934],
        [0.4176],
        [0.7449],
        [0.3566],
        [0.7014],
        [0.9404],
        [0.2896],
        [0.8476],
        [0.1200],
        [0.2913],
        [0.5076],
        [0.7594],
        [0.2302],
        [0.2065],
        [0.1495],
        [0.9981],
        [0.1863],
        [0.7272],
        [0.9307],
        [0.4636],
        [0.5078],
        [0.9957],
        [0.4482],
        [0.1667],
        [0.9992],
        [0.4733],
        [0.7781],
        [0.9093],
        [0.2527],
        [0.9302],
        [0.2235],
        [0.0994],
        [0.5801],
        [0.1998],
        [0.5693],
        [0.8167],
        [0.2685],
        [0.8435],
        [0.7218],
        [0.5904],
        [0.6950],
        [0.3159],
        [0.3219],
        [0.6366],
        [0.2415],
        [0.7840],
        [0.1577],
        [0.4582],
        [0.4219],
        [0.7288],
        [0.4303],
        [0.6708],
        [0.7839],
        [0.7972],
        [0.9412],
        [0.9614],
        [0.9448],
        [0.6805],
        [0.1511],
        [0.1183],
        [0.2485],
        [0.9604],
        [0.9384],
        [0.2819],
        [0.9976],
        [0.8374],
        [0.5731],
        [0.8243],
        [0.8032],
        [0.2161],
        [0.9426],
        [0.9461],
        [0.3661],
        [0.7982],
        [0.6275],
        [0.4923],
        [0.0047],
        [0.9961],
        [0.3320],
        [0.4009],
        [0.2706],
        [0.0388],
        [0.0431],
        [0.8954],
        [0.6620],
        [0.6674],
        [0.5645],
        [0.0198],
        [0.8694],
        [0.0130],
        [0.5212],
        [0.7630],
        [0.4569],
        [0.1089],
        [0.0243],
        [0.0927],
        [0.7604],
        [0.8162],
        [0.8061],
        [0.7696],
        [0.2705],
        [0.5888],
        [0.4556],
        [0.6378],
        [0.3707],
        [0.5437],
        [0.1346],
        [0.4670],
        [0.5126],
        [0.0649],
        [0.8202],
        [0.7022],
        [0.6246],
        [0.9776],
        [0.1892],
        [0.1788],
        [0.9226],
        [0.8081],
        [0.5404],
        [0.7209],
        [0.3352],
        [0.1450],
        [0.1594],
        [0.8688],
        [0.6550],
        [0.7857],
        [0.1463],
        [0.1521],
        [0.8446],
        [0.8691],
        [0.0134],
        [0.7356],
        [0.7981],
        [0.2212],
        [0.8324],
        [0.6278],
        [0.4123],
        [0.7467],
        [0.8659],
        [0.5169],
        [0.6889],
        [0.9054],
        [0.2225],
        [0.4377],
        [0.2263],
        [0.5676],
        [0.8674],
        [0.4071],
        [0.1896],
        [0.9522],
        [0.1551],
        [0.1211],
        [0.6566],
        [0.0611],
        [0.8046],
        [0.1334],
        [0.2200],
        [0.4404],
        [0.9311],
        [0.8640],
        [0.1579],
        [0.3940],
        [0.3332],
        [0.0968],
        [0.9941],
        [0.0157],
        [0.5711],
        [0.3592],
        [0.9216],
        [0.1751],
        [0.5038],
        [0.2176],
        [0.5646],
        [0.8435],
        [0.2960]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False,  True, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-1.6479,  0.2295],
        [ 1.6360,  2.3120],
        [ 1.2292,  1.6280],
        ...,
        [ 2.7354,  1.8032],
        [-1.1907,  0.7326],
        [ 0.0988,  2.3570]]) torch.Size([9984, 2])
samples tensor([[ 3.4567e+00,  1.4552e+00],
        [ 3.6880e+00, -7.9217e-03],
        [ 2.0414e+00,  3.0894e-01],
        [ 3.4730e+00, -4.8907e-02],
        [ 2.5830e+00, -6.3850e-01],
        [ 2.0810e+00,  1.1815e+00],
        [ 2.9867e+00, -9.0312e-01],
        [ 2.7644e+00, -1.9348e+00],
        [ 4.3073e+00, -5.0855e-01],
        [ 3.6008e+00,  5.8360e-01],
        [ 2.2534e+00,  8.2204e-01],
        [ 4.5944e+00, -5.3046e-02],
        [ 3.6310e+00, -1.8216e+00],
        [ 2.4995e+00, -8.2070e-01],
        [ 2.1637e+00, -4.9929e-01],
        [ 3.2540e+00, -4.7367e-01],
        [ 2.7957e+00,  1.0014e+00],
        [ 3.0897e+00,  3.7827e-01],
        [ 6.2831e-01,  9.5748e-01],
        [ 1.8633e+00,  6.0844e-01],
        [ 2.6460e+00,  4.8831e-01],
        [ 1.9909e+00,  8.6637e-02],
        [ 2.7587e+00, -1.1915e+00],
        [ 2.4349e+00, -6.8945e-01],
        [ 1.3273e+00, -4.1693e-01],
        [ 2.0877e+00,  6.0859e-01],
        [ 2.4801e+00, -3.3452e-01],
        [ 3.3328e+00, -6.6265e-01],
        [ 2.0874e+00, -3.9942e-01],
        [ 3.9317e+00,  2.8289e-02],
        [ 1.2700e+00, -5.8706e-02],
        [ 2.5360e+00, -4.7741e-01],
        [ 2.7243e+00, -1.0269e-01],
        [ 2.3190e+00, -9.5850e-01],
        [ 2.4744e+00, -3.1946e-02],
        [ 3.7091e+00,  1.1333e-01],
        [ 2.8754e+00,  1.3256e+00],
        [ 1.2078e+00,  8.1279e-01],
        [ 2.0134e+00, -1.4129e+00],
        [ 1.0271e+00,  8.5834e-01],
        [ 2.4082e+00, -1.8034e+00],
        [ 2.8926e+00, -6.2979e-01],
        [ 1.0055e+00, -6.2087e-01],
        [ 2.7686e+00,  4.6082e-01],
        [ 2.6699e+00,  1.3944e-01],
        [ 2.9992e+00, -1.7060e+00],
        [ 2.2328e+00,  9.0794e-01],
        [ 1.5426e+00, -2.2851e-01],
        [ 3.0517e+00, -7.3135e-01],
        [ 1.4042e+00, -7.7765e-01],
        [ 1.9145e+00,  1.1145e+00],
        [ 3.0858e+00, -9.4590e-01],
        [ 2.3511e+00,  7.4137e-01],
        [ 2.0187e+00,  1.4195e-01],
        [ 2.2710e+00, -1.4541e+00],
        [ 1.8082e+00, -2.9937e-01],
        [ 3.2200e+00, -1.5378e+00],
        [ 1.3461e+00,  1.9496e-01],
        [ 3.9020e+00, -6.6685e-02],
        [ 2.9293e+00,  1.1790e+00],
        [ 3.1140e-02, -1.1065e+00],
        [ 3.1809e+00, -2.9335e+00],
        [ 1.6052e+00,  6.9121e-01],
        [ 1.3936e+00, -2.2921e+00],
        [ 1.6073e+00,  7.1867e-01],
        [ 1.4179e+00, -1.9944e-01],
        [ 1.6062e+00,  8.9394e-01],
        [ 2.6682e+00,  8.9195e-01],
        [ 2.1135e+00,  1.2602e+00],
        [ 4.1896e+00, -6.6332e-01],
        [ 2.4490e+00, -2.7805e-01],
        [ 1.7273e+00,  5.0680e-01],
        [ 2.8745e+00,  1.2989e+00],
        [ 3.8832e+00, -1.4613e+00],
        [ 1.2119e+00,  8.5432e-01],
        [ 2.1650e+00,  7.2547e-01],
        [ 1.8735e+00,  7.4634e-02],
        [ 3.6024e+00,  6.0463e-02],
        [ 3.1282e+00, -1.5305e+00],
        [ 2.0608e+00,  8.5730e-01],
        [ 2.8126e+00,  1.2137e+00],
        [ 1.3809e+00, -2.5495e-01],
        [ 2.3055e+00,  1.8283e+00],
        [ 5.6272e-01, -6.2259e-01],
        [ 4.2258e+00, -9.8498e-01],
        [ 2.6642e+00,  1.4029e+00],
        [ 1.1659e+00, -9.8209e-01],
        [ 4.1166e+00,  7.2524e-01],
        [ 3.4693e+00, -1.6652e-01],
        [ 1.7874e+00,  1.6716e+00],
        [ 3.1510e+00, -1.1016e-01],
        [ 3.1089e+00, -1.3060e+00],
        [ 3.2771e+00, -1.9388e-01],
        [ 1.2172e+00, -2.3747e-01],
        [ 2.8754e+00, -2.4995e-01],
        [ 2.3591e+00, -1.1767e-01],
        [ 1.0838e+00, -1.4866e+00],
        [ 3.1896e+00, -1.3312e+00],
        [ 2.9611e+00, -7.0170e-01],
        [ 1.1280e+00, -6.4487e-01],
        [ 3.3393e+00,  5.5501e-02],
        [ 2.0544e+00, -2.0575e-01],
        [ 3.5186e+00, -5.7861e-01],
        [ 3.4917e+00, -1.1094e+00],
        [ 1.8449e+00,  2.7385e+00],
        [ 4.6278e-01, -3.5952e-01],
        [ 2.1236e+00,  1.2994e+00],
        [ 3.1620e+00, -1.9652e-01],
        [ 2.7519e+00, -1.5726e+00],
        [ 2.6756e+00,  4.4851e-01],
        [ 2.3067e+00,  1.3583e-01],
        [ 1.0474e+00,  4.9125e-01],
        [ 3.1751e+00, -7.9804e-01],
        [ 1.0555e+00,  1.2564e-01],
        [ 2.5015e+00, -1.8700e+00],
        [ 3.8245e+00,  1.6533e+00],
        [ 2.8703e+00,  5.3258e-01],
        [ 1.4497e+00, -9.6449e-01],
        [ 2.2484e+00,  4.3679e-02],
        [ 1.9433e+00,  1.2060e+00],
        [ 1.0716e+00,  6.1291e-01],
        [ 3.4174e+00,  1.4179e+00],
        [ 2.9928e+00,  1.6830e+00],
        [ 2.8030e+00,  1.1639e+00],
        [ 2.6710e+00,  1.1518e+00],
        [ 8.1590e-01,  1.9542e-01],
        [ 4.0667e+00, -3.5272e-01],
        [ 2.4218e+00, -5.4849e-01],
        [ 3.7088e+00,  3.3172e-01],
        [ 2.7684e+00, -9.8245e-01],
        [ 2.1047e+00, -1.8105e+00],
        [ 3.5556e+00, -2.7479e-01],
        [ 2.8371e+00,  2.1823e-01],
        [ 2.6569e+00, -2.2819e-01],
        [ 2.3944e+00, -7.7268e-01],
        [ 4.0278e+00,  1.6355e+00],
        [ 3.7609e+00, -1.9487e+00],
        [ 2.9697e+00,  6.7132e-01],
        [ 3.7890e+00,  4.2191e-01],
        [ 3.4264e+00, -5.6567e-01],
        [ 1.8488e+00, -7.6448e-01],
        [ 1.7550e+00,  1.1755e+00],
        [ 1.4880e+00, -3.6590e-01],
        [ 2.8810e+00, -1.9533e-01],
        [ 1.7867e+00, -1.0726e-01],
        [ 1.0066e+00, -9.9895e-01],
        [ 2.1830e+00, -1.2036e+00],
        [ 3.4851e+00, -8.6662e-01],
        [ 2.9829e+00, -1.7051e-01],
        [ 4.5185e+00, -2.1583e+00],
        [ 3.0285e+00,  2.4131e-01],
        [ 1.1826e+00, -8.0249e-01],
        [ 3.1989e-01,  3.3927e-01],
        [ 2.8652e+00, -1.4373e+00],
        [ 1.9210e+00, -1.2904e+00],
        [ 3.0353e+00, -4.4095e-01],
        [ 2.0886e+00, -2.7746e-01],
        [ 3.3877e+00, -4.7921e-02],
        [ 3.3462e+00,  1.0043e+00],
        [ 2.1396e+00, -6.8547e-01],
        [ 3.9256e+00,  9.7077e-01],
        [ 2.0227e+00, -4.9915e-01],
        [ 2.9927e+00,  6.7816e-02],
        [ 1.5613e+00, -1.1958e+00],
        [ 2.7560e+00,  1.7392e-01],
        [ 3.2055e+00, -1.4444e+00],
        [ 2.5683e+00, -2.0444e-01],
        [ 3.5348e+00, -2.0684e+00],
        [ 1.6146e+00,  2.3813e-01],
        [ 3.4020e+00,  6.0926e-01],
        [ 3.5298e-01, -6.8941e-01],
        [ 1.7731e+00, -8.7128e-01],
        [ 2.2136e+00,  8.3606e-01],
        [ 2.0121e+00, -5.1170e-01],
        [ 2.6084e+00, -2.6417e+00],
        [ 1.5830e+00,  3.2409e-01],
        [ 1.1758e+00,  5.9727e-01],
        [ 2.8347e+00, -1.0514e+00],
        [ 2.0098e+00,  2.2255e-01],
        [ 3.4880e+00, -6.6496e-01],
        [ 2.2982e+00,  1.0240e-01],
        [ 2.5768e+00, -1.2480e-01],
        [ 3.9382e-01, -1.0288e+00],
        [ 1.9240e+00, -9.6880e-01],
        [ 3.1923e+00, -1.3479e+00],
        [ 1.3444e+00, -1.0048e+00],
        [ 1.6494e+00,  2.3344e-01],
        [ 2.7901e+00, -2.0152e+00],
        [ 4.1251e+00, -1.9675e-01],
        [ 1.6127e+00,  1.9279e-01],
        [ 2.1041e+00,  3.1719e-01],
        [ 3.0326e+00, -2.2220e+00],
        [ 7.5553e-01, -5.5758e-01],
        [ 2.3456e+00, -7.8179e-01],
        [ 2.6391e+00, -9.0838e-01],
        [ 2.3379e+00, -1.6884e+00],
        [ 2.8003e+00,  1.1005e+00],
        [ 5.4523e-01, -6.2320e-01],
        [ 2.3319e+00,  5.3285e-01],
        [ 1.8868e+00,  6.6219e-02],
        [ 7.6646e-01, -4.7930e-01],
        [ 2.1187e+00,  9.8558e-01],
        [ 2.6901e+00, -3.9654e-01],
        [ 1.3061e+00,  3.7091e-02],
        [ 3.1959e+00,  4.0031e-01],
        [ 4.8619e-01,  8.3730e-01],
        [ 4.4244e-01, -4.2380e-01],
        [ 3.8376e+00,  9.1702e-01],
        [ 2.9997e+00,  7.3122e-01],
        [ 2.2580e+00, -6.7977e-01],
        [ 3.5842e+00,  1.0513e+00],
        [ 1.7834e+00, -1.6751e-01],
        [ 2.8751e+00,  1.0499e-01],
        [ 1.5042e+00,  1.4758e-01],
        [ 2.3134e+00,  8.1429e-01],
        [ 4.2056e+00,  8.1628e-02],
        [ 3.3664e+00,  6.6222e-01],
        [ 1.5002e+00,  6.7311e-01],
        [ 4.4449e+00,  9.8825e-01],
        [ 3.7455e+00,  1.3324e+00],
        [ 3.1724e+00,  6.3259e-01],
        [ 1.7658e+00, -1.3258e+00],
        [ 2.7334e+00, -4.8480e-01],
        [ 3.5234e+00, -7.9773e-01],
        [ 7.2987e-01, -4.4223e-01],
        [ 4.4623e+00, -1.1644e-01],
        [ 1.8294e+00,  1.1774e+00],
        [ 1.0275e+00, -1.2237e+00],
        [ 6.7150e-01, -2.3626e-01],
        [ 3.8931e+00, -9.9404e-01],
        [ 3.3560e+00,  1.3699e+00],
        [ 1.4816e-01, -4.7799e-01],
        [-6.1734e-01,  3.4413e-01],
        [ 2.4861e+00, -1.2015e+00],
        [ 2.3389e+00,  2.9245e-02],
        [ 2.1249e+00,  4.6333e-02],
        [ 3.2716e+00, -3.1660e+00],
        [ 1.1157e+00, -3.5521e-01],
        [ 2.2849e+00, -6.4577e-01],
        [ 2.2599e+00, -1.8498e-01],
        [ 1.9888e+00,  1.1764e+00],
        [ 2.0994e+00, -1.3519e+00],
        [ 1.8353e+00, -4.3618e-02],
        [ 1.1594e+00,  4.1946e-01],
        [ 1.6679e+00,  1.9112e+00],
        [ 4.5180e+00,  1.1139e-01],
        [ 1.9325e+00,  1.8409e-01],
        [ 4.0279e+00, -1.4250e-01],
        [ 1.3287e+00,  8.2690e-02],
        [ 1.0684e+00, -9.8048e-01],
        [ 2.6053e+00,  2.4171e-01],
        [ 2.1219e+00, -2.2376e-02],
        [ 3.0078e+00,  2.7731e-01],
        [ 1.3985e+00, -1.4289e-01],
        [ 1.3338e+00, -1.1790e+00],
        [ 1.9121e+00,  3.3354e-02],
        [-3.1300e-01, -1.3686e+00],
        [ 3.2818e+00, -1.6374e-01],
        [ 2.3198e+00,  5.9873e-01],
        [ 1.7958e+00, -4.2905e-01],
        [ 1.7733e+00, -1.4257e+00],
        [ 4.1008e+00, -7.3301e-01],
        [ 2.6814e+00, -3.6600e-01],
        [ 7.6710e-01,  2.8924e-01],
        [ 1.8282e+00, -1.4030e+00],
        [ 3.1065e+00, -2.1802e+00],
        [ 2.9815e+00, -4.1414e-01],
        [ 1.4501e+00, -1.9739e-01],
        [ 3.0099e+00, -1.5725e-01],
        [ 1.8753e+00, -4.9348e-01],
        [ 2.5145e+00,  2.4194e-01],
        [ 3.2844e+00,  2.2148e-01],
        [ 1.9619e+00,  4.7683e-02],
        [ 1.6683e+00, -6.1086e-02],
        [ 2.3100e+00,  2.5753e-01],
        [ 3.7590e+00, -1.8406e+00],
        [ 1.4919e+00, -1.8438e+00],
        [ 1.9487e+00,  6.0092e-01],
        [ 1.5658e+00, -2.8678e+00],
        [ 2.4781e+00,  1.6518e-01],
        [ 1.7647e+00, -4.9345e-01],
        [ 4.0584e+00, -1.7451e+00],
        [ 2.8408e+00, -2.3626e+00],
        [ 1.8063e+00, -1.1191e-01],
        [ 2.7133e+00, -7.2946e-01],
        [ 3.0024e+00,  1.2011e+00],
        [ 2.1803e+00, -4.6080e-01],
        [ 9.7589e-01,  1.8675e+00],
        [ 1.7222e+00, -3.5779e-01],
        [ 2.9970e+00, -2.4930e-01],
        [ 4.0747e+00,  1.4268e+00],
        [ 2.0343e+00,  1.6912e+00],
        [ 2.7911e+00, -5.1468e-01],
        [ 2.4613e+00, -1.7313e-02],
        [ 1.6646e+00,  8.6131e-01],
        [ 2.8848e+00, -2.2140e-01],
        [ 2.2899e+00, -8.2249e-01],
        [ 2.4406e+00, -1.5558e-01],
        [ 2.8145e+00, -6.9653e-01],
        [ 3.4887e+00, -3.5723e-01],
        [ 3.7759e-01,  4.2599e-02],
        [-2.7882e-01, -7.9728e-01],
        [ 2.8178e+00,  5.9704e-01],
        [ 2.2875e+00, -1.9701e+00],
        [ 2.8397e+00, -1.1967e+00],
        [ 1.6801e+00, -4.2064e-03],
        [ 1.9752e+00, -1.7543e+00],
        [ 3.1044e+00, -1.2175e+00],
        [ 2.7227e+00,  9.9896e-01],
        [ 2.6221e+00, -1.7397e+00],
        [ 5.9340e-01, -1.2074e+00],
        [ 1.7962e+00,  1.1241e+00]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[6.1802e-02, 6.1802e-02, 6.1803e-02,  ..., 8.1975e-01, 1.0000e+00,
         1.0000e+00],
        [8.2960e-05, 2.1281e-03, 1.0889e-02,  ..., 9.8656e-01, 9.8725e-01,
         1.0000e+00],
        [4.4877e-04, 3.7715e-03, 3.7902e-03,  ..., 9.6182e-01, 9.6827e-01,
         1.0000e+00],
        ...,
        [8.1340e-02, 1.1658e-01, 1.1676e-01,  ..., 9.9770e-01, 1.0000e+00,
         1.0000e+00],
        [6.3426e-08, 1.7719e-02, 3.6272e-02,  ..., 9.9872e-01, 1.0000e+00,
         1.0000e+00],
        [9.6729e-04, 9.6772e-04, 1.2273e-02,  ..., 8.1724e-01, 8.6160e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[5.2613e-01],
        [4.5516e-01],
        [6.0646e-01],
        [3.8505e-01],
        [1.6708e-01],
        [3.2892e-01],
        [9.6692e-01],
        [7.3104e-01],
        [5.3326e-01],
        [9.2708e-01],
        [4.3891e-01],
        [4.0451e-01],
        [7.8770e-01],
        [8.3291e-01],
        [7.7638e-01],
        [6.6582e-01],
        [7.1125e-01],
        [5.2091e-01],
        [7.0823e-01],
        [7.1671e-01],
        [3.9634e-01],
        [9.2987e-01],
        [1.6078e-01],
        [4.8171e-01],
        [4.6960e-01],
        [3.8201e-01],
        [4.2938e-01],
        [3.4550e-01],
        [7.3630e-01],
        [9.7434e-02],
        [5.4260e-01],
        [5.4021e-01],
        [5.5701e-01],
        [8.5849e-01],
        [3.1799e-01],
        [2.7855e-01],
        [2.9003e-01],
        [8.8759e-01],
        [8.8032e-01],
        [7.6009e-01],
        [6.7659e-01],
        [5.4887e-01],
        [9.9868e-01],
        [9.5407e-02],
        [8.0853e-01],
        [6.5139e-01],
        [8.2822e-01],
        [6.7177e-01],
        [4.8873e-01],
        [7.6757e-01],
        [1.6804e-01],
        [5.6033e-01],
        [8.1107e-01],
        [8.1845e-01],
        [3.8168e-01],
        [7.0205e-01],
        [7.0323e-01],
        [2.3525e-01],
        [7.9486e-01],
        [4.2244e-01],
        [8.7368e-01],
        [5.2165e-01],
        [5.8594e-02],
        [3.4994e-01],
        [7.1120e-01],
        [3.9287e-01],
        [1.0837e-01],
        [7.9898e-01],
        [3.2039e-01],
        [5.8402e-01],
        [1.3706e-01],
        [2.3139e-01],
        [2.0292e-02],
        [6.3401e-01],
        [8.7265e-01],
        [4.7800e-01],
        [9.4546e-01],
        [1.9345e-01],
        [8.8259e-01],
        [1.7264e-01],
        [4.2886e-04],
        [4.9556e-01],
        [7.9077e-01],
        [1.1977e-01],
        [7.7246e-02],
        [5.5694e-01],
        [8.9517e-01],
        [2.2661e-01],
        [7.5578e-01],
        [3.5797e-01],
        [3.4410e-01],
        [6.7766e-01],
        [2.9110e-01],
        [6.7305e-01],
        [3.9525e-01],
        [4.1215e-02],
        [8.6284e-01],
        [2.6184e-01],
        [1.9036e-01],
        [5.1805e-01],
        [4.8990e-02],
        [2.8267e-01],
        [4.5338e-01],
        [1.5260e-01],
        [3.8499e-01],
        [2.1344e-02],
        [4.5066e-01],
        [6.6112e-01],
        [1.4513e-01],
        [1.0997e-01],
        [2.6934e-01],
        [8.7892e-01],
        [6.2314e-01],
        [7.3754e-01],
        [2.9562e-02],
        [4.5966e-01],
        [6.9227e-02],
        [1.9237e-01],
        [4.2342e-01],
        [2.1241e-01],
        [1.2164e-01],
        [3.2897e-01],
        [8.6006e-01],
        [8.9637e-01],
        [1.3514e-01],
        [5.3308e-01],
        [4.2366e-01],
        [9.4112e-01],
        [7.6135e-01],
        [4.7405e-01],
        [8.1826e-01],
        [5.0854e-01],
        [8.6876e-01],
        [2.4601e-01],
        [8.2600e-01],
        [9.6243e-01],
        [2.1640e-01],
        [8.8086e-01],
        [6.0001e-02],
        [9.9842e-01],
        [9.9259e-02],
        [8.0165e-01],
        [8.8724e-01],
        [7.5733e-01],
        [6.2691e-01],
        [2.2041e-01],
        [1.1253e-01],
        [4.6847e-02],
        [1.8515e-01],
        [9.7336e-01],
        [2.0384e-01],
        [2.7578e-01],
        [2.1542e-01],
        [6.7180e-01],
        [7.8105e-01],
        [9.5787e-01],
        [3.2830e-01],
        [9.7462e-01],
        [3.5882e-01],
        [6.4222e-01],
        [3.5741e-01],
        [1.5435e-02],
        [8.7004e-01],
        [8.2177e-01],
        [7.2508e-01],
        [4.1000e-01],
        [3.4572e-01],
        [5.4057e-01],
        [4.9183e-01],
        [4.3581e-01],
        [3.0924e-01],
        [4.5954e-01],
        [4.9231e-01],
        [6.3539e-01],
        [9.0735e-01],
        [8.4775e-02],
        [3.3372e-03],
        [4.1116e-01],
        [6.1050e-02],
        [8.9116e-01],
        [6.1395e-01],
        [1.8212e-01],
        [8.2007e-01],
        [7.1532e-01],
        [3.2195e-01],
        [5.3967e-01],
        [1.0153e-01],
        [2.5049e-01],
        [1.7490e-02],
        [3.2963e-01],
        [7.3881e-01],
        [6.6731e-01],
        [4.3842e-01],
        [1.4249e-01],
        [9.2297e-01],
        [9.0623e-01],
        [5.1757e-01],
        [2.3453e-01],
        [9.9178e-01],
        [5.4343e-01],
        [7.9141e-01],
        [4.8173e-01],
        [3.1005e-01],
        [4.6247e-01],
        [9.2919e-01],
        [8.6323e-01],
        [2.6390e-01],
        [6.4234e-01],
        [9.1376e-01],
        [7.5121e-01],
        [4.4745e-01],
        [9.7219e-01],
        [6.9291e-01],
        [7.0572e-01],
        [4.2523e-01],
        [4.0466e-01],
        [6.0642e-01],
        [2.4068e-01],
        [9.0618e-01],
        [7.8630e-01],
        [4.7038e-01],
        [4.5283e-01],
        [7.5427e-01],
        [9.7650e-01],
        [6.6197e-01],
        [5.6345e-01],
        [3.0408e-01],
        [7.0103e-01],
        [3.5544e-01],
        [6.6308e-01],
        [4.3735e-01],
        [8.4075e-02],
        [2.4705e-01],
        [5.6926e-01],
        [8.1321e-01],
        [9.6026e-02],
        [8.5656e-01],
        [9.1918e-01],
        [1.0983e-01],
        [9.2366e-01],
        [3.2051e-01],
        [8.7737e-02],
        [8.9286e-01],
        [2.9622e-02],
        [1.4830e-01],
        [1.0815e-01],
        [3.9350e-02],
        [2.5077e-01],
        [9.8488e-01],
        [4.2937e-02],
        [5.3616e-02],
        [3.2361e-01],
        [4.1761e-01],
        [4.3419e-01],
        [1.6032e-01],
        [4.2656e-01],
        [4.3096e-01],
        [7.3966e-01],
        [9.1456e-01],
        [7.1302e-02],
        [9.4614e-01],
        [5.4972e-01],
        [9.2154e-01],
        [4.4624e-01],
        [4.6394e-01],
        [6.6167e-01],
        [8.9759e-01],
        [1.5267e-01],
        [3.4882e-01],
        [2.0467e-01],
        [5.1082e-02],
        [2.7043e-01],
        [9.9900e-01],
        [3.9846e-01],
        [3.0331e-01],
        [3.4011e-01],
        [4.0827e-01],
        [3.6855e-01],
        [4.2120e-01],
        [7.9991e-01],
        [7.5055e-01],
        [6.0239e-01],
        [3.8838e-01],
        [1.1033e-01],
        [6.1403e-01],
        [7.6617e-01],
        [1.8745e-01],
        [4.3858e-01],
        [6.9873e-01],
        [1.5091e-01],
        [1.8192e-02],
        [4.3818e-01],
        [5.9954e-01],
        [6.4163e-01],
        [8.4388e-01],
        [9.3404e-01],
        [4.0058e-01],
        [6.8101e-01],
        [4.3303e-01],
        [8.1436e-01],
        [2.9779e-01],
        [8.2584e-01],
        [8.9297e-02],
        [9.2222e-01],
        [9.7618e-01],
        [8.2668e-01],
        [7.5478e-01],
        [4.5382e-01],
        [5.2496e-01],
        [2.5056e-01],
        [7.8926e-01],
        [8.9486e-02]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 2.5857,  1.2894],
        [-3.5413, -0.1099],
        [-2.3857,  0.9843],
        ...,
        [ 0.9819,  1.1510],
        [ 2.3765,  0.9025],
        [ 3.1206, -2.2974]]) torch.Size([9984, 2])
samples tensor([[ 1.8616e+00, -8.8611e-01],
        [ 2.6299e+00, -2.0551e+00],
        [ 2.3886e+00, -8.1473e-01],
        [ 2.8907e+00, -2.0013e+00],
        [ 3.0510e+00,  7.0179e-01],
        [ 2.2422e+00,  1.5500e+00],
        [ 2.2505e+00,  9.3066e-01],
        [ 1.8608e+00, -1.3454e+00],
        [ 2.6543e+00,  3.5974e-01],
        [ 6.4221e-01, -1.1444e+00],
        [ 3.7129e+00, -1.3737e+00],
        [ 2.1191e+00,  2.9416e-01],
        [ 2.7738e+00, -9.6166e-01],
        [ 1.3567e+00,  1.6037e+00],
        [ 1.9312e+00,  5.7518e-01],
        [ 1.9850e+00, -1.4156e+00],
        [ 3.3750e+00, -2.4198e-01],
        [ 2.8330e+00,  1.6518e+00],
        [ 9.0365e-01, -1.4916e+00],
        [ 3.1516e+00, -1.5109e+00],
        [ 2.5307e+00, -1.0783e+00],
        [ 1.9311e+00,  8.5311e-02],
        [ 1.8698e+00,  1.4348e+00],
        [ 2.2955e+00,  6.4547e-01],
        [ 2.3617e+00, -3.0728e-03],
        [ 4.0511e+00,  1.1091e+00],
        [ 3.7999e+00, -2.5224e+00],
        [ 1.8855e+00,  1.1737e+00],
        [ 3.0169e+00, -4.6078e-02],
        [ 3.3351e+00,  1.9427e-01],
        [ 1.7693e+00, -1.7820e+00],
        [ 4.8944e-01, -3.4079e-01],
        [ 2.5427e+00, -1.1206e+00],
        [ 3.0444e+00, -9.8259e-01],
        [ 2.2243e+00, -3.2134e-01],
        [ 2.3434e+00, -1.6976e+00],
        [ 2.7639e+00, -3.5912e-01],
        [ 2.2953e+00, -7.6107e-01],
        [ 3.1205e+00, -8.0860e-01],
        [ 1.8851e+00,  7.3198e-01],
        [ 3.3835e+00,  5.5338e-01],
        [ 2.1148e+00, -1.0710e+00],
        [ 1.2014e+00, -3.2844e-01],
        [ 3.0481e+00,  3.8131e-01],
        [ 3.3904e+00, -1.5233e+00],
        [ 1.7336e+00,  1.2556e-01],
        [ 2.4449e+00, -1.6005e+00],
        [ 2.0193e+00, -1.2045e+00],
        [ 2.7704e+00,  3.1961e-01],
        [ 3.6896e+00,  1.4188e+00],
        [ 2.2914e+00, -1.1096e-01],
        [ 2.0266e+00, -5.9804e-01],
        [ 1.5071e+00, -3.7755e-01],
        [ 7.1552e-01,  2.1808e-01],
        [ 1.8347e+00, -1.0579e+00],
        [ 2.0173e+00, -5.1040e-01],
        [ 4.3750e+00, -1.3719e+00],
        [ 4.9193e+00,  2.3747e-01],
        [ 2.7146e+00, -1.1698e+00],
        [ 3.2562e+00,  9.8469e-02],
        [ 1.5885e+00, -2.9767e-01],
        [ 3.2680e+00, -1.0582e+00],
        [ 2.9435e-01,  1.0992e+00],
        [ 2.5537e+00,  3.4574e-01],
        [ 2.3961e+00, -4.1680e-01],
        [ 2.8740e+00,  2.0035e+00],
        [ 2.4535e+00, -1.3453e+00],
        [ 2.8067e+00, -1.0811e+00],
        [ 2.3146e+00, -3.8588e-01],
        [ 3.2507e+00,  2.2033e-01],
        [ 3.0089e+00,  1.2058e+00],
        [ 3.4366e+00,  8.9391e-01],
        [ 4.9147e-01, -3.4603e-01],
        [ 1.9505e+00, -1.3849e+00],
        [ 8.6355e-01,  1.2723e-01],
        [ 6.6515e-01, -9.2696e-01],
        [ 2.9750e+00,  1.4081e+00],
        [ 1.2405e+00, -3.8644e-01],
        [ 6.9251e-01, -5.9053e-01],
        [ 2.7869e+00,  1.1530e+00],
        [ 4.0224e+00, -7.4635e-01],
        [ 9.0815e-01, -5.0523e-01],
        [ 2.3845e+00,  2.3237e+00],
        [ 4.4671e+00, -4.2304e-01],
        [ 2.1522e+00,  1.3804e-01],
        [ 1.6305e+00,  6.6667e-01],
        [ 2.8308e+00,  2.0956e+00],
        [ 4.1165e+00,  3.5110e-01],
        [ 4.5903e+00, -5.9373e-01],
        [ 2.0751e+00,  1.2292e+00],
        [ 3.2683e+00, -1.1358e+00],
        [ 1.9763e+00,  1.9424e-02],
        [ 3.6969e+00,  2.4115e-01],
        [ 2.1114e+00, -2.4397e-01],
        [ 2.3513e+00, -8.4121e-01],
        [ 3.6763e+00,  8.2027e-01],
        [ 2.7479e+00,  9.4468e-01],
        [ 1.2965e+00, -3.8251e-01],
        [ 2.0030e+00, -1.0555e+00],
        [ 2.1925e+00, -1.5110e+00],
        [ 1.9609e+00, -6.5370e-01],
        [ 2.8829e+00, -8.4642e-01],
        [ 3.3404e+00,  5.9428e-01],
        [ 4.4678e+00,  4.4957e-01],
        [ 3.0944e+00,  3.4459e-01],
        [ 6.1926e-01, -3.3383e-01],
        [ 3.0753e-02,  2.2379e-01],
        [ 3.7790e+00, -2.2496e-01],
        [ 3.9448e+00,  4.0281e-01],
        [ 2.0760e+00, -5.5589e-01],
        [ 1.0995e+00,  7.6483e-02],
        [ 2.2823e+00, -1.0170e+00],
        [ 4.3522e+00, -3.2316e-02],
        [ 2.2895e+00,  4.7114e-01],
        [ 2.1883e+00, -3.7021e-02],
        [ 2.4231e+00, -1.2931e+00],
        [ 1.8333e+00,  6.1556e-01],
        [ 2.6073e+00,  1.1622e+00],
        [ 2.4660e+00, -4.7637e-01],
        [ 3.8983e+00, -2.2604e-02],
        [ 1.8933e+00,  3.0077e-01],
        [ 7.8297e-01, -2.0953e-01],
        [ 3.3182e+00,  4.4036e-01],
        [ 2.3751e+00,  6.3245e-02],
        [ 1.8841e+00, -4.5967e-01],
        [ 1.4242e+00,  8.4496e-01],
        [ 3.6130e+00,  1.2840e+00],
        [ 2.8555e+00, -1.8207e+00],
        [ 3.0938e+00, -4.1147e-01],
        [ 3.3840e+00, -9.4678e-01],
        [ 3.4544e+00, -1.2276e+00],
        [ 4.1599e+00,  5.6370e-01],
        [ 2.4147e+00,  7.2496e-01],
        [ 5.6563e-01,  2.6669e-01],
        [ 3.8557e+00,  3.5077e-01],
        [ 3.1940e+00,  5.7569e-01],
        [ 4.1209e+00,  1.7039e-01],
        [ 2.5526e+00, -2.1942e+00],
        [ 1.3150e+00,  7.2630e-01],
        [-1.6555e-01,  1.0041e+00],
        [ 2.1359e+00, -8.7109e-01],
        [ 2.0043e+00, -7.7110e-01],
        [ 1.4789e+00, -1.3004e-01],
        [ 1.6429e+00, -1.3270e+00],
        [ 3.1186e+00, -1.1103e+00],
        [ 1.9761e+00, -9.8991e-01],
        [ 2.3914e+00, -2.7372e-01],
        [ 4.3736e+00,  7.4278e-01],
        [ 1.8854e+00, -1.4722e+00],
        [ 9.3488e-01,  1.6436e-01],
        [ 3.2802e+00, -4.7274e-01],
        [ 4.4121e+00,  1.1208e+00],
        [ 2.9587e+00, -1.7206e+00],
        [ 3.3471e+00, -1.6893e+00],
        [ 3.7478e+00, -9.4949e-01],
        [ 3.3900e+00, -7.7844e-01],
        [ 2.5054e+00,  8.0795e-01],
        [ 3.5268e+00, -8.6234e-01],
        [ 2.9209e+00, -1.1964e-01],
        [ 3.1103e+00,  8.8759e-01],
        [ 2.2071e+00,  5.0589e-01],
        [ 3.8879e+00, -2.7422e-02],
        [ 2.5083e+00, -2.7225e-02],
        [ 2.9061e+00,  3.8858e-01],
        [ 7.4180e-01, -8.9862e-01],
        [ 1.5805e+00, -1.3521e-01],
        [ 2.6518e+00, -3.8531e-01],
        [ 2.3262e+00, -1.1400e+00],
        [ 2.9372e+00, -1.8845e-01],
        [ 2.3535e+00,  1.7045e+00],
        [ 2.3385e+00,  2.3848e-01],
        [ 4.2441e+00, -1.0279e+00],
        [ 9.4209e-01, -4.6633e-01],
        [ 4.6228e+00, -1.1867e+00],
        [ 3.2838e+00, -7.7649e-01],
        [ 2.5579e+00, -1.4860e+00],
        [ 7.8685e-01,  1.1450e+00],
        [ 2.7267e+00,  1.0688e+00],
        [ 2.3411e+00,  7.0225e-01],
        [ 2.0113e+00,  8.0777e-01],
        [ 1.8941e+00,  7.0274e-01],
        [ 3.7039e+00,  5.7771e-01],
        [ 4.9262e+00, -6.0117e-01],
        [ 1.8229e+00, -4.9001e-01],
        [ 3.6899e+00, -4.1721e-01],
        [ 1.9879e+00,  7.1605e-01],
        [ 3.2777e+00, -1.5564e+00],
        [ 2.4747e+00,  1.8786e-01],
        [ 4.5654e+00,  3.0488e-01],
        [ 2.1635e+00, -7.3464e-01],
        [ 1.2236e+00,  8.4081e-01],
        [ 4.0938e-01,  4.9532e-01],
        [ 2.3172e+00, -1.1511e-01],
        [ 3.5170e+00, -5.8678e-01],
        [ 2.3317e+00, -2.2710e-01],
        [ 2.2659e+00,  1.4232e-01],
        [ 3.2532e+00, -1.9552e+00],
        [ 3.0555e+00, -5.7729e-01],
        [ 1.3117e+00,  3.6015e-01],
        [ 3.0235e+00,  2.5600e-01],
        [ 6.5353e-01, -3.8660e-01],
        [ 2.3127e+00, -1.1180e+00],
        [ 1.6358e+00, -1.5857e-01],
        [ 3.0956e+00,  1.2732e+00],
        [ 3.5637e+00,  1.3591e+00],
        [ 2.3682e+00, -4.2592e-01],
        [ 2.7814e+00,  3.7535e-01],
        [ 2.1721e+00, -3.4882e-01],
        [ 3.1090e+00, -7.4556e-01],
        [ 3.6816e+00,  5.7636e-01],
        [ 3.6511e+00,  3.5716e-01],
        [ 2.1390e+00,  1.8337e-01],
        [ 3.0226e+00,  1.6705e-01],
        [ 2.0262e+00,  6.4598e-01],
        [ 2.6662e+00,  1.2563e+00],
        [ 2.5057e+00,  1.5154e+00],
        [ 3.3075e+00, -1.5425e+00],
        [ 1.4473e+00, -1.1209e+00],
        [ 1.7946e+00, -8.6565e-01],
        [ 3.0389e+00, -1.2577e+00],
        [ 1.3303e+00, -1.4957e+00],
        [ 1.5725e+00, -2.6543e-01],
        [ 3.0611e+00, -2.3702e+00],
        [ 4.3959e-01, -1.4403e+00],
        [ 4.6203e+00, -7.6325e-01],
        [ 2.1819e+00,  2.7190e+00],
        [ 2.5415e+00, -9.7832e-01],
        [ 3.2936e+00,  9.2364e-02],
        [ 3.0293e+00, -8.8562e-01],
        [ 3.1986e+00,  7.4631e-01],
        [ 2.6827e+00,  8.7890e-01],
        [ 4.1502e+00,  1.3476e+00],
        [ 2.7265e+00,  1.2929e+00],
        [ 2.1370e-01, -4.4642e-01],
        [ 4.9454e-01, -1.7895e+00],
        [ 2.7057e+00,  4.3336e-01],
        [ 1.6980e+00, -8.7312e-01],
        [ 3.0874e+00, -6.4791e-01],
        [ 2.2573e+00, -1.0846e+00],
        [ 1.6072e+00, -7.3014e-01],
        [ 3.5225e+00,  7.7718e-01],
        [ 7.8773e-01,  8.3977e-01],
        [ 4.8706e+00, -4.7442e-01],
        [ 2.6128e+00, -1.1130e+00],
        [ 4.5964e+00, -1.2843e+00],
        [ 2.0572e+00, -8.2181e-01],
        [ 2.0402e+00,  9.9764e-01],
        [ 1.3664e+00,  2.2737e-01],
        [ 2.3786e+00, -1.8102e+00],
        [ 1.8929e+00, -2.7582e-01],
        [ 5.6295e-01, -1.2771e+00],
        [ 1.8638e+00, -4.2227e-01],
        [ 1.3571e+00,  5.8736e-01],
        [ 3.0178e+00,  9.1251e-02],
        [ 3.2916e+00, -1.2415e+00],
        [ 4.7610e+00, -3.8410e-01],
        [ 1.6995e+00, -1.8484e-01],
        [ 1.2946e+00,  1.4677e-01],
        [ 9.0460e-01, -7.2740e-01],
        [ 1.4520e+00,  3.0846e-01],
        [ 3.3374e+00,  9.7952e-01],
        [ 3.6296e+00, -1.1146e+00],
        [ 5.4718e-01,  1.3537e+00],
        [ 2.6670e+00, -5.9918e-01],
        [ 2.3537e+00, -1.4082e+00],
        [ 1.4029e+00,  1.3615e+00],
        [ 8.7805e-01, -5.0400e-01],
        [ 2.5482e+00, -1.0446e+00],
        [ 1.3341e+00,  3.2078e-01],
        [ 7.3490e-01, -3.5387e-01],
        [ 1.0606e+00,  5.6427e-01],
        [ 1.5931e+00, -7.7991e-01],
        [ 2.9272e+00, -1.0953e+00],
        [ 1.2880e+00, -1.8394e+00],
        [ 1.0287e+00, -1.3109e+00],
        [ 2.2995e+00, -1.9631e+00],
        [ 2.0633e+00, -4.7448e-01],
        [ 2.3455e+00, -1.4261e+00],
        [ 1.7902e+00, -5.1366e-01],
        [ 3.5421e+00,  1.2081e+00],
        [ 2.7757e+00, -5.1091e-01],
        [ 4.1116e+00, -9.1917e-01],
        [ 1.9187e+00, -1.3897e+00],
        [ 2.1228e+00,  1.9428e+00],
        [ 2.1683e+00, -1.2765e+00],
        [ 4.1917e+00,  4.0950e-03],
        [ 2.5675e+00,  1.7181e+00],
        [ 2.2657e+00,  1.5759e+00],
        [ 2.6938e+00, -1.3721e-01],
        [ 2.7775e+00,  1.7776e-02],
        [ 3.0087e+00,  1.5985e+00],
        [ 1.7294e+00,  9.6804e-01],
        [ 2.0422e+00, -7.6454e-01],
        [ 2.1457e+00,  3.3076e-02],
        [ 2.6636e+00, -1.2711e-02],
        [ 2.1625e+00,  1.0429e+00],
        [ 3.3539e+00, -6.7054e-01],
        [ 1.0617e+00, -1.4600e+00],
        [ 3.1899e+00, -3.1582e-01],
        [ 5.9011e-01,  4.1462e-01],
        [ 1.0768e+00,  1.1856e-01],
        [ 1.7789e+00, -5.4115e-02],
        [ 2.8178e+00,  1.2112e+00],
        [ 3.3423e+00,  3.6996e-01],
        [ 3.0827e+00,  1.6320e+00],
        [ 2.9788e+00, -6.3303e-01],
        [ 2.6096e+00, -6.3097e-01],
        [ 2.2826e+00, -4.1838e-01],
        [ 4.6516e+00, -3.7813e-01],
        [ 3.7392e+00, -1.4341e+00],
        [ 2.2137e+00,  2.9286e+00],
        [ 2.1454e+00,  1.9618e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.7963e-03, 1.0522e-02, 2.1283e-02,  ..., 9.5995e-01, 9.6202e-01,
         1.0000e+00],
        [2.8651e-03, 7.3671e-02, 9.1382e-02,  ..., 9.9935e-01, 9.9935e-01,
         1.0000e+00],
        [5.4243e-02, 6.3254e-02, 6.8370e-02,  ..., 9.6109e-01, 9.9206e-01,
         1.0000e+00],
        ...,
        [7.2084e-03, 6.0351e-02, 6.0351e-02,  ..., 9.9800e-01, 9.9870e-01,
         1.0000e+00],
        [5.4912e-06, 2.4694e-01, 2.4694e-01,  ..., 9.9999e-01, 1.0000e+00,
         1.0000e+00],
        [1.3790e-02, 3.6968e-02, 3.8154e-02,  ..., 9.1670e-01, 9.1695e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.9257],
        [0.4203],
        [0.5223],
        [0.7590],
        [0.0318],
        [0.4400],
        [0.7571],
        [0.2636],
        [0.0862],
        [0.8832],
        [0.5741],
        [0.1334],
        [0.6567],
        [0.5190],
        [0.7153],
        [0.6211],
        [0.4909],
        [0.5955],
        [0.7305],
        [0.0425],
        [0.6114],
        [0.4095],
        [0.4002],
        [0.1760],
        [0.4213],
        [0.7328],
        [0.7397],
        [0.1580],
        [0.0545],
        [0.9880],
        [0.1660],
        [0.3612],
        [0.4537],
        [0.8705],
        [0.6760],
        [0.9638],
        [0.9384],
        [0.6019],
        [0.8451],
        [0.4677],
        [0.0258],
        [0.2333],
        [0.1110],
        [0.7989],
        [0.3178],
        [0.7704],
        [0.2658],
        [0.0302],
        [0.9776],
        [0.8067],
        [0.4893],
        [0.1712],
        [0.4375],
        [0.6929],
        [0.9429],
        [0.7136],
        [0.3567],
        [0.0033],
        [0.8715],
        [0.0099],
        [0.6838],
        [0.6083],
        [0.8043],
        [0.6660],
        [0.2751],
        [0.2872],
        [0.9701],
        [0.1285],
        [0.6366],
        [0.4567],
        [0.6544],
        [0.4086],
        [0.2576],
        [0.2614],
        [0.3593],
        [0.0084],
        [0.7249],
        [0.6799],
        [0.5166],
        [0.8823],
        [0.2755],
        [0.4391],
        [0.9225],
        [0.1525],
        [0.9144],
        [0.8025],
        [0.0906],
        [0.0784],
        [0.1386],
        [0.8957],
        [0.8894],
        [0.1725],
        [0.8689],
        [0.4087],
        [0.0080],
        [0.0159],
        [0.4757],
        [0.8717],
        [0.6175],
        [0.0327],
        [0.3806],
        [0.1995],
        [0.8244],
        [0.2170],
        [0.9172],
        [0.1764],
        [0.0076],
        [0.2061],
        [0.4910],
        [0.4976],
        [0.2645],
        [0.8341],
        [0.5509],
        [0.1207],
        [0.4144],
        [0.4326],
        [0.4268],
        [0.6630],
        [0.0776],
        [0.3734],
        [0.1534],
        [0.0282],
        [0.9712],
        [0.9332],
        [0.1426],
        [0.1477],
        [0.2691],
        [0.4474],
        [0.7103],
        [0.8744],
        [0.7015],
        [0.1529],
        [0.0584],
        [0.0967],
        [0.4512],
        [0.4961],
        [0.8307],
        [0.9750],
        [0.7541],
        [0.1877],
        [0.3458],
        [0.9707],
        [0.0496],
        [0.9545],
        [0.7118],
        [0.7404],
        [0.3549],
        [0.6208],
        [0.2095],
        [0.3556],
        [0.0516],
        [0.8335],
        [0.5872],
        [0.0569],
        [0.4868],
        [0.2736],
        [0.9445],
        [0.6392],
        [0.7600],
        [0.4944],
        [0.7611],
        [0.1398],
        [0.2461],
        [0.8983],
        [0.3745],
        [0.9296],
        [0.4728],
        [0.9100],
        [0.0491],
        [0.1933],
        [0.9258],
        [0.3841],
        [0.2365],
        [0.0373],
        [0.9299],
        [0.9078],
        [0.2827],
        [0.3159],
        [0.4762],
        [0.0059],
        [0.6308],
        [0.1682],
        [0.3536],
        [0.4521],
        [0.9433],
        [0.6725],
        [0.3287],
        [0.7434],
        [0.0786],
        [0.9875],
        [0.0170],
        [0.3107],
        [0.1204],
        [0.3942],
        [0.6673],
        [0.8753],
        [0.7528],
        [0.5277],
        [0.0356],
        [0.7346],
        [0.0800],
        [0.5274],
        [0.8035],
        [0.8719],
        [0.3753],
        [0.7057],
        [0.0060],
        [0.8595],
        [0.6685],
        [0.8247],
        [0.3644],
        [0.8515],
        [0.3399],
        [0.7845],
        [0.4467],
        [0.0446],
        [0.6434],
        [0.0299],
        [0.7347],
        [0.6737],
        [0.5897],
        [0.9848],
        [0.8787],
        [0.8922],
        [0.5290],
        [0.1744],
        [0.7804],
        [0.4117],
        [0.9415],
        [0.7301],
        [0.9537],
        [0.7363],
        [0.2074],
        [0.0587],
        [0.5470],
        [0.3587],
        [0.9355],
        [0.8603],
        [0.6043],
        [0.9364],
        [0.4484],
        [0.4643],
        [0.5653],
        [0.1295],
        [0.2336],
        [0.7516],
        [0.7529],
        [0.1917],
        [0.9096],
        [0.7734],
        [0.5940],
        [0.0023],
        [0.2675],
        [0.5020],
        [0.5336],
        [0.4672],
        [0.8204],
        [0.9598],
        [0.1081],
        [0.9155],
        [0.2060],
        [0.7798],
        [0.4855],
        [0.3665],
        [0.6423],
        [0.6660],
        [0.8354],
        [0.7027],
        [0.3923],
        [0.4725],
        [0.2232],
        [0.0066],
        [0.5629],
        [0.5596],
        [0.8045],
        [0.3455],
        [0.6670],
        [0.9283],
        [0.9063],
        [0.2359],
        [0.1200],
        [0.8993],
        [0.2556],
        [0.1482],
        [0.3586],
        [0.1690],
        [0.7954],
        [0.8541],
        [0.8722],
        [0.9706],
        [0.8079],
        [0.3705],
        [0.7679],
        [0.9757],
        [0.1406],
        [0.2061],
        [0.7459],
        [0.9258],
        [0.3443],
        [0.9764],
        [0.4673],
        [0.4567],
        [0.6760],
        [0.4874],
        [0.7033],
        [0.5605],
        [0.1725],
        [0.5735],
        [0.2036],
        [0.4222],
        [0.0808],
        [0.6861]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-0.4477, -0.3674],
        [ 1.3477,  1.3639],
        [ 0.5148,  0.0374],
        ...,
        [ 3.3531,  0.9324],
        [-0.6945,  0.5364],
        [ 2.4059,  0.4548]]) torch.Size([9984, 2])
samples tensor([[ 2.7215e+00, -1.2577e-01],
        [ 1.5943e+00,  1.0800e+00],
        [ 3.1751e+00, -4.3291e-01],
        [ 3.1867e+00, -1.7806e+00],
        [ 1.8649e+00,  8.2541e-01],
        [ 3.6881e+00,  4.1212e-01],
        [ 1.5400e+00,  2.1182e-01],
        [ 2.8723e+00,  1.8407e-02],
        [ 1.5569e+00,  5.0573e-01],
        [ 2.5848e+00,  7.8773e-02],
        [ 4.7573e+00, -3.4734e-01],
        [ 4.0076e+00, -2.1601e+00],
        [ 9.3856e-01, -1.2234e+00],
        [ 2.4052e+00, -1.5204e+00],
        [ 2.3117e+00,  5.5783e-01],
        [ 2.1146e+00, -8.2766e-01],
        [ 3.0305e+00, -1.1465e+00],
        [ 4.1469e+00,  7.8587e-01],
        [ 2.7988e+00,  3.2885e-01],
        [ 2.0837e+00,  1.1550e+00],
        [ 3.5224e+00,  5.6770e-01],
        [ 1.3158e+00,  5.1392e-01],
        [ 2.3827e+00,  8.0769e-01],
        [ 4.1543e+00,  5.6804e-01],
        [ 2.1656e+00,  1.6171e+00],
        [ 3.5246e+00, -2.1874e+00],
        [ 2.5801e+00,  1.5062e+00],
        [ 3.3777e+00, -8.8362e-01],
        [ 4.0287e+00, -8.5042e-01],
        [ 2.2197e+00,  6.3755e-01],
        [ 3.5449e+00, -1.3115e+00],
        [ 2.5224e+00, -3.7189e-01],
        [ 1.3456e+00, -2.2765e+00],
        [ 3.1927e+00,  2.6187e-01],
        [ 1.7362e+00, -1.7509e+00],
        [ 1.6095e+00, -1.4097e+00],
        [ 3.9496e+00, -2.9749e-01],
        [ 3.8747e+00, -2.4943e+00],
        [ 1.6024e+00, -8.6191e-01],
        [ 2.2976e+00,  1.7270e+00],
        [ 1.7960e+00, -7.6349e-01],
        [ 3.5895e+00,  4.9423e-01],
        [ 2.2252e+00,  6.6526e-01],
        [ 2.7706e+00, -4.5932e-01],
        [ 2.5426e+00, -3.2246e-01],
        [ 1.3984e+00, -1.8607e-01],
        [ 2.6678e+00,  1.2975e+00],
        [ 2.7466e+00, -4.5186e-01],
        [ 2.9620e+00,  5.8089e-01],
        [ 3.3531e+00, -4.2884e-01],
        [ 8.2482e-01, -2.2580e-03],
        [ 3.1831e+00, -5.1772e-01],
        [ 1.7756e+00,  2.3211e-02],
        [ 3.6375e+00,  4.9651e-01],
        [ 8.3189e-01,  2.9571e-01],
        [ 1.9227e+00, -1.3315e-01],
        [ 2.6919e+00, -5.1231e-01],
        [ 1.0257e-01, -3.6566e-01],
        [ 4.6874e+00,  5.5249e-01],
        [ 4.7906e+00,  9.1723e-01],
        [ 3.5748e+00, -1.0780e-01],
        [ 1.0658e+00, -4.7929e-02],
        [ 1.4611e+00,  2.1296e+00],
        [ 1.9722e+00,  1.7878e-01],
        [ 3.3454e+00, -2.7840e-01],
        [ 2.8987e+00, -4.5721e-01],
        [ 2.5226e+00,  2.7384e-01],
        [ 3.3462e+00, -1.5960e+00],
        [ 2.8871e+00, -7.6185e-01],
        [ 4.0303e+00,  1.4283e+00],
        [ 2.6595e+00,  2.5560e-01],
        [ 1.1406e+00,  3.0592e-01],
        [ 3.5396e+00, -3.4249e-01],
        [ 2.2405e+00,  5.9475e-01],
        [ 2.7970e+00,  3.7089e-01],
        [ 1.8196e+00,  5.0647e-01],
        [ 2.3845e+00,  4.1506e-01],
        [ 2.7805e+00, -7.2476e-02],
        [ 3.4606e+00, -1.1361e+00],
        [ 2.7076e+00, -1.1438e+00],
        [ 1.2267e+00, -3.2807e-01],
        [ 3.5933e+00, -1.4926e+00],
        [ 1.5938e+00,  1.5245e+00],
        [ 1.6830e+00,  6.2150e-01],
        [ 1.1157e+00, -1.5530e+00],
        [ 1.8377e+00, -3.7068e-01],
        [ 2.0011e+00,  1.3997e+00],
        [ 8.8802e-01,  6.4626e-01],
        [ 4.3395e+00,  4.4975e-01],
        [ 2.0234e-01,  1.0297e+00],
        [ 1.2143e+00, -3.1136e-01],
        [ 7.6806e-01, -4.3680e-01],
        [ 1.1996e+00, -2.0023e-01],
        [ 2.1796e+00, -1.2906e+00],
        [ 3.5214e+00,  3.6504e-01],
        [ 6.1522e-01,  7.7306e-01],
        [ 1.5548e+00,  1.4680e-01],
        [ 3.3327e+00,  5.9070e-01],
        [ 7.7554e-01, -8.8744e-01],
        [ 2.3545e+00,  1.6216e+00],
        [ 2.7694e+00, -1.7947e+00],
        [ 2.3739e+00,  8.5411e-01],
        [-7.9337e-03, -1.5831e+00],
        [ 2.4772e-01,  1.1742e+00],
        [ 2.8618e+00, -5.6091e-01],
        [ 1.5715e+00, -1.2052e+00],
        [ 3.9344e+00,  1.5632e+00],
        [ 1.3342e+00,  4.1818e-01],
        [ 3.1765e+00, -1.9910e+00],
        [ 2.2447e+00,  7.8366e-01],
        [ 2.7933e+00, -1.3193e+00],
        [ 2.5936e+00, -6.9330e-01],
        [ 2.1356e+00,  1.6395e+00],
        [ 1.7368e+00, -1.8556e-01],
        [ 2.7773e+00, -1.4099e-01],
        [ 1.9149e+00, -3.0785e+00],
        [ 3.1226e+00,  7.5754e-02],
        [ 3.8038e+00, -1.4835e+00],
        [ 3.0239e+00,  2.1521e-01],
        [ 1.0219e+00,  3.8196e-01],
        [ 2.3707e+00,  1.4084e+00],
        [ 2.2168e+00,  1.1930e-01],
        [ 1.4535e+00,  2.1510e+00],
        [ 1.5243e-01,  8.4456e-02],
        [ 2.8918e+00,  2.3242e+00],
        [ 2.9060e+00, -9.3352e-01],
        [ 3.9243e+00,  4.6936e-01],
        [ 2.9234e+00, -1.0442e+00],
        [ 2.6566e+00, -2.6414e-01],
        [ 3.7990e+00,  1.8842e+00],
        [ 1.0686e+00, -1.8850e-01],
        [ 2.4633e+00, -1.0872e+00],
        [ 2.4421e+00, -4.2961e-02],
        [ 3.8386e+00, -4.5354e-01],
        [ 3.4129e+00,  2.2247e+00],
        [ 1.5053e+00, -8.1677e-01],
        [ 1.3727e+00, -1.6470e-01],
        [ 2.9263e+00,  1.4342e+00],
        [ 2.0484e+00, -4.3081e-01],
        [ 1.0228e+00,  8.2831e-01],
        [ 2.2508e+00, -1.3111e+00],
        [ 1.6708e+00,  5.2151e-02],
        [ 3.3316e+00, -2.8949e-01],
        [ 5.0840e-01, -2.2015e-01],
        [ 2.5331e+00,  3.0157e-01],
        [ 2.1055e+00,  1.9219e-01],
        [ 2.3456e+00,  2.9315e-01],
        [ 1.5590e+00,  1.4686e+00],
        [ 2.3168e+00,  1.1793e-01],
        [ 1.4477e+00,  1.2674e+00],
        [ 2.0870e+00, -1.8488e+00],
        [ 1.8923e+00, -1.2878e+00],
        [ 9.6730e-01,  1.2587e-01],
        [ 1.2311e+00, -2.9348e-01],
        [ 1.6322e+00,  8.3465e-01],
        [ 4.0469e+00,  2.5035e-01],
        [ 4.1992e+00,  1.1662e+00],
        [ 2.8990e+00, -1.0367e-01],
        [ 1.7038e+00, -2.6095e-01],
        [ 3.6581e+00, -4.9485e-01],
        [ 1.3060e+00,  6.1179e-01],
        [ 3.1186e+00,  1.9248e-01],
        [ 2.1574e+00, -4.8878e-01],
        [ 1.4977e+00, -1.4062e-01],
        [ 3.2128e+00, -1.0364e+00],
        [ 1.9558e+00, -1.3255e-01],
        [ 1.5157e+00, -1.6310e+00],
        [ 3.4009e+00, -1.8500e+00],
        [ 3.1966e+00, -1.6587e+00],
        [ 3.1192e+00, -1.1161e+00],
        [ 1.2937e+00,  9.2648e-01],
        [ 1.9410e+00, -2.1440e+00],
        [ 1.8234e+00,  1.4348e+00],
        [ 4.7273e+00,  8.4111e-01],
        [ 5.4670e-01, -3.6654e-02],
        [ 3.1831e+00, -1.1601e-01],
        [ 2.4652e+00, -5.3227e-02],
        [ 1.9162e+00,  1.5824e+00],
        [ 3.4748e+00, -1.0362e+00],
        [ 2.8732e+00,  1.6690e+00],
        [ 1.2439e+00, -6.5118e-01],
        [ 3.5851e+00,  6.1965e-01],
        [ 1.6577e+00,  7.8812e-01],
        [ 2.4021e+00,  9.9529e-01],
        [ 9.6035e-01,  1.4586e-01],
        [ 3.0988e+00,  2.0523e-01],
        [ 3.6688e+00, -5.5109e-01],
        [ 3.2440e-01, -1.3341e+00],
        [ 2.1280e+00, -9.6322e-01],
        [ 7.5412e-01, -5.6391e-01],
        [ 1.5654e+00,  8.8418e-01],
        [ 3.4712e+00, -6.3376e-02],
        [ 1.2270e+00,  7.9490e-01],
        [ 3.8134e+00,  4.9484e-01],
        [ 3.2463e+00, -5.6404e-01],
        [ 3.7743e+00,  8.5685e-01],
        [ 2.5730e+00,  6.1610e-01],
        [ 3.1040e+00, -1.3785e+00],
        [ 2.2390e+00,  1.1859e+00],
        [ 3.2169e+00, -1.5975e+00],
        [ 1.2823e+00, -4.5043e-01],
        [ 3.4467e+00, -4.1555e-01],
        [ 3.4352e+00,  6.7942e-03],
        [ 2.9096e+00, -8.6035e-02],
        [ 3.6182e+00, -1.4725e+00],
        [ 2.1004e+00,  8.5502e-01],
        [ 1.7327e+00,  8.4537e-01],
        [ 3.0275e+00,  5.0852e-01],
        [ 7.5907e-01, -1.1464e+00],
        [ 1.0776e+00, -2.3277e+00],
        [ 1.8420e+00, -5.0442e-01],
        [ 2.7565e+00, -1.1959e+00],
        [ 2.9451e+00,  5.9262e-01],
        [ 2.7784e+00, -1.0290e+00],
        [ 1.8137e+00,  1.7259e+00],
        [ 1.4616e+00,  2.6020e+00],
        [ 1.2629e+00,  2.6906e-01],
        [ 2.7539e+00, -3.5441e-01],
        [ 4.8035e+00, -1.5040e+00],
        [ 2.6078e+00, -4.5499e-01],
        [ 2.1881e+00, -6.6610e-01],
        [ 1.2795e+00, -2.8988e-01],
        [ 3.6260e+00, -4.1558e-01],
        [ 3.9588e+00, -3.6157e-01],
        [ 3.4234e+00,  8.8083e-01],
        [ 1.6045e+00, -9.4308e-01],
        [ 2.7498e+00, -2.1745e-01],
        [ 1.9773e+00, -2.4230e-01],
        [ 1.5254e+00, -1.2729e+00],
        [ 1.5897e+00, -1.1535e-01],
        [ 1.6692e+00,  8.7677e-01],
        [ 1.9285e+00, -1.5508e+00],
        [ 1.0391e+00, -1.7053e+00],
        [ 7.0641e-01, -4.4402e-01],
        [ 3.4658e+00, -6.9393e-01],
        [ 2.1945e+00, -1.2796e+00],
        [ 6.4028e-01, -6.7304e-01],
        [ 2.7105e+00, -3.8011e-01],
        [ 1.3736e+00, -6.9892e-01],
        [ 2.9437e+00, -9.8246e-01],
        [ 2.4759e+00,  1.9234e-01],
        [ 2.2235e+00,  7.7299e-02],
        [ 2.2237e+00, -4.5264e-01],
        [ 1.6575e+00, -2.2951e+00],
        [ 2.4750e+00, -1.8328e-01],
        [ 1.4297e+00,  7.5167e-01],
        [ 1.1783e+00, -2.2256e+00],
        [ 3.2804e+00,  7.6666e-01],
        [ 1.6189e+00, -7.6835e-01],
        [ 2.7807e+00,  1.0803e-02],
        [ 1.6588e+00,  8.4008e-01],
        [-2.4437e-01, -1.1846e+00],
        [ 2.3785e+00,  7.4154e-01],
        [ 3.4482e+00, -5.1103e-01],
        [ 3.2046e+00,  9.6890e-01],
        [ 3.5000e+00, -1.5477e+00],
        [ 1.3797e+00,  1.3496e+00],
        [ 2.8197e+00,  8.6030e-01],
        [ 2.9137e+00, -1.8024e+00],
        [ 2.3433e+00, -1.5117e+00],
        [ 1.6235e+00, -1.3011e+00],
        [ 3.5380e+00,  9.0784e-01],
        [ 2.0232e+00, -6.0931e-01],
        [ 2.3198e+00, -1.7340e+00],
        [ 1.6904e+00, -4.6983e-01],
        [ 3.2097e+00, -1.8532e-01],
        [ 1.0260e+00,  2.2299e-01],
        [ 3.4906e-01, -7.1265e-01],
        [ 2.4928e+00, -1.1798e+00],
        [ 6.8037e-01, -9.8680e-02],
        [ 4.1496e+00, -9.0676e-01],
        [ 1.2005e+00,  7.1898e-01],
        [ 1.6687e+00,  4.7766e-01],
        [ 4.7244e-01,  7.5954e-01],
        [ 1.7568e+00, -6.6991e-02],
        [ 2.9431e+00, -1.9741e+00],
        [ 2.7501e+00,  1.0940e+00],
        [ 7.2520e-01, -5.0069e-01],
        [ 2.3246e+00,  8.4579e-01],
        [ 2.9917e+00, -2.5316e-01],
        [ 3.4417e+00, -6.2426e-01],
        [ 2.1233e-01,  1.3957e+00],
        [ 3.2275e+00,  8.8202e-01],
        [ 3.7894e+00,  1.5333e+00],
        [ 2.2501e+00,  3.3099e-01],
        [ 2.0778e+00, -2.4984e+00],
        [ 2.3976e+00, -1.3215e+00],
        [ 1.8443e+00, -1.7198e+00],
        [ 3.7181e+00, -5.0552e-01],
        [ 2.2198e+00,  2.3673e-01],
        [ 1.4100e+00, -3.9822e-01],
        [ 6.3302e-01, -1.2209e+00],
        [ 3.8584e+00, -2.6730e+00],
        [ 1.2826e+00, -8.0602e-01],
        [ 2.9659e+00, -1.0088e-02],
        [ 1.2501e+00,  1.0935e+00],
        [ 1.6906e+00,  8.6036e-01],
        [ 1.0108e+00, -8.6651e-01],
        [ 4.4807e+00, -1.1466e-02],
        [ 1.8760e+00,  8.9078e-01],
        [ 2.6381e+00, -1.3572e+00],
        [ 2.6019e+00, -6.3016e-02],
        [ 2.9000e+00, -6.7196e-01],
        [ 2.7161e+00,  6.9158e-02],
        [ 3.4699e+00, -6.1124e-01],
        [-4.8603e-01, -8.6333e-01],
        [ 1.5765e+00, -3.2122e-01],
        [ 1.9889e+00,  1.0030e-01],
        [ 2.8594e+00, -7.7936e-01],
        [ 2.6349e+00, -5.9992e-02],
        [ 2.4083e+00, -2.9546e+00],
        [ 2.0450e+00, -5.7169e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[4.8697e-10, 1.1030e-01, 1.1030e-01,  ..., 9.9541e-01, 9.9552e-01,
         1.0000e+00],
        [1.5312e-01, 1.5316e-01, 2.0265e-01,  ..., 9.9627e-01, 9.9667e-01,
         1.0000e+00],
        [5.1596e-03, 1.9103e-02, 1.9103e-02,  ..., 9.9714e-01, 9.9728e-01,
         1.0000e+00],
        ...,
        [5.0824e-06, 6.2010e-03, 2.2358e-02,  ..., 6.8734e-01, 7.7324e-01,
         1.0000e+00],
        [4.0256e-03, 1.0892e-02, 1.4011e-02,  ..., 8.2634e-01, 8.2634e-01,
         1.0000e+00],
        [1.5676e-02, 6.5597e-02, 7.1789e-02,  ..., 9.9950e-01, 9.9998e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.0957],
        [0.0592],
        [0.1456],
        [0.6692],
        [0.6175],
        [0.3609],
        [0.1008],
        [0.4906],
        [0.9877],
        [0.6593],
        [0.9677],
        [0.4237],
        [0.7858],
        [0.6959],
        [0.7331],
        [0.4523],
        [0.3777],
        [0.9570],
        [0.9198],
        [0.7025],
        [0.6490],
        [0.8782],
        [0.0847],
        [0.0436],
        [0.3458],
        [0.8110],
        [0.6279],
        [0.8933],
        [0.9138],
        [0.4408],
        [0.9536],
        [0.0711],
        [0.2472],
        [0.6690],
        [0.9300],
        [0.4894],
        [0.7697],
        [0.8985],
        [0.4935],
        [0.1529],
        [0.4722],
        [0.2434],
        [0.5772],
        [0.3814],
        [0.5461],
        [0.0645],
        [0.6058],
        [0.7546],
        [0.4673],
        [0.8192],
        [0.0516],
        [0.3840],
        [0.0278],
        [0.5638],
        [0.5837],
        [0.6805],
        [0.6877],
        [0.5954],
        [0.3541],
        [0.3478],
        [0.5502],
        [0.3916],
        [0.6880],
        [0.7336],
        [0.6893],
        [0.2252],
        [0.2173],
        [0.5513],
        [0.4143],
        [0.9585],
        [0.9273],
        [0.0367],
        [0.1860],
        [0.6774],
        [0.8229],
        [0.3028],
        [0.0538],
        [0.7460],
        [0.2319],
        [0.1476],
        [0.7407],
        [0.1946],
        [0.5159],
        [0.7975],
        [0.4218],
        [0.6981],
        [0.1599],
        [0.5973],
        [0.2873],
        [0.9437],
        [0.0461],
        [0.8628],
        [0.8258],
        [0.5976],
        [0.7008],
        [0.0579],
        [0.4342],
        [0.9582],
        [0.1971],
        [0.8754],
        [0.6450],
        [0.7895],
        [0.0852],
        [0.3064],
        [0.9404],
        [0.6729],
        [0.3398],
        [0.4396],
        [0.7528],
        [0.4390],
        [0.1010],
        [0.8536],
        [0.3708],
        [0.1305],
        [0.3219],
        [0.0075],
        [0.9319],
        [0.6298],
        [0.8294],
        [0.9247],
        [0.2627],
        [0.9050],
        [0.8221],
        [0.5333],
        [0.9887],
        [0.8880],
        [0.9953],
        [0.6721],
        [0.1442],
        [0.3283],
        [0.1368],
        [0.4618],
        [0.2907],
        [0.4003],
        [0.6482],
        [0.5261],
        [0.0668],
        [0.1231],
        [0.9629],
        [0.0779],
        [0.6134],
        [0.5222],
        [0.4685],
        [0.5500],
        [0.8981],
        [0.2025],
        [0.6713],
        [0.9856],
        [0.3248],
        [0.6525],
        [0.8378],
        [0.6230],
        [0.9923],
        [0.6455],
        [0.5147],
        [0.5217],
        [0.5841],
        [0.6436],
        [0.7372],
        [0.0585],
        [0.1025],
        [0.9484],
        [0.8144],
        [0.0602],
        [0.0915],
        [0.9703],
        [0.1517],
        [0.7086],
        [0.4877],
        [0.4609],
        [0.4563],
        [0.9689],
        [0.8836],
        [0.0274],
        [0.7991],
        [0.4802],
        [0.8841],
        [0.0890],
        [0.8510],
        [0.1472],
        [0.8368],
        [0.2457],
        [0.3683],
        [0.0620],
        [0.8941],
        [0.8996],
        [0.6546],
        [0.5591],
        [0.0803],
        [0.9781],
        [0.0313],
        [0.5101],
        [0.1100],
        [0.3611],
        [0.7537],
        [0.7493],
        [0.2313],
        [0.7495],
        [0.3213],
        [0.3314],
        [0.0950],
        [0.1800],
        [0.6535],
        [0.3602],
        [0.4162],
        [0.5679],
        [0.7662],
        [0.9812],
        [0.2226],
        [0.4087],
        [0.8783],
        [0.1614],
        [0.7575],
        [0.7992],
        [0.2627],
        [0.1583],
        [0.4485],
        [0.0609],
        [0.9059],
        [0.5573],
        [0.6520],
        [0.1534],
        [0.5245],
        [0.6482],
        [0.3982],
        [0.7089],
        [0.6688],
        [0.0296],
        [0.2409],
        [0.3207],
        [0.6956],
        [0.9262],
        [0.4947],
        [0.3219],
        [0.0969],
        [0.0413],
        [0.2574],
        [0.0160],
        [0.6900],
        [0.6859],
        [0.0115],
        [0.4763],
        [0.1090],
        [0.0684],
        [0.9602],
        [0.0471],
        [0.4444],
        [0.6184],
        [0.1890],
        [0.2413],
        [0.9161],
        [0.1365],
        [0.8109],
        [0.3382],
        [0.3531],
        [0.5515],
        [0.6156],
        [0.8453],
        [0.3814],
        [0.9668],
        [0.2756],
        [0.7389],
        [0.5725],
        [0.6968],
        [0.1650],
        [0.9593],
        [0.5670],
        [0.4476],
        [0.3750],
        [0.4813],
        [0.9928],
        [0.0885],
        [0.2401],
        [0.6219],
        [0.1965],
        [0.1863],
        [0.3609],
        [0.1280],
        [0.4744],
        [0.8843],
        [0.5025],
        [0.8608],
        [0.2119],
        [0.3121],
        [0.8722],
        [0.3853],
        [0.0387],
        [0.6378],
        [0.7772],
        [0.1267],
        [0.4834],
        [0.4319],
        [0.4253],
        [0.9284],
        [0.3641],
        [0.3981],
        [0.7266],
        [0.5048],
        [0.9735],
        [0.7169],
        [0.1289],
        [0.8358],
        [0.3072],
        [0.2543],
        [0.7767],
        [0.6305],
        [0.8202],
        [0.3255],
        [0.7525],
        [0.9706],
        [0.5142],
        [0.9353]]) torch.Size([312, 1])
mask tensor([[False,  True, False,  ..., False, False, False],
        [ True, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False,  True],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-3.9570,  0.5638],
        [ 2.1706,  0.3302],
        [-3.1424, -0.1032],
        ...,
        [-0.7391,  0.6996],
        [-0.5700,  0.7222],
        [-1.3413,  1.9923]]) torch.Size([9984, 2])
samples tensor([[ 2.1706e+00,  3.3024e-01],
        [ 8.6827e-01, -3.2541e-01],
        [ 2.8028e-01,  3.2546e-01],
        [ 3.5658e+00,  5.8616e-01],
        [ 2.6509e+00,  1.9419e+00],
        [ 2.8807e+00, -2.0194e-01],
        [ 7.3097e-01, -2.0313e-02],
        [ 1.7425e+00,  4.1770e-01],
        [ 1.9336e+00, -1.2109e+00],
        [ 3.1044e+00, -1.1602e+00],
        [ 1.2334e+00, -7.4907e-01],
        [ 7.1167e-01, -7.9428e-01],
        [ 2.5903e+00, -6.8262e-01],
        [ 1.1553e+00, -1.3188e-01],
        [ 3.4712e+00, -2.3074e-02],
        [ 1.9162e+00,  2.0603e+00],
        [ 1.0618e+00,  1.8707e+00],
        [ 8.7627e-01, -6.3667e-01],
        [ 1.7197e+00,  6.7641e-01],
        [ 1.6558e+00,  9.3212e-02],
        [ 3.5118e+00,  5.7338e-01],
        [ 2.2922e+00,  1.2673e+00],
        [ 4.0110e+00,  1.1414e+00],
        [ 3.8313e+00,  4.7715e-01],
        [ 1.6863e+00,  5.3758e-02],
        [ 3.0866e+00, -3.2560e-01],
        [ 1.2718e+00, -4.2383e-01],
        [ 4.3584e+00, -4.7719e-03],
        [ 2.3239e+00,  8.9633e-01],
        [ 1.9236e+00, -5.3643e-02],
        [ 2.6293e+00,  1.2107e+00],
        [ 3.2702e+00,  1.6867e-01],
        [ 2.8802e+00, -7.6651e-01],
        [ 2.8409e+00,  3.8137e-01],
        [ 1.3450e+00,  1.8567e-01],
        [ 1.6776e+00, -8.3852e-01],
        [ 2.4619e+00, -1.0379e+00],
        [ 1.0234e+00, -5.1605e-01],
        [ 2.5571e+00, -1.3294e+00],
        [ 2.4030e+00, -1.2831e+00],
        [ 1.8711e+00,  3.2809e-01],
        [ 2.7081e+00,  3.3391e-01],
        [ 2.6232e+00, -1.9516e+00],
        [ 1.2735e+00,  4.6883e-01],
        [ 1.9013e+00,  2.3808e-01],
        [ 2.4839e+00, -1.0221e+00],
        [ 2.7734e+00, -7.2522e-01],
        [-5.1392e-02, -9.9498e-02],
        [ 5.8791e-01, -1.0994e+00],
        [ 2.2190e+00,  8.0072e-01],
        [ 2.7472e+00, -1.9173e+00],
        [ 2.5501e+00,  1.6703e-01],
        [ 1.6000e+00, -3.2189e-01],
        [ 1.4914e+00, -1.4585e-01],
        [ 2.2666e+00,  4.3157e-01],
        [ 1.5296e+00,  9.4335e-01],
        [ 3.6584e-01, -7.1547e-01],
        [ 2.1855e+00,  5.9190e-01],
        [ 3.8301e+00, -1.2692e-01],
        [ 2.2522e+00, -5.2950e-01],
        [ 2.2945e+00,  1.2439e-01],
        [ 3.0804e+00, -2.4934e+00],
        [ 2.0161e+00,  1.2481e+00],
        [ 2.2451e+00,  5.1507e-01],
        [ 3.6544e+00, -7.3409e-01],
        [ 2.8349e+00, -2.1499e+00],
        [ 2.9032e+00,  9.5554e-01],
        [ 1.1398e+00, -1.3052e+00],
        [ 3.2961e+00, -4.3884e-01],
        [ 1.5541e+00,  2.4833e+00],
        [ 9.0615e-01, -1.1892e+00],
        [-3.3472e-03,  7.7642e-01],
        [ 2.0827e+00,  1.0171e+00],
        [ 2.7380e+00,  3.4685e-01],
        [ 4.1788e+00, -9.4802e-01],
        [ 1.6932e+00,  1.3162e+00],
        [ 1.4392e+00,  2.3716e-01],
        [ 2.9392e+00, -2.0765e-01],
        [ 1.8934e+00, -3.4515e+00],
        [ 2.5769e+00,  1.5653e-01],
        [ 1.7695e+00,  9.3207e-01],
        [ 1.6033e+00,  2.0254e-01],
        [ 1.6787e+00, -3.7402e-01],
        [ 2.5868e+00, -1.1903e-01],
        [ 2.5451e+00, -8.1473e-01],
        [ 3.5407e+00, -9.1833e-01],
        [ 3.5691e+00,  7.3210e-01],
        [ 3.4024e+00, -9.6670e-01],
        [ 2.5169e+00, -1.5297e+00],
        [ 2.6463e+00, -7.7160e-01],
        [ 2.7520e+00, -2.4343e-01],
        [ 1.6608e+00, -2.1786e-01],
        [ 4.2804e+00, -1.7322e+00],
        [ 3.6016e+00,  1.0173e+00],
        [ 2.8167e+00,  1.6624e+00],
        [ 4.6136e-01, -6.5147e-01],
        [ 8.5286e-01, -1.0863e+00],
        [ 4.8499e+00, -3.4655e-01],
        [ 7.2064e-01,  7.6285e-01],
        [ 3.6610e+00,  5.6265e-01],
        [ 2.3014e+00, -7.7413e-01],
        [ 2.5176e+00, -2.0612e+00],
        [ 4.2988e-01,  4.7434e-02],
        [ 2.4615e+00,  6.8029e-01],
        [ 2.4783e+00, -9.9786e-02],
        [ 2.6936e+00, -1.0994e+00],
        [ 2.4468e+00, -1.3160e+00],
        [ 3.5369e+00, -1.0785e-01],
        [ 2.6964e+00,  4.2760e-01],
        [ 2.0618e+00, -6.8761e-01],
        [ 2.7555e+00,  9.0818e-01],
        [ 9.1356e-01,  1.0957e+00],
        [ 1.6133e+00, -1.0867e+00],
        [ 2.1269e+00, -7.6124e-01],
        [ 8.2481e-01,  1.1410e-01],
        [ 1.4673e+00,  9.6949e-01],
        [ 2.4267e-02, -1.0089e+00],
        [ 2.3285e+00,  6.7420e-02],
        [ 1.4094e+00,  1.7487e+00],
        [ 9.1648e-01, -2.2597e-01],
        [ 1.5257e+00, -1.1017e+00],
        [ 2.7157e+00,  6.3555e-01],
        [ 4.0124e+00, -3.8843e-02],
        [ 3.2248e+00, -1.2083e-02],
        [ 1.8491e+00, -1.0294e+00],
        [ 3.3608e+00,  9.2172e-01],
        [ 1.7002e+00,  1.0766e+00],
        [ 1.5854e+00,  1.6314e+00],
        [ 4.1428e-01, -1.2333e+00],
        [ 1.9389e+00,  1.8193e-01],
        [ 1.5119e+00, -3.1598e-01],
        [ 1.8953e+00, -1.4103e+00],
        [ 3.7814e+00,  1.8048e-01],
        [ 2.7851e+00, -1.3955e+00],
        [ 1.4979e+00,  8.4386e-01],
        [ 2.9919e+00, -1.0030e+00],
        [ 2.2396e+00, -1.5120e+00],
        [ 1.7412e+00, -1.1323e+00],
        [ 1.8606e+00,  3.2443e-01],
        [ 3.2054e+00,  1.7504e+00],
        [ 2.7435e+00, -8.1115e-01],
        [ 2.5042e+00, -9.7049e-01],
        [ 3.9291e+00, -1.1785e+00],
        [ 5.5081e-01,  2.6865e-01],
        [ 6.2783e-01, -6.6760e-01],
        [ 2.5014e+00, -2.2928e+00],
        [ 1.8028e+00, -4.6278e-01],
        [ 1.0145e+00,  2.8780e-01],
        [ 2.2138e+00,  6.6920e-01],
        [ 2.2489e+00,  5.6657e-01],
        [ 1.4528e+00,  5.4648e-01],
        [ 2.2896e+00, -1.1851e+00],
        [ 3.3334e+00,  1.1142e+00],
        [-2.1296e-01,  5.7018e-01],
        [ 9.2390e-01,  7.7841e-01],
        [ 1.9093e+00, -6.3845e-01],
        [ 1.6881e+00,  9.5183e-01],
        [ 4.5758e+00,  1.6052e-01],
        [ 4.2324e+00, -4.3141e-01],
        [ 2.0049e+00, -2.6648e-01],
        [ 7.2026e-01, -9.3335e-01],
        [ 1.6310e+00, -1.3332e+00],
        [ 3.2387e+00, -5.3923e-01],
        [ 2.8878e+00, -4.5715e-01],
        [ 2.5941e+00, -5.5942e-01],
        [-7.4066e-01,  4.5139e-01],
        [ 9.6622e-01, -1.3850e+00],
        [ 1.4360e+00,  3.5685e-01],
        [ 2.7054e+00, -3.3783e-01],
        [ 3.4072e+00,  1.8609e-01],
        [ 2.8055e+00, -7.9888e-02],
        [ 3.2368e+00, -6.1742e-01],
        [ 2.7373e+00,  1.2748e-01],
        [ 4.9762e-01,  9.2233e-01],
        [ 3.3541e+00, -2.8530e+00],
        [ 2.8005e+00, -6.7667e-01],
        [ 2.0465e+00,  2.3111e-02],
        [ 2.4674e+00,  7.9413e-01],
        [ 8.3781e-01, -1.1219e+00],
        [ 2.4917e+00, -1.3906e+00],
        [-4.9813e-01, -7.5751e-01],
        [ 2.1806e+00,  4.7364e-01],
        [ 2.0534e+00,  1.5659e-01],
        [ 1.2604e+00,  1.6466e-01],
        [ 1.8756e+00, -7.5287e-01],
        [ 2.0236e+00, -6.1422e-01],
        [ 2.3553e+00,  1.3290e-01],
        [ 2.4860e+00, -1.6462e+00],
        [ 3.9439e+00, -2.2054e+00],
        [ 1.2433e+00,  6.6501e-02],
        [ 1.8725e+00, -1.3201e+00],
        [ 3.0114e+00, -2.1163e+00],
        [ 1.4950e+00, -5.0903e-01],
        [ 1.5216e+00,  8.3362e-01],
        [ 2.4279e+00, -2.2110e-01],
        [ 2.9629e+00, -4.0149e-03],
        [ 3.5264e+00, -7.2028e-01],
        [ 2.2243e+00, -1.4727e+00],
        [ 2.3681e+00,  4.0314e-01],
        [ 1.4251e-01, -5.3407e-01],
        [ 2.7662e+00, -5.8689e-01],
        [ 2.5596e+00, -8.3557e-01],
        [ 2.9983e+00, -2.1106e+00],
        [ 1.8356e+00, -3.1375e+00],
        [ 1.6866e+00, -1.6645e+00],
        [-5.9034e-01, -1.7110e+00],
        [ 2.0048e+00,  6.7962e-01],
        [ 2.2268e+00,  3.8658e-01],
        [ 3.1325e+00, -2.0848e+00],
        [ 3.2303e+00,  2.9354e-02],
        [ 1.3162e+00,  8.3086e-02],
        [ 1.3813e+00,  1.7942e-01],
        [ 3.1656e+00,  6.1439e-01],
        [ 2.1035e+00, -3.6832e-02],
        [ 3.2464e+00, -9.0755e-01],
        [ 1.7563e+00,  4.1609e-01],
        [ 2.0472e+00,  1.1622e+00],
        [ 2.2612e+00,  7.4338e-01],
        [ 9.5619e-01, -8.0490e-01],
        [ 3.0966e+00, -9.8595e-01],
        [ 1.8015e+00,  8.8719e-01],
        [ 4.0656e+00, -1.5566e+00],
        [ 4.3635e+00, -1.4167e+00],
        [ 2.8637e+00, -1.2978e+00],
        [ 1.4826e+00, -1.7088e+00],
        [ 2.3817e+00, -1.4911e+00],
        [ 4.8307e+00, -2.1091e+00],
        [ 1.4343e+00,  5.8341e-01],
        [ 3.1095e+00,  6.0261e-01],
        [ 1.4551e+00,  3.6913e-01],
        [ 3.0812e+00, -1.2832e+00],
        [ 1.5788e+00, -2.1225e-01],
        [ 4.5026e+00, -9.6699e-01],
        [ 3.9645e+00, -1.7288e+00],
        [ 2.6988e+00, -7.1599e-01],
        [ 2.7696e+00,  3.1019e-01],
        [ 4.5897e+00,  1.3984e+00],
        [ 2.6881e+00,  1.3333e+00],
        [ 3.3567e+00, -2.1652e+00],
        [ 1.1335e-01,  6.8781e-01],
        [ 1.4698e+00,  2.0780e+00],
        [ 1.5355e+00,  4.4000e-01],
        [ 1.7547e+00, -2.6757e-01],
        [ 2.7309e+00, -1.6455e+00],
        [ 2.9199e+00,  1.0346e+00],
        [ 3.5634e+00,  1.5108e+00],
        [ 2.5114e+00, -1.7040e-01],
        [ 2.6690e+00,  1.1138e-01],
        [ 2.4165e+00, -8.9524e-01],
        [ 1.6398e+00, -1.1999e+00],
        [ 2.8882e+00, -1.2943e+00],
        [ 1.5137e+00, -1.2083e+00],
        [ 2.3865e+00, -9.9495e-02],
        [ 2.5024e+00,  4.4783e-01],
        [ 2.6121e+00, -2.5030e-01],
        [ 3.1519e+00,  1.2993e-01],
        [ 4.2179e+00, -7.6896e-01],
        [ 2.7984e+00, -9.9075e-01],
        [-1.2582e-01, -1.6000e-01],
        [ 1.4546e+00,  1.2234e+00],
        [ 2.2849e+00, -1.6365e+00],
        [ 4.3523e+00, -4.3914e-01],
        [ 2.2598e+00, -1.7868e+00],
        [ 2.6172e+00, -4.2485e-01],
        [ 2.7352e+00,  3.6780e-01],
        [ 2.1998e+00, -2.1051e+00],
        [ 2.4515e+00,  1.0476e+00],
        [ 7.7484e-01, -5.5715e-01],
        [ 6.5890e-01, -3.7322e-01],
        [ 2.9675e+00,  7.7556e-01],
        [ 3.6039e+00,  1.9174e+00],
        [ 2.3632e+00, -1.5124e+00],
        [ 2.1704e+00, -1.0991e+00],
        [ 3.3689e+00,  3.2714e-01],
        [ 1.1669e+00, -1.3294e+00],
        [ 2.8948e+00, -2.6265e+00],
        [ 3.2053e+00, -9.3257e-01],
        [ 2.5398e+00,  3.5889e-01],
        [ 3.7054e+00,  1.7825e-01],
        [ 1.7395e+00,  7.9529e-01],
        [ 1.0312e+00, -3.4378e-01],
        [ 2.4039e+00,  4.7677e-01],
        [ 1.9282e+00, -9.6549e-01],
        [ 2.3701e+00,  2.8337e-01],
        [ 1.4451e+00,  7.3883e-01],
        [ 1.9661e+00, -1.5563e+00],
        [ 1.1230e+00,  9.4418e-01],
        [ 2.0729e+00,  1.4535e-01],
        [ 4.8274e+00, -1.3301e-01],
        [ 1.9275e+00, -4.3711e-01],
        [ 3.2012e+00,  2.0447e-01],
        [ 3.7162e+00, -1.9465e+00],
        [ 2.8642e+00, -8.1534e-01],
        [ 5.4058e-01,  1.5426e+00],
        [ 1.6115e+00, -3.9451e-01],
        [ 3.8085e+00, -1.5447e+00],
        [ 1.6971e+00, -7.9006e-01],
        [ 1.3144e+00, -7.0849e-02],
        [ 3.1520e+00,  7.5012e-01],
        [ 3.2292e+00,  3.4395e-01],
        [ 3.0863e+00, -1.0594e+00],
        [ 2.9864e+00, -6.7226e-01],
        [ 4.8342e+00, -2.0027e+00],
        [ 3.6047e+00,  1.1614e+00],
        [ 2.6310e+00, -7.1911e-01],
        [ 2.3727e+00,  3.0741e-01],
        [ 2.3498e+00, -1.7455e+00],
        [ 2.9368e+00,  2.8360e-01],
        [ 3.2640e+00, -2.3037e+00],
        [ 3.7305e+00, -1.0116e+00],
        [ 2.6713e+00, -1.4032e-01],
        [ 2.8254e+00,  8.1196e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[2.7790e-04, 1.9367e-01, 1.9720e-01,  ..., 8.3951e-01, 8.6727e-01,
         1.0000e+00],
        [2.8802e-01, 2.8807e-01, 2.8813e-01,  ..., 9.4759e-01, 9.4759e-01,
         1.0000e+00],
        [1.3037e-04, 1.4870e-01, 1.5661e-01,  ..., 9.9689e-01, 1.0000e+00,
         1.0000e+00],
        ...,
        [3.5453e-11, 1.9182e-10, 4.2105e-03,  ..., 9.7987e-01, 9.7998e-01,
         1.0000e+00],
        [2.8263e-03, 2.1912e-01, 2.1916e-01,  ..., 9.9210e-01, 9.9998e-01,
         1.0000e+00],
        [1.6592e-03, 5.8600e-03, 5.8609e-03,  ..., 9.7873e-01, 9.8116e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[5.2945e-01],
        [5.5700e-01],
        [3.8864e-01],
        [9.1752e-01],
        [3.4719e-01],
        [8.6546e-01],
        [3.3501e-01],
        [5.8002e-01],
        [1.8345e-01],
        [3.5166e-02],
        [2.3272e-01],
        [4.5047e-01],
        [7.6294e-01],
        [1.4596e-02],
        [9.8779e-01],
        [1.5786e-01],
        [5.9804e-01],
        [6.8836e-01],
        [7.5247e-01],
        [1.4254e-01],
        [9.2984e-01],
        [9.0804e-01],
        [2.2226e-01],
        [5.1185e-01],
        [3.8315e-01],
        [1.7535e-01],
        [6.0765e-01],
        [1.1578e-01],
        [9.0069e-01],
        [4.8644e-01],
        [5.4738e-01],
        [2.8435e-01],
        [7.9661e-02],
        [6.1198e-01],
        [7.5087e-01],
        [4.5884e-01],
        [5.3443e-01],
        [3.9924e-01],
        [7.5872e-01],
        [8.3369e-01],
        [7.6697e-01],
        [3.1959e-01],
        [3.8807e-01],
        [8.2821e-01],
        [8.1509e-01],
        [6.9264e-01],
        [4.7600e-01],
        [9.2479e-01],
        [8.8245e-01],
        [2.2135e-01],
        [9.5181e-01],
        [4.6475e-01],
        [5.7093e-02],
        [9.1719e-01],
        [3.2723e-01],
        [1.8774e-01],
        [9.4767e-01],
        [5.5352e-01],
        [7.9706e-01],
        [2.2111e-01],
        [1.6534e-01],
        [6.9671e-01],
        [5.1297e-01],
        [8.7848e-01],
        [3.5976e-01],
        [5.9135e-01],
        [2.7975e-01],
        [5.0139e-01],
        [2.3794e-01],
        [3.5636e-01],
        [7.7748e-02],
        [2.7393e-01],
        [1.6121e-01],
        [7.8615e-01],
        [5.6716e-01],
        [8.4643e-01],
        [4.9701e-01],
        [4.8041e-01],
        [5.4866e-01],
        [8.9481e-01],
        [4.8106e-01],
        [2.3347e-01],
        [5.9669e-01],
        [9.3100e-01],
        [9.6244e-01],
        [3.7238e-01],
        [2.0473e-01],
        [3.0574e-01],
        [2.2673e-01],
        [6.5915e-01],
        [1.7206e-01],
        [5.6497e-01],
        [3.3540e-01],
        [5.5015e-01],
        [7.9595e-01],
        [2.4310e-01],
        [7.7179e-01],
        [9.8376e-01],
        [4.0675e-02],
        [5.8460e-01],
        [6.8361e-01],
        [2.6063e-01],
        [5.8279e-01],
        [2.4347e-01],
        [1.8578e-01],
        [5.8121e-01],
        [4.7413e-01],
        [3.9720e-01],
        [1.1475e-01],
        [4.2210e-01],
        [5.0544e-01],
        [9.1903e-02],
        [8.8103e-01],
        [5.5297e-01],
        [9.0720e-01],
        [6.7415e-01],
        [8.4855e-01],
        [3.6163e-01],
        [6.6809e-01],
        [2.9239e-01],
        [2.1315e-02],
        [6.5504e-01],
        [7.2682e-02],
        [3.0164e-01],
        [1.6413e-01],
        [3.5769e-01],
        [8.3556e-01],
        [9.3947e-01],
        [5.3758e-01],
        [2.5750e-01],
        [5.5807e-01],
        [5.0780e-01],
        [1.8678e-01],
        [3.1271e-01],
        [4.8273e-01],
        [7.6194e-01],
        [4.1586e-01],
        [4.5026e-01],
        [3.0085e-01],
        [5.1144e-02],
        [6.4515e-01],
        [2.7724e-01],
        [1.2880e-02],
        [4.9754e-01],
        [3.3532e-01],
        [4.5779e-01],
        [2.1787e-01],
        [5.4249e-01],
        [1.0700e-01],
        [2.5349e-01],
        [6.4162e-01],
        [8.3329e-01],
        [7.8025e-01],
        [9.6639e-01],
        [1.6662e-01],
        [7.9430e-01],
        [6.9541e-02],
        [5.9915e-01],
        [7.7135e-01],
        [3.0905e-01],
        [1.1419e-01],
        [3.1567e-01],
        [1.5005e-01],
        [5.8502e-01],
        [1.6620e-01],
        [6.3248e-01],
        [1.1671e-01],
        [1.6307e-01],
        [4.6353e-01],
        [9.4332e-01],
        [7.7124e-01],
        [1.1285e-01],
        [9.2250e-01],
        [2.2226e-01],
        [3.8538e-01],
        [2.7449e-01],
        [7.2721e-01],
        [8.7416e-01],
        [9.7013e-04],
        [6.4427e-01],
        [8.3908e-01],
        [9.4184e-01],
        [1.7573e-01],
        [1.6524e-01],
        [1.5275e-01],
        [1.4585e-01],
        [8.4151e-01],
        [5.4326e-01],
        [4.5613e-01],
        [4.5283e-01],
        [3.4721e-02],
        [3.5816e-01],
        [8.6069e-01],
        [7.7178e-02],
        [1.7933e-01],
        [8.6796e-01],
        [6.1880e-01],
        [7.4964e-01],
        [6.7492e-01],
        [8.2714e-01],
        [6.5973e-01],
        [2.2623e-01],
        [6.1421e-01],
        [9.5276e-01],
        [9.5576e-04],
        [9.6602e-01],
        [7.4269e-01],
        [2.4308e-01],
        [1.1218e-02],
        [9.3002e-01],
        [1.0460e-01],
        [7.5780e-01],
        [1.4189e-01],
        [7.5018e-01],
        [3.4476e-02],
        [4.7321e-01],
        [4.4708e-01],
        [4.6550e-01],
        [1.1555e-01],
        [1.3573e-02],
        [5.8689e-01],
        [1.8775e-01],
        [9.9551e-01],
        [5.8861e-01],
        [4.3288e-01],
        [2.9000e-01],
        [8.5529e-01],
        [4.6044e-01],
        [9.4744e-01],
        [7.9746e-01],
        [8.8870e-01],
        [3.8238e-01],
        [3.3099e-01],
        [4.9407e-01],
        [2.0076e-01],
        [1.4031e-01],
        [5.1926e-01],
        [8.3839e-01],
        [2.1713e-01],
        [8.1373e-01],
        [8.9346e-01],
        [3.5796e-01],
        [7.9700e-01],
        [8.9596e-01],
        [2.3986e-01],
        [1.2200e-01],
        [4.9712e-01],
        [7.1128e-01],
        [1.4363e-01],
        [3.7395e-01],
        [1.1263e-01],
        [1.1606e-01],
        [6.5529e-01],
        [5.2133e-01],
        [2.4975e-02],
        [2.4519e-02],
        [2.8184e-02],
        [4.3865e-01],
        [8.7977e-01],
        [9.6179e-01],
        [7.6777e-01],
        [8.1458e-01],
        [1.7568e-01],
        [5.8704e-01],
        [7.7990e-01],
        [4.2556e-01],
        [7.6428e-01],
        [1.6376e-01],
        [7.2709e-03],
        [5.1577e-01],
        [9.4812e-01],
        [2.3374e-01],
        [3.2044e-01],
        [8.3028e-01],
        [5.9045e-01],
        [4.6785e-02],
        [9.8284e-01],
        [7.1235e-01],
        [5.6591e-01],
        [3.2022e-01],
        [2.9573e-01],
        [2.8484e-01],
        [8.9730e-01],
        [3.9700e-01],
        [3.0713e-02],
        [5.1198e-01],
        [5.5838e-01],
        [8.0745e-01],
        [4.5395e-01],
        [1.4033e-01],
        [6.2896e-01],
        [4.6523e-01],
        [7.3571e-01],
        [7.7303e-01],
        [2.8687e-02],
        [1.1762e-01],
        [3.1535e-01],
        [2.2797e-01],
        [9.2967e-01],
        [2.6666e-01],
        [7.5389e-01],
        [5.7736e-01],
        [1.4499e-01],
        [2.2241e-01],
        [6.5510e-01],
        [6.6548e-01],
        [7.4908e-01],
        [2.7839e-01],
        [7.7782e-01],
        [7.0855e-01],
        [2.6633e-02],
        [9.3247e-01]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False,  True, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-7.5792e-01, -5.1349e-02],
        [ 1.7094e+00, -1.3095e+00],
        [ 1.2086e+00,  1.6483e+00],
        ...,
        [ 1.8988e+00,  2.4336e+00],
        [-3.1414e-01,  2.5183e-02],
        [ 5.0468e-01,  1.2901e-03]]) torch.Size([9984, 2])
samples tensor([[ 2.6244, -0.3288],
        [ 2.6215,  0.0834],
        [ 3.0015, -1.1636],
        [ 2.3345, -0.6898],
        [ 3.0893, -1.3194],
        [ 2.2924,  0.3317],
        [ 1.6904,  0.7515],
        [ 2.9050,  1.5006],
        [ 2.2060,  1.9952],
        [ 2.3812,  1.1296],
        [ 2.5630, -1.2837],
        [ 3.1094, -1.3993],
        [ 2.8459,  0.9929],
        [ 2.8355, -2.5551],
        [ 1.7477, -0.9152],
        [ 1.8615,  1.2307],
        [ 1.6504, -0.8877],
        [ 1.5587,  0.9355],
        [ 3.1436, -0.7061],
        [ 2.5305,  0.7692],
        [ 3.7260,  0.8412],
        [ 3.4054,  2.2914],
        [ 2.9565,  0.1065],
        [ 0.1636,  0.9765],
        [ 2.4272,  0.0365],
        [ 2.5837, -0.1358],
        [ 2.3624,  1.4647],
        [ 2.8812,  0.4898],
        [ 2.3546, -0.3726],
        [ 2.4910,  0.4543],
        [ 2.2792,  0.2395],
        [ 2.4662, -0.3755],
        [ 1.9304,  0.5026],
        [ 0.6442, -0.8468],
        [ 2.3520, -1.2063],
        [ 0.5533,  0.8670],
        [ 2.6557, -0.8702],
        [ 2.0578,  0.4575],
        [ 2.9433, -1.9493],
        [ 2.7326, -0.4452],
        [ 1.5105, -0.0892],
        [ 2.2684, -0.4553],
        [ 2.0248,  1.3430],
        [ 2.4341, -1.6035],
        [ 0.6964,  0.8452],
        [ 2.9455, -2.2956],
        [ 3.6037,  1.1101],
        [ 0.5787, -0.4493],
        [ 3.1442,  0.1193],
        [ 3.1134, -0.5298],
        [ 2.1969, -0.2385],
        [ 2.8462, -0.5554],
        [ 3.2873,  0.7411],
        [ 2.0746, -1.7199],
        [ 2.8583,  0.0611],
        [ 2.5884,  0.0666],
        [ 1.9347, -0.0292],
        [ 1.1888, -0.2613],
        [ 2.0256, -0.6170],
        [ 4.8283,  1.0856],
        [ 3.6765, -2.9052],
        [ 1.1497,  0.7668],
        [ 4.8633, -1.9201],
        [ 3.4232,  2.3419],
        [ 2.7205,  0.1990],
        [ 1.7529,  0.5969],
        [ 4.4043,  0.0457],
        [ 1.9908, -1.7982],
        [ 1.5544,  2.4851],
        [ 2.3882, -0.9858],
        [ 2.1554,  0.0453],
        [ 4.2462,  0.7233],
        [ 1.5002, -0.0292],
        [ 1.2977, -0.8058],
        [ 4.4940,  0.6371],
        [ 0.7005,  0.1223],
        [ 2.6939, -2.1155],
        [ 3.1548, -0.7917],
        [ 3.1229, -1.0001],
        [ 3.6202, -1.7224],
        [ 3.9401,  0.6294],
        [ 2.9534, -0.0248],
        [ 1.5743,  0.1176],
        [ 4.1724, -2.1193],
        [ 2.6474, -0.2700],
        [ 2.5668, -0.0977],
        [ 0.8788, -0.6864],
        [ 2.2165, -0.6289],
        [ 0.4556, -0.3931],
        [ 3.2017,  0.4186],
        [ 0.7230,  0.9981],
        [ 0.8471, -1.3426],
        [ 4.9597, -0.1260],
        [ 4.1341,  0.5660],
        [ 3.3719,  0.5731],
        [ 1.3302, -0.8325],
        [ 3.3693, -0.6177],
        [ 1.5349,  0.6479],
        [ 1.7567, -0.5239],
        [ 2.7130,  0.3369],
        [ 2.6940,  1.5323],
        [ 1.2238,  1.7985],
        [ 2.7974,  0.3021],
        [ 1.7710,  0.0369],
        [ 2.3820,  0.1366],
        [ 1.7972, -0.9406],
        [ 1.9333, -1.4536],
        [ 2.9467, -1.1636],
        [ 1.7185, -1.0746],
        [ 2.8106,  0.5777],
        [ 4.6065, -0.2790],
        [ 0.7955,  0.3411],
        [ 2.6291,  0.2485],
        [ 3.6599, -0.7119],
        [ 2.7577, -1.3997],
        [ 2.4435, -1.0996],
        [ 2.5989, -0.7433],
        [ 3.2719,  0.1868],
        [ 3.3828, -0.8474],
        [ 1.5353,  0.2982],
        [ 1.1995,  1.9301],
        [ 1.6617,  0.1257],
        [ 1.2556,  0.2876],
        [ 2.6965,  0.8500],
        [ 2.9107, -0.8254],
        [ 1.9079, -0.8780],
        [ 1.7555, -0.1270],
        [ 1.3834, -0.3926],
        [ 3.4999,  1.3381],
        [ 2.2422, -1.9295],
        [ 3.0679,  0.9161],
        [ 1.2148, -0.6026],
        [ 1.3963,  0.3751],
        [ 3.7920, -0.3870],
        [ 1.6055, -0.0922],
        [ 1.7618, -0.8052],
        [ 2.2420, -0.4612],
        [ 1.8494,  0.3084],
        [ 3.2105, -1.3082],
        [ 1.6481, -1.4745],
        [ 2.1910,  0.2963],
        [ 2.2114, -1.4254],
        [ 2.4628,  1.1549],
        [ 2.9677,  0.3165],
        [ 3.9344,  0.6629],
        [ 2.2703,  2.1393],
        [ 3.5052, -1.2984],
        [ 3.7670,  1.4939],
        [ 0.5026, -0.5686],
        [ 1.9112, -0.2657],
        [ 3.5043, -1.0678],
        [ 0.4926, -0.9717],
        [ 1.6437,  0.2915],
        [ 2.2440,  1.1889],
        [ 3.1797, -0.0487],
        [ 4.3698,  0.5370],
        [ 2.7466,  0.2428],
        [ 2.4907,  1.0408],
        [ 2.4980, -0.1350],
        [ 3.4787, -1.5973],
        [ 0.4909,  0.1161],
        [ 2.6007, -0.1283],
        [ 1.9166,  0.3276],
        [ 2.2250, -1.6983],
        [ 1.6219,  0.3647],
        [ 1.1795, -0.6531],
        [ 2.0528,  0.5354],
        [ 1.5912, -0.0294],
        [ 2.7887,  1.0018],
        [ 1.0796,  1.9422],
        [ 1.1283, -0.5767],
        [ 2.9611,  0.6708],
        [ 2.8607,  0.8251],
        [ 0.8136,  0.2848],
        [ 3.3453,  0.1379],
        [ 2.8770, -0.5077],
        [ 1.4249, -1.0677],
        [ 2.9279, -0.7061],
        [ 0.0746,  0.3061],
        [ 3.1964, -0.4163],
        [ 2.9241, -0.7003],
        [ 1.8156, -0.5198],
        [ 3.5045, -0.3338],
        [ 1.6922,  0.6545],
        [ 2.1869,  1.2373],
        [ 0.5131, -0.7678],
        [ 3.7500, -0.2050],
        [ 3.4122,  0.6464],
        [ 1.9317, -1.2514],
        [ 1.3714,  0.1213],
        [ 3.7302, -0.0636],
        [ 3.7306,  1.6574],
        [ 2.6093,  0.2783],
        [ 2.5355,  0.5534],
        [ 0.5298, -1.0852],
        [ 0.1246,  1.2028],
        [ 2.4090,  0.5212],
        [ 2.0905, -0.8672],
        [ 4.0939, -0.5831],
        [ 2.7034, -0.3527],
        [ 3.0973,  0.1125],
        [ 4.8178, -1.1743],
        [ 0.7303, -0.0102],
        [ 1.9818,  0.5056],
        [ 0.7785, -1.5641],
        [ 1.1012,  0.4566],
        [ 3.5893, -1.0330],
        [ 0.5526, -1.0072],
        [ 2.2215,  0.6035],
        [ 3.0888,  0.2955],
        [ 0.4024, -1.2384],
        [ 2.3504, -0.0578],
        [ 3.3119, -0.2744],
        [ 2.8001,  0.1132],
        [ 3.2312, -0.3888],
        [ 1.6617, -0.4542],
        [ 0.6520, -0.7312],
        [ 1.6538, -0.1383],
        [ 1.7125,  1.1078],
        [ 1.4980,  0.0430],
        [ 2.8298,  0.9793],
        [ 2.8828,  0.3369],
        [ 2.3051, -0.7706],
        [ 2.9177, -1.2126],
        [ 1.7588, -0.3656],
        [ 1.7631, -0.0087],
        [ 2.8767, -0.5598],
        [ 1.8122, -0.1965],
        [ 4.2621,  1.3942],
        [ 2.2660,  0.8253],
        [ 0.5232, -0.4328],
        [ 3.4196,  0.0216],
        [ 3.8410, -0.0154],
        [ 4.2107, -0.3875],
        [ 1.4873,  0.0574],
        [ 1.1107,  0.9791],
        [ 1.9645,  3.1685],
        [ 1.1741,  1.2121],
        [ 1.9083, -0.4084],
        [ 2.5323, -1.9186],
        [ 0.8118,  0.5451],
        [ 2.5165, -2.7097],
        [ 2.7617, -0.6457],
        [ 3.2740,  1.0664],
        [ 3.2092,  0.3496],
        [ 2.5888,  0.3336],
        [ 1.9853,  0.6459],
        [ 2.4946, -0.9225],
        [ 1.5763,  1.2276],
        [ 1.7317,  0.4268],
        [ 3.4813,  1.5459],
        [ 2.0360,  1.4217],
        [ 2.7228, -1.0310],
        [ 1.5120, -0.4344],
        [ 3.0062,  0.2651],
        [ 0.9669, -0.2559],
        [ 2.6816,  0.5191],
        [ 2.7137, -0.8402],
        [ 4.5388,  0.9568],
        [ 4.0340, -1.2852],
        [ 2.9174, -1.6606],
        [ 1.0493, -1.7543],
        [ 3.4387, -0.1752],
        [ 2.5004, -0.2528],
        [ 3.5841, -0.4782],
        [ 3.0805,  0.2704],
        [ 3.6908, -0.3465],
        [ 1.7357, -0.6531],
        [ 1.1304,  1.0511],
        [ 2.0278,  1.1902],
        [ 2.0311, -0.1334],
        [ 1.0174,  0.2082],
        [ 1.1264, -0.0055],
        [ 1.9017,  1.1222],
        [ 3.2584,  0.8658],
        [ 3.1714, -0.2919],
        [ 2.3522, -0.0791],
        [ 3.4949, -0.6085],
        [ 2.6296,  0.0824],
        [ 1.4230, -0.8876],
        [ 2.6834, -0.1674],
        [ 3.0817, -0.4959],
        [ 3.6312,  0.1024],
        [ 2.8045, -1.1796],
        [ 2.4271,  1.1803],
        [ 2.3565,  0.4907],
        [ 2.7732,  1.6901],
        [ 3.2449,  1.3248],
        [ 3.3747, -1.4106],
        [ 2.3018, -0.2575],
        [ 4.8601, -0.0752],
        [ 2.2021, -0.2381],
        [ 1.5928, -1.6901],
        [ 2.2230, -1.0506],
        [ 1.0552, -0.0633],
        [ 0.6259, -1.3470],
        [ 1.6363,  1.3658],
        [ 1.8032,  1.0080],
        [ 1.8228,  0.6077],
        [ 2.0471, -0.9110],
        [ 3.0080,  0.7606],
        [ 2.0180,  0.0314],
        [ 0.4107, -0.4807],
        [ 2.9456,  0.1167],
        [ 3.3514, -0.5265],
        [ 3.1863,  0.3291],
        [ 2.0597, -1.0002],
        [ 2.8538, -0.7554],
        [ 1.7703,  0.2603],
        [ 2.8149, -1.6894],
        [ 2.6309, -0.1498],
        [ 1.8466,  0.5894]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[4.7564e-07, 4.1120e-02, 4.1122e-02,  ..., 9.9843e-01, 9.9849e-01,
         1.0000e+00],
        [9.1987e-09, 9.6166e-02, 2.0773e-01,  ..., 9.7749e-01, 9.7749e-01,
         1.0000e+00],
        [1.7509e-06, 1.4680e-02, 7.1291e-02,  ..., 9.9977e-01, 9.9979e-01,
         1.0000e+00],
        ...,
        [1.3277e-04, 4.4634e-04, 1.6181e-03,  ..., 9.4977e-01, 9.9313e-01,
         1.0000e+00],
        [2.4817e-02, 2.7570e-02, 5.0513e-02,  ..., 9.9958e-01, 1.0000e+00,
         1.0000e+00],
        [4.1671e-05, 7.7781e-04, 7.7781e-04,  ..., 8.2205e-01, 8.2241e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.3995],
        [0.7139],
        [0.4784],
        [0.1683],
        [0.3519],
        [0.8154],
        [0.1262],
        [0.7861],
        [0.9926],
        [0.1345],
        [0.5857],
        [0.7353],
        [0.7837],
        [0.5723],
        [0.3182],
        [0.9082],
        [0.8983],
        [0.9452],
        [0.0198],
        [0.4332],
        [0.4553],
        [0.3248],
        [0.1246],
        [0.0668],
        [0.7260],
        [0.3396],
        [0.6583],
        [0.2914],
        [0.3922],
        [0.6736],
        [0.2230],
        [0.8154],
        [0.6022],
        [0.8255],
        [0.6662],
        [0.1857],
        [0.8080],
        [0.2983],
        [0.6129],
        [0.9161],
        [0.7317],
        [0.5274],
        [0.7097],
        [0.3452],
        [0.4782],
        [0.1202],
        [0.7429],
        [0.4925],
        [0.1828],
        [0.9566],
        [0.1458],
        [0.9355],
        [0.1640],
        [0.8692],
        [0.5522],
        [0.0784],
        [0.4162],
        [0.8915],
        [0.6236],
        [0.9529],
        [0.7917],
        [0.2538],
        [0.3151],
        [0.7349],
        [0.2893],
        [0.8861],
        [0.9809],
        [0.4319],
        [0.8034],
        [0.7803],
        [0.7169],
        [0.0194],
        [0.7444],
        [0.2203],
        [0.8498],
        [0.4580],
        [0.3625],
        [0.9488],
        [0.2095],
        [0.0725],
        [0.9354],
        [0.5198],
        [0.4584],
        [0.9506],
        [0.7497],
        [0.0395],
        [0.4461],
        [0.0680],
        [0.5384],
        [0.6778],
        [0.0207],
        [0.5163],
        [0.9613],
        [0.3856],
        [0.8797],
        [0.5328],
        [0.5877],
        [0.2807],
        [0.3097],
        [0.2031],
        [0.8128],
        [0.2725],
        [0.2202],
        [0.6298],
        [0.8538],
        [0.7034],
        [0.3727],
        [0.1527],
        [0.1729],
        [0.7613],
        [0.2615],
        [0.8022],
        [0.3580],
        [0.8919],
        [0.4729],
        [0.7169],
        [0.4043],
        [0.1709],
        [0.1566],
        [0.4382],
        [0.8278],
        [0.5769],
        [0.4260],
        [0.7932],
        [0.4212],
        [0.5894],
        [0.9049],
        [0.3766],
        [0.4566],
        [0.5473],
        [0.3681],
        [0.1530],
        [0.2094],
        [0.7050],
        [0.9028],
        [0.2304],
        [0.2781],
        [0.4256],
        [0.9504],
        [0.8976],
        [0.3871],
        [0.8014],
        [0.0751],
        [0.2229],
        [0.0479],
        [0.9514],
        [0.1420],
        [0.2913],
        [0.1030],
        [0.9848],
        [0.2809],
        [0.5917],
        [0.9421],
        [0.7804],
        [0.3705],
        [0.0411],
        [0.5737],
        [0.3948],
        [0.9107],
        [0.4233],
        [0.3372],
        [0.5704],
        [0.2590],
        [0.5105],
        [0.3902],
        [0.6490],
        [0.4917],
        [0.5434],
        [0.1105],
        [0.2037],
        [0.5513],
        [0.8413],
        [0.4051],
        [0.4847],
        [0.2791],
        [0.4766],
        [0.3264],
        [0.6912],
        [0.9796],
        [0.1566],
        [0.3531],
        [0.7744],
        [0.6499],
        [0.1721],
        [0.5236],
        [0.8970],
        [0.1657],
        [0.8192],
        [0.6300],
        [0.2570],
        [0.4132],
        [0.9918],
        [0.1270],
        [0.4492],
        [0.8922],
        [0.9631],
        [0.7749],
        [0.5604],
        [0.7326],
        [0.4081],
        [0.5644],
        [0.2597],
        [0.7598],
        [0.3504],
        [0.9756],
        [0.9598],
        [0.7576],
        [0.2225],
        [0.7908],
        [0.4717],
        [0.1266],
        [0.7380],
        [0.0054],
        [0.5038],
        [0.5274],
        [0.3798],
        [0.1150],
        [0.8359],
        [0.5651],
        [0.7024],
        [0.7752],
        [0.6127],
        [0.0934],
        [0.7318],
        [0.7576],
        [0.3349],
        [0.9460],
        [0.1352],
        [0.9616],
        [0.3909],
        [0.1643],
        [0.8751],
        [0.5166],
        [0.4706],
        [0.5817],
        [0.5772],
        [0.6572],
        [0.8559],
        [0.1561],
        [0.0682],
        [0.1968],
        [0.3130],
        [0.1775],
        [0.3810],
        [0.3988],
        [0.0109],
        [0.1315],
        [0.3809],
        [0.0815],
        [0.8831],
        [0.4913],
        [0.6626],
        [0.9265],
        [0.1939],
        [0.4418],
        [0.0816],
        [0.9523],
        [0.8094],
        [0.2785],
        [0.8296],
        [0.4363],
        [0.2711],
        [0.1025],
        [0.1375],
        [0.1915],
        [0.8627],
        [0.0532],
        [0.8086],
        [0.4231],
        [0.0865],
        [0.7354],
        [0.8910],
        [0.5720],
        [0.3986],
        [0.8231],
        [0.2062],
        [0.1800],
        [0.8053],
        [0.5766],
        [0.6790],
        [0.0681],
        [0.8656],
        [0.9486],
        [0.7466],
        [0.1538],
        [0.8688],
        [0.8649],
        [0.1797],
        [0.7794],
        [0.7958],
        [0.0387],
        [0.4948],
        [0.2969],
        [0.0718],
        [0.4412],
        [0.2526],
        [0.2991],
        [0.8017],
        [0.3973],
        [0.5735],
        [0.4913],
        [0.7137],
        [0.8575],
        [0.4417],
        [0.0797],
        [0.9853],
        [0.5260],
        [0.4204],
        [0.3028],
        [0.6382],
        [0.4757],
        [0.9788]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False,  True]]) torch.Size([312, 32])
thetas tensor([[-2.5398,  0.2915],
        [ 2.4416,  1.1723],
        [-1.9394,  1.5867],
        ...,
        [ 2.7818,  3.5648],
        [-0.4469,  1.6847],
        [ 1.1386, -0.7713]]) torch.Size([9984, 2])
samples tensor([[ 2.0442e+00, -1.8015e+00],
        [ 3.3275e+00,  1.3190e+00],
        [ 1.4329e+00,  5.2462e-01],
        [ 7.6452e-01, -6.4446e-01],
        [ 2.5028e+00, -3.1982e+00],
        [ 3.9521e+00,  7.3146e-02],
        [ 2.1743e+00,  2.0659e+00],
        [ 3.7649e+00, -3.1203e-01],
        [ 2.3731e+00,  2.2001e+00],
        [ 2.2483e+00, -1.2906e+00],
        [ 1.5788e+00,  1.1464e+00],
        [ 3.1313e+00,  5.5520e-02],
        [ 3.3035e+00,  8.8973e-01],
        [ 4.1469e+00, -2.4737e+00],
        [ 2.0599e+00,  8.1088e-02],
        [ 1.5476e+00,  1.1020e+00],
        [ 3.2587e+00, -1.8838e-01],
        [ 1.4750e+00,  1.8272e+00],
        [ 3.7849e+00,  6.1147e-01],
        [ 3.8490e+00,  3.2905e+00],
        [ 1.5715e+00, -1.5261e+00],
        [ 2.9411e+00,  1.8404e-01],
        [ 1.1650e+00, -7.5123e-01],
        [ 1.0074e+00,  8.1893e-01],
        [ 2.9538e+00, -2.2228e+00],
        [ 3.1534e+00, -1.2699e+00],
        [ 2.1111e+00,  2.9807e-02],
        [ 3.9705e+00, -1.0218e+00],
        [ 3.5351e+00, -4.1580e-01],
        [ 1.8730e+00, -1.8280e+00],
        [ 3.4835e+00, -3.5071e-01],
        [ 2.1630e+00,  4.7703e-02],
        [ 3.2970e+00, -4.5404e-01],
        [ 1.2534e+00, -4.3327e-01],
        [ 2.3149e+00,  5.5498e-01],
        [ 2.4703e+00,  6.3411e-01],
        [ 1.7158e+00,  1.4922e-01],
        [ 2.2166e+00, -8.4624e-01],
        [ 2.7628e+00,  7.7494e-01],
        [ 1.2229e+00,  1.9598e-01],
        [ 3.6286e+00,  9.9191e-02],
        [ 4.0516e+00,  6.0545e-01],
        [ 2.5287e+00,  1.9384e-01],
        [ 1.2157e+00,  5.1640e-01],
        [ 1.3136e+00, -1.8201e+00],
        [ 1.9021e+00,  7.8224e-01],
        [ 2.2863e+00,  2.1798e-01],
        [ 1.3787e+00,  8.2447e-01],
        [ 2.4349e+00, -8.2046e-01],
        [ 3.8329e+00,  6.2425e-01],
        [ 1.8893e+00,  9.0311e-01],
        [ 3.8410e+00,  7.0309e-01],
        [ 2.7095e+00,  1.0675e-01],
        [ 3.0320e+00, -4.5291e-01],
        [ 1.2621e+00,  2.2868e-01],
        [ 2.3007e+00,  5.8601e-01],
        [ 3.4907e+00, -3.4522e-01],
        [ 6.6371e-01,  9.3289e-02],
        [ 3.1216e+00, -6.4652e-01],
        [ 8.9516e-01, -4.7498e-01],
        [ 4.6435e+00, -1.4310e+00],
        [ 2.5977e+00,  2.9988e-01],
        [ 8.8792e-01,  8.4720e-01],
        [ 1.7364e+00, -3.6484e-01],
        [ 3.5663e+00,  2.5830e-01],
        [ 3.0826e+00, -3.1332e+00],
        [ 1.8741e+00,  3.0242e-02],
        [ 1.8281e+00, -2.0434e+00],
        [ 6.9745e-01, -1.5821e+00],
        [ 1.8567e+00, -1.7819e-01],
        [ 1.3980e+00, -5.8737e-01],
        [ 2.7860e+00,  1.5515e+00],
        [ 2.4318e+00, -1.1472e+00],
        [ 1.8546e+00,  1.6105e-01],
        [ 2.2743e+00,  2.8318e-01],
        [ 2.9555e+00, -1.2945e+00],
        [ 3.6951e+00,  3.0641e-01],
        [ 1.1839e+00,  1.0857e-01],
        [ 2.0254e+00, -8.2972e-01],
        [ 9.6309e-01,  7.8545e-01],
        [ 1.8510e+00,  1.0053e+00],
        [ 2.4314e+00,  7.4874e-01],
        [ 3.0321e+00, -6.6507e-01],
        [ 2.9790e+00, -2.9558e+00],
        [ 2.7249e+00, -4.3747e-01],
        [ 3.4281e+00, -1.6022e+00],
        [ 3.1614e+00, -2.5542e-01],
        [ 2.6505e+00,  1.0736e+00],
        [ 3.1044e+00, -1.1235e+00],
        [ 3.5394e+00,  1.2207e+00],
        [ 1.9147e+00,  2.2944e-02],
        [ 5.7615e-01,  5.3484e-01],
        [ 3.6026e+00, -5.7964e-01],
        [ 9.0297e-01, -1.4353e+00],
        [ 3.7014e+00, -7.2870e-01],
        [ 7.8439e-01,  2.1323e+00],
        [ 3.5711e+00, -3.2512e-01],
        [ 2.1817e+00,  3.5723e-01],
        [ 2.3644e+00, -1.3986e+00],
        [ 2.5358e+00, -1.9386e+00],
        [ 4.2527e+00, -2.2126e+00],
        [ 1.1626e+00,  5.7163e-01],
        [ 7.0410e-01, -1.1741e+00],
        [ 1.5114e+00,  3.4251e-01],
        [ 2.9275e+00, -3.6862e-01],
        [ 3.3159e+00,  1.6353e+00],
        [ 1.4744e+00, -1.7689e+00],
        [ 1.1478e+00, -5.5023e-01],
        [ 9.1922e-01,  1.6841e+00],
        [ 1.9393e+00,  1.4087e+00],
        [ 2.5324e+00,  6.4188e-01],
        [ 3.7546e+00,  8.6849e-01],
        [ 2.4788e+00, -2.2879e+00],
        [ 2.7072e+00, -1.2770e+00],
        [ 2.9120e+00, -1.7857e+00],
        [ 2.8497e+00,  5.6554e-01],
        [ 1.9331e+00,  1.0651e+00],
        [ 2.6093e+00,  1.1965e+00],
        [ 3.3499e+00,  1.4349e+00],
        [ 4.5457e+00, -1.3388e+00],
        [ 1.7383e+00,  1.2181e-01],
        [ 2.5087e+00, -4.3156e-01],
        [ 2.7600e+00, -3.4173e-01],
        [ 4.0551e+00, -7.8325e-02],
        [ 3.0418e+00, -2.3037e-02],
        [ 4.6334e+00, -1.5260e-03],
        [ 2.3545e+00, -1.4323e+00],
        [ 3.1886e-01, -1.7699e+00],
        [ 2.7316e+00,  6.9067e-01],
        [ 1.9692e+00, -4.2702e-01],
        [ 1.0203e+00,  3.1840e-01],
        [ 2.5211e+00, -2.3378e+00],
        [ 2.9020e+00,  1.0941e+00],
        [ 3.8337e+00, -1.0181e+00],
        [ 1.4368e+00,  1.1013e+00],
        [ 3.7871e+00,  4.7799e-01],
        [ 2.5625e+00,  1.8124e+00],
        [ 3.7365e+00,  5.3056e-01],
        [ 3.2318e+00,  7.6441e-01],
        [ 3.4084e+00,  7.5899e-01],
        [ 3.4012e+00, -1.5882e+00],
        [ 1.8196e+00,  1.7598e-01],
        [ 3.1183e+00,  3.6478e-01],
        [ 1.7116e+00, -5.0630e-01],
        [ 2.5592e+00, -4.8156e-01],
        [ 2.3718e+00,  3.9056e-01],
        [ 1.9917e+00, -6.4939e-01],
        [ 1.7483e+00, -8.0113e-01],
        [ 1.0751e+00, -6.9625e-01],
        [ 3.6416e+00,  9.3511e-01],
        [ 7.9531e-01, -1.0621e+00],
        [ 3.8205e+00,  1.5141e+00],
        [ 3.0158e+00,  2.3770e-02],
        [ 2.4771e+00,  8.4656e-01],
        [ 2.6343e+00, -4.4134e-01],
        [ 9.0845e-01, -1.7198e-01],
        [ 8.2095e-01,  1.1707e-01],
        [ 2.5072e+00, -1.0935e-01],
        [ 3.0162e+00,  9.2582e-01],
        [ 2.5225e+00, -1.7382e+00],
        [ 1.7326e+00, -1.2727e+00],
        [ 3.8088e+00, -2.5129e-01],
        [ 2.5858e+00,  5.3149e-01],
        [ 3.4133e+00,  7.2479e-01],
        [ 2.5844e+00,  3.7058e-01],
        [ 1.6420e+00, -7.7769e-01],
        [ 3.0526e+00,  4.6862e-01],
        [ 2.3417e+00,  7.0636e-01],
        [ 3.2641e+00, -1.9903e+00],
        [ 3.0601e+00, -2.3339e+00],
        [ 3.7688e+00, -1.5865e+00],
        [ 2.0277e+00,  1.3229e+00],
        [ 7.4006e-01, -1.2161e+00],
        [ 2.0656e+00,  6.9583e-01],
        [ 2.6907e+00,  7.2051e-02],
        [ 4.1225e+00, -1.3390e+00],
        [ 2.4399e+00, -3.5703e-01],
        [ 1.5481e+00,  5.4865e-02],
        [ 2.0713e+00,  7.5136e-02],
        [ 1.9390e+00, -3.9716e-01],
        [ 1.2266e+00,  2.5383e+00],
        [ 2.1503e+00, -1.4420e-02],
        [ 1.2764e+00,  6.6675e-02],
        [ 1.9429e+00, -1.1010e+00],
        [ 3.1059e+00, -1.4022e+00],
        [ 2.3986e+00,  3.3464e-01],
        [ 3.5000e+00, -9.2510e-02],
        [ 3.3116e+00,  2.5203e+00],
        [ 1.7550e+00,  9.7508e-01],
        [ 2.2934e+00, -1.3579e+00],
        [ 3.6553e+00, -1.1397e-01],
        [ 1.5978e+00, -1.8536e+00],
        [ 1.9828e+00, -2.2436e-01],
        [ 3.3289e+00,  1.5732e-01],
        [ 1.7117e+00, -7.6058e-01],
        [-1.0503e-01,  9.7033e-01],
        [ 2.2474e+00,  4.9867e-01],
        [ 2.7475e+00,  2.6160e+00],
        [ 2.1665e+00, -4.8483e-01],
        [ 1.4530e+00, -2.0256e+00],
        [ 3.1002e+00, -2.3294e-01],
        [ 1.0904e+00,  3.5012e-01],
        [ 2.6098e+00, -1.1548e+00],
        [ 1.6602e+00, -3.2037e-01],
        [ 1.7509e+00, -1.0416e+00],
        [ 1.4588e+00,  1.5448e-01],
        [ 2.3926e+00,  9.2322e-01],
        [ 2.2031e+00, -9.8607e-01],
        [ 1.4656e+00,  1.5518e+00],
        [ 3.7606e+00, -9.5345e-02],
        [ 1.5297e+00,  1.8026e-01],
        [ 3.3280e+00, -5.0962e-01],
        [ 3.5030e+00,  4.6334e-01],
        [ 1.0226e+00, -1.4727e-02],
        [ 3.0901e+00,  6.7555e-01],
        [ 3.3732e+00, -1.7804e+00],
        [ 1.7063e+00,  3.4190e-01],
        [ 2.5325e+00,  1.4186e+00],
        [ 3.5023e+00, -6.6156e-01],
        [ 3.2497e-01,  1.1110e-01],
        [ 1.9858e+00,  2.7929e-01],
        [ 2.0423e-01, -1.8222e+00],
        [ 8.2539e-01, -1.1886e+00],
        [ 1.3334e+00,  2.5559e-01],
        [ 3.0346e+00,  9.3262e-01],
        [ 3.4041e+00, -1.3935e+00],
        [ 1.4556e+00,  1.5492e-01],
        [ 4.1462e+00,  7.0608e-01],
        [ 1.2823e+00,  9.5047e-01],
        [ 9.9667e-01, -3.9833e-01],
        [ 2.2579e+00,  6.9469e-01],
        [ 2.9116e+00,  1.9904e-01],
        [ 2.7953e+00, -1.6746e-02],
        [ 3.4405e+00, -1.2108e+00],
        [ 3.2384e+00,  5.2609e-01],
        [ 1.9290e+00, -1.0835e+00],
        [ 3.4119e+00, -1.6368e+00],
        [ 3.7516e+00,  1.0754e-01],
        [ 1.9398e+00,  2.9119e-01],
        [ 1.6267e+00,  4.7013e-01],
        [ 1.6991e+00, -6.0203e-01],
        [ 2.3552e+00, -5.8156e-01],
        [ 8.4641e-01, -2.7308e-01],
        [ 2.5411e+00, -1.4995e+00],
        [ 2.5967e+00, -1.2945e+00],
        [ 3.0599e+00, -2.9050e-02],
        [ 3.3233e+00, -6.5657e-02],
        [ 2.8155e+00, -1.9006e-01],
        [ 1.5985e+00,  3.2574e-01],
        [ 2.3080e+00,  1.0972e-01],
        [ 2.4896e+00, -8.2059e-01],
        [ 2.0235e+00,  7.4246e-01],
        [ 3.3325e+00,  6.7046e-02],
        [ 1.1755e+00,  3.6991e-01],
        [ 3.1568e+00,  1.6271e-02],
        [ 1.1727e+00,  6.5585e-02],
        [ 2.3328e+00,  9.5344e-01],
        [ 2.5953e+00, -1.7207e-01],
        [ 2.5602e+00, -1.0632e+00],
        [ 2.1039e+00, -2.2345e-01],
        [ 3.5559e+00, -2.1393e-01],
        [ 2.0119e+00, -1.1436e+00],
        [ 3.0073e+00, -6.5598e-01],
        [ 3.0269e+00, -9.6309e-01],
        [ 2.1582e+00,  7.8537e-01],
        [ 3.5453e+00,  1.6847e-01],
        [ 7.6600e-01, -2.5132e-01],
        [ 2.4796e+00,  1.7883e+00],
        [ 2.3220e+00,  6.9371e-01],
        [ 1.9585e+00, -5.8415e-02],
        [ 2.3002e+00, -4.5445e-01],
        [ 9.5605e-01, -2.4200e-01],
        [ 1.7047e+00,  5.4767e-01],
        [ 1.6142e+00,  1.2299e+00],
        [ 3.6089e+00, -9.5670e-01],
        [ 7.8435e-01, -2.6425e-01],
        [ 2.7598e+00,  9.6211e-01],
        [ 3.2350e+00, -6.1711e-01],
        [ 2.0825e+00, -9.1135e-01],
        [ 3.0734e+00,  9.8844e-01],
        [ 2.0632e+00,  2.0277e-01],
        [ 1.8580e+00,  6.3679e-01],
        [ 1.4765e+00,  9.1317e-01],
        [ 2.9539e+00, -1.3172e-01],
        [ 2.8326e+00, -7.4192e-01],
        [ 4.3916e+00, -6.3190e-02],
        [ 1.3604e+00, -4.8072e-01],
        [ 4.0457e+00, -4.1175e-01],
        [ 2.6237e+00, -1.7122e+00],
        [ 3.1464e+00,  1.8409e+00],
        [ 2.1667e+00,  7.9232e-01],
        [ 2.8714e+00, -1.7959e+00],
        [ 2.6961e+00, -2.0349e+00],
        [ 1.6884e+00,  1.1167e+00],
        [ 2.2123e+00, -3.5500e-01],
        [ 2.5134e+00, -1.0955e+00],
        [ 2.3172e+00,  1.5414e+00],
        [ 3.3363e+00,  5.8595e-01],
        [ 2.4468e+00, -7.0034e-01],
        [ 1.6565e+00, -7.0683e-01],
        [ 1.7215e+00,  9.2773e-01],
        [ 2.3616e+00, -8.7738e-01],
        [ 7.0451e-01, -1.4777e+00],
        [ 2.4648e+00, -1.2669e+00],
        [ 1.5220e+00, -1.2606e+00],
        [ 2.1526e+00,  1.2105e+00],
        [ 4.4789e+00,  6.3674e-01],
        [ 3.5238e+00, -2.2523e+00],
        [ 3.8436e-01,  9.1575e-01],
        [ 2.8066e+00, -4.7648e-01],
        [ 3.1536e+00, -4.6874e-01],
        [ 1.1386e+00, -7.7129e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.5402e-06, 1.2609e-01, 1.2609e-01,  ..., 9.8936e-01, 9.8936e-01,
         1.0000e+00],
        [1.3356e-03, 3.8154e-03, 1.0073e-02,  ..., 9.9470e-01, 9.9613e-01,
         1.0000e+00],
        [1.5126e-02, 7.1660e-02, 8.3672e-02,  ..., 4.3341e-01, 4.3341e-01,
         1.0000e+00],
        ...,
        [1.6093e-04, 3.1387e-03, 3.9273e-03,  ..., 7.9909e-01, 8.1274e-01,
         1.0000e+00],
        [1.8032e-03, 3.7066e-03, 3.7081e-03,  ..., 9.4648e-01, 9.4655e-01,
         1.0000e+00],
        [2.3584e-03, 1.3908e-01, 3.0676e-01,  ..., 9.9105e-01, 1.0000e+00,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.5509],
        [0.7408],
        [0.0017],
        [0.3619],
        [0.7298],
        [0.7946],
        [0.9191],
        [0.1020],
        [0.3436],
        [0.7338],
        [0.3208],
        [0.9311],
        [0.9341],
        [0.6590],
        [0.8880],
        [0.3167],
        [0.2315],
        [0.0849],
        [0.4959],
        [0.5750],
        [0.0806],
        [0.8500],
        [0.5325],
        [0.5900],
        [0.1571],
        [0.6991],
        [0.9254],
        [0.1297],
        [0.5519],
        [0.1363],
        [0.8513],
        [0.7898],
        [0.1486],
        [0.0211],
        [0.9601],
        [0.9017],
        [0.7513],
        [0.8493],
        [0.0838],
        [0.1129],
        [0.1651],
        [0.2722],
        [0.6790],
        [0.0655],
        [0.3913],
        [0.6574],
        [0.4118],
        [0.5305],
        [0.7143],
        [0.8413],
        [0.0641],
        [0.7156],
        [0.0934],
        [0.6202],
        [0.0788],
        [0.0758],
        [0.6040],
        [0.2191],
        [0.2649],
        [0.7213],
        [0.0289],
        [0.5631],
        [0.5597],
        [0.1722],
        [0.2713],
        [0.2872],
        [0.1155],
        [0.4589],
        [0.8017],
        [0.3609],
        [0.4279],
        [0.5827],
        [0.2161],
        [0.2685],
        [0.1345],
        [0.6947],
        [0.4466],
        [0.9919],
        [0.2190],
        [0.1345],
        [0.3930],
        [0.6733],
        [0.3378],
        [0.4727],
        [0.0792],
        [0.2871],
        [0.8075],
        [0.5557],
        [0.6357],
        [0.0911],
        [0.4996],
        [0.9235],
        [0.4351],
        [0.4842],
        [0.1502],
        [0.6340],
        [0.9773],
        [0.2986],
        [0.2161],
        [0.7945],
        [0.6661],
        [0.1482],
        [0.9196],
        [0.4192],
        [0.0832],
        [0.0733],
        [0.1868],
        [0.3679],
        [0.3907],
        [0.7724],
        [0.7803],
        [0.7495],
        [0.2761],
        [0.2980],
        [0.3904],
        [0.7524],
        [0.9093],
        [0.5965],
        [0.0621],
        [0.5419],
        [0.0160],
        [0.8988],
        [0.3874],
        [0.0464],
        [0.2400],
        [0.7722],
        [0.8527],
        [0.0677],
        [0.8313],
        [0.1996],
        [0.9876],
        [0.4227],
        [0.9732],
        [0.2700],
        [0.7542],
        [0.4701],
        [0.7943],
        [0.7676],
        [0.1499],
        [0.7131],
        [0.7146],
        [0.7487],
        [0.6752],
        [0.7958],
        [0.1393],
        [0.0808],
        [0.2124],
        [0.1533],
        [0.1557],
        [0.3589],
        [0.0577],
        [0.4948],
        [0.8197],
        [0.4825],
        [0.8729],
        [0.7488],
        [0.6378],
        [0.0546],
        [0.4245],
        [0.4965],
        [0.2795],
        [0.5918],
        [0.0122],
        [0.7633],
        [0.7739],
        [0.5756],
        [0.6863],
        [0.9947],
        [0.2027],
        [0.5087],
        [0.9518],
        [0.5894],
        [0.5630],
        [0.5547],
        [0.8477],
        [0.0132],
        [0.0640],
        [0.9310],
        [0.6981],
        [0.6532],
        [0.9860],
        [0.9405],
        [0.5961],
        [0.0268],
        [0.2905],
        [0.7147],
        [0.6893],
        [0.3412],
        [0.2448],
        [0.9113],
        [0.7781],
        [0.4102],
        [0.0871],
        [0.8233],
        [0.4522],
        [0.2593],
        [0.8127],
        [0.0927],
        [0.8844],
        [0.6595],
        [0.9858],
        [0.3903],
        [0.3237],
        [0.3255],
        [0.2407],
        [0.0734],
        [0.7581],
        [0.9357],
        [0.6791],
        [0.2792],
        [0.5280],
        [0.8186],
        [0.6442],
        [0.8728],
        [0.5245],
        [0.1263],
        [0.7017],
        [0.9256],
        [0.5125],
        [0.3881],
        [0.7490],
        [0.9959],
        [0.8724],
        [0.6729],
        [0.1871],
        [0.7258],
        [0.4786],
        [0.4537],
        [0.0260],
        [0.4344],
        [0.9098],
        [0.2805],
        [0.9272],
        [0.3794],
        [0.1083],
        [0.7774],
        [0.1417],
        [0.1514],
        [0.9041],
        [0.5237],
        [0.1139],
        [0.8758],
        [0.1783],
        [0.3726],
        [0.5208],
        [0.8998],
        [0.7259],
        [0.5947],
        [0.8568],
        [0.8800],
        [0.5497],
        [0.0768],
        [0.6876],
        [0.2388],
        [0.2927],
        [0.6101],
        [0.4291],
        [0.7261],
        [0.1185],
        [0.0068],
        [0.5548],
        [0.3107],
        [0.5929],
        [0.1547],
        [0.6245],
        [0.0184],
        [0.8540],
        [0.6355],
        [0.9924],
        [0.3134],
        [0.5525],
        [0.1939],
        [0.9685],
        [0.4942],
        [0.6352],
        [0.6565],
        [0.4030],
        [0.2299],
        [0.6001],
        [0.1852],
        [0.1188],
        [0.5840],
        [0.8607],
        [0.9929],
        [0.1857],
        [0.6132],
        [0.5419],
        [0.7746],
        [0.1796],
        [0.8987],
        [0.5839],
        [0.8511],
        [0.9490],
        [0.4679],
        [0.3495],
        [0.3030],
        [0.3931],
        [0.3773],
        [0.9350],
        [0.7302],
        [0.6399],
        [0.8410],
        [0.7915],
        [0.6825],
        [0.2180],
        [0.1452],
        [0.2960],
        [0.8574],
        [0.1357],
        [0.7358],
        [0.6426],
        [0.7445]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [ True, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-2.5569, -0.2481],
        [ 1.6768,  0.4394],
        [-4.6025, -0.0825],
        ...,
        [ 3.5634, -1.3398],
        [ 1.4263,  1.0908],
        [-2.5801, -0.1989]]) torch.Size([9984, 2])
samples tensor([[ 9.4465e-01, -2.3446e-01],
        [ 1.2090e+00,  4.1963e-01],
        [ 2.8659e+00,  2.3457e+00],
        [ 2.8349e+00,  5.1580e-01],
        [ 3.3740e+00,  6.6353e-01],
        [ 2.4144e+00,  5.0690e-01],
        [ 3.4470e+00, -5.1491e-01],
        [ 2.6888e+00,  6.1983e-01],
        [ 2.5981e+00,  2.0505e-01],
        [ 2.3029e+00, -1.6079e+00],
        [ 3.4919e+00, -2.2508e+00],
        [ 3.6943e+00,  1.3212e+00],
        [ 2.3896e+00,  1.1987e+00],
        [ 1.8135e+00, -7.9221e-01],
        [ 2.0047e+00,  2.2434e-01],
        [ 2.4507e+00, -1.8632e+00],
        [ 2.7427e+00, -2.1023e+00],
        [ 2.2545e+00,  1.2306e+00],
        [ 2.5404e+00, -6.3376e-01],
        [ 4.2982e+00, -1.5958e+00],
        [ 1.9394e+00, -1.6240e-01],
        [ 1.6967e+00,  4.4156e-01],
        [ 1.9940e+00, -1.9722e+00],
        [ 1.6035e+00,  1.6048e+00],
        [ 1.5810e+00,  9.3689e-01],
        [ 2.2430e+00, -1.4905e+00],
        [ 2.5439e+00,  7.1784e-01],
        [ 3.4905e+00, -6.9947e-01],
        [ 2.3973e+00, -9.7164e-01],
        [ 1.8408e+00, -1.0460e+00],
        [ 3.1992e+00, -1.9067e+00],
        [ 3.9850e+00,  1.6787e+00],
        [ 5.8794e-01, -5.4670e-01],
        [ 1.3360e+00,  1.2902e-01],
        [ 1.1938e+00,  7.1569e-01],
        [ 3.3918e+00,  3.0509e-01],
        [ 3.8295e+00, -1.4595e+00],
        [ 2.0892e+00,  1.1834e+00],
        [ 1.5495e+00, -4.2162e-01],
        [ 2.6268e+00, -2.0679e+00],
        [ 1.7829e+00,  5.3221e-01],
        [ 2.5595e+00, -6.6197e-02],
        [ 3.3679e+00,  1.8406e+00],
        [ 2.5139e+00, -2.6857e-01],
        [ 2.1528e+00,  2.7227e-01],
        [ 2.8845e+00,  2.5011e+00],
        [ 2.3612e+00, -6.4195e-01],
        [ 3.0329e+00,  1.5136e+00],
        [ 1.4892e+00,  2.7439e-01],
        [ 1.6965e+00, -3.9155e-01],
        [ 2.5996e+00, -7.4970e-01],
        [ 4.0458e+00,  8.1510e-01],
        [ 1.4367e+00, -6.1931e-02],
        [ 2.0353e+00, -1.3979e+00],
        [ 1.3183e+00,  4.6620e-01],
        [ 6.0255e-01,  3.1459e-01],
        [ 3.0666e+00, -1.3641e+00],
        [ 3.7882e+00, -1.3989e-01],
        [ 4.5480e+00,  4.1013e-01],
        [ 1.7335e+00,  1.4482e+00],
        [ 6.8403e-01,  7.3779e-01],
        [ 3.3810e+00, -4.4934e-01],
        [ 1.5260e+00,  9.5011e-01],
        [ 2.5885e+00, -2.9189e-01],
        [ 3.0991e+00,  8.1090e-01],
        [ 1.4316e+00, -1.8673e+00],
        [ 2.5955e+00,  1.1176e+00],
        [ 8.0518e-01,  1.0024e+00],
        [ 1.5613e+00,  4.6266e-01],
        [ 7.9492e-01,  2.2200e+00],
        [ 3.4295e+00,  6.7635e-01],
        [ 2.5825e+00, -6.2900e-01],
        [ 1.8801e+00,  1.0365e+00],
        [ 3.0008e+00,  1.3378e-01],
        [ 1.0483e+00,  1.3678e+00],
        [ 1.9868e+00,  8.7625e-01],
        [ 2.0117e+00,  1.3045e-01],
        [ 1.1057e+00,  1.2163e+00],
        [ 1.4802e+00, -8.7190e-01],
        [ 2.4069e+00,  1.6149e+00],
        [ 1.3365e+00, -9.1076e-01],
        [ 1.9360e+00, -4.0805e-01],
        [ 2.1678e+00, -1.3632e+00],
        [ 3.3636e+00,  9.6959e-02],
        [ 4.9013e+00,  1.5847e-01],
        [ 2.9988e+00, -3.4680e+00],
        [ 1.4783e+00, -1.8584e-01],
        [ 2.5403e+00,  6.8921e-01],
        [ 2.2983e+00, -2.9616e-02],
        [-7.7548e-02, -7.6729e-01],
        [ 2.4797e+00,  1.3540e+00],
        [ 2.6372e+00,  5.0600e-01],
        [ 2.2004e+00,  5.7186e-01],
        [ 1.7097e+00, -1.4503e+00],
        [ 3.6435e+00, -8.1459e-01],
        [ 3.8503e+00, -1.5902e-01],
        [ 3.1039e+00,  1.7156e-01],
        [ 2.0362e+00,  1.3449e+00],
        [ 3.0264e+00, -1.2703e+00],
        [ 2.6763e+00, -2.1001e-01],
        [ 3.5552e+00,  6.3673e-01],
        [ 3.4315e+00,  1.2186e+00],
        [ 2.5109e+00, -4.3098e-01],
        [ 9.5793e-01,  1.5122e+00],
        [ 2.1115e+00, -5.9865e-01],
        [ 3.1604e-01,  5.9103e-01],
        [ 3.3603e+00, -5.2078e-01],
        [ 3.2158e+00, -2.9346e-01],
        [ 3.7283e+00, -1.4784e+00],
        [ 2.2775e+00,  1.0680e+00],
        [ 3.1680e+00,  6.4705e-01],
        [ 3.5470e+00,  8.0580e-01],
        [ 2.0336e+00, -4.6831e-01],
        [ 1.8693e+00, -2.0002e+00],
        [ 2.1384e+00,  1.2370e-01],
        [ 6.7199e-01,  6.1076e-01],
        [ 2.6266e+00,  6.7841e-01],
        [ 3.1607e+00,  9.9457e-01],
        [ 1.0979e+00, -5.5348e-01],
        [ 3.4486e+00,  4.4863e-01],
        [ 5.3888e-01, -2.3906e-01],
        [ 2.5151e+00, -1.1135e-01],
        [ 2.0725e+00,  6.4742e-01],
        [ 2.8938e+00,  1.4065e+00],
        [ 2.1013e+00,  4.4395e-01],
        [ 4.9675e+00, -5.0754e-01],
        [ 2.6856e+00, -1.0557e-01],
        [ 2.1044e+00, -1.3740e-01],
        [ 1.9182e+00, -4.5195e-01],
        [ 2.6522e+00,  5.0992e-01],
        [ 3.6006e+00,  2.1739e-01],
        [ 1.8640e+00, -4.5732e-01],
        [ 1.3802e+00,  1.3187e+00],
        [ 2.4586e+00, -1.8125e-01],
        [ 2.6318e+00,  1.3631e-01],
        [ 5.7959e-01, -5.2738e-01],
        [ 1.3770e+00,  1.3234e+00],
        [ 1.5677e+00, -9.4991e-01],
        [ 2.3089e+00, -2.6085e-02],
        [ 1.2195e+00,  5.0537e-01],
        [ 1.6732e+00, -7.8322e-01],
        [ 4.0654e+00,  3.8137e-01],
        [ 1.9644e+00, -1.5988e+00],
        [ 2.7831e+00,  9.3959e-02],
        [ 2.2181e+00,  4.6304e-01],
        [ 5.5457e-01,  4.5027e-01],
        [ 1.7443e+00, -7.6013e-01],
        [ 1.2149e+00, -7.6907e-01],
        [ 1.5011e+00, -4.7869e-01],
        [ 1.3237e+00, -2.4036e+00],
        [ 3.0128e+00, -1.9333e+00],
        [ 2.9964e+00, -1.2087e+00],
        [ 2.6081e+00,  8.3839e-01],
        [ 3.0818e+00,  4.1936e-01],
        [ 2.9306e+00, -4.7032e-01],
        [ 2.5931e+00, -1.2149e+00],
        [ 2.1189e+00, -8.3079e-02],
        [ 1.7015e+00,  1.7802e+00],
        [ 3.1228e+00, -1.9647e+00],
        [ 2.2682e+00,  5.8294e-01],
        [ 2.8767e+00, -1.3449e+00],
        [ 1.1040e+00,  9.3961e-01],
        [ 4.4850e-01, -6.1503e-01],
        [ 4.6398e+00,  1.9965e+00],
        [ 4.5203e+00, -1.6092e-01],
        [ 2.3531e+00,  5.1516e-01],
        [ 1.8958e+00,  5.6769e-01],
        [ 9.3344e-01,  8.8539e-01],
        [ 3.4472e+00, -9.1380e-01],
        [ 2.7846e+00, -5.3224e-01],
        [ 3.8380e+00,  2.0410e-01],
        [ 3.2883e+00,  5.9560e-01],
        [ 3.2205e+00,  1.2581e+00],
        [ 1.6359e+00,  2.9902e-01],
        [ 2.5347e+00,  6.3461e-02],
        [ 8.8694e-01,  4.5189e-01],
        [ 1.9279e+00,  6.7393e-01],
        [ 2.9567e+00,  4.1244e-01],
        [ 4.3998e+00, -1.7002e+00],
        [ 2.1083e+00, -1.8864e-01],
        [ 1.7792e+00,  1.5109e+00],
        [ 1.3816e+00, -1.1702e+00],
        [ 2.6524e+00, -1.5869e+00],
        [ 1.8234e+00,  3.8121e-01],
        [ 2.0838e+00, -2.7524e-01],
        [ 2.2850e+00, -5.9603e-01],
        [ 2.2240e+00,  1.0310e+00],
        [ 2.8653e+00,  8.2505e-01],
        [ 3.9020e+00,  2.2765e-01],
        [ 3.2037e+00,  5.5588e-01],
        [ 2.7587e+00, -3.2760e-01],
        [ 4.1195e+00,  4.6594e-01],
        [ 2.2710e+00,  1.0582e+00],
        [ 2.3805e+00, -1.7134e+00],
        [ 2.0196e+00,  1.1387e-02],
        [ 2.0368e+00,  4.2945e-01],
        [ 2.0048e+00, -1.4544e+00],
        [ 2.3931e+00, -2.6238e-01],
        [ 2.0768e+00,  1.7638e-01],
        [ 1.8870e+00,  3.8584e-01],
        [ 2.5267e+00, -4.7560e-01],
        [ 2.1647e+00, -6.7389e-02],
        [ 4.6353e+00, -6.9686e-01],
        [ 2.9317e+00,  1.4731e-02],
        [ 3.5791e+00, -4.0773e-01],
        [ 2.0688e+00, -9.1721e-01],
        [ 2.6170e+00, -1.2054e+00],
        [ 2.1372e+00,  1.8650e+00],
        [ 1.6575e+00, -4.1580e-01],
        [ 2.7901e+00, -7.1693e-01],
        [ 2.1866e+00, -1.2893e+00],
        [ 2.7719e+00,  4.0585e-01],
        [ 3.5481e+00,  1.0470e+00],
        [ 3.7275e+00,  8.1090e-01],
        [ 2.1364e+00, -3.7648e-01],
        [ 2.0460e+00, -3.2741e-01],
        [ 1.7094e+00,  1.2552e+00],
        [ 7.1128e-01, -8.8622e-01],
        [ 1.3733e+00,  5.3501e-01],
        [ 3.5017e+00,  5.5906e-04],
        [ 1.9199e+00, -4.7160e-01],
        [ 2.4642e+00,  2.3755e-01],
        [ 3.8386e-01,  4.1791e-01],
        [ 4.6303e-01,  2.6272e-02],
        [ 2.3078e+00, -1.3559e+00],
        [ 2.3489e+00, -2.4939e+00],
        [ 2.0253e+00, -1.1873e+00],
        [ 3.0367e+00, -1.8201e+00],
        [ 2.7381e+00,  1.0830e-01],
        [ 2.7699e+00,  1.1936e+00],
        [ 6.9991e-01, -1.9942e-01],
        [ 3.4647e+00,  4.4621e-01],
        [ 2.2718e+00,  4.2421e-01],
        [ 3.5592e+00,  2.4017e-01],
        [ 1.7488e+00,  1.4463e+00],
        [ 2.3791e+00, -7.2610e-01],
        [ 1.2879e+00, -2.0272e-01],
        [ 1.1311e+00, -4.9749e-01],
        [ 2.6643e+00,  3.0323e-01],
        [ 5.6670e-01,  6.4869e-01],
        [ 3.0807e+00, -8.1691e-01],
        [ 2.7298e+00, -1.6239e-01],
        [ 3.2106e+00,  2.0176e+00],
        [ 3.0646e+00, -1.2538e-01],
        [ 3.5736e+00,  1.2502e+00],
        [ 1.9513e+00,  4.7108e-03],
        [ 2.6571e+00, -1.7541e+00],
        [ 1.0473e+00, -1.8007e+00],
        [ 1.0623e+00, -1.5290e-01],
        [ 2.9806e+00,  3.3996e-01],
        [ 9.7874e-01,  2.2696e-01],
        [ 2.6513e+00, -3.4294e-01],
        [ 2.0948e+00,  1.2867e+00],
        [ 1.3257e+00, -4.7430e-01],
        [ 3.9575e+00,  1.0578e+00],
        [ 1.9520e+00, -1.0342e+00],
        [ 2.3234e+00,  1.6824e+00],
        [ 4.5130e+00,  1.2733e+00],
        [ 3.1121e+00, -5.7663e-01],
        [ 2.0815e+00,  7.1261e-01],
        [ 3.2639e+00, -4.0921e-01],
        [ 3.4401e+00,  1.0147e+00],
        [ 1.4381e+00, -5.1068e-01],
        [ 2.0222e+00,  3.7102e-01],
        [ 9.8607e-01,  5.9622e-01],
        [ 4.6237e+00,  2.7829e-02],
        [ 2.4984e+00, -6.0574e-01],
        [ 2.4896e+00, -1.1569e+00],
        [ 2.3530e+00,  1.8874e+00],
        [ 1.7697e+00,  7.7348e-01],
        [ 3.2493e+00,  1.4120e+00],
        [ 4.0260e+00, -2.0153e+00],
        [ 3.0970e+00, -1.0247e+00],
        [ 4.8188e-01,  7.8215e-01],
        [ 2.6187e+00, -1.0867e+00],
        [ 1.5385e+00, -1.3442e+00],
        [ 3.6760e+00, -2.1728e-01],
        [ 2.2615e+00, -2.8150e-01],
        [ 1.6357e+00,  4.6396e-01],
        [ 1.6725e+00, -3.5619e-01],
        [ 3.0172e+00, -7.9699e-01],
        [ 2.3309e+00, -1.3958e+00],
        [ 2.3978e+00,  1.5676e+00],
        [ 1.2853e+00,  1.3336e+00],
        [ 1.2547e+00, -3.0152e-01],
        [ 1.2817e+00, -5.3834e-01],
        [ 2.8158e+00,  8.8797e-02],
        [ 2.7121e+00,  2.5483e-01],
        [ 2.8557e+00, -4.7001e-01],
        [ 4.0173e+00,  4.6909e-01],
        [ 1.9979e+00, -4.6792e-01],
        [ 4.2862e+00, -1.5789e-01],
        [ 3.0256e+00, -1.4461e+00],
        [ 2.6919e+00, -5.5203e-01],
        [ 2.9096e+00,  2.1037e+00],
        [ 1.9606e+00,  1.1717e+00],
        [ 4.4930e+00, -8.5447e-01],
        [ 3.1394e+00, -6.1570e-01],
        [ 1.1991e+00,  3.2431e-01],
        [ 3.1769e+00, -1.0275e+00],
        [ 2.1122e+00,  1.0869e+00],
        [ 1.5272e+00, -3.5797e-01],
        [ 1.2261e+00, -1.3426e+00],
        [ 2.8860e+00,  3.7251e-01],
        [ 2.2553e-01, -6.0205e-01],
        [ 3.6654e+00,  3.4749e-01],
        [ 1.9571e+00,  5.7163e-01],
        [ 3.0612e+00, -1.2848e+00],
        [ 4.8547e+00, -1.3816e-01],
        [ 2.6414e+00, -4.8991e-01],
        [ 2.0949e+00,  2.9282e-01],
        [ 2.6356e+00, -1.4066e+00]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[1.7882e-03, 2.1099e-02, 4.4053e-02,  ..., 9.9999e-01, 1.0000e+00,
         1.0000e+00],
        [1.2660e-02, 1.3937e-02, 2.2551e-02,  ..., 9.8825e-01, 9.8841e-01,
         1.0000e+00],
        [4.6043e-04, 2.5078e-01, 2.9011e-01,  ..., 8.4691e-01, 8.4692e-01,
         1.0000e+00],
        ...,
        [1.8127e-10, 2.1064e-01, 2.1067e-01,  ..., 9.9999e-01, 9.9999e-01,
         1.0000e+00],
        [6.4549e-03, 6.4611e-03, 7.9589e-03,  ..., 9.9806e-01, 9.9971e-01,
         1.0000e+00],
        [1.0792e-02, 1.3065e-02, 1.3496e-02,  ..., 9.6661e-01, 9.9752e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.0757],
        [0.3916],
        [0.6416],
        [0.4547],
        [0.5854],
        [0.0798],
        [0.7822],
        [0.7302],
        [0.3376],
        [0.8744],
        [0.9476],
        [0.3477],
        [0.9516],
        [0.8770],
        [0.1432],
        [0.6987],
        [0.2824],
        [0.6219],
        [0.7012],
        [0.2802],
        [0.7194],
        [0.9598],
        [0.3065],
        [0.5219],
        [0.3276],
        [0.3450],
        [0.3576],
        [0.9737],
        [0.9681],
        [0.6198],
        [0.8215],
        [0.7792],
        [0.4650],
        [0.8190],
        [0.1125],
        [0.3709],
        [0.6695],
        [0.9017],
        [0.9106],
        [0.4421],
        [0.0473],
        [0.4480],
        [0.3344],
        [0.3950],
        [0.1529],
        [0.2866],
        [0.9508],
        [0.8101],
        [0.7708],
        [0.5943],
        [0.0569],
        [0.3846],
        [0.3409],
        [0.4594],
        [0.1666],
        [0.9566],
        [0.1472],
        [0.7229],
        [0.1622],
        [0.1258],
        [0.6381],
        [0.3982],
        [0.0927],
        [0.1655],
        [0.5280],
        [0.1708],
        [0.4642],
        [0.5233],
        [0.0167],
        [0.6844],
        [0.0186],
        [0.9707],
        [0.5550],
        [0.2992],
        [0.5020],
        [0.2857],
        [0.6674],
        [0.7013],
        [0.0758],
        [0.3462],
        [0.0781],
        [0.4204],
        [0.3928],
        [0.0015],
        [0.4487],
        [0.9273],
        [0.1282],
        [0.1345],
        [0.1797],
        [0.4857],
        [0.9437],
        [0.5002],
        [0.9667],
        [0.3070],
        [0.0234],
        [0.4717],
        [0.1912],
        [0.3652],
        [0.7834],
        [0.1881],
        [0.8992],
        [0.2890],
        [0.5798],
        [0.6198],
        [0.8974],
        [0.1439],
        [0.2453],
        [0.7806],
        [0.1384],
        [0.4448],
        [0.6019],
        [0.0197],
        [0.4480],
        [0.4555],
        [0.7431],
        [0.4192],
        [0.2760],
        [0.8531],
        [0.8643],
        [0.9893],
        [0.7554],
        [0.8792],
        [0.0592],
        [0.1637],
        [0.5494],
        [0.4462],
        [0.1062],
        [0.1791],
        [0.1230],
        [0.4317],
        [0.0428],
        [0.1663],
        [0.6335],
        [0.7421],
        [0.1949],
        [0.4120],
        [0.3806],
        [0.2991],
        [0.0401],
        [0.1919],
        [0.7387],
        [0.4435],
        [0.4141],
        [0.7185],
        [0.6022],
        [0.5185],
        [0.7759],
        [0.9616],
        [0.7373],
        [0.4671],
        [0.4691],
        [0.3762],
        [0.2731],
        [0.7440],
        [0.1166],
        [0.5791],
        [0.4492],
        [0.5418],
        [0.9928],
        [0.8442],
        [0.7326],
        [0.4196],
        [0.0893],
        [0.3789],
        [0.8345],
        [0.7966],
        [0.7337],
        [0.5587],
        [0.1243],
        [0.4673],
        [0.9022],
        [0.7814],
        [0.0544],
        [0.8960],
        [0.6265],
        [0.3738],
        [0.0105],
        [0.5394],
        [0.2965],
        [0.7045],
        [0.6250],
        [0.4906],
        [0.4528],
        [0.5629],
        [0.5089],
        [0.3910],
        [0.8300],
        [0.5809],
        [0.0934],
        [0.2101],
        [0.1711],
        [0.6041],
        [0.3842],
        [0.9518],
        [0.6800],
        [0.9563],
        [0.2613],
        [0.5013],
        [0.6101],
        [0.9231],
        [0.4637],
        [0.6387],
        [0.1900],
        [0.4496],
        [0.3672],
        [0.4143],
        [0.1759],
        [0.2801],
        [0.0163],
        [0.5276],
        [0.9596],
        [0.2049],
        [0.2800],
        [0.8972],
        [0.3283],
        [0.6170],
        [0.9573],
        [0.9999],
        [0.4707],
        [0.7931],
        [0.4476],
        [0.8267],
        [0.6722],
        [0.5954],
        [0.2604],
        [0.7544],
        [0.9113],
        [0.1753],
        [0.0039],
        [0.8374],
        [0.2888],
        [0.1811],
        [0.7138],
        [0.7232],
        [0.1475],
        [0.6237],
        [0.0553],
        [0.1054],
        [0.0714],
        [0.0058],
        [0.4417],
        [0.3966],
        [0.7569],
        [0.9961],
        [0.7481],
        [0.2735],
        [0.9212],
        [0.1026],
        [0.6359],
        [0.3645],
        [0.5020],
        [0.9778],
        [0.0852],
        [0.4823],
        [0.5121],
        [0.7376],
        [0.9758],
        [0.3936],
        [0.6038],
        [0.3034],
        [0.8922],
        [0.1101],
        [0.0816],
        [0.5724],
        [0.3276],
        [0.7480],
        [0.0776],
        [0.1360],
        [0.3203],
        [0.6545],
        [0.0333],
        [0.7610],
        [0.5937],
        [0.3421],
        [0.2936],
        [0.7624],
        [0.4995],
        [0.8118],
        [0.6577],
        [0.1584],
        [0.4628],
        [0.0880],
        [0.3155],
        [0.9738],
        [0.6466],
        [0.0637],
        [0.6723],
        [0.6665],
        [0.2690],
        [0.4775],
        [0.1199],
        [0.5163],
        [0.3720],
        [0.9865],
        [0.2600],
        [0.0852],
        [0.8539],
        [0.8713],
        [0.7697],
        [0.9806],
        [0.3280],
        [0.8770],
        [0.9221],
        [0.2711],
        [0.0139],
        [0.9982],
        [0.7911],
        [0.4998],
        [0.4678],
        [0.6947],
        [0.7828],
        [0.0647]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-0.2002,  0.7387],
        [ 1.9408,  1.9504],
        [ 2.0480,  1.8723],
        ...,
        [-2.7503, -0.3761],
        [ 1.8729,  0.8758],
        [ 0.4581,  1.1236]]) torch.Size([9984, 2])
samples tensor([[ 2.6878e+00,  1.3261e+00],
        [ 3.4066e+00,  2.4546e-02],
        [ 1.6464e+00,  7.8408e-01],
        [ 2.0820e+00, -7.2677e-01],
        [ 1.7768e+00, -9.4129e-01],
        [ 3.3076e+00,  1.2447e+00],
        [ 2.4347e+00, -2.0747e-01],
        [ 2.8258e+00, -2.6620e-01],
        [ 1.9410e+00, -5.3959e-01],
        [ 7.4208e-01, -2.6276e-01],
        [ 1.0669e+00, -1.6217e-01],
        [ 2.1667e+00, -1.5013e+00],
        [ 2.7867e+00,  6.9394e-01],
        [ 2.5353e+00, -1.0237e+00],
        [ 1.7565e+00, -8.5177e-01],
        [ 3.4714e+00, -1.8448e+00],
        [ 6.1685e-01,  3.2175e-01],
        [ 2.0142e+00, -1.6190e+00],
        [ 2.1603e+00, -1.0059e-01],
        [ 2.1912e+00, -5.4398e-01],
        [ 3.9526e+00, -7.3560e-01],
        [-2.4392e-01,  1.7425e+00],
        [ 1.1925e+00, -1.9766e-01],
        [ 3.1322e+00, -1.6643e-01],
        [ 9.8356e-01, -1.1432e+00],
        [ 2.5932e-01, -1.2623e+00],
        [ 3.8550e+00,  5.1838e-01],
        [ 1.6067e+00,  7.4941e-01],
        [ 3.2844e+00, -2.5760e-01],
        [ 2.4460e+00, -2.0402e+00],
        [ 2.2626e+00, -8.3186e-02],
        [ 1.5476e+00, -1.4055e+00],
        [ 2.3228e+00,  6.9896e-01],
        [ 4.6723e-02,  1.8764e+00],
        [ 8.5435e-01, -6.2414e-01],
        [ 3.2188e+00,  3.9321e-01],
        [ 2.3713e+00, -7.9448e-01],
        [ 3.6205e+00, -1.1241e+00],
        [ 2.9857e+00, -5.2453e-01],
        [ 2.3255e+00,  1.0067e+00],
        [ 1.1471e+00, -6.6896e-01],
        [ 2.0624e+00, -5.7811e-01],
        [ 2.1823e+00, -1.4513e+00],
        [ 3.9268e+00,  1.9144e+00],
        [ 3.0661e+00, -3.6011e-01],
        [ 2.9586e+00,  2.7681e-01],
        [ 2.7726e+00,  1.1502e+00],
        [ 1.9252e+00,  1.8858e-01],
        [ 1.2235e+00, -1.1125e+00],
        [ 1.9282e+00, -4.8844e-02],
        [ 1.4432e+00,  2.9659e-01],
        [ 1.7867e+00,  1.1400e+00],
        [ 2.5154e+00, -4.4715e-01],
        [ 2.1010e+00, -1.1909e+00],
        [ 4.0603e+00, -6.7751e-01],
        [ 1.6985e+00,  8.4455e-01],
        [ 1.4308e+00,  2.1292e+00],
        [ 3.0124e+00,  1.2955e+00],
        [ 2.5081e+00,  1.7288e-01],
        [ 4.4726e+00, -2.9458e-01],
        [ 2.2575e+00,  3.8661e-01],
        [ 4.0061e+00, -1.1956e+00],
        [ 2.7027e+00,  1.9238e-01],
        [ 1.9009e+00, -1.1804e+00],
        [ 1.9088e+00, -9.2929e-01],
        [ 3.4974e+00, -2.0804e+00],
        [ 2.9034e+00,  7.8345e-02],
        [ 2.6149e-01, -1.8164e+00],
        [ 1.9589e+00, -9.3450e-01],
        [ 8.0747e-01,  1.4433e+00],
        [ 2.1571e+00, -2.5132e-01],
        [ 1.9350e+00, -3.8128e-01],
        [ 1.5993e+00,  5.4769e-01],
        [ 3.4589e+00, -2.2046e+00],
        [ 1.4582e+00, -7.4516e-02],
        [ 1.6090e+00, -2.7187e-01],
        [-8.9162e-03,  1.5055e+00],
        [ 2.9699e+00, -4.6591e-01],
        [ 1.6396e+00,  4.0576e-01],
        [ 1.0744e+00, -8.6388e-01],
        [ 2.8351e+00, -1.2444e+00],
        [ 3.0166e+00, -6.9813e-01],
        [ 2.7597e+00, -1.8137e+00],
        [ 6.0038e-01,  3.8648e-01],
        [ 3.2005e+00,  1.1144e+00],
        [ 1.7540e+00,  4.3864e-01],
        [ 2.2413e+00, -3.8608e-01],
        [ 2.9750e+00, -2.9513e-01],
        [ 1.7227e+00, -4.2181e-01],
        [ 2.7041e+00, -8.0724e-02],
        [ 2.3135e+00,  1.2081e+00],
        [ 1.4985e+00,  1.2080e-01],
        [ 3.3391e+00,  1.2814e-02],
        [ 1.5818e+00, -1.1508e+00],
        [ 2.9206e+00,  1.3897e+00],
        [ 3.9947e-01,  2.7718e-01],
        [ 1.6121e+00,  1.6381e+00],
        [ 2.3019e+00,  7.8125e-01],
        [ 1.8557e+00, -8.4357e-01],
        [ 1.9962e+00, -8.6626e-01],
        [ 2.7862e+00, -1.4272e-02],
        [ 8.4725e-01,  8.8015e-01],
        [ 1.7180e+00, -8.1290e-01],
        [ 1.3603e+00,  8.1625e-02],
        [ 2.3960e+00,  7.8330e-01],
        [ 2.5899e+00,  7.9896e-02],
        [ 1.5570e+00, -8.0747e-02],
        [ 2.8744e+00, -4.0237e-01],
        [ 2.0693e+00,  3.4737e-01],
        [ 4.8879e+00,  3.9138e-02],
        [ 1.1642e+00,  1.0078e+00],
        [ 3.5324e+00,  7.4355e-01],
        [ 1.9196e+00, -5.5366e-01],
        [ 2.3702e+00,  1.5174e-02],
        [ 1.4986e+00, -1.2053e+00],
        [ 3.4773e+00, -1.8924e+00],
        [ 1.8055e+00,  1.8814e-01],
        [ 3.9956e+00, -9.2819e-01],
        [ 3.7818e+00,  6.6893e-01],
        [ 3.8633e+00,  1.4014e+00],
        [ 1.0175e+00,  7.9493e-01],
        [ 1.0300e+00,  9.3625e-01],
        [ 4.7396e+00,  7.3240e-01],
        [ 1.4284e+00,  4.4080e-01],
        [ 2.8136e+00, -1.6386e+00],
        [ 2.2827e+00,  1.0416e+00],
        [ 2.4800e+00,  1.2476e+00],
        [ 2.3192e+00, -1.3841e-01],
        [ 2.8275e+00, -5.5313e-01],
        [ 2.2464e+00, -2.1473e+00],
        [ 1.7604e+00,  3.1733e-01],
        [ 2.9167e+00,  1.0792e+00],
        [ 2.3779e+00, -1.9215e+00],
        [ 1.2790e+00, -6.9525e-01],
        [ 6.3659e-01,  7.7261e-01],
        [ 2.4412e+00,  8.7796e-02],
        [ 1.2991e+00, -8.0705e-01],
        [ 3.4555e+00,  1.9318e-02],
        [ 1.4849e+00, -7.5628e-02],
        [ 2.6874e+00, -3.2686e-01],
        [ 1.4486e+00,  9.5522e-01],
        [ 3.6548e+00,  1.9590e-02],
        [ 1.6864e+00,  4.4919e-02],
        [ 3.2609e+00,  5.6915e-01],
        [ 2.2237e+00, -1.5155e+00],
        [ 3.3667e+00, -1.4203e+00],
        [ 2.5233e+00,  1.4459e+00],
        [ 3.5280e+00,  9.7744e-01],
        [ 1.5254e+00, -8.2393e-01],
        [ 3.4114e+00,  1.1877e+00],
        [ 3.4409e+00, -5.9070e-02],
        [ 3.5504e+00, -2.3453e-01],
        [ 1.0062e+00,  8.4509e-02],
        [ 1.6195e+00,  1.0167e+00],
        [ 3.4667e+00, -7.8671e-02],
        [ 3.4679e+00, -4.5063e-01],
        [ 3.5283e+00, -1.3215e+00],
        [ 3.5237e+00,  1.8265e-01],
        [ 6.0988e-01,  7.6545e-02],
        [ 4.5750e-01, -1.1002e+00],
        [ 1.7065e+00, -1.0079e-01],
        [ 2.7975e+00, -4.5446e-01],
        [ 8.9249e-01,  7.7221e-02],
        [ 3.0623e+00, -3.4215e-01],
        [ 1.6324e+00, -2.7539e-01],
        [ 2.9944e+00, -9.8567e-01],
        [ 1.8898e+00, -5.6851e-01],
        [ 3.1553e+00, -1.8841e-01],
        [ 2.4355e+00, -5.0765e-01],
        [ 1.6719e+00, -3.6262e-01],
        [ 1.8999e+00,  2.7782e-01],
        [ 2.7331e+00, -8.7162e-02],
        [ 1.2820e+00,  1.7853e-01],
        [ 1.7429e+00,  3.5802e-01],
        [ 2.5248e+00, -9.0166e-01],
        [ 1.9012e+00,  1.5675e+00],
        [ 3.0172e+00,  1.8867e+00],
        [ 3.0612e+00, -9.4568e-02],
        [ 1.7977e+00, -9.4829e-01],
        [ 2.0191e+00,  1.5521e+00],
        [ 2.6713e+00, -1.1962e+00],
        [ 2.2907e+00,  1.4169e+00],
        [ 1.8160e+00, -1.8481e+00],
        [ 2.6845e+00, -4.2901e-01],
        [ 2.0774e+00,  4.9769e-03],
        [ 2.6298e+00, -2.5692e-01],
        [ 2.2470e+00, -2.8095e+00],
        [ 2.5502e+00,  1.2866e+00],
        [ 3.1793e+00, -6.4597e-01],
        [ 2.2475e+00, -4.6107e-01],
        [ 1.7950e+00, -6.2458e-01],
        [ 2.4558e+00, -7.6357e-01],
        [ 1.0543e+00,  4.0339e-02],
        [ 2.6044e+00, -2.6806e-01],
        [ 2.5857e+00,  8.6033e-01],
        [ 2.2232e+00,  1.4098e-01],
        [ 2.1324e+00, -5.8753e-02],
        [ 1.5573e+00, -2.6463e-01],
        [ 2.3764e+00,  5.5077e-01],
        [ 2.1636e+00,  1.3291e+00],
        [ 2.1473e+00,  2.0066e+00],
        [ 2.3944e+00, -9.2114e-01],
        [ 1.9504e+00, -8.5567e-01],
        [ 2.7166e+00,  1.9699e-02],
        [ 1.6569e+00,  1.0500e+00],
        [ 1.2478e+00,  1.5389e-01],
        [ 2.8387e+00, -6.4378e-01],
        [-1.0130e-01, -8.0157e-01],
        [ 2.0982e+00,  5.2139e-02],
        [ 2.0562e+00, -1.2179e+00],
        [-3.6495e-01, -1.0504e-01],
        [ 1.3131e+00, -3.4325e-01],
        [ 1.8047e+00, -8.1844e-01],
        [ 3.3223e+00,  2.0677e+00],
        [ 2.3990e+00, -1.2857e-01],
        [ 2.1962e+00,  5.2815e-01],
        [ 2.0757e+00,  6.8862e-01],
        [ 8.8375e-01, -1.7087e+00],
        [ 3.7532e+00,  2.6638e-01],
        [ 1.6686e+00, -9.4663e-01],
        [ 2.3351e+00, -5.4017e-01],
        [ 2.5688e+00, -5.5408e-01],
        [ 1.1013e+00,  6.2495e-01],
        [ 3.0570e+00,  8.0116e-01],
        [ 2.6931e+00, -2.6623e-01],
        [ 1.8846e+00, -1.8641e+00],
        [ 3.7070e+00, -4.5570e-01],
        [ 3.3984e+00,  3.4068e-01],
        [ 6.4406e-01,  8.2295e-01],
        [ 4.2481e+00, -1.2610e-01],
        [ 2.3224e+00, -1.5339e+00],
        [ 3.1369e+00, -1.2942e+00],
        [ 3.3862e+00, -7.4611e-01],
        [ 2.6424e+00,  7.6303e-01],
        [ 3.9883e+00, -1.3030e+00],
        [ 2.2557e+00,  4.7624e-01],
        [ 1.8903e+00, -2.1560e+00],
        [ 2.1575e+00, -4.3295e-01],
        [ 2.9744e+00, -1.9825e-01],
        [ 1.8519e+00,  1.1859e+00],
        [ 3.5756e+00,  5.4069e-01],
        [ 3.1907e+00,  4.0109e-01],
        [ 3.6339e+00,  1.8688e+00],
        [ 5.9347e-01,  1.5406e+00],
        [ 3.3304e+00, -9.7760e-01],
        [ 1.5609e+00, -4.4374e-01],
        [ 2.2528e+00, -5.7379e-01],
        [ 1.3959e+00, -8.0085e-01],
        [ 3.8300e+00, -9.6793e-01],
        [ 4.7364e+00, -7.8476e-01],
        [ 2.5962e+00, -2.1219e-01],
        [ 3.9448e+00,  4.6900e-01],
        [ 1.4506e+00, -1.4624e+00],
        [ 2.8009e+00, -8.7561e-01],
        [ 2.2680e+00,  8.9251e-01],
        [ 3.5774e+00,  6.0678e-01],
        [ 2.2953e+00, -2.7355e-02],
        [ 2.0714e+00, -5.8906e-01],
        [ 1.8334e+00,  1.6085e+00],
        [ 1.3932e+00, -6.2916e-01],
        [ 8.3012e-01,  8.6009e-01],
        [ 2.1750e+00, -4.4540e-01],
        [ 1.7275e+00, -8.2325e-01],
        [ 2.7457e+00, -1.1134e-01],
        [ 1.0036e+00,  1.5544e+00],
        [ 3.1633e+00, -8.2018e-01],
        [ 9.5580e-01,  1.8172e+00],
        [ 1.3434e+00, -6.0353e-01],
        [ 2.3545e+00,  1.2932e+00],
        [ 2.9332e+00, -1.7078e-01],
        [ 1.9335e+00,  2.1000e-01],
        [ 3.3027e+00, -4.2126e-01],
        [ 2.6774e+00,  8.0991e-01],
        [ 6.6251e-01, -1.3784e+00],
        [ 3.3880e+00,  1.2715e-01],
        [ 4.3586e+00,  9.8414e-01],
        [ 2.0537e+00,  1.2898e-01],
        [ 2.1991e+00, -2.5088e-01],
        [ 1.1815e+00, -2.2245e+00],
        [ 2.4974e+00,  1.0115e-01],
        [ 2.3619e+00, -3.6319e-01],
        [ 2.5889e+00,  1.3487e-01],
        [ 3.3677e+00, -3.2632e-01],
        [ 3.4680e+00,  1.7959e+00],
        [ 4.3601e+00,  1.6514e+00],
        [ 4.4541e+00,  5.5863e-01],
        [ 1.5675e+00,  2.3797e-01],
        [ 8.2438e-01, -5.6783e-01],
        [ 4.1256e+00,  2.0598e-01],
        [ 3.1017e+00, -2.9499e-01],
        [ 2.3390e+00, -1.0853e+00],
        [ 4.1148e+00,  6.0248e-02],
        [ 3.1932e+00, -1.1714e+00],
        [ 1.2865e+00,  3.0225e-01],
        [ 2.5645e+00, -2.6348e-01],
        [ 2.0610e+00,  9.7587e-02],
        [ 2.6176e+00, -4.3935e-03],
        [ 2.6581e+00,  4.2214e-01],
        [ 2.7542e+00, -1.1728e+00],
        [ 2.7539e+00, -1.0289e+00],
        [ 2.3026e+00, -5.5336e-01],
        [ 2.0919e+00,  3.0511e-02],
        [ 2.7587e+00,  2.6906e-01],
        [ 1.5962e+00, -1.0187e+00],
        [ 5.1412e-01, -3.2023e-01],
        [ 3.4952e+00,  2.6118e+00],
        [ 2.8961e+00, -1.4559e+00],
        [ 9.7166e-01, -2.7498e-01],
        [ 2.7794e+00,  9.4963e-01],
        [ 2.0812e+00, -1.8063e+00],
        [ 2.9030e+00, -1.3045e+00],
        [ 1.8204e+00,  3.7433e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[5.7962e-03, 6.6508e-03, 6.7763e-03,  ..., 9.6238e-01, 9.6238e-01,
         1.0000e+00],
        [2.1966e-01, 2.1966e-01, 2.2099e-01,  ..., 9.8478e-01, 9.9993e-01,
         1.0000e+00],
        [1.3039e-03, 3.0179e-03, 4.1648e-01,  ..., 9.9649e-01, 9.9655e-01,
         1.0000e+00],
        ...,
        [5.5921e-02, 5.7329e-02, 9.5090e-02,  ..., 9.9171e-01, 1.0000e+00,
         1.0000e+00],
        [2.5833e-01, 2.6448e-01, 2.6735e-01,  ..., 9.0462e-01, 9.5580e-01,
         1.0000e+00],
        [4.0626e-07, 9.0282e-03, 9.0282e-03,  ..., 9.9198e-01, 9.9974e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.3023],
        [0.5719],
        [0.9171],
        [0.0722],
        [0.3520],
        [0.8808],
        [0.8152],
        [0.7893],
        [0.2332],
        [0.1073],
        [0.2491],
        [0.2337],
        [0.4914],
        [0.9221],
        [0.1685],
        [0.8910],
        [0.9689],
        [0.9405],
        [0.0536],
        [0.2878],
        [0.8784],
        [0.9417],
        [0.3875],
        [0.2644],
        [0.7686],
        [0.2026],
        [0.9093],
        [0.7564],
        [0.3739],
        [0.1234],
        [0.6330],
        [0.4843],
        [0.1741],
        [0.2623],
        [0.5914],
        [0.3575],
        [0.2878],
        [0.3035],
        [0.0648],
        [0.2442],
        [0.2995],
        [0.1560],
        [0.6693],
        [0.9786],
        [0.0478],
        [0.4791],
        [0.2423],
        [0.2384],
        [0.0691],
        [0.4432],
        [0.7426],
        [0.3096],
        [0.6073],
        [0.5866],
        [0.7109],
        [0.2303],
        [0.3868],
        [0.0178],
        [0.2958],
        [0.1589],
        [0.2714],
        [0.2786],
        [0.8562],
        [0.4201],
        [0.5542],
        [0.7950],
        [0.9415],
        [0.8734],
        [0.8241],
        [0.0570],
        [0.2539],
        [0.6971],
        [0.3598],
        [0.7156],
        [0.8073],
        [0.5756],
        [0.6210],
        [0.2109],
        [0.7971],
        [0.0552],
        [0.4289],
        [0.9356],
        [0.7990],
        [0.1670],
        [0.0936],
        [0.7437],
        [0.4702],
        [0.5881],
        [0.4328],
        [0.5792],
        [0.8358],
        [0.1174],
        [0.7464],
        [0.8412],
        [0.3203],
        [0.2751],
        [0.3556],
        [0.3523],
        [0.4002],
        [0.1249],
        [0.6295],
        [0.5510],
        [0.2519],
        [0.7150],
        [0.7489],
        [0.0874],
        [0.9225],
        [0.8305],
        [0.3392],
        [0.7611],
        [0.2277],
        [0.6147],
        [0.0234],
        [0.5301],
        [0.4746],
        [0.5133],
        [0.9712],
        [0.6127],
        [0.5941],
        [0.0787],
        [0.4801],
        [0.5771],
        [0.2610],
        [0.6265],
        [0.5729],
        [0.1941],
        [0.3973],
        [0.9734],
        [0.8022],
        [0.9598],
        [0.3793],
        [0.4324],
        [0.4142],
        [0.9651],
        [0.3737],
        [0.7982],
        [0.0856],
        [0.8175],
        [0.2891],
        [0.8845],
        [0.4875],
        [0.5224],
        [0.4601],
        [0.9826],
        [0.7755],
        [0.9151],
        [0.1596],
        [0.8449],
        [0.5058],
        [0.9517],
        [0.0407],
        [0.8523],
        [0.3920],
        [0.2100],
        [0.8905],
        [0.3426],
        [0.4790],
        [0.4692],
        [0.0655],
        [0.2790],
        [0.2729],
        [0.3488],
        [0.3514],
        [0.5686],
        [0.0099],
        [0.1895],
        [0.3060],
        [0.1157],
        [0.0801],
        [0.9929],
        [0.1507],
        [0.1293],
        [0.1682],
        [0.9213],
        [0.5855],
        [0.7434],
        [0.6196],
        [0.3709],
        [0.5143],
        [0.3924],
        [0.2195],
        [0.4374],
        [0.9785],
        [0.2498],
        [0.3812],
        [0.1748],
        [0.7145],
        [0.7234],
        [0.7447],
        [0.8233],
        [0.3471],
        [0.9850],
        [0.6017],
        [0.9684],
        [0.8602],
        [0.9465],
        [0.2727],
        [0.8867],
        [0.5682],
        [0.5332],
        [0.1266],
        [0.4703],
        [0.1245],
        [0.8590],
        [0.6239],
        [0.6151],
        [0.0151],
        [0.8225],
        [0.6913],
        [0.3778],
        [0.2527],
        [0.8630],
        [0.8937],
        [0.1865],
        [0.8629],
        [0.5327],
        [0.3188],
        [0.0960],
        [0.5734],
        [0.2198],
        [0.0745],
        [0.8787],
        [0.4613],
        [0.1851],
        [0.8338],
        [0.1797],
        [0.5730],
        [0.0533],
        [0.8659],
        [0.1094],
        [0.0217],
        [0.6862],
        [0.2327],
        [0.9676],
        [0.9365],
        [0.3742],
        [0.7727],
        [0.9535],
        [0.0061],
        [0.2056],
        [0.2758],
        [0.5981],
        [0.8907],
        [0.6646],
        [0.8515],
        [0.4101],
        [0.2019],
        [0.2478],
        [0.3816],
        [0.2909],
        [0.8810],
        [0.2173],
        [0.1516],
        [0.2690],
        [0.2671],
        [0.9984],
        [0.0165],
        [0.9823],
        [0.0111],
        [0.8836],
        [0.7690],
        [0.0332],
        [0.6717],
        [0.2766],
        [0.0464],
        [0.9169],
        [0.4158],
        [0.0063],
        [0.2933],
        [0.2771],
        [0.7295],
        [0.5187],
        [0.9414],
        [0.4068],
        [0.1046],
        [0.7311],
        [0.0756],
        [0.3112],
        [0.8343],
        [0.5892],
        [0.2551],
        [0.6839],
        [0.7455],
        [0.1166],
        [0.2534],
        [0.6648],
        [0.7178],
        [0.2760],
        [0.9878],
        [0.1901],
        [0.8980],
        [0.0662],
        [0.6040],
        [0.2721],
        [0.5207],
        [0.9246],
        [0.3753],
        [0.4801],
        [0.9522],
        [0.4429],
        [0.5665],
        [0.9047],
        [0.6870],
        [0.4307],
        [0.2906],
        [0.5541],
        [0.2558],
        [0.3985],
        [0.9816],
        [0.2753],
        [0.7242],
        [0.7320]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 1.6399,  1.9841],
        [ 0.0443,  1.1860],
        [-0.9360,  0.4089],
        ...,
        [-1.2342,  0.5024],
        [ 2.6426,  2.7001],
        [-0.8548,  0.6405]]) torch.Size([9984, 2])
samples tensor([[ 2.0921e+00,  1.1336e-01],
        [ 2.3189e+00, -2.6874e+00],
        [ 2.8213e+00,  1.0002e+00],
        [ 2.6197e+00,  1.3097e+00],
        [ 8.4618e-01, -4.6152e-01],
        [ 3.1899e+00, -1.4695e+00],
        [ 2.8705e+00, -1.5489e+00],
        [ 2.5218e+00,  9.4725e-01],
        [ 3.4699e+00,  3.3402e-01],
        [ 3.2641e+00,  4.0111e-01],
        [ 1.1444e+00, -1.5945e+00],
        [ 1.4345e+00,  2.5731e-01],
        [ 1.3562e+00, -1.7973e+00],
        [ 3.0473e+00,  4.0386e-01],
        [ 2.8298e+00, -4.5061e-01],
        [ 2.8322e+00,  1.0248e+00],
        [ 3.1937e+00, -2.0928e+00],
        [ 2.5072e+00,  1.5605e-01],
        [ 1.1409e+00,  3.5191e-02],
        [ 1.7949e+00, -2.3404e+00],
        [ 2.0685e+00, -9.3806e-01],
        [ 2.9261e+00, -1.6898e+00],
        [ 2.1663e+00, -5.9147e-03],
        [ 2.9299e+00, -1.4375e+00],
        [ 1.9115e+00, -1.5680e-01],
        [ 2.6080e+00,  8.5434e-01],
        [ 3.4162e+00, -5.5505e-01],
        [ 3.4278e+00, -4.7701e-01],
        [ 1.4594e+00, -2.9936e-01],
        [ 4.4578e+00, -4.0341e-01],
        [ 2.5280e+00, -5.3349e-01],
        [ 3.4116e+00,  1.0276e+00],
        [ 3.4204e+00, -7.7865e-01],
        [ 2.7328e+00, -1.5497e-01],
        [ 2.6823e+00,  1.3368e-01],
        [ 7.2527e-01, -2.2068e-01],
        [ 2.3302e+00, -2.0908e+00],
        [ 3.1677e+00, -1.1628e+00],
        [ 1.6038e+00,  2.5999e-01],
        [ 2.4130e+00, -7.6493e-03],
        [ 8.8710e-01,  1.8843e+00],
        [ 1.4432e+00, -1.7679e+00],
        [ 1.2737e+00,  1.0065e+00],
        [ 1.6387e+00,  2.1490e+00],
        [ 3.5047e+00, -5.2477e-01],
        [ 2.3471e+00, -3.5997e-01],
        [ 3.2827e+00,  1.3483e-01],
        [ 3.0214e+00, -8.2068e-01],
        [ 2.9358e+00,  8.7585e-02],
        [ 2.1290e+00, -9.5063e-01],
        [ 2.4930e+00, -3.3205e-01],
        [ 7.9079e-01,  1.1120e+00],
        [ 2.5863e+00, -1.3159e+00],
        [ 3.3513e+00,  1.5681e-01],
        [ 1.6307e+00,  1.0187e+00],
        [ 1.9638e+00, -3.9675e-01],
        [ 2.1079e+00, -1.0627e+00],
        [ 1.1139e+00,  1.1179e-01],
        [ 3.0741e+00,  5.8512e-01],
        [ 2.3747e+00,  3.8623e-01],
        [ 2.6202e+00, -2.2677e+00],
        [ 4.5011e+00,  1.2365e+00],
        [ 3.0209e+00, -1.5234e+00],
        [ 1.5550e+00, -1.2734e+00],
        [ 4.1268e+00, -4.5198e-01],
        [ 1.8020e+00,  1.1840e+00],
        [ 2.4856e+00, -2.0189e+00],
        [ 2.5102e+00,  1.0633e+00],
        [ 3.4521e+00,  4.4238e-01],
        [ 4.2447e+00,  9.2631e-01],
        [ 1.2469e+00, -1.2295e+00],
        [ 2.3727e+00, -8.3751e-01],
        [ 1.3674e+00,  8.1073e-01],
        [ 1.8236e+00,  1.0059e+00],
        [ 1.5266e+00, -8.9695e-01],
        [ 2.1283e+00,  3.8843e-01],
        [ 2.6483e+00,  7.5883e-01],
        [ 3.2689e+00, -1.4149e+00],
        [ 2.1359e+00,  7.7648e-02],
        [ 1.4587e+00, -1.5701e+00],
        [ 1.1133e+00, -1.6432e+00],
        [ 4.5675e+00, -1.1994e+00],
        [ 3.0519e+00,  1.0663e+00],
        [ 3.3875e+00, -4.6298e-01],
        [ 2.7195e+00,  5.6895e-01],
        [ 3.3058e+00, -7.6730e-01],
        [ 2.2625e+00,  1.9521e+00],
        [ 1.5847e+00, -1.4362e-01],
        [ 3.2060e+00, -1.0038e+00],
        [ 1.3808e+00, -1.1469e+00],
        [ 2.5661e+00, -1.5370e-01],
        [ 5.4125e-01,  2.7291e-01],
        [ 2.9926e+00, -4.8484e-03],
        [ 2.2798e+00, -6.5299e-01],
        [ 1.9967e+00, -1.8288e+00],
        [ 2.4542e+00, -4.3406e-01],
        [ 2.2578e+00,  6.3102e-01],
        [ 2.4546e+00, -1.1834e-01],
        [ 4.6776e+00,  1.4228e+00],
        [ 3.8151e+00,  6.6488e-01],
        [ 4.1385e+00,  1.7034e+00],
        [ 1.8312e+00, -1.2162e+00],
        [ 2.9410e+00, -6.5166e-01],
        [ 2.5304e+00, -2.4478e-01],
        [ 3.0041e+00,  4.8253e-01],
        [ 2.4499e+00,  4.0277e-01],
        [-1.3664e+00,  8.4263e-01],
        [ 2.8091e+00, -4.0561e-01],
        [ 2.4326e+00,  5.5998e-01],
        [-3.5114e-01, -6.9891e-01],
        [ 1.7625e+00,  6.4574e-01],
        [ 3.3742e+00, -1.9017e+00],
        [ 1.8197e+00, -7.7953e-01],
        [ 1.7541e+00, -1.7019e-01],
        [ 3.3475e+00, -1.4426e+00],
        [ 2.7828e+00,  2.6509e-01],
        [ 6.4606e-01, -4.5342e-01],
        [ 3.2767e+00,  2.5385e-01],
        [ 5.4744e-01, -5.2708e-01],
        [ 2.2005e+00,  8.8529e-01],
        [ 2.3794e+00,  8.9038e-01],
        [ 1.7324e+00, -1.2120e-01],
        [ 2.6456e+00, -6.4392e-01],
        [ 8.8625e-01, -1.6794e+00],
        [ 2.4615e+00, -1.1531e+00],
        [ 4.0709e+00,  9.9660e-01],
        [ 2.3014e+00, -6.0704e-01],
        [ 1.3229e+00, -4.9400e-01],
        [ 3.3823e+00,  1.3747e+00],
        [ 1.4089e+00,  7.9027e-01],
        [ 2.4450e+00, -1.5711e+00],
        [ 1.4872e+00,  8.0475e-01],
        [ 2.4112e+00,  2.2399e-01],
        [ 2.8563e+00, -3.4759e-01],
        [ 1.0339e+00, -2.0595e+00],
        [ 1.6824e+00,  1.0543e+00],
        [ 1.2640e+00,  2.6417e-02],
        [ 3.1977e+00, -5.5014e-01],
        [ 2.4496e+00,  4.5905e-01],
        [ 2.1717e+00, -1.5571e+00],
        [ 2.5954e+00,  1.0098e-01],
        [ 2.3588e+00, -2.4590e+00],
        [ 2.4680e+00, -6.1285e-01],
        [ 2.9456e+00,  1.4588e+00],
        [ 3.3673e+00,  1.4659e+00],
        [ 1.8335e+00, -5.3828e-02],
        [ 2.6424e+00, -1.4021e+00],
        [-1.8284e-01,  1.8266e+00],
        [ 4.0436e+00, -1.0578e+00],
        [ 2.4445e+00,  7.0409e-01],
        [ 3.1622e+00, -7.1656e-01],
        [ 2.1662e+00,  4.5490e-01],
        [ 4.5741e+00, -1.8879e+00],
        [ 1.5155e+00,  3.0418e-01],
        [ 2.9737e+00, -8.2648e-01],
        [ 2.5856e+00, -2.3951e-01],
        [ 2.4250e+00, -2.0067e+00],
        [ 1.5947e+00, -7.9497e-01],
        [ 9.1572e-01,  2.4331e-01],
        [ 3.6403e+00, -1.1155e-01],
        [ 1.5862e+00,  3.2151e-02],
        [ 2.9504e+00, -1.3607e+00],
        [ 3.3495e+00,  1.5454e+00],
        [ 2.6509e+00, -9.9583e-01],
        [ 1.1726e+00, -7.0437e-01],
        [ 1.9212e+00, -9.2240e-01],
        [ 1.8182e+00,  1.9418e+00],
        [ 2.5632e+00,  6.6089e-01],
        [ 2.6257e+00,  8.1812e-01],
        [-3.1994e-01, -4.5791e-02],
        [ 2.5658e+00, -9.9638e-01],
        [ 1.6247e+00,  6.2449e-01],
        [ 2.7269e+00,  1.4325e+00],
        [ 3.0446e+00, -1.2857e+00],
        [ 3.9312e+00,  1.0919e+00],
        [ 3.1111e+00,  1.3781e+00],
        [ 4.2150e-01, -7.4769e-01],
        [ 1.9770e+00, -4.7559e-01],
        [ 1.7330e+00, -3.6410e-01],
        [ 1.5442e+00,  9.8756e-01],
        [ 1.2024e+00,  6.7252e-01],
        [ 1.3505e+00, -2.9587e-01],
        [ 1.6391e+00,  1.5117e+00],
        [ 3.8175e+00, -5.9647e-01],
        [ 2.3884e+00,  5.5280e-01],
        [ 3.7531e+00, -1.1775e+00],
        [ 1.8683e+00, -1.4181e+00],
        [ 8.8547e-01, -4.1974e-02],
        [ 1.9201e+00, -7.8260e-01],
        [ 1.9020e+00,  2.2897e-01],
        [ 2.5885e+00, -2.8233e-01],
        [ 2.6468e+00, -7.5825e-02],
        [ 3.1827e+00, -1.8759e+00],
        [ 1.7480e+00, -1.5312e-02],
        [ 4.2303e+00, -1.3233e+00],
        [ 1.3908e+00,  1.5055e+00],
        [ 3.1955e+00, -1.5535e+00],
        [ 2.3309e+00,  4.8679e-02],
        [ 2.2942e+00,  1.7286e-01],
        [ 3.0833e+00, -1.3693e+00],
        [ 2.6219e+00, -1.1443e+00],
        [ 1.4137e+00, -3.7731e-01],
        [ 3.2666e+00, -1.3300e+00],
        [ 2.8677e+00, -7.5906e-01],
        [ 1.6070e+00,  1.2541e-01],
        [ 2.3347e+00, -1.3006e+00],
        [ 4.2224e+00, -2.3366e+00],
        [ 2.2290e+00, -6.8987e-01],
        [ 1.9578e+00, -1.2759e-01],
        [ 4.2771e+00,  4.2909e-01],
        [ 2.6418e+00,  2.2309e-01],
        [ 1.3715e+00, -3.6785e-01],
        [ 6.6579e-01, -7.5887e-01],
        [ 2.7677e+00, -1.0224e+00],
        [ 2.9014e+00, -1.1897e+00],
        [ 2.6068e+00, -1.0305e-01],
        [ 2.4243e+00, -5.8833e-01],
        [ 1.1658e+00,  2.4858e-01],
        [ 1.6773e+00,  8.1571e-04],
        [ 2.7083e+00,  8.0004e-02],
        [ 2.8453e+00,  9.2290e-01],
        [ 1.4282e+00,  1.2766e+00],
        [ 1.3969e+00,  6.7363e-01],
        [ 1.6161e+00, -8.2697e-01],
        [ 2.7431e+00, -1.4020e+00],
        [ 1.6902e+00, -9.3589e-01],
        [ 1.7900e+00,  1.4653e+00],
        [ 1.8598e+00, -1.2923e+00],
        [ 2.6656e+00, -4.6726e-01],
        [ 1.2943e+00, -1.0031e+00],
        [ 1.2874e+00, -8.1706e-01],
        [ 3.3846e+00,  6.8810e-01],
        [ 2.8140e+00, -1.7043e-01],
        [ 2.4506e+00,  3.2851e-01],
        [ 2.4556e+00,  4.5544e-01],
        [ 3.2918e+00,  7.2145e-01],
        [ 4.0779e+00, -3.5280e-01],
        [ 1.5335e+00, -3.7930e-01],
        [ 3.5706e+00,  1.9710e+00],
        [ 1.5707e+00,  1.4045e-01],
        [ 2.3671e+00, -2.8092e+00],
        [ 2.6496e+00,  1.9412e-01],
        [ 1.8955e+00,  2.9165e-01],
        [ 4.1354e+00, -1.7446e+00],
        [ 2.7200e+00, -1.9020e+00],
        [ 1.9514e+00, -7.9268e-01],
        [ 3.1943e+00, -8.8337e-01],
        [ 2.6491e+00, -1.7857e+00],
        [ 2.6398e+00, -1.1575e+00],
        [ 3.4657e+00, -2.6416e-01],
        [ 2.2027e+00, -4.1071e-01],
        [ 3.3740e+00,  1.3572e+00],
        [ 2.9681e+00, -1.3192e+00],
        [ 3.4708e+00, -1.0625e+00],
        [ 2.0587e+00, -8.1314e-01],
        [ 3.5756e+00,  2.1120e+00],
        [ 4.0426e+00,  9.3503e-01],
        [ 1.0409e+00, -1.1056e+00],
        [ 2.2782e+00,  7.5086e-01],
        [ 1.9722e+00,  1.0474e+00],
        [ 1.7055e+00,  6.7447e-01],
        [ 1.9670e+00, -3.3415e-01],
        [ 2.9348e+00, -1.2902e+00],
        [ 2.9590e+00, -1.7205e+00],
        [ 1.3886e+00,  6.5429e-01],
        [ 3.4103e+00, -1.2554e+00],
        [ 7.7820e-01, -6.8497e-01],
        [ 1.3326e+00, -1.7576e-01],
        [ 3.3678e+00, -1.5290e+00],
        [ 2.3697e+00, -8.9167e-01],
        [ 2.3338e+00,  2.7321e-01],
        [ 1.8569e+00,  9.6358e-01],
        [ 2.3074e+00, -3.9121e-01],
        [ 2.9554e+00, -1.4218e-01],
        [ 1.5621e+00, -8.3039e-01],
        [ 1.1215e+00,  6.3199e-01],
        [ 6.8011e-01, -5.6141e-01],
        [ 2.1801e+00, -1.5151e+00],
        [ 1.2295e+00, -9.9278e-01],
        [ 1.4567e+00, -1.4441e+00],
        [ 3.6096e+00, -6.9180e-01],
        [ 1.5977e+00,  6.1756e-01],
        [ 2.3531e+00,  1.0868e+00],
        [ 4.4708e+00, -6.3480e-01],
        [ 2.6088e+00, -7.7801e-01],
        [ 2.4713e+00, -1.4048e-01],
        [ 3.2934e+00,  3.1315e-01],
        [ 1.1298e+00, -9.2207e-01],
        [ 1.4568e+00,  1.2534e+00],
        [ 2.8043e+00,  9.1853e-02],
        [ 2.3558e+00,  4.2052e-01],
        [ 8.3723e-02,  3.1727e-01],
        [ 1.0260e+00,  2.2052e-01],
        [ 2.9444e+00, -9.1403e-01],
        [ 3.3412e+00, -3.5398e-01],
        [ 2.3222e+00, -1.5201e-01],
        [ 3.3281e+00, -2.2541e+00],
        [ 4.3589e+00, -1.3047e+00],
        [ 2.0106e+00,  7.3364e-01],
        [ 1.3451e+00,  1.0964e+00],
        [ 2.7485e+00,  1.2877e+00],
        [ 2.7411e+00, -2.2450e+00],
        [ 1.9381e+00, -1.7156e-01],
        [ 3.5577e+00,  1.1759e-01],
        [ 2.6510e+00,  2.5863e+00],
        [ 1.7934e+00, -2.0156e+00],
        [ 6.1406e-01, -1.5241e-01],
        [ 2.3820e+00, -2.6636e-01],
        [ 2.7224e+00, -6.1521e-01],
        [ 3.0403e+00, -4.3566e-01],
        [ 1.5337e+00,  4.4730e-01],
        [ 4.2510e+00, -5.7308e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[5.7150e-03, 1.6778e-01, 1.8372e-01,  ..., 8.4374e-01, 1.0000e+00,
         1.0000e+00],
        [2.0360e-03, 2.1357e-03, 6.8483e-02,  ..., 8.4654e-01, 8.5069e-01,
         1.0000e+00],
        [8.9537e-02, 9.0614e-02, 9.0664e-02,  ..., 9.5597e-01, 9.8502e-01,
         1.0000e+00],
        ...,
        [1.6530e-03, 1.6686e-03, 1.6432e-02,  ..., 9.2979e-01, 9.7345e-01,
         1.0000e+00],
        [4.7645e-11, 3.5923e-02, 5.4727e-02,  ..., 9.5745e-01, 9.9884e-01,
         1.0000e+00],
        [5.3925e-12, 6.8887e-02, 9.8586e-02,  ..., 7.9129e-01, 7.9129e-01,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.8206],
        [0.8313],
        [0.1477],
        [0.8523],
        [0.3726],
        [0.0124],
        [0.6178],
        [0.3591],
        [0.3697],
        [0.0672],
        [0.2132],
        [0.7549],
        [0.9436],
        [0.9663],
        [0.2385],
        [0.5329],
        [0.7304],
        [0.2564],
        [0.7182],
        [0.9232],
        [0.5079],
        [0.4617],
        [0.2063],
        [0.9711],
        [0.2756],
        [0.1634],
        [0.8469],
        [0.5056],
        [0.8430],
        [0.3440],
        [0.2782],
        [0.5780],
        [0.8380],
        [0.8619],
        [0.0382],
        [0.9205],
        [0.8347],
        [0.9757],
        [0.6857],
        [0.4887],
        [0.4626],
        [0.3809],
        [0.0152],
        [0.9314],
        [0.0982],
        [0.9962],
        [0.3019],
        [0.8115],
        [0.2045],
        [0.7836],
        [0.3466],
        [0.4427],
        [0.7379],
        [0.0407],
        [0.5874],
        [0.1826],
        [0.2554],
        [0.9301],
        [0.5517],
        [0.5624],
        [0.9428],
        [0.5735],
        [0.8303],
        [0.3169],
        [0.5901],
        [0.4957],
        [0.3849],
        [0.9392],
        [0.3185],
        [0.5936],
        [0.6036],
        [0.3243],
        [0.1529],
        [0.4782],
        [0.6336],
        [0.7241],
        [0.5519],
        [0.8894],
        [0.8016],
        [0.6102],
        [0.5442],
        [0.3048],
        [0.5981],
        [0.0254],
        [0.4310],
        [0.0579],
        [0.1947],
        [0.6515],
        [0.7909],
        [0.1921],
        [0.0286],
        [0.3676],
        [0.7988],
        [0.2273],
        [0.3721],
        [0.6610],
        [0.3649],
        [0.3934],
        [0.3475],
        [0.7029],
        [0.6209],
        [0.4631],
        [0.3875],
        [0.4541],
        [0.4915],
        [0.5846],
        [0.0235],
        [0.0559],
        [0.4597],
        [0.3130],
        [0.7754],
        [0.6995],
        [0.6179],
        [0.9466],
        [0.0206],
        [0.8393],
        [0.3675],
        [0.8923],
        [0.3254],
        [0.9752],
        [0.3801],
        [0.2263],
        [0.8655],
        [0.5563],
        [0.0033],
        [0.5282],
        [0.6324],
        [0.0028],
        [0.4943],
        [0.9314],
        [0.9722],
        [0.1257],
        [0.6275],
        [0.4136],
        [0.2257],
        [0.8557],
        [0.2978],
        [0.7032],
        [0.7966],
        [0.7030],
        [0.2843],
        [0.0388],
        [0.8684],
        [0.9128],
        [0.4454],
        [0.8438],
        [0.9171],
        [0.7310],
        [0.0406],
        [0.4741],
        [0.3994],
        [0.6145],
        [0.5732],
        [0.8740],
        [0.4095],
        [0.9950],
        [0.2159],
        [0.0688],
        [0.8896],
        [0.1415],
        [0.1868],
        [0.0762],
        [0.2401],
        [0.3344],
        [0.3861],
        [0.3622],
        [0.4869],
        [0.7840],
        [0.3673],
        [0.9312],
        [0.7315],
        [0.5801],
        [0.7553],
        [0.1069],
        [0.9683],
        [0.2600],
        [0.4340],
        [0.7367],
        [0.9801],
        [0.6703],
        [0.4402],
        [0.5004],
        [0.3599],
        [0.0865],
        [0.8051],
        [0.7965],
        [0.1461],
        [0.3128],
        [0.3742],
        [0.5914],
        [0.4210],
        [0.8145],
        [0.8228],
        [0.2446],
        [0.8489],
        [0.4149],
        [0.1139],
        [0.8176],
        [0.6173],
        [0.2136],
        [0.8288],
        [0.9675],
        [0.3272],
        [0.9590],
        [0.6885],
        [0.7695],
        [0.1531],
        [0.4956],
        [0.6708],
        [0.8430],
        [0.3334],
        [0.6703],
        [0.2352],
        [0.4256],
        [0.4463],
        [0.0814],
        [0.8805],
        [0.9521],
        [0.7857],
        [0.4264],
        [0.6855],
        [0.4585],
        [0.7011],
        [0.6680],
        [0.8294],
        [0.8790],
        [0.5145],
        [0.2573],
        [0.7639],
        [0.2773],
        [0.0320],
        [0.1208],
        [0.7325],
        [0.3382],
        [0.6595],
        [0.4092],
        [0.1526],
        [0.1838],
        [0.6882],
        [0.0032],
        [0.5258],
        [0.4429],
        [0.4255],
        [0.8973],
        [0.5471],
        [0.2364],
        [0.4665],
        [0.8951],
        [0.7909],
        [0.0112],
        [0.4048],
        [0.5868],
        [0.3203],
        [0.1914],
        [0.3378],
        [0.0030],
        [0.6735],
        [0.8897],
        [0.3514],
        [0.0180],
        [0.5593],
        [0.1716],
        [0.4714],
        [0.1400],
        [0.0168],
        [0.9169],
        [0.1154],
        [0.4277],
        [0.6520],
        [0.1754],
        [0.8923],
        [0.8382],
        [0.9197],
        [0.8806],
        [0.2264],
        [0.5247],
        [0.7057],
        [0.9991],
        [0.7896],
        [0.6878],
        [0.6067],
        [0.3128],
        [0.8979],
        [0.1501],
        [0.5171],
        [0.3511],
        [0.8918],
        [0.4294],
        [0.2471],
        [0.3364],
        [0.9362],
        [0.3925],
        [0.0507],
        [0.8488],
        [0.6102],
        [0.4152],
        [0.8029],
        [0.1256],
        [0.3710],
        [0.0329],
        [0.6489],
        [0.7002],
        [0.3672],
        [0.3053],
        [0.0774],
        [0.0808],
        [0.4287],
        [0.0800],
        [0.9139],
        [0.8710],
        [0.8152],
        [0.0231]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False,  True, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[ 2.7414,  2.6252],
        [ 2.9542, -2.5611],
        [ 1.1647,  0.7752],
        ...,
        [ 1.7704,  1.5614],
        [-2.2214, -1.3501],
        [ 2.4014, -0.8556]]) torch.Size([9984, 2])
samples tensor([[ 1.5748e+00,  6.6512e-01],
        [ 3.4105e+00,  9.0575e-02],
        [ 2.1486e+00,  5.9562e-01],
        [ 2.2568e+00,  1.0473e+00],
        [ 2.0805e+00, -4.6587e-01],
        [ 1.6730e+00, -5.6834e-01],
        [ 2.7604e+00, -8.4460e-01],
        [ 3.7157e+00,  1.0217e+00],
        [ 2.2078e+00, -1.3644e-01],
        [ 2.4460e+00,  1.2522e+00],
        [ 3.0342e+00,  1.2227e-01],
        [ 3.1267e+00,  6.3216e-01],
        [ 1.5781e+00,  9.4531e-01],
        [ 1.8287e+00,  1.5691e+00],
        [ 3.6890e+00, -1.3886e+00],
        [ 2.5703e+00, -3.2474e-01],
        [ 2.2964e+00, -3.2635e-01],
        [ 4.3828e+00,  1.2993e-01],
        [ 1.9591e+00, -6.5018e-01],
        [ 3.8127e+00, -7.2323e-01],
        [ 1.6107e+00, -5.0670e-01],
        [ 2.4975e+00, -1.0125e-01],
        [ 9.9444e-01, -4.0007e-02],
        [ 1.3631e+00,  3.4366e-01],
        [ 1.2079e+00, -6.0965e-02],
        [ 2.7442e+00, -8.3562e-01],
        [ 1.8483e+00, -3.9191e-01],
        [ 9.1969e-01, -3.3091e-03],
        [ 8.6873e-02,  1.9148e-01],
        [ 2.6468e+00, -1.4790e+00],
        [ 3.8396e+00,  2.0040e-01],
        [ 3.3712e+00,  4.9789e-01],
        [ 3.1275e+00, -1.0385e-01],
        [ 2.6797e+00,  2.1621e-01],
        [ 1.9263e+00,  3.8638e-01],
        [ 1.0089e+00,  2.1496e-01],
        [ 1.4286e+00, -1.4019e+00],
        [ 1.7258e+00,  2.5620e-01],
        [ 1.0494e+00, -6.1695e-01],
        [ 2.2265e+00,  1.1928e-02],
        [ 3.6089e+00, -1.2920e-01],
        [ 2.1842e+00, -9.7688e-01],
        [ 1.5445e+00,  2.6647e-01],
        [ 1.1217e+00,  7.8656e-01],
        [ 8.0464e-01,  1.0300e+00],
        [ 9.2446e-01, -9.6784e-01],
        [ 2.0051e+00, -2.7640e-01],
        [ 3.0523e+00,  9.8662e-02],
        [ 2.4417e+00, -6.6065e-01],
        [ 1.0419e+00, -1.0579e+00],
        [ 2.1341e+00,  1.7951e-01],
        [ 2.3598e+00, -1.4332e+00],
        [ 3.1338e+00,  5.5310e-01],
        [ 2.9310e+00,  1.7670e+00],
        [ 2.8569e+00,  8.3477e-01],
        [ 3.0123e+00,  1.1206e+00],
        [ 3.3999e+00,  2.5279e-01],
        [ 3.2925e+00,  1.0309e+00],
        [ 2.4806e+00,  1.0925e-01],
        [ 2.3898e+00,  2.2159e-01],
        [ 1.9798e+00,  1.8062e-02],
        [ 3.4373e+00,  1.5569e+00],
        [ 2.0820e+00, -1.0003e-01],
        [ 1.9807e+00, -3.6933e-01],
        [ 2.7806e+00, -4.2916e-01],
        [ 2.7729e+00,  6.4874e-03],
        [ 3.0889e+00, -1.6793e+00],
        [ 3.7497e+00,  1.0249e+00],
        [ 3.7664e-01,  8.1884e-01],
        [ 1.8038e+00, -7.0758e-01],
        [ 2.4307e+00,  4.8615e-01],
        [ 2.5157e+00, -1.5855e+00],
        [ 1.3001e+00, -1.0787e+00],
        [ 2.8562e+00, -1.9724e+00],
        [ 2.4179e+00, -5.6943e-01],
        [ 3.3046e+00, -7.5637e-01],
        [ 2.8097e+00,  1.0434e+00],
        [ 8.1664e-01, -1.6793e+00],
        [ 2.5419e+00,  7.9944e-01],
        [ 3.5572e+00,  9.6421e-01],
        [ 3.2722e+00, -1.1267e-01],
        [ 5.8175e-01, -3.6740e-01],
        [ 3.5263e+00, -2.5219e+00],
        [ 3.2021e+00, -3.5320e+00],
        [ 1.6266e+00,  1.6670e+00],
        [ 1.7788e+00, -1.2426e-01],
        [ 2.3352e+00, -5.6810e-01],
        [ 1.3176e+00, -3.5788e-01],
        [ 4.1981e+00, -2.7975e-01],
        [ 2.4365e+00,  9.4064e-01],
        [ 1.5989e+00,  4.6658e-01],
        [ 3.3647e+00,  7.3233e-01],
        [ 2.6730e+00, -9.5622e-01],
        [ 1.4379e+00,  1.5231e+00],
        [ 3.8664e+00, -3.5268e-01],
        [ 2.1148e+00,  6.3734e-01],
        [ 3.1867e+00,  4.7593e-01],
        [ 1.3584e+00, -8.8159e-01],
        [ 2.4514e+00, -1.3794e+00],
        [ 2.4167e-01, -3.5623e-02],
        [ 2.5869e+00,  9.9771e-02],
        [ 9.7546e-01, -7.7420e-01],
        [ 2.2681e+00, -1.5003e-01],
        [ 2.7860e+00,  5.4610e-01],
        [ 1.2811e+00, -5.2863e-01],
        [ 1.1741e+00, -7.7412e-01],
        [ 2.0475e+00,  8.7262e-01],
        [ 1.3814e+00, -2.5992e-01],
        [ 2.3340e+00,  4.2307e-01],
        [ 2.1765e+00, -3.6507e+00],
        [ 1.9064e+00, -1.2500e+00],
        [ 1.9588e+00, -1.8533e+00],
        [ 2.5940e+00, -2.6674e+00],
        [ 1.7831e+00, -2.3465e-01],
        [ 8.5712e-01,  7.6099e-01],
        [ 1.9731e+00, -2.0773e+00],
        [ 2.7665e+00, -3.0731e-01],
        [ 1.9092e+00, -3.4881e-01],
        [ 2.3178e+00,  4.0802e-01],
        [ 3.7020e+00,  1.1379e+00],
        [ 4.4457e+00,  1.5074e+00],
        [ 3.5678e+00, -6.3903e-01],
        [ 1.4905e+00, -2.9208e-01],
        [ 3.3827e+00, -5.9204e-01],
        [ 1.0686e+00,  5.5403e-01],
        [ 2.6358e+00,  7.0673e-01],
        [ 1.5353e+00, -2.0214e+00],
        [ 1.7765e+00,  6.0426e-01],
        [ 1.3874e+00, -1.8536e+00],
        [ 9.6774e-01, -1.2498e+00],
        [ 3.8445e+00,  1.1901e+00],
        [ 9.4109e-01,  2.2539e-01],
        [ 2.6236e+00,  4.6520e-01],
        [ 2.3852e+00, -2.6751e-01],
        [ 1.4971e+00,  2.1733e-01],
        [ 3.9300e+00,  4.4390e-01],
        [ 5.1244e-01, -1.1545e+00],
        [ 1.5678e+00, -2.1512e-01],
        [ 2.7575e+00, -1.5440e-01],
        [ 8.7355e-01, -1.3103e+00],
        [ 3.3879e+00, -1.8219e+00],
        [ 7.3339e-01,  3.6509e-01],
        [ 1.6715e+00, -1.4153e+00],
        [ 1.9352e+00, -1.0310e+00],
        [ 1.3457e+00,  5.2418e-01],
        [ 4.3327e+00,  2.8645e-01],
        [ 2.1878e+00,  1.1513e+00],
        [ 1.6639e-01, -2.3741e-01],
        [ 1.9361e+00,  1.0690e+00],
        [ 2.2145e+00,  1.0612e-01],
        [ 2.7228e+00, -1.3539e+00],
        [ 4.3568e+00, -7.9163e-01],
        [ 1.1363e+00,  1.0268e+00],
        [ 2.5515e+00,  1.4839e-01],
        [ 3.0407e+00, -1.5143e-01],
        [ 2.2079e+00,  2.0493e+00],
        [ 1.7186e+00, -6.5234e-01],
        [ 4.0696e+00, -1.2897e-01],
        [ 2.1222e+00, -8.7459e-01],
        [ 3.8548e+00,  6.6901e-02],
        [ 3.1870e+00, -1.1487e+00],
        [ 1.4502e+00, -5.2199e-01],
        [ 3.1476e+00, -9.3661e-01],
        [ 1.9827e+00,  7.5676e-01],
        [ 2.0761e+00,  1.5396e-01],
        [ 3.4532e+00, -6.9147e-01],
        [ 3.0510e+00, -3.0474e-01],
        [ 2.7760e+00, -9.2511e-01],
        [ 3.8867e+00,  1.2015e+00],
        [ 1.6503e+00, -4.8225e-01],
        [ 2.2865e+00, -1.7556e+00],
        [ 2.6456e+00,  1.2926e+00],
        [ 3.2832e+00, -1.2562e+00],
        [ 1.3711e+00, -2.0696e-01],
        [ 2.8757e+00,  4.3073e-01],
        [ 2.0565e+00, -1.5891e+00],
        [ 1.4201e+00, -3.0848e+00],
        [ 2.1610e+00, -1.7824e-01],
        [ 1.6914e+00,  9.9076e-01],
        [ 3.2876e+00, -1.1048e-01],
        [ 4.2089e+00,  1.6168e-01],
        [ 3.5110e+00, -1.5417e+00],
        [ 3.9453e+00,  4.4619e-01],
        [ 1.7849e+00, -1.2073e-01],
        [ 2.7077e+00,  6.8029e-01],
        [ 3.5666e+00,  1.1820e+00],
        [ 2.0694e+00, -2.3544e-01],
        [ 2.4211e+00,  6.8303e-01],
        [ 2.6554e+00,  1.9850e+00],
        [ 4.1362e+00, -1.5750e+00],
        [ 8.9999e-01, -3.7501e-01],
        [ 3.5907e+00, -1.7254e+00],
        [ 2.3740e+00,  1.3220e-01],
        [ 3.7913e+00,  3.3673e-01],
        [ 1.5338e+00, -2.0915e+00],
        [ 3.2009e+00, -3.5942e-01],
        [ 2.4948e+00,  5.7002e-01],
        [ 1.4258e+00,  9.1420e-01],
        [ 2.3722e+00, -1.0930e+00],
        [ 4.1028e-01, -9.5599e-01],
        [ 2.2194e+00,  5.7977e-01],
        [ 2.0176e+00,  5.5117e-02],
        [ 2.8746e+00, -1.9925e-02],
        [ 2.0687e+00, -1.3426e+00],
        [ 2.6407e+00, -1.0257e+00],
        [ 2.8297e+00,  1.9408e-01],
        [ 1.9181e+00, -2.8919e-01],
        [ 4.1799e+00, -1.9759e+00],
        [ 4.9784e+00,  1.2740e+00],
        [ 2.1161e+00,  8.4444e-01],
        [ 8.1144e-01,  2.3324e-01],
        [ 3.5527e+00,  1.1761e-01],
        [ 1.7949e+00,  1.3814e+00],
        [ 4.6125e+00, -3.5963e-01],
        [ 2.3271e+00, -6.7322e-01],
        [ 3.7467e+00,  6.0503e-01],
        [ 2.1632e+00, -5.4999e-01],
        [ 3.5003e+00, -1.6124e-02],
        [ 3.1372e+00, -9.1571e-02],
        [ 2.2233e+00,  2.5333e-01],
        [ 1.8863e+00, -1.7194e+00],
        [ 3.2183e+00, -1.0608e+00],
        [ 3.3923e+00,  2.6118e-01],
        [ 2.8736e+00,  1.3572e+00],
        [ 2.2161e+00, -1.9054e+00],
        [ 2.0092e+00,  7.4460e-01],
        [ 2.5358e+00, -2.9410e-01],
        [ 3.2031e+00, -7.3816e-01],
        [ 2.6028e+00,  3.2083e-01],
        [ 4.0622e+00, -1.9339e-01],
        [ 2.4544e+00, -1.4535e+00],
        [ 1.7172e+00, -3.3482e-01],
        [ 4.5646e-01,  6.2350e-01],
        [ 4.2548e+00, -1.4756e+00],
        [ 3.2005e+00, -1.2267e+00],
        [ 2.9794e+00, -1.2444e+00],
        [ 6.1245e-01,  1.1618e-01],
        [ 1.1730e+00,  1.0875e+00],
        [ 2.2598e+00, -1.8569e-01],
        [ 2.8959e+00,  2.4153e+00],
        [ 2.9680e+00, -1.1573e+00],
        [ 2.1879e+00, -8.9113e-01],
        [ 2.1098e+00, -3.7810e-01],
        [ 3.5607e+00,  6.8827e-01],
        [ 2.1624e+00,  9.5269e-01],
        [ 2.7314e+00,  3.3669e-01],
        [ 2.0010e+00, -1.1585e+00],
        [ 1.1064e+00, -4.4861e-02],
        [ 1.5018e+00,  1.3407e-02],
        [ 2.8909e+00,  1.7605e+00],
        [ 2.3967e+00, -1.1652e+00],
        [ 2.9649e+00,  2.1494e-01],
        [ 3.0249e+00, -1.6350e+00],
        [ 2.9723e+00,  2.3841e+00],
        [ 2.7132e+00, -4.1278e-01],
        [ 9.0224e-01,  3.0541e+00],
        [ 1.8516e+00, -1.2011e+00],
        [ 1.6183e+00, -1.4854e-01],
        [ 4.9019e-01,  9.6905e-01],
        [ 3.0528e+00,  2.3730e+00],
        [ 2.1911e+00, -3.1204e-01],
        [ 3.2803e+00,  1.5786e+00],
        [ 1.6463e+00,  5.2284e-01],
        [ 2.9364e+00, -5.4513e-01],
        [ 2.2500e+00,  1.9084e+00],
        [ 1.9489e+00, -7.0188e-01],
        [ 3.7724e-01, -9.8398e-01],
        [ 2.7826e+00,  1.0828e+00],
        [ 2.2076e+00,  4.3566e-01],
        [ 2.7867e+00, -5.5517e-01],
        [ 3.0548e+00, -1.5787e+00],
        [ 3.1076e+00,  1.0897e+00],
        [ 8.1708e-01,  6.8789e-01],
        [ 1.8437e+00,  7.6104e-01],
        [ 2.2378e+00,  7.9765e-01],
        [ 2.5399e+00,  9.9374e-01],
        [ 2.7259e+00,  3.1306e-02],
        [ 3.8711e+00, -1.8700e+00],
        [ 3.0073e+00, -2.0422e+00],
        [ 1.8535e+00, -6.6463e-02],
        [ 2.2565e+00,  1.9162e+00],
        [ 1.9708e+00,  4.7272e-01],
        [ 2.8176e+00,  2.1174e+00],
        [ 2.0731e+00, -6.3278e-01],
        [ 2.5507e+00,  7.3524e-01],
        [ 1.7688e+00, -8.9459e-01],
        [ 2.3946e+00,  1.9587e+00],
        [ 3.4376e-01,  5.6878e-01],
        [ 2.6411e+00,  2.9128e-01],
        [ 3.4041e+00, -3.3682e-01],
        [ 1.0747e+00,  1.7319e+00],
        [ 3.4745e+00,  1.0979e+00],
        [ 2.3752e+00,  2.1483e-01],
        [ 1.6822e+00, -1.6372e+00],
        [ 2.0474e+00,  1.2184e+00],
        [ 3.9363e+00, -3.2945e+00],
        [ 2.2731e+00, -1.7057e+00],
        [ 3.0323e+00,  4.2794e-01],
        [ 3.2685e-01, -5.4029e-01],
        [ 2.2787e+00,  8.0107e-01],
        [ 1.7773e+00,  2.5732e+00],
        [ 2.5272e+00, -1.9369e+00],
        [ 3.7335e+00, -2.5846e+00],
        [ 2.1096e+00,  1.0141e+00],
        [ 2.9123e+00,  1.2164e+00],
        [ 3.6629e+00, -2.8382e-01],
        [ 2.0374e+00, -3.3719e-01],
        [ 3.2954e+00,  1.1134e+00],
        [ 2.8126e+00, -4.7277e-01],
        [ 8.7315e-01, -6.8058e-01],
        [ 4.9065e+00, -3.7545e-01],
        [ 2.3058e+00,  3.8376e-01]]) torch.Size([312, 2])



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]


batch_size 312
weights tensor([[2.2378e-04, 2.2382e-04, 4.0735e-04,  ..., 9.5972e-01, 9.5972e-01,
         1.0000e+00],
        [1.6763e-02, 1.6936e-02, 2.5870e-02,  ..., 9.8845e-01, 9.9217e-01,
         1.0000e+00],
        [6.2434e-02, 6.2438e-02, 6.2858e-02,  ..., 7.2481e-01, 7.7349e-01,
         1.0000e+00],
        ...,
        [1.0455e-04, 1.7796e-02, 2.0527e-02,  ..., 6.8730e-01, 8.2094e-01,
         1.0000e+00],
        [1.1285e-02, 1.1940e-01, 1.1941e-01,  ..., 9.6500e-01, 9.7798e-01,
         1.0000e+00],
        [1.1140e-02, 5.9760e-02, 7.2801e-02,  ..., 8.6188e-01, 1.0000e+00,
         1.0000e+00]]) torch.Size([312, 32])
uniform_decision tensor([[0.1674],
        [0.7188],
        [0.0245],
        [0.4920],
        [0.2697],
        [0.3584],
        [0.4400],
        [0.2117],
        [0.1262],
        [0.3596],
        [0.2191],
        [0.8166],
        [0.5127],
        [0.8835],
        [0.7096],
        [0.6857],
        [0.1644],
        [0.3477],
        [0.9732],
        [0.1356],
        [0.7517],
        [0.6777],
        [0.8052],
        [0.3554],
        [0.1854],
        [0.6233],
        [0.8289],
        [0.0501],
        [0.4435],
        [0.0811],
        [0.5240],
        [0.5856],
        [0.3775],
        [0.9253],
        [0.8189],
        [0.9028],
        [0.0962],
        [0.6072],
        [0.3299],
        [0.7449],
        [0.3825],
        [0.5911],
        [0.6724],
        [0.5207],
        [0.9632],
        [0.9169],
        [0.7288],
        [0.2593],
        [0.4107],
        [0.8629],
        [0.4118],
        [0.6922],
        [0.7690],
        [0.6571],
        [0.8241],
        [0.5773],
        [0.3467],
        [0.1615],
        [0.2494],
        [0.0731],
        [0.7821],
        [0.7652],
        [0.3801],
        [0.7114],
        [0.0848],
        [0.8962],
        [0.1074],
        [0.4326],
        [0.6061],
        [0.4355],
        [0.8781],
        [0.2483],
        [0.1354],
        [0.4075],
        [0.2897],
        [0.1809],
        [0.7299],
        [0.9577],
        [0.8804],
        [0.8429],
        [0.1474],
        [0.8715],
        [0.0967],
        [0.2660],
        [0.7014],
        [0.1321],
        [0.9451],
        [0.9840],
        [0.8185],
        [0.1219],
        [0.4172],
        [0.8620],
        [0.8511],
        [0.7066],
        [0.1622],
        [0.5141],
        [0.5511],
        [0.1177],
        [0.1980],
        [0.3664],
        [0.1437],
        [0.3117],
        [0.7830],
        [0.1647],
        [0.0847],
        [0.3948],
        [0.2538],
        [0.9781],
        [0.9202],
        [0.3541],
        [0.2936],
        [0.3752],
        [0.0087],
        [0.0989],
        [0.6840],
        [0.7077],
        [0.8762],
        [0.0871],
        [0.9755],
        [0.6200],
        [0.8982],
        [0.4847],
        [0.9410],
        [0.2292],
        [0.0455],
        [0.7776],
        [0.2621],
        [0.7873],
        [0.3883],
        [0.2744],
        [0.3896],
        [0.7369],
        [0.5316],
        [0.5297],
        [0.5587],
        [0.6461],
        [0.9411],
        [0.8517],
        [0.3086],
        [0.0361],
        [0.3189],
        [0.3334],
        [0.9025],
        [0.0356],
        [0.8485],
        [0.6198],
        [0.2524],
        [0.2943],
        [0.9302],
        [0.9764],
        [0.4106],
        [0.9880],
        [0.2071],
        [0.6378],
        [0.2856],
        [0.7937],
        [0.6132],
        [0.9761],
        [0.2929],
        [0.4963],
        [0.1570],
        [0.6032],
        [0.0394],
        [0.6941],
        [0.2509],
        [0.2903],
        [0.5267],
        [0.5166],
        [0.7326],
        [0.4189],
        [0.6656],
        [0.1574],
        [0.2965],
        [0.5947],
        [0.5134],
        [0.8260],
        [0.3934],
        [0.6670],
        [0.6432],
        [0.9951],
        [0.2939],
        [0.5823],
        [0.6044],
        [0.9228],
        [0.1621],
        [0.1296],
        [0.9659],
        [0.8733],
        [0.7260],
        [0.9358],
        [0.2761],
        [0.2267],
        [0.0228],
        [0.5355],
        [0.1155],
        [0.0985],
        [0.5066],
        [0.8887],
        [0.9133],
        [0.5043],
        [0.8422],
        [0.0808],
        [0.2079],
        [0.4488],
        [0.4730],
        [0.9598],
        [0.6867],
        [0.3951],
        [0.4248],
        [0.4462],
        [0.8272],
        [0.7956],
        [0.1956],
        [0.3158],
        [0.0618],
        [0.5687],
        [0.5242],
        [0.5379],
        [0.5888],
        [0.2179],
        [0.9658],
        [0.6571],
        [0.4635],
        [0.1319],
        [0.8225],
        [0.9845],
        [0.2999],
        [0.6915],
        [0.2786],
        [0.0899],
        [0.4351],
        [0.3574],
        [0.9057],
        [0.4036],
        [0.4407],
        [0.8050],
        [0.1386],
        [0.2048],
        [0.4658],
        [0.4106],
        [0.3676],
        [0.6689],
        [0.1007],
        [0.2981],
        [0.5558],
        [0.7584],
        [0.9684],
        [0.0066],
        [0.3945],
        [0.3823],
        [0.7166],
        [0.7930],
        [0.3469],
        [0.2134],
        [0.9138],
        [0.5855],
        [0.8910],
        [0.9430],
        [0.5766],
        [0.9267],
        [0.1210],
        [0.5129],
        [0.4725],
        [0.2813],
        [0.6343],
        [0.2631],
        [0.4356],
        [0.9252],
        [0.0715],
        [0.6764],
        [0.0536],
        [0.1878],
        [0.3163],
        [0.6788],
        [0.5866],
        [0.8075],
        [0.4291],
        [0.8776],
        [0.2763],
        [0.3929],
        [0.0639],
        [0.5026],
        [0.4577],
        [0.9654],
        [0.0898],
        [0.9318],
        [0.1721],
        [0.6255],
        [0.9588],
        [0.0238],
        [0.5816],
        [0.7527],
        [0.8935],
        [0.0978],
        [0.5396],
        [0.6795],
        [0.1594],
        [0.8476],
        [0.2262],
        [0.9429],
        [0.9110],
        [0.7937],
        [0.8653],
        [0.8008],
        [0.5564],
        [0.7972],
        [0.1050],
        [0.6682],
        [0.5952],
        [0.5492],
        [0.1329],
        [0.4652]]) torch.Size([312, 1])
mask tensor([[False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [ True, False, False,  ..., False, False, False],
        ...,
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False],
        [False, False, False,  ..., False, False, False]]) torch.Size([312, 32])
thetas tensor([[-0.6964,  0.8339],
        [-2.9023,  1.4815],
        [-1.2076, -0.4469],
        ...,
        [ 0.4430,  0.1385],
        [ 2.7782,  0.1458],
        [-4.0567,  0.5252]]) torch.Size([9984, 2])
samples tensor([[ 2.0566e+00, -1.0804e+00],
        [ 2.6606e+00, -7.7666e-01],
        [ 1.8765e+00,  4.2155e-01],
        [ 2.1586e+00, -2.7307e+00],
        [ 2.1851e+00,  1.8609e+00],
        [ 2.5785e+00, -1.6698e+00],
        [ 8.6696e-01, -1.9129e+00],
        [ 2.4005e+00,  1.1971e+00],
        [ 1.2874e+00,  8.7262e-02],
        [ 4.1687e+00, -1.5779e+00],
        [ 3.3556e+00, -2.1102e-01],
        [ 2.0069e+00, -1.5278e+00],
        [ 2.5493e+00, -2.7697e+00],
        [ 2.3087e+00, -3.1843e-02],
        [ 3.0342e+00, -1.4025e+00],
        [ 2.6558e+00, -5.6993e-01],
        [ 2.5493e+00,  4.1488e-01],
        [ 2.0536e+00, -1.5803e-01],
        [ 1.6271e+00,  3.9703e-01],
        [ 2.2534e+00,  5.7948e-01],
        [ 3.4507e+00, -3.2207e-01],
        [ 3.1050e+00,  2.6483e+00],
        [ 3.8426e+00, -1.7396e-01],
        [ 2.5750e+00,  1.0184e+00],
        [ 1.0063e+00,  8.2336e-01],
        [ 3.1102e+00, -1.2728e+00],
        [ 3.0450e+00,  2.3619e-01],
        [ 3.6385e+00, -9.7288e-02],
        [ 1.6703e+00, -1.8690e-01],
        [ 3.2929e+00, -3.9270e+00],
        [ 3.4524e+00, -3.4106e-01],
        [ 3.9942e+00,  3.7075e-01],
        [ 1.1734e+00, -2.2467e-01],
        [ 1.8875e+00,  1.1406e+00],
        [ 3.5675e+00,  1.4710e+00],
        [ 2.9736e+00, -4.0362e-02],
        [ 1.9795e+00, -9.1918e-03],
        [ 1.2020e+00,  5.0370e-01],
        [ 2.4677e-01,  4.9973e-01],
        [ 3.3603e+00,  6.3148e-01],
        [ 1.0239e+00, -7.0265e-02],
        [ 1.7998e+00,  1.0963e-01],
        [ 1.8498e+00, -6.0503e-01],
        [ 2.3365e+00, -1.1755e+00],
        [ 6.7820e-01, -4.8300e-01],
        [ 3.2108e+00, -1.5101e+00],
        [ 2.9752e+00, -5.3494e-01],
        [ 3.5361e+00, -4.0761e-01],
        [ 1.6218e+00, -1.1678e+00],
        [ 1.5396e+00,  4.4086e-02],
        [ 1.4943e+00, -1.3593e+00],
        [ 3.2501e+00, -8.6062e-01],
        [ 2.0382e+00, -6.0504e-01],
        [ 3.6453e+00,  6.9754e-01],
        [ 3.2859e+00,  1.2723e+00],
        [ 3.9847e+00,  2.8398e-01],
        [ 1.1675e+00, -2.1553e+00],
        [ 2.5196e+00, -4.1727e-01],
        [ 2.3019e+00, -6.2441e-01],
        [ 2.7073e+00, -5.9011e-01],
        [ 3.2821e+00,  5.6452e-01],
        [ 3.2788e+00,  1.1373e+00],
        [ 5.4238e-01,  1.0050e+00],
        [ 2.4965e+00, -1.9136e+00],
        [ 3.6016e+00, -1.3356e+00],
        [ 2.6992e+00,  6.3325e-01],
        [ 2.9273e+00,  1.9093e-01],
        [ 3.2826e+00,  1.8166e+00],
        [ 2.6880e+00,  9.1477e-01],
        [ 1.1138e+00, -1.4490e+00],
        [ 1.6660e+00, -5.5003e-01],
        [ 2.3374e+00, -1.0072e+00],
        [ 2.3261e+00,  7.1190e-01],
        [ 7.0046e-01, -4.8016e-01],
        [ 1.9348e+00, -8.5276e-01],
        [ 4.3826e+00,  1.6593e-01],
        [ 2.9130e+00, -1.0641e+00],
        [ 2.0206e+00,  1.6084e+00],
        [ 9.3813e-01, -5.6144e-01],
        [ 1.9276e+00, -5.6635e-02],
        [ 3.6676e+00, -1.5827e+00],
        [ 3.8730e+00, -7.1781e-02],
        [ 1.8116e+00, -1.7837e+00],
        [ 3.5064e+00, -2.7130e-02],
        [ 3.2539e+00, -5.3110e-01],
        [ 2.8272e+00, -2.1387e+00],
        [ 2.2522e+00,  1.3467e+00],
        [ 1.8588e+00,  1.7203e+00],
        [ 1.1556e+00, -3.6235e-01],
        [ 3.5351e+00,  9.6270e-01],
        [ 3.4138e+00, -5.6474e-01],
        [ 1.8334e+00, -7.5833e-01],
        [ 4.0229e+00, -1.0130e+00],
        [ 1.6705e+00, -1.2351e+00],
        [ 3.4130e+00,  6.3482e-01],
        [ 3.1420e+00,  6.4155e-01],
        [ 2.9443e+00,  6.4665e-01],
        [ 3.1650e+00, -2.3953e+00],
        [ 8.4095e-01,  1.4381e+00],
        [ 3.6020e+00,  1.3672e+00],
        [ 1.3287e+00, -9.2148e-01],
        [ 1.6847e+00,  1.1752e-01],
        [ 4.3315e+00, -1.7723e+00],
        [ 1.8795e+00,  8.4262e-01],
        [ 2.4912e+00, -1.5800e+00],
        [ 2.1012e+00,  1.4856e+00],
        [ 2.4881e+00, -2.4093e-01],
        [ 1.6490e+00,  3.8678e-01],
        [ 2.3247e+00,  2.0098e-02],
        [ 2.4916e+00, -1.9438e+00],
        [ 2.0090e+00,  7.6900e-01],
        [ 2.5689e+00, -1.2883e+00],
        [ 3.9550e+00,  1.0238e+00],
        [ 1.4942e+00, -1.6763e+00],
        [ 2.1616e+00, -4.0942e-01],
        [ 2.4347e+00,  1.2918e+00],
        [ 8.3926e-01,  1.3678e+00],
        [ 1.8419e+00,  2.9456e-01],
        [ 1.0932e+00,  8.6534e-01],
        [ 5.3859e-01,  9.1471e-01],
        [ 4.1917e+00, -2.1975e+00],
        [ 2.4666e+00,  9.0527e-01],
        [ 2.9460e+00,  1.4987e+00],
        [ 2.4349e+00,  1.7878e+00],
        [ 1.2953e+00, -2.1804e-01],
        [ 1.2239e+00, -1.0794e-01],
        [ 8.7889e-01,  1.7305e+00],
        [ 2.9263e+00,  9.7232e-02],
        [ 3.6923e+00, -7.8224e-01],
        [ 1.8978e+00, -8.1462e-01],
        [ 3.3519e+00, -1.0483e+00],
        [ 3.5255e+00, -1.4183e+00],
        [ 2.2218e+00, -1.0676e-01],
        [ 2.8887e+00,  3.5724e-01],
        [ 9.2938e-01, -6.0108e-01],
        [ 1.6468e+00, -1.0592e+00],
        [ 1.6210e+00,  8.0369e-01],
        [ 3.0489e+00, -6.2138e-01],
        [ 1.6197e+00,  6.9900e-01],
        [ 7.1443e-01, -1.1651e+00],
        [ 3.5887e+00, -4.8372e-01],
        [ 2.7805e+00,  6.5564e-01],
        [ 2.8514e+00,  4.1654e-01],
        [ 2.4881e+00,  1.0498e+00],
        [ 4.3188e+00,  3.1348e-01],
        [ 2.3655e+00, -6.2196e-02],
        [ 3.6382e+00,  2.5450e-01],
        [ 1.6756e+00,  2.3375e+00],
        [ 1.4139e+00,  4.3297e-02],
        [ 1.9015e+00,  3.3836e-01],
        [ 2.2681e+00,  2.4282e+00],
        [ 2.2877e+00, -9.3849e-01],
        [ 2.6506e+00,  4.0390e-01],
        [ 3.5866e+00,  1.6369e-02],
        [ 1.9845e+00, -2.8849e-01],
        [ 3.6425e+00, -7.3408e-01],
        [ 1.4594e+00, -5.1622e-01],
        [ 8.4448e-01, -7.3670e-01],
        [ 3.5946e+00, -5.8416e-01],
        [ 4.1853e+00, -7.9674e-01],
        [ 4.9938e-01, -3.0381e-01],
        [ 2.8534e+00,  5.2522e-01],
        [ 9.7611e-01,  7.7014e-02],
        [ 2.0031e+00, -3.0281e-01],
        [ 4.4462e+00, -8.3250e-01],
        [ 3.6532e+00, -5.4660e-01],
        [-1.5241e-01, -9.9735e-01],
        [ 4.9138e+00,  7.0061e-01],
        [ 3.5144e+00,  7.5198e-01],
        [ 2.9349e+00,  2.2416e-01],
        [ 2.1572e+00,  1.3727e-01],
        [ 1.0554e+00, -9.3947e-01],
        [ 3.1914e+00, -2.2539e-01],
        [ 2.2300e+00,  1.3671e+00],
        [ 2.1570e+00, -7.1066e-01],
        [ 1.8880e+00, -6.1749e-01],
        [ 1.5768e+00, -2.0948e+00],
        [ 2.9752e+00, -2.5194e-01],
        [ 2.7881e+00,  2.6110e-01],
        [ 3.4370e+00,  4.5078e-01],
        [ 2.1835e+00, -1.2171e+00],
        [ 4.2030e+00,  1.3325e-01],
        [ 3.1739e+00, -4.5697e-01],
        [ 1.1574e+00, -3.8246e-01],
        [ 2.9750e+00, -1.2944e+00],
        [ 2.5414e+00,  8.4456e-01],
        [ 3.3010e+00, -2.0808e+00],
        [ 9.1341e-01, -1.7572e+00],
        [ 3.7604e+00,  4.7261e-03],
        [ 2.8181e+00, -6.4527e-01],
        [ 3.4286e+00,  4.0296e-01],
        [ 3.5025e+00,  8.0682e-01],
        [ 5.0521e-01,  4.3012e-02],
        [ 3.5908e+00, -1.1092e-01],
        [ 2.8813e+00,  1.4549e+00],
        [ 1.7159e+00, -3.1263e-01],
        [ 3.2260e+00,  3.5095e+00],
        [ 2.1134e+00,  9.2662e-01],
        [ 1.2954e+00, -3.7381e-01],
        [ 1.8390e+00,  1.1772e-01],
        [ 3.2809e+00,  1.6234e-01],
        [ 9.3195e-01,  1.7716e+00],
        [ 2.7372e+00, -7.5285e-01],
        [ 2.0238e+00, -1.5727e+00],
        [ 5.5781e-01, -9.0900e-01],
        [ 8.8994e-01, -6.7544e-01],
        [ 3.4152e+00, -5.4750e-01],
        [ 1.8302e+00, -7.1042e-01],
        [ 2.1596e+00, -2.0176e+00],
        [ 2.4246e+00, -8.3360e-01],
        [ 2.0937e+00,  2.0887e-01],
        [ 2.3347e+00, -1.0783e+00],
        [ 2.1942e+00, -9.7597e-01],
        [ 2.4834e+00,  9.9830e-02],
        [ 1.5122e+00,  6.5871e-01],
        [ 2.3860e+00, -4.9633e-01],
        [ 3.0673e+00, -1.5074e+00],
        [ 1.9988e+00, -1.8192e+00],
        [ 2.4722e+00, -6.9229e-01],
        [ 3.0360e+00, -8.2838e-01],
        [ 1.1576e+00,  4.5205e-01],
        [ 4.0644e+00, -1.2388e+00],
        [ 2.8641e+00,  6.8281e-01],
        [ 2.5796e+00, -5.5502e-01],
        [ 3.9656e+00, -1.3982e+00],
        [ 2.5314e+00,  1.7613e+00],
        [ 3.2430e+00,  1.4881e-01],
        [ 1.4885e+00, -2.6818e-01],
        [ 3.3928e+00,  1.6708e+00],
        [ 2.1793e+00,  2.3319e-01],
        [ 2.7979e+00, -4.7182e-01],
        [ 2.1340e+00,  3.8084e-01],
        [ 1.7631e+00,  4.0900e-02],
        [ 3.3934e+00,  2.0149e-01],
        [ 2.2117e+00, -1.0862e-01],
        [ 1.4286e+00, -1.4204e+00],
        [ 2.3244e+00, -9.6825e-01],
        [ 6.1312e-01, -1.3216e-01],
        [ 2.8229e+00, -9.6281e-01],
        [ 1.5815e+00, -4.5157e-01],
        [ 3.0163e+00,  2.4756e+00],
        [ 2.2036e+00, -1.8917e+00],
        [ 2.4449e+00,  2.7157e-01],
        [ 2.2126e+00, -1.5493e+00],
        [ 4.5114e-01,  7.0364e-01],
        [ 2.1031e+00,  1.1230e+00],
        [ 1.6165e+00,  2.0425e-01],
        [ 1.5534e+00,  1.5273e+00],
        [ 2.3761e+00,  3.8975e-01],
        [ 2.8353e+00,  1.2485e-01],
        [ 3.1413e+00,  2.0645e-01],
        [ 2.4109e-01, -7.6570e-01],
        [ 1.8500e+00, -1.3881e+00],
        [ 2.5769e+00,  4.6391e-01],
        [ 3.1729e+00,  3.4357e-02],
        [ 2.2448e+00,  6.7691e-01],
        [ 2.4331e+00,  8.8931e-01],
        [ 2.4986e+00,  1.1141e+00],
        [ 7.1723e-01, -9.2739e-01],
        [ 2.1557e+00, -3.3531e-01],
        [ 1.0756e+00, -5.3108e-01],
        [ 2.7291e+00, -1.6756e-01],
        [ 1.8847e+00, -1.5585e+00],
        [ 1.3452e+00, -4.6690e-02],
        [ 2.9718e+00, -1.7957e+00],
        [ 2.4603e+00,  2.9114e-01],
        [ 1.9149e+00, -1.2619e-01],
        [ 1.5205e+00,  1.7448e+00],
        [ 2.6990e+00, -1.9306e-01],
        [ 3.3108e+00, -4.0385e-01],
        [ 4.0314e+00, -1.0534e+00],
        [ 1.3800e+00, -5.8088e-01],
        [ 4.5294e+00, -7.3603e-01],
        [ 1.6385e-01, -4.4486e-01],
        [ 2.7958e+00, -6.8028e-02],
        [ 2.9866e+00, -1.5906e+00],
        [ 4.3250e+00,  1.9174e-01],
        [ 2.4392e-01, -5.3338e-01],
        [ 1.4583e+00,  1.5405e-01],
        [ 2.4005e+00, -3.0276e+00],
        [ 1.2512e+00, -1.7534e+00],
        [ 2.1771e+00, -7.4014e-01],
        [ 1.3409e+00, -8.6556e-01],
        [ 1.9360e+00,  4.5482e-01],
        [ 2.8951e+00, -1.7568e+00],
        [ 2.7601e+00,  6.6906e-01],
        [ 3.2467e+00,  3.0874e-01],
        [ 2.0186e+00, -1.8200e+00],
        [ 3.2549e+00,  1.2921e+00],
        [ 1.1949e+00,  7.5689e-01],
        [ 3.0175e+00, -1.2808e+00],
        [ 1.8830e+00, -5.8291e-01],
        [ 4.3109e+00,  1.9025e+00],
        [ 2.0676e+00, -3.6236e-01],
        [ 3.1168e+00, -1.6357e+00],
        [ 2.4126e+00,  4.6843e-02],
        [ 2.1164e+00,  3.3750e-01],
        [ 3.3635e+00, -1.1217e+00],
        [ 4.3504e+00,  5.8908e-01],
        [ 1.3861e+00,  1.3800e-01],
        [ 2.2707e+00,  5.6894e-01],
        [ 3.5025e+00, -3.7722e-01],
        [ 3.3911e+00,  1.2212e+00],
        [ 2.4421e+00, -8.3540e-01],
        [ 4.3475e+00, -1.0266e+00],
        [ 2.7242e+00, -8.6750e-01],
        [ 2.6827e+00,  5.0487e-01],
        [ 3.4966e+00, -9.7933e-01],
        [ 3.1738e+00, -5.2980e-01],
        [ 3.1731e+00, -1.0725e+00],
        [ 1.9618e+00,  5.5628e-01],
        [ 2.4399e+00, -2.3726e-01]]) torch.Size([312, 2])



Drawing 512 posterior samples:   0%|          | 0/512 [00:00&lt;?, ?it/s]


batch_size 16
weights tensor([[8.1593e-04, 1.0512e-03, 8.5689e-02, 8.5696e-02, 1.2302e-01, 1.4705e-01,
         1.4707e-01, 1.4707e-01, 2.1163e-01, 2.2965e-01, 2.3050e-01, 2.3055e-01,
         2.3111e-01, 2.3112e-01, 2.3147e-01, 2.3165e-01, 2.7941e-01, 2.7968e-01,
         2.7976e-01, 2.7976e-01, 4.9991e-01, 5.0009e-01, 6.4366e-01, 6.4366e-01,
         6.4366e-01, 6.5187e-01, 6.5395e-01, 9.5090e-01, 9.9995e-01, 9.9999e-01,
         9.9999e-01, 1.0000e+00],
        [4.1718e-04, 3.8413e-03, 3.8413e-03, 3.8418e-03, 2.0433e-02, 3.7250e-01,
         3.7250e-01, 3.7250e-01, 3.8290e-01, 3.8348e-01, 3.8383e-01, 4.0635e-01,
         4.0635e-01, 4.0635e-01, 4.1645e-01, 4.9673e-01, 4.9689e-01, 4.9730e-01,
         4.9730e-01, 4.9731e-01, 8.0501e-01, 8.0534e-01, 8.0534e-01, 8.1814e-01,
         8.2504e-01, 8.2518e-01, 8.4641e-01, 8.5256e-01, 8.8789e-01, 8.8814e-01,
         9.9265e-01, 1.0000e+00],
        [4.7591e-03, 4.7593e-03, 7.8859e-03, 2.1814e-02, 2.2332e-02, 4.7094e-02,
         5.4670e-02, 2.0013e-01, 2.0013e-01, 2.0013e-01, 2.8241e-01, 3.6080e-01,
         5.6699e-01, 5.6743e-01, 5.6765e-01, 5.6872e-01, 6.7286e-01, 6.7293e-01,
         6.7449e-01, 6.7449e-01, 6.7458e-01, 6.7458e-01, 7.1303e-01, 7.1326e-01,
         7.1799e-01, 7.2272e-01, 7.2273e-01, 7.2303e-01, 7.3078e-01, 7.3110e-01,
         7.3457e-01, 1.0000e+00],
        [1.0211e-05, 4.9363e-04, 4.8813e-02, 4.9466e-02, 8.8238e-02, 8.8246e-02,
         8.8289e-02, 9.1148e-02, 9.1149e-02, 9.1161e-02, 9.1366e-02, 1.5871e-01,
         7.9373e-01, 7.9422e-01, 7.9778e-01, 8.0717e-01, 8.0717e-01, 8.2142e-01,
         8.2147e-01, 8.2147e-01, 8.2148e-01, 8.2149e-01, 8.2150e-01, 8.2283e-01,
         8.2307e-01, 8.9861e-01, 9.8483e-01, 9.9271e-01, 9.9271e-01, 9.9311e-01,
         1.0000e+00, 1.0000e+00],
        [3.9965e-03, 4.1940e-03, 4.1940e-03, 2.3957e-02, 9.6023e-02, 9.6033e-02,
         1.1017e-01, 1.1017e-01, 1.1148e-01, 1.1148e-01, 1.1964e-01, 1.1964e-01,
         1.3281e-01, 1.3281e-01, 1.3310e-01, 3.3698e-01, 3.3708e-01, 3.3708e-01,
         3.3750e-01, 5.7621e-01, 5.7630e-01, 5.7996e-01, 5.8005e-01, 5.9884e-01,
         6.0100e-01, 6.0100e-01, 7.9541e-01, 7.9541e-01, 9.8564e-01, 9.8752e-01,
         9.9799e-01, 1.0000e+00],
        [2.3669e-01, 2.7951e-01, 3.3153e-01, 3.3212e-01, 3.5797e-01, 3.5849e-01,
         3.5850e-01, 4.2687e-01, 4.2720e-01, 5.4782e-01, 5.4782e-01, 5.5888e-01,
         5.5889e-01, 5.7365e-01, 5.8065e-01, 5.8081e-01, 6.8634e-01, 6.8634e-01,
         6.8647e-01, 6.8730e-01, 6.8731e-01, 7.3431e-01, 7.4327e-01, 7.7185e-01,
         8.8045e-01, 8.8348e-01, 8.8468e-01, 8.8469e-01, 8.8510e-01, 9.1985e-01,
         9.7219e-01, 1.0000e+00],
        [9.8879e-08, 4.4151e-03, 1.0149e-02, 1.0609e-02, 1.4244e-01, 1.4255e-01,
         1.4299e-01, 3.9106e-01, 4.0020e-01, 4.4709e-01, 4.9264e-01, 4.9401e-01,
         4.9480e-01, 4.9480e-01, 5.0188e-01, 5.0188e-01, 5.4702e-01, 5.4702e-01,
         5.8991e-01, 5.8991e-01, 8.8818e-01, 8.8819e-01, 8.9644e-01, 9.1021e-01,
         9.1477e-01, 9.1477e-01, 9.1641e-01, 9.1721e-01, 9.1736e-01, 9.2303e-01,
         1.0000e+00, 1.0000e+00],
        [4.3773e-06, 1.0665e-04, 1.0957e-04, 4.4341e-02, 4.4343e-02, 4.4346e-02,
         5.3596e-02, 5.3597e-02, 7.1110e-02, 7.1393e-02, 7.1511e-02, 1.0530e-01,
         1.1129e-01, 1.1142e-01, 1.5739e-01, 1.5742e-01, 1.5919e-01, 4.9656e-01,
         4.9656e-01, 5.0749e-01, 5.0758e-01, 5.0760e-01, 5.1548e-01, 5.1953e-01,
         5.2947e-01, 8.3456e-01, 8.4866e-01, 8.4866e-01, 8.4887e-01, 9.9619e-01,
         9.9995e-01, 1.0000e+00],
        [2.6152e-04, 2.6161e-04, 2.9293e-04, 3.1188e-04, 4.4316e-02, 4.4331e-02,
         4.4331e-02, 1.3094e-01, 1.5450e-01, 1.8813e-01, 1.9995e-01, 2.0397e-01,
         2.0712e-01, 2.7111e-01, 2.7112e-01, 3.1899e-01, 3.1899e-01, 5.5622e-01,
         7.3306e-01, 7.3508e-01, 7.6858e-01, 7.6858e-01, 9.0500e-01, 9.0500e-01,
         9.0501e-01, 9.0509e-01, 9.0511e-01, 9.6894e-01, 9.9292e-01, 9.9543e-01,
         9.9547e-01, 1.0000e+00],
        [1.1028e-01, 1.2440e-01, 1.2769e-01, 1.3043e-01, 5.5492e-01, 5.5493e-01,
         5.5501e-01, 5.5502e-01, 5.5588e-01, 6.3590e-01, 6.4036e-01, 6.4181e-01,
         6.4181e-01, 6.6782e-01, 6.8371e-01, 6.9509e-01, 7.0305e-01, 7.0770e-01,
         7.5587e-01, 7.6236e-01, 7.7006e-01, 7.7010e-01, 7.7013e-01, 9.7006e-01,
         9.9619e-01, 9.9621e-01, 9.9626e-01, 9.9626e-01, 9.9931e-01, 9.9978e-01,
         1.0000e+00, 1.0000e+00],
        [2.4095e-05, 2.4103e-05, 2.4496e-05, 2.7235e-01, 2.7259e-01, 2.7360e-01,
         2.7364e-01, 2.8041e-01, 2.8041e-01, 2.9622e-01, 3.4743e-01, 3.5580e-01,
         3.5862e-01, 4.4911e-01, 4.4911e-01, 4.4912e-01, 8.0514e-01, 8.1364e-01,
         8.2935e-01, 8.2936e-01, 8.4256e-01, 8.4490e-01, 8.4526e-01, 8.5067e-01,
         8.5083e-01, 8.5135e-01, 9.1890e-01, 9.1890e-01, 9.1890e-01, 9.1894e-01,
         9.1994e-01, 1.0000e+00],
        [4.0196e-10, 1.4963e-04, 9.7903e-02, 1.6644e-01, 1.6644e-01, 1.6913e-01,
         3.1075e-01, 3.4377e-01, 3.4378e-01, 3.4378e-01, 3.5580e-01, 3.5599e-01,
         3.5804e-01, 3.6616e-01, 3.6630e-01, 4.5079e-01, 4.5081e-01, 6.0488e-01,
         6.6700e-01, 6.6795e-01, 6.7111e-01, 6.7120e-01, 6.7978e-01, 6.7978e-01,
         7.5660e-01, 8.0333e-01, 8.0333e-01, 8.0333e-01, 8.2043e-01, 9.9823e-01,
         9.9825e-01, 1.0000e+00],
        [1.3210e-08, 3.6135e-07, 1.4009e-03, 1.4719e-03, 2.0179e-01, 3.5828e-01,
         3.7389e-01, 3.7546e-01, 3.7675e-01, 3.9316e-01, 5.5827e-01, 5.8126e-01,
         5.8128e-01, 5.8128e-01, 5.8315e-01, 5.8914e-01, 5.9698e-01, 7.3467e-01,
         7.3599e-01, 7.4093e-01, 7.5730e-01, 7.5745e-01, 7.8266e-01, 9.9701e-01,
         9.9701e-01, 9.9878e-01, 9.9878e-01, 9.9892e-01, 9.9898e-01, 9.9916e-01,
         9.9917e-01, 1.0000e+00],
        [3.1885e-02, 3.2166e-02, 3.2333e-02, 3.2333e-02, 3.3780e-02, 3.7313e-02,
         3.7317e-02, 3.7771e-02, 4.5534e-01, 4.6860e-01, 4.6860e-01, 4.6878e-01,
         4.6891e-01, 4.6894e-01, 4.7511e-01, 4.7513e-01, 4.7513e-01, 8.1233e-01,
         8.2838e-01, 8.8444e-01, 9.5531e-01, 9.5631e-01, 9.5632e-01, 9.6106e-01,
         9.6701e-01, 9.7317e-01, 9.7317e-01, 9.7622e-01, 9.7625e-01, 9.7626e-01,
         9.7628e-01, 1.0000e+00],
        [1.4748e-02, 1.6440e-02, 3.1843e-02, 3.1843e-02, 3.1847e-02, 3.1877e-02,
         3.4775e-02, 3.4797e-02, 3.6236e-02, 3.9044e-01, 3.9044e-01, 4.1089e-01,
         4.1258e-01, 4.4425e-01, 4.4425e-01, 4.4431e-01, 4.4626e-01, 4.4626e-01,
         6.9312e-01, 6.9315e-01, 6.9338e-01, 7.4038e-01, 7.4060e-01, 9.5267e-01,
         9.5547e-01, 9.5926e-01, 9.6786e-01, 9.7806e-01, 9.9948e-01, 9.9948e-01,
         9.9951e-01, 1.0000e+00],
        [4.8540e-02, 5.1860e-02, 3.9096e-01, 3.9096e-01, 3.9096e-01, 3.9337e-01,
         3.9412e-01, 3.9459e-01, 4.0521e-01, 4.0525e-01, 4.0561e-01, 4.1855e-01,
         4.1897e-01, 4.2104e-01, 4.2130e-01, 4.2155e-01, 4.2368e-01, 4.2389e-01,
         8.5300e-01, 8.5303e-01, 8.5304e-01, 8.6363e-01, 8.6665e-01, 8.7962e-01,
         8.7962e-01, 8.7962e-01, 8.7965e-01, 8.7965e-01, 8.8267e-01, 9.9738e-01,
         9.9738e-01, 1.0000e+00]]) torch.Size([16, 32])
uniform_decision tensor([[0.8520],
        [0.0456],
        [0.1339],
        [0.1599],
        [0.2245],
        [0.7124],
        [0.1367],
        [0.9855],
        [0.2702],
        [0.4623],
        [0.5226],
        [0.6647],
        [0.8427],
        [0.9547],
        [0.7779],
        [0.8923]]) torch.Size([16, 1])
mask tensor([[False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False,  True, False, False,
         False, False],
        [False, False, False, False, False,  True, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False,  True, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False,  True, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False,  True, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False,  True, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False,  True, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False,  True, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False,  True, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False,  True, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
          True, False, False, False, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False,  True, False, False, False, False, False, False,
         False, False],
        [False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False, False,
         False, False, False, False, False, False, False, False, False,  True,
         False, False]]) torch.Size([16, 32])
thetas tensor([[-0.2931,  0.5207],
        [-0.7866,  0.3730],
        [ 4.9572,  0.1860],
        ...,
        [ 1.4958, -0.0133],
        [-3.2456,  0.5106],
        [ 0.0861,  0.9045]]) torch.Size([512, 2])
samples tensor([[ 2.7641, -1.0670],
        [ 2.3962, -0.1905],
        [ 1.3104, -0.4666],
        [ 1.7428, -2.6051],
        [ 2.5024, -0.6990],
        [ 4.1916,  1.6638],
        [ 2.0104,  0.0144],
        [ 2.1081,  0.2179],
        [ 2.0445,  0.4226],
        [ 1.5249, -1.4755],
        [ 2.3338, -1.5420],
        [ 2.2381,  0.6313],
        [ 3.3044, -1.0268],
        [ 1.9700,  0.6789],
        [ 1.7458, -0.4808],
        [ 1.4958, -0.0133]]) torch.Size([16, 2])
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">theta_inferred_sir_2</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>torch.Size([10000, 2])
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">marginal_plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">theta_inferred_sir_2</span><span class="p">,</span> <span class="n">theta_inferred_sir_32</span><span class="p">,</span> <span class="n">gt_samples</span><span class="p">],</span>
    <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span>
    <span class="n">diag</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>  <span class="c1"># smooth histogram</span>
<span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;NPE&quot;</span><span class="p">,</span> <span class="s2">&quot;NPE-IS&quot;</span><span class="p">,</span> <span class="s2">&quot;Groud Truth&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">[</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>&lt;matplotlib.legend.Legend at 0x2abeadba0&gt;
</code></pre></div>

<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_20_1.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">marginal_plot</span><span class="p">(</span>
    <span class="p">[</span><span class="n">gt_samples</span><span class="p">,</span> <span class="n">theta_inferred</span><span class="p">],</span>
    <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
    <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="n">w</span><span class="p">],</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span>
    <span class="n">diag</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>  <span class="c1"># smooth histogram</span>
<span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;NPE&quot;</span><span class="p">,</span> <span class="s2">&quot;Corrected&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">[</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>&lt;matplotlib.legend.Legend at 0x2bbd8efb0&gt;
</code></pre></div>

<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_21_1.png" /></p>
<div class="highlight"><pre><span></span><code>    <span class="n">corrected_posterior</span> <span class="o">=</span> <span class="n">ImportanceSamplingPosterior</span><span class="p">(</span>
        <span class="n">potential_fn</span><span class="o">=</span><span class="n">log_prob_fn</span><span class="p">,</span>
        <span class="n">proposal</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">observation</span><span class="p">),</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sir&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">corrected_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">),),</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="n">oversampling_factor</span><span class="p">)</span>
    <span class="n">corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corrected_samples</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

Cell In[90], line 6
      1 corrected_posterior = ImportanceSamplingPosterior(
      2     potential_fn=log_prob_fn,
      3     proposal=posterior.set_default_x(observation),
      4     method=&quot;sir&quot;,
      5 )
----&gt; 6 corrected_samples = corrected_posterior.sample((len(theta_inferred),), oversampling_factor=oversampling_factor)
      7 corrected_samples_for_all_observations.append(corrected_samples)


NameError: name &#39;oversampling_factor&#39; is not defined
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># gt samples</span>
<span class="n">gt_samples</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">)</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,))</span>
<span class="n">gt_samples</span> <span class="o">=</span> <span class="n">gt_samples</span><span class="p">[</span><span class="n">prior</span><span class="o">.</span><span class="n">support</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)][:</span><span class="nb">len</span><span class="p">(</span><span class="n">theta_inferred</span><span class="p">)]</span>

<span class="n">kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="k">for</span> <span class="n">idx_param</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">[:,</span> <span class="n">idx_param</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_23_0.png" /></p>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_23_1.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">50</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">inference</span> <span class="o">=</span> <span class="n">SNPE</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">append_simulations</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">build_posterior</span><span class="p">()</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">theta_gt</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,))</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">theta_gt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;observations.shape&quot;</span><span class="p">,</span> <span class="n">observations</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="n">oversampling_factor</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># higher will be slower but more accurate</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">non_corrected_samples_for_all_observations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">corrected_samples_for_all_observations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">true_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="n">observations</span><span class="p">:</span>
    <span class="n">non_corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,)))</span>
    <span class="n">corrected_posterior</span> <span class="o">=</span> <span class="n">ImportanceSamplingPosterior</span><span class="p">(</span>
        <span class="n">potential_fn</span><span class="o">=</span><span class="n">Potential</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_o</span><span class="o">=</span><span class="n">obs</span><span class="p">),</span>
        <span class="n">proposal</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sir&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">corrected_samples</span> <span class="o">=</span> <span class="n">corrected_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,),</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="n">oversampling_factor</span><span class="p">)</span>
    <span class="n">corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corrected_samples</span><span class="p">)</span>

    <span class="n">gt_samples</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,))</span>
    <span class="n">gt_samples</span> <span class="o">=</span> <span class="n">gt_samples</span><span class="p">[</span><span class="n">prior</span><span class="o">.</span><span class="n">support</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)][:</span><span class="n">n_samples</span><span class="p">]</span>
    <span class="n">true_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)</span>


<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">observations</span><span class="p">)):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">marginal_plot</span><span class="p">(</span>
        <span class="p">[</span><span class="n">non_corrected_samples_for_all_observations</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">corrected_samples_for_all_observations</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">true_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
        <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
        <span class="n">points</span><span class="o">=</span><span class="n">theta_gt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span>
        <span class="n">diag</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>  <span class="c1"># smooth histogram</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;NPE&quot;</span><span class="p">,</span> <span class="s2">&quot;Corrected&quot;</span><span class="p">,</span> <span class="s2">&quot;Ground truth&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">[</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</code></pre></div>
<p>_ = torch.manual_seed(3)
theta = prior.sample((50,))
x = sim.sample(theta)</p>
<p>_ = torch.manual_seed(4)
inference = SNPE(prior=prior)
_ = inference.append_simulations(theta, x).train()
posterior = inference.build_posterior()</p>
<p>_ = torch.manual_seed(2)
theta_gt = prior.sample((5,))
observations = sim.sample(theta_gt)
print(&ldquo;observations.shape&rdquo;, observations.shape)</p>
<p>oversampling_factor = 128  # higher will be slower but more accurate
n_samples = 5000</p>
<p>non_corrected_samples_for_all_observations = []
corrected_samples_for_all_observations = []
true_samples = []
for obs in observations:
    non_corrected_samples_for_all_observations.append(posterior.set_default_x(obs).sample((n_samples,)))
    corrected_posterior = ImportanceSamplingPosterior(
        potential_fn=Potential(prior=None, x_o=obs),
        proposal=posterior.set_default_x(obs),
        method=&rdquo;sir&rdquo;,
    )
    corrected_samples = corrected_posterior.sample((n_samples,), oversampling_factor=oversampling_factor)
    corrected_samples_for_all_observations.append(corrected_samples)</p>
<div class="codehilite"><pre><span></span><code>gt_samples = MultivariateNormal(obs, eye(2)).sample((n_samples * 5,))
gt_samples = gt_samples[prior.support.check(gt_samples)][:n_samples]
true_samples.append(gt_samples)
</code></pre></div>

<p>for i in range(len(observations)):
    fig, ax = marginal_plot(
        [non_corrected_samples_for_all_observations[i], corrected_samples_for_all_observations[i], true_samples[i]], 
        limits=[[-5, 5], [-5, 5]], 
        points=theta_gt[i], 
        figsize=(5, 1.5),
        diag=&rdquo;kde&rdquo;,  # smooth histogram
    )
    ax[0][1].legend([&ldquo;NPE&rdquo;, &ldquo;Corrected&rdquo;, &ldquo;Ground truth&rdquo;], loc=&rdquo;upper right&rdquo;, bbox_to_anchor=[1.8, 1.0, 0.0, 0.0])</p>
<div class="highlight"><pre><span></span><code><span class="n">log_prob</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">myprior</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">log_prob</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>tensor([ -7.0203,  -6.7757,  -8.7409, -11.0604,  -6.8828,  -6.8849,  -6.7167,
         -6.5307,  -7.6620,  -7.1050,  -6.9813,  -7.7949,  -6.4848,  -8.8385,
         -6.5047,  -7.5428,  -6.5311,  -7.8525,  -7.6094,  -6.8969,  -6.5591,
         -8.4800,  -9.2732,  -7.5526,  -6.8612,  -6.9509,  -6.6061,  -6.9288,
         -8.6525,  -6.8885,  -9.0233,  -6.6701,  -6.9285, -11.2049,  -6.5632,
         -6.6593,  -7.2530,  -7.5786, -11.1936,  -6.6386,  -6.6733,  -7.0817,
         -6.5013, -10.9662,  -6.8552,  -7.1537,  -7.4354,  -8.6405,  -7.6694,
         -6.6940])
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">ones</span><span class="p">,</span> <span class="n">eye</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">MultivariateNormal</span>

<span class="kn">from</span> <span class="nn">sbi.inference</span> <span class="kn">import</span> <span class="n">SNPE</span><span class="p">,</span> <span class="n">ImportanceSamplingPosterior</span>
<span class="kn">from</span> <span class="nn">sbi.utils</span> <span class="kn">import</span> <span class="n">BoxUniform</span>
<span class="kn">from</span> <span class="nn">sbi.inference.potentials.base_potential</span> <span class="kn">import</span> <span class="n">BasePotential</span>
<span class="kn">from</span> <span class="nn">sbi.analysis</span> <span class="kn">import</span> <span class="n">pairplot</span><span class="p">,</span> <span class="n">marginal_plot</span>


<span class="k">class</span> <span class="nc">Simulator</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">log_prob</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">prior</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">Potential</span><span class="p">(</span><span class="n">BasePotential</span><span class="p">):</span>
    <span class="n">allow_iid_x</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">prior</span><span class="p">,</span> <span class="n">x_o</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">sim</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x_o</span><span class="p">)</span>


<span class="n">prior</span> <span class="o">=</span> <span class="n">BoxUniform</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span> <span class="o">*</span> <span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,)),</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">ones</span><span class="p">((</span><span class="mi">2</span><span class="p">,)))</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">Simulator</span><span class="p">()</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">50</span><span class="p">,))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">inference</span> <span class="o">=</span> <span class="n">SNPE</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">append_simulations</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="n">posterior</span> <span class="o">=</span> <span class="n">inference</span><span class="o">.</span><span class="n">build_posterior</span><span class="p">()</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">theta_gt</span> <span class="o">=</span> <span class="n">prior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="mi">5</span><span class="p">,))</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">theta_gt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;observations.shape&quot;</span><span class="p">,</span> <span class="n">observations</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>


<span class="n">oversampling_factor</span> <span class="o">=</span> <span class="mi">128</span>  <span class="c1"># higher will be slower but more accurate</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">5000</span>

<span class="n">non_corrected_samples_for_all_observations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">corrected_samples_for_all_observations</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">true_samples</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">obs</span> <span class="ow">in</span> <span class="n">observations</span><span class="p">:</span>
    <span class="n">non_corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,)))</span>
    <span class="n">corrected_posterior</span> <span class="o">=</span> <span class="n">ImportanceSamplingPosterior</span><span class="p">(</span>
        <span class="n">potential_fn</span><span class="o">=</span><span class="n">Potential</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_o</span><span class="o">=</span><span class="n">obs</span><span class="p">),</span>
        <span class="n">proposal</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span>
        <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sir&quot;</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">corrected_samples</span> <span class="o">=</span> <span class="n">corrected_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,),</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="n">oversampling_factor</span><span class="p">)</span>
    <span class="n">corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corrected_samples</span><span class="p">)</span>

    <span class="n">gt_samples</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,))</span>
    <span class="n">gt_samples</span> <span class="o">=</span> <span class="n">gt_samples</span><span class="p">[</span><span class="n">prior</span><span class="o">.</span><span class="n">support</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)][:</span><span class="n">n_samples</span><span class="p">]</span>
    <span class="n">true_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)</span>


<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">observations</span><span class="p">)):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">marginal_plot</span><span class="p">(</span>
        <span class="p">[</span><span class="n">non_corrected_samples_for_all_observations</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">corrected_samples_for_all_observations</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">true_samples</span><span class="p">[</span><span class="n">i</span><span class="p">]],</span>
        <span class="n">limits</span><span class="o">=</span><span class="p">[[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]],</span>
        <span class="n">points</span><span class="o">=</span><span class="n">theta_gt</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">),</span>
        <span class="n">diag</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span>  <span class="c1"># smooth histogram</span>
    <span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;NPE&quot;</span><span class="p">,</span> <span class="s2">&quot;Corrected&quot;</span><span class="p">,</span> <span class="s2">&quot;Ground truth&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;upper right&quot;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">[</span><span class="mf">1.8</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">])</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code> Neural network successfully converged after 93 epochs.observations.shape torch.Size([5, 2])



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 256 posterior samples:   0%|          | 0/256 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 256 posterior samples:   0%|          | 0/256 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 256 posterior samples:   0%|          | 0/256 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 256 posterior samples:   0%|          | 0/256 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 9984 posterior samples:   0%|          | 0/9984 [00:00&lt;?, ?it/s]



Drawing 256 posterior samples:   0%|          | 0/256 [00:00&lt;?, ?it/s]
</code></pre></div>

<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_28_96.png" /></p>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_28_97.png" /></p>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_28_98.png" /></p>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_28_99.png" /></p>
<p><img alt="png" src="../17_importance_sampled_posteriors_files/17_importance_sampled_posteriors_28_100.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">potential_logprobs</span> <span class="o">=</span> <span class="n">potential_fn</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">proposal_logprobs</span> <span class="o">=</span> <span class="n">proposal</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">log_importance_weights</span> <span class="o">=</span> <span class="n">potential_logprobs</span> <span class="o">-</span> <span class="n">proposal_logprobs</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">corrected_posterior</span><span class="o">.</span><span class="n">method</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>&#39;sir&#39;
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">observations</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>tensor([[ 0.6470, -1.2714],
        [ 1.2079,  1.2723],
        [ 1.7336,  1.2876],
        [-1.1429, -5.3115],
        [ 1.7205, -5.9448]])
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,))</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]





tensor([[ 0.5436, -4.4635],
        [ 0.9399, -4.8755],
        [ 0.7478, -3.8601],
        ...,
        [ 3.1949, -3.7732],
        [ 2.4367, -3.1603],
        [ 0.2160, -4.4788]])
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">corrected_posterior</span> <span class="o">=</span> <span class="n">ImportanceSamplingPosterior</span><span class="p">(</span>
    <span class="n">potential_fn</span><span class="o">=</span><span class="n">Potential</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_o</span><span class="o">=</span><span class="n">obs</span><span class="p">),</span>
    <span class="n">proposal</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span>
    <span class="c1"># method=&quot;sir&quot;,</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;importance&quot;</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">oversampling_factor</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>128
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">corrected_samples</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">corrected_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,),</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="n">oversampling_factor</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>Drawing 5000 posterior samples:   0%|          | 0/5000 [00:00&lt;?, ?it/s]
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>tensor(2356.5281)
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>tensor(0.0033)
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">corrected_samples</span>
</code></pre></div>
<div class="codehilite"><pre><span></span><code>(tensor([[ 0.7254, -4.4200],
         [ 0.0597, -4.9532],
         [ 1.5032, -4.4630],
         ...,
         [ 0.2389, -4.5077],
         [ 0.1377, -4.4233],
         [ 1.6937, -4.9443]]),
 tensor([-5.6697, -5.8994, -5.0362,  ..., -6.1128, -6.3228, -4.3970]))
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">non_corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,)))</span>
<span class="n">corrected_posterior</span> <span class="o">=</span> <span class="n">ImportanceSamplingPosterior</span><span class="p">(</span>
    <span class="n">potential_fn</span><span class="o">=</span><span class="n">Potential</span><span class="p">(</span><span class="n">prior</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">x_o</span><span class="o">=</span><span class="n">obs</span><span class="p">),</span>
    <span class="n">proposal</span><span class="o">=</span><span class="n">posterior</span><span class="o">.</span><span class="n">set_default_x</span><span class="p">(</span><span class="n">obs</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;sir&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">corrected_samples</span> <span class="o">=</span> <span class="n">corrected_posterior</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,),</span> <span class="n">oversampling_factor</span><span class="o">=</span><span class="n">oversampling_factor</span><span class="p">)</span>
<span class="n">corrected_samples_for_all_observations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corrected_samples</span><span class="p">)</span>

<span class="n">gt_samples</span> <span class="o">=</span> <span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sample</span><span class="p">((</span><span class="n">n_samples</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,))</span>
<span class="n">gt_samples</span> <span class="o">=</span> <span class="n">gt_samples</span><span class="p">[</span><span class="n">prior</span><span class="o">.</span><span class="n">support</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)][:</span><span class="n">n_samples</span><span class="p">]</span>
<span class="n">true_samples</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gt_samples</span><span class="p">)</span>
</code></pre></div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/sbi-dev/sbi" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["content.code.copy"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.fe8b6f2b.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>